[
  {
    "question": "Create a GitHub Actions workflow that replicates the CI process of testing CloudFormation Guard rules and building a ruleset, as defined in the provided YAML.",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:57.650917Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch configurations trigger this GitHub Actions workflow?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:58.212878Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:58.635846Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `VERSION` environment variable used in the `buildRuleSet` job's Python script execution?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:59.079387Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or goal of this CI workflow?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:59.523621Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML's PR GPU tests, including concurrency, matrix strategy, and secrets.",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:00.262442Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"PR GPU tests\" workflow?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:00.703950Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:01.091911Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `MCLOUD_API_KEY` secret used within the `pytest-gpu` job?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:01.665699Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, which runs GPU-based pytest jobs on pull requests and pushes to main/release branches?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:02.253606Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the cabal CI build process defined in the provided YAML file.",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:14.635683Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on which branches trigger this GitHub Actions workflow?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:15.203021Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:15.707179Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached paths for cabal packages, store, and dist-newstyle differentiated for different GHC versions?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:16.206172Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this Cabal CI workflow?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:16.714720Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided YAML, including Go setup, Redis service, and tests.",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:17.347426Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:17.829708Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Run Tests' workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:18.272708Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize environment variables, secrets, caching, or artifacts to enhance its testing process?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:18.768610Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this \"Run Tests\" workflow?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:19.160046Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Flatpak CI workflow.",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:20.860858Z",
    "question_style": "style_1"
  },
  {
    "question": "What push or pull request events on the main or flatpak-1.x.x branches trigger this workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:21.546192Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and what dependencies exist between the jobs and their steps?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:22.268307Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the build and test processes in the workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:22.852477Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the \"Flatpak CI\" workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:23.463969Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided CodeQL workflow for code analysis.",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:24.177596Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedule configurations trigger this CodeQL workflow to run?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:24.838621Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the CodeQL workflow run in parallel, and which have dependencies on others?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:25.402337Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching or artifacts?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:25.796755Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CodeQL workflow?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:26.215093Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that duplicates the functionality of the provided YAML, assigning reviewers based on a configuration file.",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:07.200490Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request event triggers this workflow?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:07.654947Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or are contingent upon the completion of others?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:08.210769Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the `auto_assign.yml` configuration file contain any secrets or environment variables?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:08.811271Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding pull requests?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:09.188007Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Crowdin Action workflow.",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:09.946922Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch trigger this Crowdin synchronization workflow?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:10.489654Z",
    "question_style": "style_2"
  },
  {
    "question": "Does this workflow have any jobs or steps that execute in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:11.147387Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `CROWDIN_PROJECT_ID` and `CROWDIN_PERSONAL_TOKEN` secrets used within the Crowdin Action?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:11.601051Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Crowdin Action workflow?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:12.000806Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML, including triggers, jobs, and steps.",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:09.001404Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the repository trigger the Zephyr West Command Tests workflow?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:10.639143Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"West Command Tests\" workflow execute in parallel, and which have dependencies on others?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:12.890911Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the pip cache keys constructed and how do they differ across operating systems?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:13.422547Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of the \"Zephyr West Command Tests\" workflow?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:14.095184Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:14.898486Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Autograding Tests workflow?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:15.321558Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:15.761589Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to pass results between autograding steps?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:16.528527Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this autograding tests workflow?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:17.127774Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:43.700037Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch and pull requests targeting specific paths trigger this workflow?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:44.204297Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:44.830953Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the virtual environment cached and what key is used to invalidate it?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:45.385604Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:45.947137Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the given YAML, checking out code, linting the repository, and saving the repolinter report as an artifact.",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:46.965726Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Repolinter\" workflow to run?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:47.490513Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Repolinter\" workflow execute concurrently or sequentially, based on dependencies?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:48.126477Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables or secrets for authentication or configuration within the repolinter container?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:48.772199Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function of this GitHub Actions workflow?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:49.345357Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML, including the matrix strategy and steps.",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:07.744083Z",
    "question_style": "style_1"
  },
  {
    "question": "What events involving the `main` branch trigger this GitHub Actions workflow?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:08.157954Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow are executed concurrently or depend on the successful completion of other jobs or steps?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:08.905314Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Meson build?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:09.343040Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by running builds and tests on Windows using MSVC?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:09.896200Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML for Docker CI.",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:10.791414Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/path conditions trigger this GitHub Actions workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:11.308987Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:11.933524Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the Docker build cache layers being scoped and utilized in the workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:12.427823Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:12.920169Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:47.886680Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:48.405808Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'PR Reports' workflow run in parallel or have dependencies on each other?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:48.974546Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the downloaded artifacts named and used in the subsequent \"Publish Test Report\" step?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:49.537729Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the \"PR Reports\" workflow?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:50.042603Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the given YAML file.",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:50.750108Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the \"Refresh Citation Style Language Files\" workflow?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:51.293624Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:51.727033Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GH_TOKEN_UPDATE_GRADLE_WRAPPER` secret used for creating a pull request?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:52.295196Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow for Citation Style Language files?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:52.728036Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML workflow for building and releasing a Linux application.",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:23:58.757204Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger this GitHub Actions workflow?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:23:59.288759Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:00.068947Z",
    "question_style": "style_3"
  },
  {
    "question": "How are AWS credentials securely passed and used to upload build artifacts to S3 buckets?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:00.920743Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow, particularly the resulting artifact?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:01.410011Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow file.",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:02.000327Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:02.553000Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which have dependencies on others?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.137403Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Android build environment within the workflow?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.586826Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or outcome of this GitHub Actions workflow?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.930093Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:05.348385Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch or pull requests trigger this workflow?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:05.975770Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Main / Pull requests build\" workflow execute in parallel or sequentially based on dependencies?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:06.453365Z",
    "question_style": "style_3"
  },
  {
    "question": "How are Maven packages cached and restored based on the OS and pom.xml files?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:07.056527Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or goal of this pull request build workflow?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:07.615127Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:08.426622Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Evaluation\" workflow?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:08.880122Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within jobs run in parallel, and are there any inter-job dependencies defined in the workflow?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:09.464978Z",
    "question_style": "style_3"
  },
  {
    "question": "How are artifacts used to persist and access the load_balancer.txt file?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:10.005816Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or goal of this workflow file?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:10.572437Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including CI, releasing packages, building Docker images, and creating releases.",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:19.408130Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run, considering its configuration?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:20.178877Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:21.021421Z",
    "question_style": "style_3"
  },
  {
    "question": "How are secrets used to authenticate and authorize the publishing of packages to PyPI?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:21.654952Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding Langflow releases and Docker builds?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:22.245106Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality defined in the provided YAML file.",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:22.931027Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Chromatic workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:24.145355Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'chromatic' job can run in parallel, and which depend on the completion of others?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:24.703239Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `CHROMATIC_PROJECT_TOKEN` and `GITHUB_TOKEN` secrets used within the workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:25.275545Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the Chromatic workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:25.721204Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML workflow, including build steps, dependency installations, ccache usage, and unit testing.",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:35.868645Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch configurations trigger this GitHub Actions workflow?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:36.464809Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which ones depend on the completion of others?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:37.109653Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the ccache key generated, and what timestamp is included in it?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:37.740442Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this Linux Debug and Test workflow?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:38.384451Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that mirrors the functionality of the provided YAML, including draft release creation.",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:39.416065Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or events trigger the \"Draft release\" workflow?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:40.084185Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in the workflow execute concurrently or sequentially, based on dependencies?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:40.593643Z",
    "question_style": "style_3"
  },
  {
    "question": "Is any caching explicitly configured beyond the npm cache for node setup?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:41.116149Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, particularly regarding releases and changelogs?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:41.872902Z",
    "question_style": "style_5"
  },
  {
    "question": "Write a GitHub Actions workflow YAML file that replicates the functionality, including build matrix, CMake configuration, testing, artifact creation, and release/publish steps, as defined in the provided YAML file.",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:45.692383Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the CMake Build Matrix workflow?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:46.378879Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:47.190637Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to specify compiler paths within the CMake configuration?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:47.799320Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this CMake Build Matrix workflow?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:48.484151Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML, including manual triggering and job dependencies.",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:49.240251Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:49.928942Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:50.743527Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:51.436497Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Chaining Jobs\" workflow?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:51.945256Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:23.604546Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events to the main branch or release branches trigger this workflow?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:24.157497Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow have dependencies on others, or run in parallel?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:24.659384Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `PROJECT_ID`, `PR_CLUSTER`, and `ZONE` environment variables used for deployment in the workflow?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:25.165513Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CI workflow triggered on pushes to main or release branches?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:25.695384Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML.",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:26.333703Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:26.884146Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:27.493639Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `PRIVATE_KEY` secret used for deployment?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:27.983691Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow deploy, or what is its main effect when triggered?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:28.418899Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building and releasing an Android application.",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:12.200623Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger this Android 64-bit Release workflow?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:12.900370Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what dependencies exist between them?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:13.477554Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` secrets used for uploading builds to S3?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:14.064841Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this Android 64-bit Release workflow?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:14.683598Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the provided YAML, focusing on build inputs, Docker build with buildx and bake, and testing.",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:15.821641Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or trigger initiates this workflow?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:16.307348Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or depend on the completion of others?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:16.895115Z",
    "question_style": "style_3"
  },
  {
    "question": "How are DOCKERHUB_USERNAME and DOCKERHUB_TOKEN secrets used for Docker login and pushing images?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:17.482458Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Build\" workflow?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:18.052124Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file for building and releasing a Windows installer.",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:06.895119Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger the Windows Release workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:07.401446Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what are the dependencies between them?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.018699Z",
    "question_style": "style_3"
  },
  {
    "question": "How are AWS access key ID and secret access key secrets used to configure AWS CLI for S3 uploads?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.557027Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or outcome of this Windows Release workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.937286Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:09.709914Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Deploy PROD EMBED\" workflow?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:10.316188Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and what dependencies exist between the defined jobs?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:10.893132Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `NETLIFY_AUTH_TOKEN` and `GH_PACKAGES` secrets used within the deployment and image building steps, respectively?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:11.485790Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this GitHub Actions workflow?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:12.023621Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:35.303967Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions initiate the \"Lint Python\" workflow?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:35.754971Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Lint Python' workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:36.328623Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used within the Mypy execution step?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:36.854320Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this Python linting workflow?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:37.245982Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file, including triggering, environment variables, jobs, and steps.",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:38.456284Z",
    "question_style": "style_1"
  },
  {
    "question": "What events—workflow completion, pushes to `ci_*` branches with specific path changes, or repository dispatches—trigger this workflow?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:39.637544Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow run in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:40.568281Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `CI_SLACK_BOT_TOKEN`, `CI_SLACK_CHANNEL_ID`, `CI_SLACK_CHANNEL_ID_DAILY`, `CI_SLACK_CHANNEL_DUMMY_TESTS`, `CI_SLACK_REPORT_CHANNEL_ID`, and `ACCESS_REPO_INFO_TOKEN` used?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:41.759143Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow in the `transformers` repository's CI process?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:42.686480Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:43.532464Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the HalKit - Deploy workflow?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:43.993423Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'deploy' job execute concurrently, and are there any dependencies between them?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:44.560229Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `NUGET_API_KEY` secret used to authenticate with the NuGet repository during package publishing?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:45.072353Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the HalKit - Deploy workflow?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:45.645652Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:46.447661Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:46.827407Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:47.325178Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the workflow utilize any secrets for installation, building, or testing?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:47.829174Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or goal of this CI workflow?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:48.325879Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that performs code linting using npm, similar to the provided workflow.",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:11.875366Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this code linting workflow?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:12.418227Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Code Linting\" workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:13.061312Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:13.587829Z",
    "question_style": "style_4"
  },
  {
    "question": "What's the primary function of this code linting workflow?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:14.201472Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file equivalent to the provided example, ensuring identical triggers, jobs, and steps.",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:15.098500Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of the \"unitTest\" workflow?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:15.894821Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"unitTest\" workflow run concurrently or have dependencies on each other?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:16.569190Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching of dependencies or artifacts?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:17.341224Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this unit testing workflow?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:17.853593Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided RSpec workflow.",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:27.278692Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the RSpec workflow in this YAML file?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:30.849680Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently, and which depend on the completion of others?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:32.627790Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `CC_TEST_REPORTER_ID` secret used by the `paambaati/codeclimate-action` action?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:38.604183Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this RSpec workflow?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:39.170898Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including jobs, steps, and configurations.",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:40.637710Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and/or push events trigger this workflow?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:42.155194Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs in this workflow run in parallel, and which have dependencies or a specific execution order?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:43.351300Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any secrets used within this workflow, and if so, where are they utilized?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:44.559832Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow file?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:45.786915Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the provided Java CI workflow's functionality, including matrix testing across different JDKs.",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:47.879074Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Java CI\" workflow?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:48.449883Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Java CI\" workflow execute in parallel, and which ones have dependencies?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:49.049110Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching or artifacts to optimize build times or share data between jobs?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:49.601829Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Java CI workflow?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:50.022553Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML, building an Emscripten project with CMake and running tests.",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:50.786635Z",
    "question_style": "style_1"
  },
  {
    "question": "What events (or actions) trigger this GitHub Actions workflow?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:51.453911Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the emscripten job execute concurrently, and what are any dependency relationships between them?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:51.944303Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching mechanisms or artifact uploads/downloads to optimize performance or share build outputs?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:52.610004Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this Emscripten build workflow?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:53.127114Z",
    "question_style": "style_5"
  }
]