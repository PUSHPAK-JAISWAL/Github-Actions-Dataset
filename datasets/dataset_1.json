[
  {
    "question": "Create a GitHub Actions workflow that replicates the CI process of testing CloudFormation Guard rules and building a ruleset, as defined in the provided YAML.",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:57.650917Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch configurations trigger this GitHub Actions workflow?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:58.212878Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:58.635846Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `VERSION` environment variable used in the `buildRuleSet` job's Python script execution?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:59.079387Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or goal of this CI workflow?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:59.523621Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML's PR GPU tests, including concurrency, matrix strategy, and secrets.",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:00.262442Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"PR GPU tests\" workflow?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:00.703950Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:01.091911Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `MCLOUD_API_KEY` secret used within the `pytest-gpu` job?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:01.665699Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, which runs GPU-based pytest jobs on pull requests and pushes to main/release branches?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:02.253606Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the cabal CI build process defined in the provided YAML file.",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:14.635683Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on which branches trigger this GitHub Actions workflow?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:15.203021Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:15.707179Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached paths for cabal packages, store, and dist-newstyle differentiated for different GHC versions?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:16.206172Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this Cabal CI workflow?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:16.714720Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided YAML, including Go setup, Redis service, and tests.",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:17.347426Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:17.829708Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Run Tests' workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:18.272708Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize environment variables, secrets, caching, or artifacts to enhance its testing process?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:18.768610Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this \"Run Tests\" workflow?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:19.160046Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Flatpak CI workflow.",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:20.860858Z",
    "question_style": "style_1"
  },
  {
    "question": "What push or pull request events on the main or flatpak-1.x.x branches trigger this workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:21.546192Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and what dependencies exist between the jobs and their steps?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:22.268307Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the build and test processes in the workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:22.852477Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the \"Flatpak CI\" workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:23.463969Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided CodeQL workflow for code analysis.",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:24.177596Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedule configurations trigger this CodeQL workflow to run?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:24.838621Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the CodeQL workflow run in parallel, and which have dependencies on others?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:25.402337Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching or artifacts?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:25.796755Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CodeQL workflow?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:26.215093Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that duplicates the functionality of the provided YAML, assigning reviewers based on a configuration file.",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:07.200490Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request event triggers this workflow?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:07.654947Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or are contingent upon the completion of others?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:08.210769Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the `auto_assign.yml` configuration file contain any secrets or environment variables?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:08.811271Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding pull requests?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:09.188007Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Crowdin Action workflow.",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:09.946922Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch trigger this Crowdin synchronization workflow?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:10.489654Z",
    "question_style": "style_2"
  },
  {
    "question": "Does this workflow have any jobs or steps that execute in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:11.147387Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `CROWDIN_PROJECT_ID` and `CROWDIN_PERSONAL_TOKEN` secrets used within the Crowdin Action?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:11.601051Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Crowdin Action workflow?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:12.000806Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML, including triggers, jobs, and steps.",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:09.001404Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the repository trigger the Zephyr West Command Tests workflow?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:10.639143Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"West Command Tests\" workflow execute in parallel, and which have dependencies on others?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:12.890911Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the pip cache keys constructed and how do they differ across operating systems?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:13.422547Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of the \"Zephyr West Command Tests\" workflow?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:14.095184Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:14.898486Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Autograding Tests workflow?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:15.321558Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:15.761589Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to pass results between autograding steps?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:16.528527Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this autograding tests workflow?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:17.127774Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:43.700037Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch and pull requests targeting specific paths trigger this workflow?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:44.204297Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:44.830953Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the virtual environment cached and what key is used to invalidate it?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:45.385604Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:45.947137Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the given YAML, checking out code, linting the repository, and saving the repolinter report as an artifact.",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:46.965726Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Repolinter\" workflow to run?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:47.490513Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Repolinter\" workflow execute concurrently or sequentially, based on dependencies?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:48.126477Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables or secrets for authentication or configuration within the repolinter container?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:48.772199Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function of this GitHub Actions workflow?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:49.345357Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML, including the matrix strategy and steps.",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:07.744083Z",
    "question_style": "style_1"
  },
  {
    "question": "What events involving the `main` branch trigger this GitHub Actions workflow?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:08.157954Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow are executed concurrently or depend on the successful completion of other jobs or steps?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:08.905314Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Meson build?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:09.343040Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by running builds and tests on Windows using MSVC?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:09.896200Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML for Docker CI.",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && ' forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '' || echo '')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:10.791414Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/path conditions trigger this GitHub Actions workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && ' forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '' || echo '')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:11.308987Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && ' forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '' || echo '')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:11.933524Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the Docker build cache layers being scoped and utilized in the workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && ' forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '' || echo '')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:12.427823Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && ' forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '' || echo '')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:12.920169Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:47.886680Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:48.405808Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'PR Reports' workflow run in parallel or have dependencies on each other?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:48.974546Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the downloaded artifacts named and used in the subsequent \"Publish Test Report\" step?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:49.537729Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the \"PR Reports\" workflow?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:50.042603Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the given YAML file.",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:50.750108Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the \"Refresh Citation Style Language Files\" workflow?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:51.293624Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:51.727033Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GH_TOKEN_UPDATE_GRADLE_WRAPPER` secret used for creating a pull request?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:52.295196Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow for Citation Style Language files?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:52.728036Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML workflow for building and releasing a Linux application.",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:23:58.757204Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger this GitHub Actions workflow?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:23:59.288759Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:00.068947Z",
    "question_style": "style_3"
  },
  {
    "question": "How are AWS credentials securely passed and used to upload build artifacts to S3 buckets?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:00.920743Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow, particularly the resulting artifact?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:01.410011Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow file.",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:02.000327Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:02.553000Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which have dependencies on others?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.137403Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Android build environment within the workflow?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.586826Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or outcome of this GitHub Actions workflow?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.930093Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:05.348385Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch or pull requests trigger this workflow?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:05.975770Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Main / Pull requests build\" workflow execute in parallel or sequentially based on dependencies?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:06.453365Z",
    "question_style": "style_3"
  },
  {
    "question": "How are Maven packages cached and restored based on the OS and pom.xml files?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:07.056527Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or goal of this pull request build workflow?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:07.615127Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:08.426622Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Evaluation\" workflow?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:08.880122Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within jobs run in parallel, and are there any inter-job dependencies defined in the workflow?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:09.464978Z",
    "question_style": "style_3"
  },
  {
    "question": "How are artifacts used to persist and access the load_balancer.txt file?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:10.005816Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or goal of this workflow file?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:10.572437Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including CI, releasing packages, building Docker images, and creating releases.",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:19.408130Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run, considering its configuration?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:20.178877Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:21.021421Z",
    "question_style": "style_3"
  },
  {
    "question": "How are secrets used to authenticate and authorize the publishing of packages to PyPI?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:21.654952Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding Langflow releases and Docker builds?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:22.245106Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality defined in the provided YAML file.",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:22.931027Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Chromatic workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:24.145355Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'chromatic' job can run in parallel, and which depend on the completion of others?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:24.703239Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `CHROMATIC_PROJECT_TOKEN` and `GITHUB_TOKEN` secrets used within the workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:25.275545Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the Chromatic workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:25.721204Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML workflow, including build steps, dependency installations, ccache usage, and unit testing.",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:35.868645Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch configurations trigger this GitHub Actions workflow?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:36.464809Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which ones depend on the completion of others?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:37.109653Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the ccache key generated, and what timestamp is included in it?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:37.740442Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this Linux Debug and Test workflow?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:38.384451Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that mirrors the functionality of the provided YAML, including draft release creation.",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:39.416065Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or events trigger the \"Draft release\" workflow?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:40.084185Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in the workflow execute concurrently or sequentially, based on dependencies?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:40.593643Z",
    "question_style": "style_3"
  },
  {
    "question": "Is any caching explicitly configured beyond the npm cache for node setup?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:41.116149Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, particularly regarding releases and changelogs?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:41.872902Z",
    "question_style": "style_5"
  },
  {
    "question": "Write a GitHub Actions workflow YAML file that replicates the functionality, including build matrix, CMake configuration, testing, artifact creation, and release/publish steps, as defined in the provided YAML file.",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:45.692383Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the CMake Build Matrix workflow?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:46.378879Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:47.190637Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to specify compiler paths within the CMake configuration?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:47.799320Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this CMake Build Matrix workflow?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:48.484151Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML, including manual triggering and job dependencies.",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:49.240251Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:49.928942Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:50.743527Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:51.436497Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Chaining Jobs\" workflow?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:51.945256Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:23.604546Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events to the main branch or release branches trigger this workflow?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:24.157497Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow have dependencies on others, or run in parallel?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:24.659384Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `PROJECT_ID`, `PR_CLUSTER`, and `ZONE` environment variables used for deployment in the workflow?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:25.165513Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CI workflow triggered on pushes to main or release branches?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:25.695384Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML.",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:26.333703Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:26.884146Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:27.493639Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `PRIVATE_KEY` secret used for deployment?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:27.983691Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow deploy, or what is its main effect when triggered?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:28.418899Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building and releasing an Android application.",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:12.200623Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger this Android 64-bit Release workflow?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:12.900370Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what dependencies exist between them?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:13.477554Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` secrets used for uploading builds to S3?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:14.064841Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this Android 64-bit Release workflow?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:14.683598Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the provided YAML, focusing on build inputs, Docker build with buildx and bake, and testing.",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:15.821641Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or trigger initiates this workflow?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:16.307348Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or depend on the completion of others?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:16.895115Z",
    "question_style": "style_3"
  },
  {
    "question": "How are DOCKERHUB_USERNAME and DOCKERHUB_TOKEN secrets used for Docker login and pushing images?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:17.482458Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Build\" workflow?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:18.052124Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file for building and releasing a Windows installer.",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:06.895119Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger the Windows Release workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:07.401446Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what are the dependencies between them?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.018699Z",
    "question_style": "style_3"
  },
  {
    "question": "How are AWS access key ID and secret access key secrets used to configure AWS CLI for S3 uploads?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.557027Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or outcome of this Windows Release workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.937286Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:09.709914Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Deploy PROD EMBED\" workflow?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:10.316188Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and what dependencies exist between the defined jobs?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:10.893132Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `NETLIFY_AUTH_TOKEN` and `GH_PACKAGES` secrets used within the deployment and image building steps, respectively?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:11.485790Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this GitHub Actions workflow?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:12.023621Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:35.303967Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions initiate the \"Lint Python\" workflow?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:35.754971Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Lint Python' workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:36.328623Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used within the Mypy execution step?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:36.854320Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this Python linting workflow?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:37.245982Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file, including triggering, environment variables, jobs, and steps.",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:38.456284Z",
    "question_style": "style_1"
  },
  {
    "question": "What eventsworkflow completion, pushes to `ci_*` branches with specific path changes, or repository dispatchestrigger this workflow?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:39.637544Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow run in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:40.568281Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `CI_SLACK_BOT_TOKEN`, `CI_SLACK_CHANNEL_ID`, `CI_SLACK_CHANNEL_ID_DAILY`, `CI_SLACK_CHANNEL_DUMMY_TESTS`, `CI_SLACK_REPORT_CHANNEL_ID`, and `ACCESS_REPO_INFO_TOKEN` used?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:41.759143Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow in the `transformers` repository's CI process?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:42.686480Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:43.532464Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the HalKit - Deploy workflow?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:43.993423Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'deploy' job execute concurrently, and are there any dependencies between them?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:44.560229Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `NUGET_API_KEY` secret used to authenticate with the NuGet repository during package publishing?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:45.072353Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the HalKit - Deploy workflow?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:45.645652Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:46.447661Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:46.827407Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:47.325178Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the workflow utilize any secrets for installation, building, or testing?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:47.829174Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or goal of this CI workflow?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:48.325879Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that performs code linting using npm, similar to the provided workflow.",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:11.875366Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this code linting workflow?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:12.418227Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Code Linting\" workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:13.061312Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:13.587829Z",
    "question_style": "style_4"
  },
  {
    "question": "What's the primary function of this code linting workflow?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:14.201472Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file equivalent to the provided example, ensuring identical triggers, jobs, and steps.",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:15.098500Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of the \"unitTest\" workflow?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:15.894821Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"unitTest\" workflow run concurrently or have dependencies on each other?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:16.569190Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching of dependencies or artifacts?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:17.341224Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this unit testing workflow?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:17.853593Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided RSpec workflow.",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:27.278692Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the RSpec workflow in this YAML file?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:30.849680Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently, and which depend on the completion of others?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:32.627790Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `CC_TEST_REPORTER_ID` secret used by the `paambaati/codeclimate-action` action?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:38.604183Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this RSpec workflow?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:39.170898Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including jobs, steps, and configurations.",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:40.637710Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and/or push events trigger this workflow?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:42.155194Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs in this workflow run in parallel, and which have dependencies or a specific execution order?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:43.351300Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any secrets used within this workflow, and if so, where are they utilized?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:44.559832Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow file?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:45.786915Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the provided Java CI workflow's functionality, including matrix testing across different JDKs.",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:47.879074Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Java CI\" workflow?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:48.449883Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Java CI\" workflow execute in parallel, and which ones have dependencies?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:49.049110Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching or artifacts to optimize build times or share data between jobs?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:49.601829Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Java CI workflow?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:50.022553Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML, building an Emscripten project with CMake and running tests.",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:50.786635Z",
    "question_style": "style_1"
  },
  {
    "question": "What events (or actions) trigger this GitHub Actions workflow?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:51.453911Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the emscripten job execute concurrently, and what are any dependency relationships between them?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:51.944303Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching mechanisms or artifact uploads/downloads to optimize performance or share build outputs?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:52.610004Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this Emscripten build workflow?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:53.127114Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the build process defined in the provided YAML.",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:24.778961Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events or pull requests targeting the main branch trigger this workflow?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:25.334395Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow execute concurrently or have dependencies on the completion of others?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:25.916409Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching or artifacts?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:26.522032Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by building and packaging the C++ project?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:27.194691Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:27.961120Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch conditions trigger this workflow to automatically minify CSS/JS files?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:28.601227Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'build' job execute in parallel, and are there any dependencies between them?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:29.201323Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching/artifacts for its execution?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:29.725202Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow file?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:30.274429Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building, publishing, and deploying to Google Kubernetes Engine.",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:14.024695Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this GitHub Actions workflow?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:15.152485Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow are configured to run in parallel or sequentially based on dependencies?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:16.006794Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GKE_PROJECT` secret used to define the `PROJECT_ID` environment variable?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:17.477718Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this GitHub Actions workflow?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:18.653146Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for lz4 CI.",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:19.828372Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the lz4 CI workflow?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:23.754631Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel, and which ones have dependencies that dictate their execution order?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:24.590543Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables like `FIXME__LZ4_CI_IGNORE`, `CC`, and `CXX` used to manage compiler options and control error handling?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:32.425251Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow for the lz4 project?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:33.558522Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML, triggered on merged pull requests to main, to verify and comment on labeling.",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} \\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:28.519746Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and branches trigger this workflow?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} \\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:29.077871Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} \\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:29.679901Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to authenticate and authorize actions within the workflow?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} \\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:30.361815Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow do when a pull request is merged into the main branch?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} \\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:30.947002Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the build, test, and badge generation steps defined in the provided YAML file.",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:31.763265Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events to the `main` branch, excluding the `badges` branch, trigger this workflow?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:32.341056Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"BuildAndTest\" workflow are executed in parallel, and what are their dependencies?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:32.973415Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to push badge commits to the `badges` branch?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:33.548272Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow related to code evaluation and reporting?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:34.209685Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that builds a mkdocs site with Python 3.11, installing dependencies from requirements.txt.",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:23.632802Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:23.989028Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow definition execute concurrently or in a specific sequential order?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:24.447137Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching/artifacts?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:24.913408Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this \"Build and Test\" workflow?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:25.465073Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file replicating the given workflow, including inputs, environment variables, and steps for releasing Axios.",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:26.286817Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions trigger the \"Release Axios\" workflow?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:26.790572Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel or have dependencies on other steps?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:27.337585Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `NPM_TOKEN` and `GITHUB_TOKEN` secrets used within the workflow?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:27.822014Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of the \"Release Axios\" workflow?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:28.382363Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file replicating the build process defined in the given workflow.",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:29.700610Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch trigger this GitHub Actions workflow?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:30.356903Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow's \"build\" job execute concurrently, and are there any dependencies between them?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:31.273104Z",
    "question_style": "style_3"
  },
  {
    "question": "How are node modules and Next.js build artifacts cached to optimize build times?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:32.290211Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this \"Build\" workflow?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:33.603829Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:35.689033Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:36.265951Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:39.063500Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the build and test processes for different platforms?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:41.805861Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this Android build workflow?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:43.000448Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:10.793612Z",
    "question_style": "style_1"
  },
  {
    "question": "What events (push, pull request, schedule) and file paths trigger this workflow?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:12.143708Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow run in parallel, and which ones have dependencies on others?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:12.904984Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the west modules cache?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:13.887850Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow, specifically what kind of application does it build and test?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:14.640269Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality defined in the provided YAML file.",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:15.270386Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch conditions trigger this GitHub Actions workflow?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:15.802393Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"build\" job run in parallel, and which have dependencies on others?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:16.392990Z",
    "question_style": "style_3"
  },
  {
    "question": "What checksum.txt file determines the Gradle cache key?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:16.981101Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this \"blueprints\" workflow?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:17.519988Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML that replicates the given workflow's deployment to GitHub Pages.",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:32.004998Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branches trigger this continuous deployment workflow?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:32.448246Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow execute in parallel or have interdependencies?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:33.021530Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used for deploying to GitHub Pages?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:33.585298Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when code is pushed to the develop branch?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:34.142596Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for deploying a Jekyll site to GitHub Pages.",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:35.631775Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Deploy Jekyll site to Pages\" GitHub Actions workflow?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:36.131956Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which ones depend on the completion of others?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:37.290464Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `JEKYLL_ENV` environment variable used to configure the Jekyll build process?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:38.656883Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose or main effect of this GitHub Actions workflow?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:40.403306Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Gofmt workflow.",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:08.595721Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of this Gofmt workflow?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:09.135691Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently, and what are their dependencies?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:09.516259Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching mechanisms?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:10.072851Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Gofmt workflow in this repository?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:10.648185Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:11.391950Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Stable build\" GitHub Actions workflow?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:11.971886Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:12.564558Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets DOCKERHUB_USERNAME and DOCKERHUB_TOKEN used in the docker-build-push workflow?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:13.384871Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or purpose of this \"Stable build\" workflow?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:13.904631Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow mirroring the provided YAML, including inputs, concurrency, jobs (build, jest, behat, complete), and steps within each job.",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:14.845857Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:15.512523Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within those jobs run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:16.234538Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached files (SSL certificates, node modules, etc.) used across different jobs?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:17.004727Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow for coverage?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:17.619198Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:18.338412Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this CI workflow?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:18.801847Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and which jobs depend on the completion of other jobs?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:19.303394Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching mechanisms for dependencies or build artifacts to optimize build times?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:19.895770Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this CI workflow for Flutter projects?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:20.454697Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that mirrors the functionality of the provided YAML file, including scheduled runs, manual triggering, building a Go-based CLI, and uploading an artifact.",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:45.214998Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of the \"AVS Rewards Claim\" workflow?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:45.686155Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow execute concurrently, and which have dependencies on others?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:46.177049Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `RPC_URL` secret used to authenticate the reward claim process?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:46.690464Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this AVS Rewards Claim workflow?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:47.100251Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file equivalent to the provided YAML configuration.",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:47.705378Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this workflow to deploy to Firebase Hosting?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:48.243771Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the build_and_deploy job execute in parallel or have dependencies on each other?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:48.788404Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP` and `GITHUB_TOKEN` secrets used for authentication and deployment?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:49.355531Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:49.840303Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:31.013603Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the Cypress Tests workflow?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:31.438046Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Cypress Tests' workflow run concurrently or have dependencies on one another?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:32.087772Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the Cypress run step utilize any environment variables or secrets for configuration?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:32.520191Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this Cypress Tests workflow?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:33.060286Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:33.668039Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow to run?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:34.096441Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or have dependencies on one another?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:34.616701Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the 'ruby/setup-ruby' action use caching, and if so, how is the cache configured?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:35.112248Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main goal or function of this pull request workflow?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:35.717347Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow mirroring the provided YAML, including triggering, OS matrix, environment variables, container, checkout, and build steps.",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:23.361933Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull requests or pushes to the master branch trigger this workflow?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:23.891225Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Cross CI workflow' run in parallel or sequentially based on dependencies?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:24.544833Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `ROS_DISTRO`, `AUTOWARE_CROSS_TARGET_PLATFORM`, `AUTOWARE_TARGET_ARCH`, `AUTOWARE_TOOLCHAIN_FILE_PATH`, and `AUTOWARE_SYSROOT` environment variables used within the build script?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:25.271922Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this cross-compilation CI workflow?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:25.780985Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided YAML file for labeling.",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:26.634985Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch(es) trigger the \"Labeler\" workflow?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:27.117208Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, or depend on the completion of other jobs or steps?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:27.688851Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching/artifacts for the labeler action?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:28.267303Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the \"Labeler\" workflow?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:28.778369Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality, inputs, environment variables, outputs, and steps outlined in the provided YAML file.",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:38.277809Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or action triggers the execution of this GitHub Actions workflow?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:38.967270Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which depend on the completion of others?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:39.819871Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables overridden and accessed at the workflow, job, and step levels?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:40.589609Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:41.175675Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that, on push to tags matching \"v*.*.*\", builds and pushes a Docker image to Docker Hub with multiple platforms.",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:42.220356Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` events, specifically related to tags, trigger this workflow?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:42.777243Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the Docker Hub push workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:43.457895Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the DOCKERHUB_TOKEN secret used to authenticate with Docker Hub?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:43.965765Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when a tagged commit is pushed?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:44.617461Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the build CI process defined in the provided YAML file.",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:16.883310Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` and `pull_request` events on the `master` branch trigger this workflow?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:17.411137Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"build\" job execute concurrently or have dependencies on other steps?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:18.044548Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching for build processes or artifacts?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:18.598152Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary goal or outcome of this CI build workflow?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:19.120908Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the given YAML, generating and updating documentation on push events, excluding the master branch.",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:19.869748Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow, excluding pushes to the master branch?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:20.454351Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or depend on the successful completion of other jobs or steps?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:20.988268Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the GITHUB_TOKEN secret used for authenticating git pushes?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:21.570704Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:22.131752Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:54.990807Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow to run?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:55.659310Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow are configured to run in parallel, and which ones have dependencies on the successful completion of other jobs?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:56.493452Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `CI_SLACK_*` secrets used to send notifications to different Slack channels?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:57.216890Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or result of this GitHub Actions workflow?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:58.042524Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML workflow.",
    "answer": "name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:38:59.203934Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions trigger the execution of this GitHub Actions workflow?",
    "answer": "name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:38:59.806485Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel or have dependencies on other jobs or steps?",
    "answer": "name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:39:00.324578Z",
    "question_style": "style_3"
  },
  {
    "question": "Is caching properly configured and utilized within the pnpm setup and node setup steps?",
    "answer": "name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:39:00.935456Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this \"Verify Content\" workflow?",
    "answer": "name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:39:01.481669Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:11.014518Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` and `pull_request` events on the `main` branch trigger this workflow?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:11.510419Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow execute in parallel or serially based on dependencies?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:11.920866Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:12.518357Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Node.js CI workflow?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:12.945856Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that triggers on workflow dispatch and a daily cron schedule, building and uploading Python wheels to PyPI.",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:13.770943Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of the \"Wheels\" workflow?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:14.329352Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Wheels\" workflow run in parallel, and which depend on others?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:14.820949Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any secrets used to authenticate the wheel uploads to PyPI?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:15.383201Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this \"Wheels\" workflow?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:15.952451Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that triggers on pull requests with the \"visual\" label, and runs Percy visual tests with the specified environment, steps, and secrets.",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:51.095529Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and conditions trigger this Percy visual tests workflow?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:51.531335Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or have dependencies on other jobs or steps?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:52.043521Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets NPM_TOKEN, GITHUB_TOKEN, ENTERPRISE_TOKEN, and PERCY_TOKEN used within the workflow steps?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:52.659131Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or result of this workflow when triggered by a pull request?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:53.166450Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML workflow, including trigger conditions, jobs, steps, and conditional execution.",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ' : 'failed '}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:54.001422Z",
    "question_style": "style_1"
  },
  {
    "question": "What specific issue comment triggers this benchmark workflow?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ' : 'failed '}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:54.536818Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ' : 'failed '}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:55.156569Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `WANDB_API_KEY`, `HUGGING_FACE_HUB_TOKEN`, and `PERSONAL_ACCESS_TOKEN_GITHUB` secrets used to authenticate with external services?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ' : 'failed '}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:55.770565Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this GitHub Actions workflow triggered by issue comments?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ' : 'failed '}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:56.381971Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file equivalent to the provided YAML, performing code scanning with CodeQL on push, pull requests, and a scheduled cron job.",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      #  Command-line programs to run using the OS shell.\n      #  https://git.io/JvXDl\n\n      #  If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:04.379627Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      #  Command-line programs to run using the OS shell.\n      #  https://git.io/JvXDl\n\n      #  If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:04.815193Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in the workflow run in parallel or have dependencies on each other?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      #  Command-line programs to run using the OS shell.\n      #  https://git.io/JvXDl\n\n      #  If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:05.223683Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      #  Command-line programs to run using the OS shell.\n      #  https://git.io/JvXDl\n\n      #  If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:05.789922Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CodeQL code scanning workflow?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      #  Command-line programs to run using the OS shell.\n      #  https://git.io/JvXDl\n\n      #  If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:06.337692Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file for running linters.",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:07.059115Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:07.604068Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs within this workflow run in parallel, and are there any dependencies between them?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:08.159913Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached pip dependencies utilized and restored in the workflow?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:08.838743Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this \"Linters\" workflow?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:09.371209Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file equivalent to the provided example, ensuring identical triggers, jobs, and steps.",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:37.266087Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this CI workflow?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:37.708248Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'industrial_ci' job run in parallel, and are there any dependencies between them?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:38.254762Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables from the matrix strategy utilized within the industrial_ci action?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:38.838790Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or impact of this continuous integration workflow?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:39.529121Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the functionality of the provided YAML file, including triggers, concurrency, and job steps.",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:40.664801Z",
    "question_style": "style_1"
  },
  {
    "question": "What push branches and file paths, or pull request file paths, trigger this CI workflow?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:41.314053Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'CI' workflow execute concurrently, and which have dependencies?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:42.168435Z",
    "question_style": "style_3"
  },
  {
    "question": "How are caching and artifacts utilized to optimize dependency management and test execution?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:42.767928Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this CI workflow?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:43.279679Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file equivalent to the provided YAML, performing static analysis and evaluation of code in a pull request.",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Vitest evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/vitest-evaluator-action\n          ref: v1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/vitest-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Vitest evaluation\n        id: evaluator\n        uses: ./.github/actions/vitest-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/projeto--password-manager",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/projeto--password-manager/blob/2274d1f93172231cb1a84f71ffe10ee82ffd64ab/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:38.933346Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events trigger this workflow?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Vitest evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/vitest-evaluator-action\n          ref: v1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/vitest-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Vitest evaluation\n        id: evaluator\n        uses: ./.github/actions/vitest-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/projeto--password-manager",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/projeto--password-manager/blob/2274d1f93172231cb1a84f71ffe10ee82ffd64ab/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:39.562247Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the completion of others?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Vitest evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/vitest-evaluator-action\n          ref: v1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/vitest-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Vitest evaluation\n        id: evaluator\n        uses: ./.github/actions/vitest-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/projeto--password-manager",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/projeto--password-manager/blob/2274d1f93172231cb1a84f71ffe10ee82ffd64ab/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:40.161804Z",
    "question_style": "style_3"
  },
  {
    "question": "How does the workflow ensure the different checkout actions using `secrets.GIT_HUB_PAT` have appropriate permissions for their respective repositories?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Vitest evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/vitest-evaluator-action\n          ref: v1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/vitest-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Vitest evaluation\n        id: evaluator\n        uses: ./.github/actions/vitest-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/projeto--password-manager",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/projeto--password-manager/blob/2274d1f93172231cb1a84f71ffe10ee82ffd64ab/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:41.120901Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this pull request workflow?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Vitest evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/vitest-evaluator-action\n          ref: v1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/vitest-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Vitest evaluation\n        id: evaluator\n        uses: ./.github/actions/vitest-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/projeto--password-manager",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/projeto--password-manager/blob/2274d1f93172231cb1a84f71ffe10ee82ffd64ab/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:41.744730Z",
    "question_style": "style_5"
  },
  {
    "question": "Write a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML, including triggers, jobs, steps, and environment variables.",
    "answer": "name: Covey.Town CI\non: # Controls when the action will run.\n  # Triggers the workflow on push or pull request events but only for the master branch. If you want to trigger the action on other branches, add here\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  build-and-test: #\n    # The type of runner that the job will run on\n    runs-on: ubuntu-20.04\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '16'\n      - name: Build and test backend service\n        env: # Pass the Twilio secrets into environmental variables for the backend tests to use\n          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}\n          TWILIO_API_AUTH_TOKEN: ${{ secrets.TWILIO_API_AUTH_TOKEN }}\n          TWILIO_API_KEY_SECRET: ${{ secrets.TWILIO_API_KEY_SECRET }}\n          TWILIO_API_KEY_SID: ${{ secrets.TWILIO_API_KEY_SID }}\n        run: cd townService; npm install && npm run prestart && npm run lint && npm test\n\n      - name: Build and test frontend components\n        run: cd frontend; npm install && npm run prestart && npm run lint && npm test\n#   deploy:\n#     if: github.ref == 'refs/heads/master'\n#     needs: build-and-test\n#     runs-on: ubuntu-latest\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: akhileshns/heroku-deploy@v3.12.12 # Deploy to Heroku action\n#         with:\n#           heroku_api_key: ${{secrets.HEROKU_API_KEY}}\n#           heroku_app_name: ${{secrets.HEROKU_APP_NAME}}\n#           heroku_email: ${{secrets.HEROKU_EMAIL}}\n",
    "source": "njit-cs-490-002-spring23/group-project-team-2",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/njit-cs-490-002-spring23/group-project-team-2/blob/fc7df680695f322a3c16b32db7b38abb5aca96f7/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:42.545234Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow?",
    "answer": "name: Covey.Town CI\non: # Controls when the action will run.\n  # Triggers the workflow on push or pull request events but only for the master branch. If you want to trigger the action on other branches, add here\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  build-and-test: #\n    # The type of runner that the job will run on\n    runs-on: ubuntu-20.04\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '16'\n      - name: Build and test backend service\n        env: # Pass the Twilio secrets into environmental variables for the backend tests to use\n          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}\n          TWILIO_API_AUTH_TOKEN: ${{ secrets.TWILIO_API_AUTH_TOKEN }}\n          TWILIO_API_KEY_SECRET: ${{ secrets.TWILIO_API_KEY_SECRET }}\n          TWILIO_API_KEY_SID: ${{ secrets.TWILIO_API_KEY_SID }}\n        run: cd townService; npm install && npm run prestart && npm run lint && npm test\n\n      - name: Build and test frontend components\n        run: cd frontend; npm install && npm run prestart && npm run lint && npm test\n#   deploy:\n#     if: github.ref == 'refs/heads/master'\n#     needs: build-and-test\n#     runs-on: ubuntu-latest\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: akhileshns/heroku-deploy@v3.12.12 # Deploy to Heroku action\n#         with:\n#           heroku_api_key: ${{secrets.HEROKU_API_KEY}}\n#           heroku_app_name: ${{secrets.HEROKU_APP_NAME}}\n#           heroku_email: ${{secrets.HEROKU_EMAIL}}\n",
    "source": "njit-cs-490-002-spring23/group-project-team-2",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/njit-cs-490-002-spring23/group-project-team-2/blob/fc7df680695f322a3c16b32db7b38abb5aca96f7/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:43.090094Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the build-and-test job run in parallel, and are there any job dependencies defined?",
    "answer": "name: Covey.Town CI\non: # Controls when the action will run.\n  # Triggers the workflow on push or pull request events but only for the master branch. If you want to trigger the action on other branches, add here\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  build-and-test: #\n    # The type of runner that the job will run on\n    runs-on: ubuntu-20.04\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '16'\n      - name: Build and test backend service\n        env: # Pass the Twilio secrets into environmental variables for the backend tests to use\n          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}\n          TWILIO_API_AUTH_TOKEN: ${{ secrets.TWILIO_API_AUTH_TOKEN }}\n          TWILIO_API_KEY_SECRET: ${{ secrets.TWILIO_API_KEY_SECRET }}\n          TWILIO_API_KEY_SID: ${{ secrets.TWILIO_API_KEY_SID }}\n        run: cd townService; npm install && npm run prestart && npm run lint && npm test\n\n      - name: Build and test frontend components\n        run: cd frontend; npm install && npm run prestart && npm run lint && npm test\n#   deploy:\n#     if: github.ref == 'refs/heads/master'\n#     needs: build-and-test\n#     runs-on: ubuntu-latest\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: akhileshns/heroku-deploy@v3.12.12 # Deploy to Heroku action\n#         with:\n#           heroku_api_key: ${{secrets.HEROKU_API_KEY}}\n#           heroku_app_name: ${{secrets.HEROKU_APP_NAME}}\n#           heroku_email: ${{secrets.HEROKU_EMAIL}}\n",
    "source": "njit-cs-490-002-spring23/group-project-team-2",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/njit-cs-490-002-spring23/group-project-team-2/blob/fc7df680695f322a3c16b32db7b38abb5aca96f7/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:43.846860Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the Twilio and Heroku secrets used to configure the testing and deployment processes?",
    "answer": "name: Covey.Town CI\non: # Controls when the action will run.\n  # Triggers the workflow on push or pull request events but only for the master branch. If you want to trigger the action on other branches, add here\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  build-and-test: #\n    # The type of runner that the job will run on\n    runs-on: ubuntu-20.04\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '16'\n      - name: Build and test backend service\n        env: # Pass the Twilio secrets into environmental variables for the backend tests to use\n          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}\n          TWILIO_API_AUTH_TOKEN: ${{ secrets.TWILIO_API_AUTH_TOKEN }}\n          TWILIO_API_KEY_SECRET: ${{ secrets.TWILIO_API_KEY_SECRET }}\n          TWILIO_API_KEY_SID: ${{ secrets.TWILIO_API_KEY_SID }}\n        run: cd townService; npm install && npm run prestart && npm run lint && npm test\n\n      - name: Build and test frontend components\n        run: cd frontend; npm install && npm run prestart && npm run lint && npm test\n#   deploy:\n#     if: github.ref == 'refs/heads/master'\n#     needs: build-and-test\n#     runs-on: ubuntu-latest\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: akhileshns/heroku-deploy@v3.12.12 # Deploy to Heroku action\n#         with:\n#           heroku_api_key: ${{secrets.HEROKU_API_KEY}}\n#           heroku_app_name: ${{secrets.HEROKU_APP_NAME}}\n#           heroku_email: ${{secrets.HEROKU_EMAIL}}\n",
    "source": "njit-cs-490-002-spring23/group-project-team-2",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/njit-cs-490-002-spring23/group-project-team-2/blob/fc7df680695f322a3c16b32db7b38abb5aca96f7/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:44.523536Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Covey.Town CI workflow?",
    "answer": "name: Covey.Town CI\non: # Controls when the action will run.\n  # Triggers the workflow on push or pull request events but only for the master branch. If you want to trigger the action on other branches, add here\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  build-and-test: #\n    # The type of runner that the job will run on\n    runs-on: ubuntu-20.04\n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '16'\n      - name: Build and test backend service\n        env: # Pass the Twilio secrets into environmental variables for the backend tests to use\n          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}\n          TWILIO_API_AUTH_TOKEN: ${{ secrets.TWILIO_API_AUTH_TOKEN }}\n          TWILIO_API_KEY_SECRET: ${{ secrets.TWILIO_API_KEY_SECRET }}\n          TWILIO_API_KEY_SID: ${{ secrets.TWILIO_API_KEY_SID }}\n        run: cd townService; npm install && npm run prestart && npm run lint && npm test\n\n      - name: Build and test frontend components\n        run: cd frontend; npm install && npm run prestart && npm run lint && npm test\n#   deploy:\n#     if: github.ref == 'refs/heads/master'\n#     needs: build-and-test\n#     runs-on: ubuntu-latest\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: akhileshns/heroku-deploy@v3.12.12 # Deploy to Heroku action\n#         with:\n#           heroku_api_key: ${{secrets.HEROKU_API_KEY}}\n#           heroku_app_name: ${{secrets.HEROKU_APP_NAME}}\n#           heroku_email: ${{secrets.HEROKU_EMAIL}}\n",
    "source": "njit-cs-490-002-spring23/group-project-team-2",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/njit-cs-490-002-spring23/group-project-team-2/blob/fc7df680695f322a3c16b32db7b38abb5aca96f7/.github/workflows/main.yml",
    "retrieved_at": "2025-10-15T01:41:45.145587Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow that links a merged pull request to a milestone using the `link-milestone` tool.",
    "answer": "---\nname: Link Milestone\n\non:\n  pull_request_target:\n    branches: [main]\n    types: ['closed']\n\njobs:\n  link-milestone:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: write\n      issues: write\n    steps:\n      - uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v5.0.0\n        with:\n          # we cannot use go-version-file here because no repositories are checked out so there is no file to reference\n          go-version: '1.21.6'\n      - run: |\n          go install github.com/stephybun/link-milestone@latest\n          link-milestone\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_REPO: ${{ github.repository }}\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/link-milestone.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/link-milestone.yaml",
    "retrieved_at": "2025-10-16T01:40:46.750790Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events on the main branch trigger this workflow when closed and merged?",
    "answer": "---\nname: Link Milestone\n\non:\n  pull_request_target:\n    branches: [main]\n    types: ['closed']\n\njobs:\n  link-milestone:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: write\n      issues: write\n    steps:\n      - uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v5.0.0\n        with:\n          # we cannot use go-version-file here because no repositories are checked out so there is no file to reference\n          go-version: '1.21.6'\n      - run: |\n          go install github.com/stephybun/link-milestone@latest\n          link-milestone\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_REPO: ${{ github.repository }}\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/link-milestone.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/link-milestone.yaml",
    "retrieved_at": "2025-10-16T01:40:47.372515Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow execute concurrently, and what dependencies exist between them?",
    "answer": "---\nname: Link Milestone\n\non:\n  pull_request_target:\n    branches: [main]\n    types: ['closed']\n\njobs:\n  link-milestone:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: write\n      issues: write\n    steps:\n      - uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v5.0.0\n        with:\n          # we cannot use go-version-file here because no repositories are checked out so there is no file to reference\n          go-version: '1.21.6'\n      - run: |\n          go install github.com/stephybun/link-milestone@latest\n          link-milestone\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_REPO: ${{ github.repository }}\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/link-milestone.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/link-milestone.yaml",
    "retrieved_at": "2025-10-16T01:40:47.960028Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `GITHUB_TOKEN` and `GITHUB_REPO` environment variables used by the `link-milestone` command?",
    "answer": "---\nname: Link Milestone\n\non:\n  pull_request_target:\n    branches: [main]\n    types: ['closed']\n\njobs:\n  link-milestone:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: write\n      issues: write\n    steps:\n      - uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v5.0.0\n        with:\n          # we cannot use go-version-file here because no repositories are checked out so there is no file to reference\n          go-version: '1.21.6'\n      - run: |\n          go install github.com/stephybun/link-milestone@latest\n          link-milestone\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_REPO: ${{ github.repository }}\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/link-milestone.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/link-milestone.yaml",
    "retrieved_at": "2025-10-16T01:40:48.563932Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when a pull request is merged into the main branch?",
    "answer": "---\nname: Link Milestone\n\non:\n  pull_request_target:\n    branches: [main]\n    types: ['closed']\n\njobs:\n  link-milestone:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: write\n      issues: write\n    steps:\n      - uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v5.0.0\n        with:\n          # we cannot use go-version-file here because no repositories are checked out so there is no file to reference\n          go-version: '1.21.6'\n      - run: |\n          go install github.com/stephybun/link-milestone@latest\n          link-milestone\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          GITHUB_REPO: ${{ github.repository }}\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/link-milestone.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/link-milestone.yaml",
    "retrieved_at": "2025-10-16T01:40:49.156213Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the linting and build processes defined in the provided YAML.",
    "answer": "name: QA\non: [pull_request]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - name: Install dependencies\n        run: pnpm install\n      - name: Check linters\n        run: pnpm lint\n      - name: Validate paths\n        run: |\n          pnpm paths\n          git diff --exit-code ./lib/\\$path.ts\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ${{ github.workspace }}/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx') }}\n          # If source files changed but packages didn't, rebuild from a prior cache.\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-\n      - name: Install dependencies\n        run: pnpm install\n      - name: Build project\n        run: pnpm build\n",
    "source": "fly0305/storeft-react-graphql-tailwind-typescript-",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/fly0305/storeft-react-graphql-tailwind-typescript-/blob/b737cfb114dba1f30b675c9177729cf9ceb25284/.github/workflows/main.yml",
    "retrieved_at": "2025-10-16T01:40:49.907941Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the execution of this GitHub Actions workflow?",
    "answer": "name: QA\non: [pull_request]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - name: Install dependencies\n        run: pnpm install\n      - name: Check linters\n        run: pnpm lint\n      - name: Validate paths\n        run: |\n          pnpm paths\n          git diff --exit-code ./lib/\\$path.ts\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ${{ github.workspace }}/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx') }}\n          # If source files changed but packages didn't, rebuild from a prior cache.\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-\n      - name: Install dependencies\n        run: pnpm install\n      - name: Build project\n        run: pnpm build\n",
    "source": "fly0305/storeft-react-graphql-tailwind-typescript-",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/fly0305/storeft-react-graphql-tailwind-typescript-/blob/b737cfb114dba1f30b675c9177729cf9ceb25284/.github/workflows/main.yml",
    "retrieved_at": "2025-10-16T01:40:50.493058Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially, and what are their dependencies?",
    "answer": "name: QA\non: [pull_request]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - name: Install dependencies\n        run: pnpm install\n      - name: Check linters\n        run: pnpm lint\n      - name: Validate paths\n        run: |\n          pnpm paths\n          git diff --exit-code ./lib/\\$path.ts\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ${{ github.workspace }}/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx') }}\n          # If source files changed but packages didn't, rebuild from a prior cache.\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-\n      - name: Install dependencies\n        run: pnpm install\n      - name: Build project\n        run: pnpm build\n",
    "source": "fly0305/storeft-react-graphql-tailwind-typescript-",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/fly0305/storeft-react-graphql-tailwind-typescript-/blob/b737cfb114dba1f30b675c9177729cf9ceb25284/.github/workflows/main.yml",
    "retrieved_at": "2025-10-16T01:40:51.124702Z",
    "question_style": "style_3"
  },
  {
    "question": "How does the workflow leverage caching for dependencies and the Next.js build?",
    "answer": "name: QA\non: [pull_request]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - name: Install dependencies\n        run: pnpm install\n      - name: Check linters\n        run: pnpm lint\n      - name: Validate paths\n        run: |\n          pnpm paths\n          git diff --exit-code ./lib/\\$path.ts\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ${{ github.workspace }}/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx') }}\n          # If source files changed but packages didn't, rebuild from a prior cache.\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-\n      - name: Install dependencies\n        run: pnpm install\n      - name: Build project\n        run: pnpm build\n",
    "source": "fly0305/storeft-react-graphql-tailwind-typescript-",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/fly0305/storeft-react-graphql-tailwind-typescript-/blob/b737cfb114dba1f30b675c9177729cf9ceb25284/.github/workflows/main.yml",
    "retrieved_at": "2025-10-16T01:40:51.745397Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow do when a pull request is opened?",
    "answer": "name: QA\non: [pull_request]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - name: Install dependencies\n        run: pnpm install\n      - name: Check linters\n        run: pnpm lint\n      - name: Validate paths\n        run: |\n          pnpm paths\n          git diff --exit-code ./lib/\\$path.ts\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: pnpm/action-setup@v2.2.1\n        with:\n          version: 6.19.1\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"16\"\n          cache: \"pnpm\"\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ${{ github.workspace }}/.next/cache\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx') }}\n          # If source files changed but packages didn't, rebuild from a prior cache.\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.json') }}-\n      - name: Install dependencies\n        run: pnpm install\n      - name: Build project\n        run: pnpm build\n",
    "source": "fly0305/storeft-react-graphql-tailwind-typescript-",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/fly0305/storeft-react-graphql-tailwind-typescript-/blob/b737cfb114dba1f30b675c9177729cf9ceb25284/.github/workflows/main.yml",
    "retrieved_at": "2025-10-16T01:40:52.319891Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "---\nname: Issue Opened Triage\n\npermissions:\n  issues: write\n\non:\n  issues:\n    types: [opened]\n\njobs:\n  issue_triage:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n    - uses: github/issue-labeler@c1b0f9f52a63158c4adc09425e858e87b32e9685 # v3.4\n      with:\n        repo-token: \"${{ secrets.GITHUB_TOKEN }}\"\n        configuration-path: .github/labeler-issue-triage.yml\n        enable-versioned-regex: 0\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/issue-opened.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/issue-opened.yaml",
    "retrieved_at": "2025-10-17T01:39:51.276421Z",
    "question_style": "style_1"
  },
  {
    "question": "What event involving issues triggers this GitHub Actions workflow?",
    "answer": "---\nname: Issue Opened Triage\n\npermissions:\n  issues: write\n\non:\n  issues:\n    types: [opened]\n\njobs:\n  issue_triage:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n    - uses: github/issue-labeler@c1b0f9f52a63158c4adc09425e858e87b32e9685 # v3.4\n      with:\n        repo-token: \"${{ secrets.GITHUB_TOKEN }}\"\n        configuration-path: .github/labeler-issue-triage.yml\n        enable-versioned-regex: 0\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/issue-opened.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/issue-opened.yaml",
    "retrieved_at": "2025-10-17T01:39:51.764722Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or have dependencies on other jobs or steps?",
    "answer": "---\nname: Issue Opened Triage\n\npermissions:\n  issues: write\n\non:\n  issues:\n    types: [opened]\n\njobs:\n  issue_triage:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n    - uses: github/issue-labeler@c1b0f9f52a63158c4adc09425e858e87b32e9685 # v3.4\n      with:\n        repo-token: \"${{ secrets.GITHUB_TOKEN }}\"\n        configuration-path: .github/labeler-issue-triage.yml\n        enable-versioned-regex: 0\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/issue-opened.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/issue-opened.yaml",
    "retrieved_at": "2025-10-17T01:39:52.326734Z",
    "question_style": "style_3"
  },
  {
    "question": "How does the workflow utilize the `GITHUB_TOKEN` secret for issue labeling?",
    "answer": "---\nname: Issue Opened Triage\n\npermissions:\n  issues: write\n\non:\n  issues:\n    types: [opened]\n\njobs:\n  issue_triage:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n    - uses: github/issue-labeler@c1b0f9f52a63158c4adc09425e858e87b32e9685 # v3.4\n      with:\n        repo-token: \"${{ secrets.GITHUB_TOKEN }}\"\n        configuration-path: .github/labeler-issue-triage.yml\n        enable-versioned-regex: 0\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/issue-opened.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/issue-opened.yaml",
    "retrieved_at": "2025-10-17T01:39:52.901400Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the \"Issue Opened Triage\" workflow?",
    "answer": "---\nname: Issue Opened Triage\n\npermissions:\n  issues: write\n\non:\n  issues:\n    types: [opened]\n\njobs:\n  issue_triage:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1\n    - uses: github/issue-labeler@c1b0f9f52a63158c4adc09425e858e87b32e9685 # v3.4\n      with:\n        repo-token: \"${{ secrets.GITHUB_TOKEN }}\"\n        configuration-path: .github/labeler-issue-triage.yml\n        enable-versioned-regex: 0\n",
    "source": "KamalakarBadri/Terraform_Azure",
    "path": ".github/workflows/issue-opened.yaml",
    "url": "https://github.com/KamalakarBadri/Terraform_Azure/blob/dde736f5278b33e98393771815d5eef3b4d11cc4/.github/workflows/issue-opened.yaml",
    "retrieved_at": "2025-10-17T01:39:53.519651Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that publishes the @devcontainers/cli package to npm when a tag is pushed.",
    "answer": "name: Publish @devcontainers/cli\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  main:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18.x'\n        registry-url: 'https://registry.npmjs.org'\n        scope: '@devcontainers'\n    - name: Verify Versions\n      run: |\n        node -e \"\n          const packageRef = 'refs/tags/v' + require('./package.json').version;\n          const githubRef = '${{ github.ref }}';\n          if (packageRef !== githubRef && packageRef + '-pre-release' != githubRef) {\n            console.log('::error::' + 'Version Mismatch.', packageRef, githubRef);\n            throw Error('Version Mismatch');\n          }\n        \"\n    - name: TGZ name\n      run: |\n        VERSION=$(jq -r '.version' < package.json)\n        echo \"TGZ=devcontainers-cli-${VERSION}.tgz\" | tee -a $GITHUB_ENV\n        echo \"TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz\" | tee -a $GITHUB_ENV\n    - name: Download TGZ\n      uses: dawidd6/action-download-artifact@09f2f74827fd3a8607589e5ad7f9398816f540fe\n      with:\n        workflow: dev-containers.yml\n        workflow_conclusion: success\n        commit: ${{ github.sha }}\n        name: ${{ env.TGZ_UPLOAD }}\n        path: .\n    - name: Publish TGZ\n      run: npm publish ${TGZ} --access public\n      env:\n        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n",
    "source": "Kaniska244/clibackup",
    "path": ".github/workflows/publish-dev-containers.yml",
    "url": "https://github.com/Kaniska244/clibackup/blob/f475b2be4c516e0b7191b338328210eae1ad9d62/.github/workflows/publish-dev-containers.yml",
    "retrieved_at": "2025-10-17T01:39:54.475746Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` events, specifically related to tags, trigger this GitHub Actions workflow?",
    "answer": "name: Publish @devcontainers/cli\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  main:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18.x'\n        registry-url: 'https://registry.npmjs.org'\n        scope: '@devcontainers'\n    - name: Verify Versions\n      run: |\n        node -e \"\n          const packageRef = 'refs/tags/v' + require('./package.json').version;\n          const githubRef = '${{ github.ref }}';\n          if (packageRef !== githubRef && packageRef + '-pre-release' != githubRef) {\n            console.log('::error::' + 'Version Mismatch.', packageRef, githubRef);\n            throw Error('Version Mismatch');\n          }\n        \"\n    - name: TGZ name\n      run: |\n        VERSION=$(jq -r '.version' < package.json)\n        echo \"TGZ=devcontainers-cli-${VERSION}.tgz\" | tee -a $GITHUB_ENV\n        echo \"TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz\" | tee -a $GITHUB_ENV\n    - name: Download TGZ\n      uses: dawidd6/action-download-artifact@09f2f74827fd3a8607589e5ad7f9398816f540fe\n      with:\n        workflow: dev-containers.yml\n        workflow_conclusion: success\n        commit: ${{ github.sha }}\n        name: ${{ env.TGZ_UPLOAD }}\n        path: .\n    - name: Publish TGZ\n      run: npm publish ${TGZ} --access public\n      env:\n        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n",
    "source": "Kaniska244/clibackup",
    "path": ".github/workflows/publish-dev-containers.yml",
    "url": "https://github.com/Kaniska244/clibackup/blob/f475b2be4c516e0b7191b338328210eae1ad9d62/.github/workflows/publish-dev-containers.yml",
    "retrieved_at": "2025-10-17T01:39:55.351856Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which ones have dependencies on others?",
    "answer": "name: Publish @devcontainers/cli\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  main:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18.x'\n        registry-url: 'https://registry.npmjs.org'\n        scope: '@devcontainers'\n    - name: Verify Versions\n      run: |\n        node -e \"\n          const packageRef = 'refs/tags/v' + require('./package.json').version;\n          const githubRef = '${{ github.ref }}';\n          if (packageRef !== githubRef && packageRef + '-pre-release' != githubRef) {\n            console.log('::error::' + 'Version Mismatch.', packageRef, githubRef);\n            throw Error('Version Mismatch');\n          }\n        \"\n    - name: TGZ name\n      run: |\n        VERSION=$(jq -r '.version' < package.json)\n        echo \"TGZ=devcontainers-cli-${VERSION}.tgz\" | tee -a $GITHUB_ENV\n        echo \"TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz\" | tee -a $GITHUB_ENV\n    - name: Download TGZ\n      uses: dawidd6/action-download-artifact@09f2f74827fd3a8607589e5ad7f9398816f540fe\n      with:\n        workflow: dev-containers.yml\n        workflow_conclusion: success\n        commit: ${{ github.sha }}\n        name: ${{ env.TGZ_UPLOAD }}\n        path: .\n    - name: Publish TGZ\n      run: npm publish ${TGZ} --access public\n      env:\n        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n",
    "source": "Kaniska244/clibackup",
    "path": ".github/workflows/publish-dev-containers.yml",
    "url": "https://github.com/Kaniska244/clibackup/blob/f475b2be4c516e0b7191b338328210eae1ad9d62/.github/workflows/publish-dev-containers.yml",
    "retrieved_at": "2025-10-17T01:39:55.982576Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `NPM_TOKEN` secret used to authenticate the npm publish command?",
    "answer": "name: Publish @devcontainers/cli\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  main:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18.x'\n        registry-url: 'https://registry.npmjs.org'\n        scope: '@devcontainers'\n    - name: Verify Versions\n      run: |\n        node -e \"\n          const packageRef = 'refs/tags/v' + require('./package.json').version;\n          const githubRef = '${{ github.ref }}';\n          if (packageRef !== githubRef && packageRef + '-pre-release' != githubRef) {\n            console.log('::error::' + 'Version Mismatch.', packageRef, githubRef);\n            throw Error('Version Mismatch');\n          }\n        \"\n    - name: TGZ name\n      run: |\n        VERSION=$(jq -r '.version' < package.json)\n        echo \"TGZ=devcontainers-cli-${VERSION}.tgz\" | tee -a $GITHUB_ENV\n        echo \"TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz\" | tee -a $GITHUB_ENV\n    - name: Download TGZ\n      uses: dawidd6/action-download-artifact@09f2f74827fd3a8607589e5ad7f9398816f540fe\n      with:\n        workflow: dev-containers.yml\n        workflow_conclusion: success\n        commit: ${{ github.sha }}\n        name: ${{ env.TGZ_UPLOAD }}\n        path: .\n    - name: Publish TGZ\n      run: npm publish ${TGZ} --access public\n      env:\n        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n",
    "source": "Kaniska244/clibackup",
    "path": ".github/workflows/publish-dev-containers.yml",
    "url": "https://github.com/Kaniska244/clibackup/blob/f475b2be4c516e0b7191b338328210eae1ad9d62/.github/workflows/publish-dev-containers.yml",
    "retrieved_at": "2025-10-17T01:39:56.985830Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, triggered by tagged pushes?",
    "answer": "name: Publish @devcontainers/cli\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  main:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18.x'\n        registry-url: 'https://registry.npmjs.org'\n        scope: '@devcontainers'\n    - name: Verify Versions\n      run: |\n        node -e \"\n          const packageRef = 'refs/tags/v' + require('./package.json').version;\n          const githubRef = '${{ github.ref }}';\n          if (packageRef !== githubRef && packageRef + '-pre-release' != githubRef) {\n            console.log('::error::' + 'Version Mismatch.', packageRef, githubRef);\n            throw Error('Version Mismatch');\n          }\n        \"\n    - name: TGZ name\n      run: |\n        VERSION=$(jq -r '.version' < package.json)\n        echo \"TGZ=devcontainers-cli-${VERSION}.tgz\" | tee -a $GITHUB_ENV\n        echo \"TGZ_UPLOAD=devcontainers-cli-${VERSION}-${GITHUB_SHA:0:8}.tgz\" | tee -a $GITHUB_ENV\n    - name: Download TGZ\n      uses: dawidd6/action-download-artifact@09f2f74827fd3a8607589e5ad7f9398816f540fe\n      with:\n        workflow: dev-containers.yml\n        workflow_conclusion: success\n        commit: ${{ github.sha }}\n        name: ${{ env.TGZ_UPLOAD }}\n        path: .\n    - name: Publish TGZ\n      run: npm publish ${TGZ} --access public\n      env:\n        NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n",
    "source": "Kaniska244/clibackup",
    "path": ".github/workflows/publish-dev-containers.yml",
    "url": "https://github.com/Kaniska244/clibackup/blob/f475b2be4c516e0b7191b338328210eae1ad9d62/.github/workflows/publish-dev-containers.yml",
    "retrieved_at": "2025-10-17T01:39:57.571225Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML.",
    "answer": "name: build\non:\n  push:\n    tags:\n      - v*\n    branches:\n      - master\n      - main\n      - kafqa_ci_fix\n  pull_request:\njobs:\n  test:\n    name: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: build\n        uses: actions/setup-go@v2\n        with:\n          go-version: '^1.13.1'\n      - name: install librdkafka\n        run: |\n          git clone https://github.com/edenhill/librdkafka.git\n          pushd librdkafka && ./configure --prefix /usr\n          sudo make\n          sudo make install\n          popd\n      - name: build\n        run: make test\n",
    "source": "gojek/kafqa",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/gojek/kafqa/blob/a82c1558a463d33e4ed8131435e15d1d335527db/.github/workflows/build.yml",
    "retrieved_at": "2025-10-18T01:27:44.369441Z",
    "question_style": "style_1"
  },
  {
    "question": "What events related to pushes and pull requests trigger this \"build\" workflow?",
    "answer": "name: build\non:\n  push:\n    tags:\n      - v*\n    branches:\n      - master\n      - main\n      - kafqa_ci_fix\n  pull_request:\njobs:\n  test:\n    name: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: build\n        uses: actions/setup-go@v2\n        with:\n          go-version: '^1.13.1'\n      - name: install librdkafka\n        run: |\n          git clone https://github.com/edenhill/librdkafka.git\n          pushd librdkafka && ./configure --prefix /usr\n          sudo make\n          sudo make install\n          popd\n      - name: build\n        run: make test\n",
    "source": "gojek/kafqa",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/gojek/kafqa/blob/a82c1558a463d33e4ed8131435e15d1d335527db/.github/workflows/build.yml",
    "retrieved_at": "2025-10-18T01:27:45.257909Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently versus sequentially, based on dependencies?",
    "answer": "name: build\non:\n  push:\n    tags:\n      - v*\n    branches:\n      - master\n      - main\n      - kafqa_ci_fix\n  pull_request:\njobs:\n  test:\n    name: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: build\n        uses: actions/setup-go@v2\n        with:\n          go-version: '^1.13.1'\n      - name: install librdkafka\n        run: |\n          git clone https://github.com/edenhill/librdkafka.git\n          pushd librdkafka && ./configure --prefix /usr\n          sudo make\n          sudo make install\n          popd\n      - name: build\n        run: make test\n",
    "source": "gojek/kafqa",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/gojek/kafqa/blob/a82c1558a463d33e4ed8131435e15d1d335527db/.github/workflows/build.yml",
    "retrieved_at": "2025-10-18T01:27:45.870720Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the workflow utilize environment variables, secrets, or caching/artifacts, and if so, how?",
    "answer": "name: build\non:\n  push:\n    tags:\n      - v*\n    branches:\n      - master\n      - main\n      - kafqa_ci_fix\n  pull_request:\njobs:\n  test:\n    name: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: build\n        uses: actions/setup-go@v2\n        with:\n          go-version: '^1.13.1'\n      - name: install librdkafka\n        run: |\n          git clone https://github.com/edenhill/librdkafka.git\n          pushd librdkafka && ./configure --prefix /usr\n          sudo make\n          sudo make install\n          popd\n      - name: build\n        run: make test\n",
    "source": "gojek/kafqa",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/gojek/kafqa/blob/a82c1558a463d33e4ed8131435e15d1d335527db/.github/workflows/build.yml",
    "retrieved_at": "2025-10-18T01:27:46.552703Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow, triggered by pushes and pull requests?",
    "answer": "name: build\non:\n  push:\n    tags:\n      - v*\n    branches:\n      - master\n      - main\n      - kafqa_ci_fix\n  pull_request:\njobs:\n  test:\n    name: test\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: build\n        uses: actions/setup-go@v2\n        with:\n          go-version: '^1.13.1'\n      - name: install librdkafka\n        run: |\n          git clone https://github.com/edenhill/librdkafka.git\n          pushd librdkafka && ./configure --prefix /usr\n          sudo make\n          sudo make install\n          popd\n      - name: build\n        run: make test\n",
    "source": "gojek/kafqa",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/gojek/kafqa/blob/a82c1558a463d33e4ed8131435e15d1d335527db/.github/workflows/build.yml",
    "retrieved_at": "2025-10-18T01:27:47.136671Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: Native CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-melodic:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest] #[ubuntu-latest, self-hosted]\n      fail-fast: false\n\n    container:\n      image: autoware/autoware:bleedingedge-melodic-base\n      env:\n        ROS_DISTRO: melodic\n      options: --user root\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Prepare repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        rosdep update && apt-get update -qqq\n        rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n\n    - name: Build and test repo\n      run: |\n        bash -c 'source /opt/ros/$ROS_DISTRO/setup.bash; \\\n        colcon build --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon build --cmake-target tests --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon test; \\\n        colcon test-result --verbose'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/native-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/native-ci.yaml",
    "retrieved_at": "2025-10-18T01:27:48.134975Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull requests or pushes to the master branch trigger this workflow?",
    "answer": "name: Native CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-melodic:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest] #[ubuntu-latest, self-hosted]\n      fail-fast: false\n\n    container:\n      image: autoware/autoware:bleedingedge-melodic-base\n      env:\n        ROS_DISTRO: melodic\n      options: --user root\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Prepare repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        rosdep update && apt-get update -qqq\n        rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n\n    - name: Build and test repo\n      run: |\n        bash -c 'source /opt/ros/$ROS_DISTRO/setup.bash; \\\n        colcon build --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon build --cmake-target tests --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon test; \\\n        colcon test-result --verbose'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/native-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/native-ci.yaml",
    "retrieved_at": "2025-10-18T01:27:48.755114Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow execute in parallel, and are there any dependencies between them?",
    "answer": "name: Native CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-melodic:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest] #[ubuntu-latest, self-hosted]\n      fail-fast: false\n\n    container:\n      image: autoware/autoware:bleedingedge-melodic-base\n      env:\n        ROS_DISTRO: melodic\n      options: --user root\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Prepare repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        rosdep update && apt-get update -qqq\n        rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n\n    - name: Build and test repo\n      run: |\n        bash -c 'source /opt/ros/$ROS_DISTRO/setup.bash; \\\n        colcon build --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon build --cmake-target tests --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon test; \\\n        colcon test-result --verbose'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/native-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/native-ci.yaml",
    "retrieved_at": "2025-10-18T01:27:49.310996Z",
    "question_style": "style_3"
  },
  {
    "question": "How does the workflow utilize the `ROS_DISTRO` environment variable within the container and build steps?",
    "answer": "name: Native CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-melodic:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest] #[ubuntu-latest, self-hosted]\n      fail-fast: false\n\n    container:\n      image: autoware/autoware:bleedingedge-melodic-base\n      env:\n        ROS_DISTRO: melodic\n      options: --user root\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Prepare repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        rosdep update && apt-get update -qqq\n        rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n\n    - name: Build and test repo\n      run: |\n        bash -c 'source /opt/ros/$ROS_DISTRO/setup.bash; \\\n        colcon build --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon build --cmake-target tests --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon test; \\\n        colcon test-result --verbose'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/native-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/native-ci.yaml",
    "retrieved_at": "2025-10-18T01:27:50.016200Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow for the Autoware project?",
    "answer": "name: Native CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-melodic:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest] #[ubuntu-latest, self-hosted]\n      fail-fast: false\n\n    container:\n      image: autoware/autoware:bleedingedge-melodic-base\n      env:\n        ROS_DISTRO: melodic\n      options: --user root\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Prepare repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        rosdep update && apt-get update -qqq\n        rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n\n    - name: Build and test repo\n      run: |\n        bash -c 'source /opt/ros/$ROS_DISTRO/setup.bash; \\\n        colcon build --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon build --cmake-target tests --cmake-args -DCMAKE_CXX_FLAGS=\"${CMAKE_CXX_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_C_FLAGS=\"${CMAKE_C_FLAGS} -fprofile-arcs -ftest-coverage\" -DCMAKE_BUILD_TYPE=Debug; \\\n        colcon test; \\\n        colcon test-result --verbose'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/native-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/native-ci.yaml",
    "retrieved_at": "2025-10-18T01:27:50.586810Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "# Sample workflow for building and deploying a Hugo site to GitHub Pages\nname: Deploy Hugo site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches:\n      - master\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\n# Default to bash\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    env:\n      HUGO_VERSION: 0.128.0\n    steps:\n      - name: Install Hugo CLI\n        run: |\n          wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\n          && sudo dpkg -i ${{ runner.temp }}/hugo.deb          \n      - name: Install Dart Sass\n        run: sudo snap install dart-sass\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          submodules: recursive\n          fetch-depth: 0\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v5\n      - name: Install Node.js dependencies\n        run: \"[[ -f package-lock.json || -f npm-shrinkwrap.json ]] && npm ci || true\"\n      - name: Build with Hugo\n        env:\n          HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache\n          HUGO_ENVIRONMENT: production\n          TZ: America/Los_Angeles\n        run: |\n          hugo \\\n            --gc \\\n            --minify \\\n            --baseURL \"${{ steps.pages.outputs.base_url }}/\"          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./public\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "CurryTang/gfm_webpage",
    "path": ".github/workflows/hugo.yml",
    "url": "https://github.com/CurryTang/gfm_webpage/blob/3f9aa1c83f6db8245e598f420db2fea0a9a511e2/.github/workflows/hugo.yml",
    "retrieved_at": "2025-10-19T01:50:34.163812Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Deploy Hugo site to Pages\" GitHub Actions workflow?",
    "answer": "# Sample workflow for building and deploying a Hugo site to GitHub Pages\nname: Deploy Hugo site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches:\n      - master\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\n# Default to bash\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    env:\n      HUGO_VERSION: 0.128.0\n    steps:\n      - name: Install Hugo CLI\n        run: |\n          wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\n          && sudo dpkg -i ${{ runner.temp }}/hugo.deb          \n      - name: Install Dart Sass\n        run: sudo snap install dart-sass\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          submodules: recursive\n          fetch-depth: 0\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v5\n      - name: Install Node.js dependencies\n        run: \"[[ -f package-lock.json || -f npm-shrinkwrap.json ]] && npm ci || true\"\n      - name: Build with Hugo\n        env:\n          HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache\n          HUGO_ENVIRONMENT: production\n          TZ: America/Los_Angeles\n        run: |\n          hugo \\\n            --gc \\\n            --minify \\\n            --baseURL \"${{ steps.pages.outputs.base_url }}/\"          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./public\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "CurryTang/gfm_webpage",
    "path": ".github/workflows/hugo.yml",
    "url": "https://github.com/CurryTang/gfm_webpage/blob/3f9aa1c83f6db8245e598f420db2fea0a9a511e2/.github/workflows/hugo.yml",
    "retrieved_at": "2025-10-19T01:50:34.705886Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run concurrently, and which ones depend on the successful completion of others?",
    "answer": "# Sample workflow for building and deploying a Hugo site to GitHub Pages\nname: Deploy Hugo site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches:\n      - master\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\n# Default to bash\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    env:\n      HUGO_VERSION: 0.128.0\n    steps:\n      - name: Install Hugo CLI\n        run: |\n          wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\n          && sudo dpkg -i ${{ runner.temp }}/hugo.deb          \n      - name: Install Dart Sass\n        run: sudo snap install dart-sass\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          submodules: recursive\n          fetch-depth: 0\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v5\n      - name: Install Node.js dependencies\n        run: \"[[ -f package-lock.json || -f npm-shrinkwrap.json ]] && npm ci || true\"\n      - name: Build with Hugo\n        env:\n          HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache\n          HUGO_ENVIRONMENT: production\n          TZ: America/Los_Angeles\n        run: |\n          hugo \\\n            --gc \\\n            --minify \\\n            --baseURL \"${{ steps.pages.outputs.base_url }}/\"          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./public\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "CurryTang/gfm_webpage",
    "path": ".github/workflows/hugo.yml",
    "url": "https://github.com/CurryTang/gfm_webpage/blob/3f9aa1c83f6db8245e598f420db2fea0a9a511e2/.github/workflows/hugo.yml",
    "retrieved_at": "2025-10-19T01:50:35.377414Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Hugo build process?",
    "answer": "# Sample workflow for building and deploying a Hugo site to GitHub Pages\nname: Deploy Hugo site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches:\n      - master\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\n# Default to bash\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    env:\n      HUGO_VERSION: 0.128.0\n    steps:\n      - name: Install Hugo CLI\n        run: |\n          wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\n          && sudo dpkg -i ${{ runner.temp }}/hugo.deb          \n      - name: Install Dart Sass\n        run: sudo snap install dart-sass\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          submodules: recursive\n          fetch-depth: 0\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v5\n      - name: Install Node.js dependencies\n        run: \"[[ -f package-lock.json || -f npm-shrinkwrap.json ]] && npm ci || true\"\n      - name: Build with Hugo\n        env:\n          HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache\n          HUGO_ENVIRONMENT: production\n          TZ: America/Los_Angeles\n        run: |\n          hugo \\\n            --gc \\\n            --minify \\\n            --baseURL \"${{ steps.pages.outputs.base_url }}/\"          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./public\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "CurryTang/gfm_webpage",
    "path": ".github/workflows/hugo.yml",
    "url": "https://github.com/CurryTang/gfm_webpage/blob/3f9aa1c83f6db8245e598f420db2fea0a9a511e2/.github/workflows/hugo.yml",
    "retrieved_at": "2025-10-19T01:50:35.905615Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this GitHub Actions workflow?",
    "answer": "# Sample workflow for building and deploying a Hugo site to GitHub Pages\nname: Deploy Hugo site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches:\n      - master\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\n# Default to bash\ndefaults:\n  run:\n    shell: bash\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    env:\n      HUGO_VERSION: 0.128.0\n    steps:\n      - name: Install Hugo CLI\n        run: |\n          wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\\n          && sudo dpkg -i ${{ runner.temp }}/hugo.deb          \n      - name: Install Dart Sass\n        run: sudo snap install dart-sass\n      - name: Checkout\n        uses: actions/checkout@v4\n        with:\n          submodules: recursive\n          fetch-depth: 0\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v5\n      - name: Install Node.js dependencies\n        run: \"[[ -f package-lock.json || -f npm-shrinkwrap.json ]] && npm ci || true\"\n      - name: Build with Hugo\n        env:\n          HUGO_CACHEDIR: ${{ runner.temp }}/hugo_cache\n          HUGO_ENVIRONMENT: production\n          TZ: America/Los_Angeles\n        run: |\n          hugo \\\n            --gc \\\n            --minify \\\n            --baseURL \"${{ steps.pages.outputs.base_url }}/\"          \n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./public\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "CurryTang/gfm_webpage",
    "path": ".github/workflows/hugo.yml",
    "url": "https://github.com/CurryTang/gfm_webpage/blob/3f9aa1c83f6db8245e598f420db2fea0a9a511e2/.github/workflows/hugo.yml",
    "retrieved_at": "2025-10-19T01:50:36.475900Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow definition.",
    "answer": "on:\n  workflow_dispatch:\n    inputs:\n      dispatch_token:\n        description: 'Token that authorize the dispatch'\n        required: true\n      head_sha:\n        description: 'Head commit SHA that dispatched the workflow'\n        required: true\n      pr_author_username:\n        description: 'Pull Request author username'\n        required: true\n      pr_number:\n        description: 'Pull Request number that dispatched the workflow'\n        required: true\n\njobs:\n  linter:\n    runs-on: self-hosted\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.inputs.pr_number }}\n\n  evaluator:\n    runs-on: self-hosted\n    needs: linter\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Jest evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/jest-evaluator-action\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/jest-evaluator\n          ref: v9\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v4\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run Jest evaluation\n        id: evaluator\n        uses: ./.github/actions/jest-evaluator\n        with:\n          pr_author_username: ${{ github.event.inputs.pr_author_username }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          pr-number: ${{ github.event.inputs.pr_number }}\n",
    "source": "Vitorlima02/projeto-trybers-and-dragons",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Vitorlima02/projeto-trybers-and-dragons/blob/b1193ce0c4992951680e3257680854ea7cf49530/.github/workflows/main.yml",
    "retrieved_at": "2025-10-19T01:50:37.228411Z",
    "question_style": "style_1"
  },
  {
    "question": "What inputs via `workflow_dispatch` trigger this GitHub Actions workflow?",
    "answer": "on:\n  workflow_dispatch:\n    inputs:\n      dispatch_token:\n        description: 'Token that authorize the dispatch'\n        required: true\n      head_sha:\n        description: 'Head commit SHA that dispatched the workflow'\n        required: true\n      pr_author_username:\n        description: 'Pull Request author username'\n        required: true\n      pr_number:\n        description: 'Pull Request number that dispatched the workflow'\n        required: true\n\njobs:\n  linter:\n    runs-on: self-hosted\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.inputs.pr_number }}\n\n  evaluator:\n    runs-on: self-hosted\n    needs: linter\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Jest evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/jest-evaluator-action\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/jest-evaluator\n          ref: v9\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v4\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run Jest evaluation\n        id: evaluator\n        uses: ./.github/actions/jest-evaluator\n        with:\n          pr_author_username: ${{ github.event.inputs.pr_author_username }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          pr-number: ${{ github.event.inputs.pr_number }}\n",
    "source": "Vitorlima02/projeto-trybers-and-dragons",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Vitorlima02/projeto-trybers-and-dragons/blob/b1193ce0c4992951680e3257680854ea7cf49530/.github/workflows/main.yml",
    "retrieved_at": "2025-10-19T01:50:37.808818Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently, and what dependencies exist between them?",
    "answer": "on:\n  workflow_dispatch:\n    inputs:\n      dispatch_token:\n        description: 'Token that authorize the dispatch'\n        required: true\n      head_sha:\n        description: 'Head commit SHA that dispatched the workflow'\n        required: true\n      pr_author_username:\n        description: 'Pull Request author username'\n        required: true\n      pr_number:\n        description: 'Pull Request number that dispatched the workflow'\n        required: true\n\njobs:\n  linter:\n    runs-on: self-hosted\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.inputs.pr_number }}\n\n  evaluator:\n    runs-on: self-hosted\n    needs: linter\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Jest evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/jest-evaluator-action\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/jest-evaluator\n          ref: v9\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v4\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run Jest evaluation\n        id: evaluator\n        uses: ./.github/actions/jest-evaluator\n        with:\n          pr_author_username: ${{ github.event.inputs.pr_author_username }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          pr-number: ${{ github.event.inputs.pr_number }}\n",
    "source": "Vitorlima02/projeto-trybers-and-dragons",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Vitorlima02/projeto-trybers-and-dragons/blob/b1193ce0c4992951680e3257680854ea7cf49530/.github/workflows/main.yml",
    "retrieved_at": "2025-10-19T01:50:38.383116Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `GIT_HUB_PAT` and `GITHUB_TOKEN` used across different actions and jobs?",
    "answer": "on:\n  workflow_dispatch:\n    inputs:\n      dispatch_token:\n        description: 'Token that authorize the dispatch'\n        required: true\n      head_sha:\n        description: 'Head commit SHA that dispatched the workflow'\n        required: true\n      pr_author_username:\n        description: 'Pull Request author username'\n        required: true\n      pr_number:\n        description: 'Pull Request number that dispatched the workflow'\n        required: true\n\njobs:\n  linter:\n    runs-on: self-hosted\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.inputs.pr_number }}\n\n  evaluator:\n    runs-on: self-hosted\n    needs: linter\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Jest evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/jest-evaluator-action\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/jest-evaluator\n          ref: v9\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v4\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run Jest evaluation\n        id: evaluator\n        uses: ./.github/actions/jest-evaluator\n        with:\n          pr_author_username: ${{ github.event.inputs.pr_author_username }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          pr-number: ${{ github.event.inputs.pr_number }}\n",
    "source": "Vitorlima02/projeto-trybers-and-dragons",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Vitorlima02/projeto-trybers-and-dragons/blob/b1193ce0c4992951680e3257680854ea7cf49530/.github/workflows/main.yml",
    "retrieved_at": "2025-10-19T01:50:39.024215Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this GitHub Actions workflow?",
    "answer": "on:\n  workflow_dispatch:\n    inputs:\n      dispatch_token:\n        description: 'Token that authorize the dispatch'\n        required: true\n      head_sha:\n        description: 'Head commit SHA that dispatched the workflow'\n        required: true\n      pr_author_username:\n        description: 'Pull Request author username'\n        required: true\n      pr_number:\n        description: 'Pull Request number that dispatched the workflow'\n        required: true\n\njobs:\n  linter:\n    runs-on: self-hosted\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.1\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.inputs.pr_number }}\n\n  evaluator:\n    runs-on: self-hosted\n    needs: linter\n\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v2\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Jest evaluator\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/jest-evaluator-action\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/jest-evaluator\n          ref: v9\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v2\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v4\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v1.4.4\n        with:\n          node-version: '14'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run Jest evaluation\n        id: evaluator\n        uses: ./.github/actions/jest-evaluator\n        with:\n          pr_author_username: ${{ github.event.inputs.pr_author_username }}\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          pr-number: ${{ github.event.inputs.pr_number }}\n",
    "source": "Vitorlima02/projeto-trybers-and-dragons",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Vitorlima02/projeto-trybers-and-dragons/blob/b1193ce0c4992951680e3257680854ea7cf49530/.github/workflows/main.yml",
    "retrieved_at": "2025-10-19T01:50:39.577727Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ master, stable ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ master, stable ]\n  schedule:\n    - cron: '41 12 * * 4'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-22.04\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'c', 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n\n    - run: |\n       sudo apt update && sudo apt -y install python3-twisted libpcap-dev libsodium-dev python3-pyroute2 python3-future python3-msgpack\n       make all_bin\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "tipoman9/wfb_fec",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/tipoman9/wfb_fec/blob/8d5b14cf92dbe286cc4e16d42beff4974ecfd427/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-20T01:48:09.732564Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the CodeQL workflow in this YAML configuration?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ master, stable ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ master, stable ]\n  schedule:\n    - cron: '41 12 * * 4'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-22.04\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'c', 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n\n    - run: |\n       sudo apt update && sudo apt -y install python3-twisted libpcap-dev libsodium-dev python3-pyroute2 python3-future python3-msgpack\n       make all_bin\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "tipoman9/wfb_fec",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/tipoman9/wfb_fec/blob/8d5b14cf92dbe286cc4e16d42beff4974ecfd427/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-20T01:48:10.277303Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"CodeQL\" workflow run in parallel or depend on the completion of other jobs or steps?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ master, stable ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ master, stable ]\n  schedule:\n    - cron: '41 12 * * 4'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-22.04\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'c', 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n\n    - run: |\n       sudo apt update && sudo apt -y install python3-twisted libpcap-dev libsodium-dev python3-pyroute2 python3-future python3-msgpack\n       make all_bin\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "tipoman9/wfb_fec",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/tipoman9/wfb_fec/blob/8d5b14cf92dbe286cc4e16d42beff4974ecfd427/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-20T01:48:10.893778Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any environment variables or secrets used within the `run` step to install dependencies or build the project?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ master, stable ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ master, stable ]\n  schedule:\n    - cron: '41 12 * * 4'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-22.04\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'c', 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n\n    - run: |\n       sudo apt update && sudo apt -y install python3-twisted libpcap-dev libsodium-dev python3-pyroute2 python3-future python3-msgpack\n       make all_bin\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "tipoman9/wfb_fec",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/tipoman9/wfb_fec/blob/8d5b14cf92dbe286cc4e16d42beff4974ecfd427/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-20T01:48:11.514498Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CodeQL workflow?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ master, stable ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ master, stable ]\n  schedule:\n    - cron: '41 12 * * 4'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-22.04\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'c', 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n\n    - run: |\n       sudo apt update && sudo apt -y install python3-twisted libpcap-dev libsodium-dev python3-pyroute2 python3-future python3-msgpack\n       make all_bin\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "tipoman9/wfb_fec",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/tipoman9/wfb_fec/blob/8d5b14cf92dbe286cc4e16d42beff4974ecfd427/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-20T01:48:12.053806Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that deploys to Firebase Hosting on pull requests using the provided configuration.",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on PR\n'on': pull_request\njobs:\n  build_and_preview:\n    if: '${{ github.event.pull_request.head.repo.full_name == github.repository }}'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-pull-request.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-pull-request.yml",
    "retrieved_at": "2025-10-20T01:48:12.785042Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on PR\n'on': pull_request\njobs:\n  build_and_preview:\n    if: '${{ github.event.pull_request.head.repo.full_name == github.repository }}'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-pull-request.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-pull-request.yml",
    "retrieved_at": "2025-10-20T01:48:13.279581Z",
    "question_style": "style_2"
  },
  {
    "question": "Which steps within the `build_and_preview` job run in parallel or sequentially?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on PR\n'on': pull_request\njobs:\n  build_and_preview:\n    if: '${{ github.event.pull_request.head.repo.full_name == github.repository }}'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-pull-request.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-pull-request.yml",
    "retrieved_at": "2025-10-20T01:48:13.909027Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the GITHUB_TOKEN and FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP secrets used for authentication and authorization?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on PR\n'on': pull_request\njobs:\n  build_and_preview:\n    if: '${{ github.event.pull_request.head.repo.full_name == github.repository }}'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-pull-request.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-pull-request.yml",
    "retrieved_at": "2025-10-20T01:48:14.583197Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow achieve when a pull request is created?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on PR\n'on': pull_request\njobs:\n  build_and_preview:\n    if: '${{ github.event.pull_request.head.repo.full_name == github.repository }}'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-pull-request.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-pull-request.yml",
    "retrieved_at": "2025-10-20T01:48:15.064166Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for CI builds and tests.",
    "answer": "name: 'CI'\n\non:\n  push:\n    branches: '**'\n  pull_request:\n    branches: '**'\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x, 14.x, 16.x, 18.x]\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          persist-credentials: false\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: npm\n      - run: npm ci\n      - run: npm test\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-21T01:42:26.605211Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch conditions trigger this CI workflow to run?",
    "answer": "name: 'CI'\n\non:\n  push:\n    branches: '**'\n  pull_request:\n    branches: '**'\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x, 14.x, 16.x, 18.x]\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          persist-credentials: false\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: npm\n      - run: npm ci\n      - run: npm test\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-21T01:42:27.213982Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'build' job run in parallel, or depend on the completion of others?",
    "answer": "name: 'CI'\n\non:\n  push:\n    branches: '**'\n  pull_request:\n    branches: '**'\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x, 14.x, 16.x, 18.x]\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          persist-credentials: false\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: npm\n      - run: npm ci\n      - run: npm test\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-21T01:42:27.909116Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the npm cache configured and utilized across different Node.js versions?",
    "answer": "name: 'CI'\n\non:\n  push:\n    branches: '**'\n  pull_request:\n    branches: '**'\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x, 14.x, 16.x, 18.x]\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          persist-credentials: false\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: npm\n      - run: npm ci\n      - run: npm test\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-21T01:42:28.583631Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or intended outcome of this CI workflow?",
    "answer": "name: 'CI'\n\non:\n  push:\n    branches: '**'\n  pull_request:\n    branches: '**'\n\npermissions:\n  contents: read\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x, 14.x, 16.x, 18.x]\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          persist-credentials: false\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: npm\n      - run: npm ci\n      - run: npm test\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-21T01:42:29.120783Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: build\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - \"*\"\n\njobs:\n  platformio-build:\n    strategy:\n      matrix:\n        type: [\"MCP3221\", \"MCP3021\"]\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install PlatformIO\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade platformio\n\n      - name: Compile ${{ matrix.type }}\n        run: |\n          pio ci --lib=\".\" --board=uno --board=zero --board=esp8285 --board=esp32dev --board=bluepill_f103c8\n        env:\n          PLATFORMIO_CI_SRC: examples/${{ matrix.type }}\n\n  arduino-build:\n    strategy:\n      matrix:\n        board: [\"UNO\", \"Zero\", \"ESP8266\", \"ESP32\", \"STM32F103C8\"]\n        include:\n          - board: \"UNO\"\n            platform: \"arduino:avr\"\n            fqbn: \"arduino:avr:uno\"\n            url: \"\"\n\n          - board: \"Zero\"\n            platform: \"arduino:samd\"\n            fqbn: \"arduino:samd:arduino_zero_native\"\n            url: \"\"\n\n          - board: \"ESP8266\"\n            platform: \"esp8266:esp8266\"\n            fqbn: \"esp8266:esp8266:esp8285\"\n            url: https://arduino.esp8266.com/stable/package_esp8266com_index.json\n\n          - board: \"ESP32\"\n            platform: \"esp32:esp32\"\n            fqbn: \"esp32:esp32:esp32\"\n            url: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json\n\n          - board: \"STM32F103C8\"\n            platform: \"STM32:stm32\"\n            fqbn: \"STM32:stm32:GenF1:pnum=BLUEPILL_F103C8\"\n            url: https://github.com/stm32duino/BoardManagerFiles/raw/master/STM32/package_stm_index.json\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Prepare\n        run: |\n          cp ./MCP3X21.cpp ./examples/MCP3221\n          cp ./MCP3X21.h ./examples/MCP3221\n          cp ./MCP3X21.cpp ./examples/MCP3021\n          cp ./MCP3X21.h ./examples/MCP3021\n\n      - name: Set up Python\n        if: ${{ matrix.board == 'ESP32' }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install pyserial\n        if: ${{ matrix.board == 'ESP32' }}\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade pyserial\n\n      - name: Setup Arduino CLI\n        uses: arduino/setup-arduino-cli@v1.1.1\n\n      - name: \"Install platform for ${{ matrix.board }}\"\n        run: |\n          arduino-cli core update-index\n          arduino-cli core install ${{ matrix.platform }}\n        env:\n          ARDUINO_BOARD_MANAGER_ADDITIONAL_URLS: ${{ matrix.url }}\n\n      - name: Compile MCP3221\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3221\n\n      - name: Compile MCP3021\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3021",
    "source": "pilotak/MCP3X21",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/pilotak/MCP3X21/blob/72b47656456c16fd51952376e8d8903233e262da/.github/workflows/build.yml",
    "retrieved_at": "2025-10-21T01:42:30.053977Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow to run?",
    "answer": "name: build\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - \"*\"\n\njobs:\n  platformio-build:\n    strategy:\n      matrix:\n        type: [\"MCP3221\", \"MCP3021\"]\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install PlatformIO\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade platformio\n\n      - name: Compile ${{ matrix.type }}\n        run: |\n          pio ci --lib=\".\" --board=uno --board=zero --board=esp8285 --board=esp32dev --board=bluepill_f103c8\n        env:\n          PLATFORMIO_CI_SRC: examples/${{ matrix.type }}\n\n  arduino-build:\n    strategy:\n      matrix:\n        board: [\"UNO\", \"Zero\", \"ESP8266\", \"ESP32\", \"STM32F103C8\"]\n        include:\n          - board: \"UNO\"\n            platform: \"arduino:avr\"\n            fqbn: \"arduino:avr:uno\"\n            url: \"\"\n\n          - board: \"Zero\"\n            platform: \"arduino:samd\"\n            fqbn: \"arduino:samd:arduino_zero_native\"\n            url: \"\"\n\n          - board: \"ESP8266\"\n            platform: \"esp8266:esp8266\"\n            fqbn: \"esp8266:esp8266:esp8285\"\n            url: https://arduino.esp8266.com/stable/package_esp8266com_index.json\n\n          - board: \"ESP32\"\n            platform: \"esp32:esp32\"\n            fqbn: \"esp32:esp32:esp32\"\n            url: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json\n\n          - board: \"STM32F103C8\"\n            platform: \"STM32:stm32\"\n            fqbn: \"STM32:stm32:GenF1:pnum=BLUEPILL_F103C8\"\n            url: https://github.com/stm32duino/BoardManagerFiles/raw/master/STM32/package_stm_index.json\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Prepare\n        run: |\n          cp ./MCP3X21.cpp ./examples/MCP3221\n          cp ./MCP3X21.h ./examples/MCP3221\n          cp ./MCP3X21.cpp ./examples/MCP3021\n          cp ./MCP3X21.h ./examples/MCP3021\n\n      - name: Set up Python\n        if: ${{ matrix.board == 'ESP32' }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install pyserial\n        if: ${{ matrix.board == 'ESP32' }}\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade pyserial\n\n      - name: Setup Arduino CLI\n        uses: arduino/setup-arduino-cli@v1.1.1\n\n      - name: \"Install platform for ${{ matrix.board }}\"\n        run: |\n          arduino-cli core update-index\n          arduino-cli core install ${{ matrix.platform }}\n        env:\n          ARDUINO_BOARD_MANAGER_ADDITIONAL_URLS: ${{ matrix.url }}\n\n      - name: Compile MCP3221\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3221\n\n      - name: Compile MCP3021\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3021",
    "source": "pilotak/MCP3X21",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/pilotak/MCP3X21/blob/72b47656456c16fd51952376e8d8903233e262da/.github/workflows/build.yml",
    "retrieved_at": "2025-10-21T01:42:30.640192Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: build\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - \"*\"\n\njobs:\n  platformio-build:\n    strategy:\n      matrix:\n        type: [\"MCP3221\", \"MCP3021\"]\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install PlatformIO\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade platformio\n\n      - name: Compile ${{ matrix.type }}\n        run: |\n          pio ci --lib=\".\" --board=uno --board=zero --board=esp8285 --board=esp32dev --board=bluepill_f103c8\n        env:\n          PLATFORMIO_CI_SRC: examples/${{ matrix.type }}\n\n  arduino-build:\n    strategy:\n      matrix:\n        board: [\"UNO\", \"Zero\", \"ESP8266\", \"ESP32\", \"STM32F103C8\"]\n        include:\n          - board: \"UNO\"\n            platform: \"arduino:avr\"\n            fqbn: \"arduino:avr:uno\"\n            url: \"\"\n\n          - board: \"Zero\"\n            platform: \"arduino:samd\"\n            fqbn: \"arduino:samd:arduino_zero_native\"\n            url: \"\"\n\n          - board: \"ESP8266\"\n            platform: \"esp8266:esp8266\"\n            fqbn: \"esp8266:esp8266:esp8285\"\n            url: https://arduino.esp8266.com/stable/package_esp8266com_index.json\n\n          - board: \"ESP32\"\n            platform: \"esp32:esp32\"\n            fqbn: \"esp32:esp32:esp32\"\n            url: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json\n\n          - board: \"STM32F103C8\"\n            platform: \"STM32:stm32\"\n            fqbn: \"STM32:stm32:GenF1:pnum=BLUEPILL_F103C8\"\n            url: https://github.com/stm32duino/BoardManagerFiles/raw/master/STM32/package_stm_index.json\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Prepare\n        run: |\n          cp ./MCP3X21.cpp ./examples/MCP3221\n          cp ./MCP3X21.h ./examples/MCP3221\n          cp ./MCP3X21.cpp ./examples/MCP3021\n          cp ./MCP3X21.h ./examples/MCP3021\n\n      - name: Set up Python\n        if: ${{ matrix.board == 'ESP32' }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install pyserial\n        if: ${{ matrix.board == 'ESP32' }}\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade pyserial\n\n      - name: Setup Arduino CLI\n        uses: arduino/setup-arduino-cli@v1.1.1\n\n      - name: \"Install platform for ${{ matrix.board }}\"\n        run: |\n          arduino-cli core update-index\n          arduino-cli core install ${{ matrix.platform }}\n        env:\n          ARDUINO_BOARD_MANAGER_ADDITIONAL_URLS: ${{ matrix.url }}\n\n      - name: Compile MCP3221\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3221\n\n      - name: Compile MCP3021\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3021",
    "source": "pilotak/MCP3X21",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/pilotak/MCP3X21/blob/72b47656456c16fd51952376e8d8903233e262da/.github/workflows/build.yml",
    "retrieved_at": "2025-10-21T01:42:31.622770Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the `arduino-cli` tool?",
    "answer": "name: build\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - \"*\"\n\njobs:\n  platformio-build:\n    strategy:\n      matrix:\n        type: [\"MCP3221\", \"MCP3021\"]\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install PlatformIO\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade platformio\n\n      - name: Compile ${{ matrix.type }}\n        run: |\n          pio ci --lib=\".\" --board=uno --board=zero --board=esp8285 --board=esp32dev --board=bluepill_f103c8\n        env:\n          PLATFORMIO_CI_SRC: examples/${{ matrix.type }}\n\n  arduino-build:\n    strategy:\n      matrix:\n        board: [\"UNO\", \"Zero\", \"ESP8266\", \"ESP32\", \"STM32F103C8\"]\n        include:\n          - board: \"UNO\"\n            platform: \"arduino:avr\"\n            fqbn: \"arduino:avr:uno\"\n            url: \"\"\n\n          - board: \"Zero\"\n            platform: \"arduino:samd\"\n            fqbn: \"arduino:samd:arduino_zero_native\"\n            url: \"\"\n\n          - board: \"ESP8266\"\n            platform: \"esp8266:esp8266\"\n            fqbn: \"esp8266:esp8266:esp8285\"\n            url: https://arduino.esp8266.com/stable/package_esp8266com_index.json\n\n          - board: \"ESP32\"\n            platform: \"esp32:esp32\"\n            fqbn: \"esp32:esp32:esp32\"\n            url: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json\n\n          - board: \"STM32F103C8\"\n            platform: \"STM32:stm32\"\n            fqbn: \"STM32:stm32:GenF1:pnum=BLUEPILL_F103C8\"\n            url: https://github.com/stm32duino/BoardManagerFiles/raw/master/STM32/package_stm_index.json\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Prepare\n        run: |\n          cp ./MCP3X21.cpp ./examples/MCP3221\n          cp ./MCP3X21.h ./examples/MCP3221\n          cp ./MCP3X21.cpp ./examples/MCP3021\n          cp ./MCP3X21.h ./examples/MCP3021\n\n      - name: Set up Python\n        if: ${{ matrix.board == 'ESP32' }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install pyserial\n        if: ${{ matrix.board == 'ESP32' }}\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade pyserial\n\n      - name: Setup Arduino CLI\n        uses: arduino/setup-arduino-cli@v1.1.1\n\n      - name: \"Install platform for ${{ matrix.board }}\"\n        run: |\n          arduino-cli core update-index\n          arduino-cli core install ${{ matrix.platform }}\n        env:\n          ARDUINO_BOARD_MANAGER_ADDITIONAL_URLS: ${{ matrix.url }}\n\n      - name: Compile MCP3221\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3221\n\n      - name: Compile MCP3021\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3021",
    "source": "pilotak/MCP3X21",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/pilotak/MCP3X21/blob/72b47656456c16fd51952376e8d8903233e262da/.github/workflows/build.yml",
    "retrieved_at": "2025-10-21T01:42:32.390870Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow?",
    "answer": "name: build\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - \"*\"\n\njobs:\n  platformio-build:\n    strategy:\n      matrix:\n        type: [\"MCP3221\", \"MCP3021\"]\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install PlatformIO\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade platformio\n\n      - name: Compile ${{ matrix.type }}\n        run: |\n          pio ci --lib=\".\" --board=uno --board=zero --board=esp8285 --board=esp32dev --board=bluepill_f103c8\n        env:\n          PLATFORMIO_CI_SRC: examples/${{ matrix.type }}\n\n  arduino-build:\n    strategy:\n      matrix:\n        board: [\"UNO\", \"Zero\", \"ESP8266\", \"ESP32\", \"STM32F103C8\"]\n        include:\n          - board: \"UNO\"\n            platform: \"arduino:avr\"\n            fqbn: \"arduino:avr:uno\"\n            url: \"\"\n\n          - board: \"Zero\"\n            platform: \"arduino:samd\"\n            fqbn: \"arduino:samd:arduino_zero_native\"\n            url: \"\"\n\n          - board: \"ESP8266\"\n            platform: \"esp8266:esp8266\"\n            fqbn: \"esp8266:esp8266:esp8285\"\n            url: https://arduino.esp8266.com/stable/package_esp8266com_index.json\n\n          - board: \"ESP32\"\n            platform: \"esp32:esp32\"\n            fqbn: \"esp32:esp32:esp32\"\n            url: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json\n\n          - board: \"STM32F103C8\"\n            platform: \"STM32:stm32\"\n            fqbn: \"STM32:stm32:GenF1:pnum=BLUEPILL_F103C8\"\n            url: https://github.com/stm32duino/BoardManagerFiles/raw/master/STM32/package_stm_index.json\n\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Prepare\n        run: |\n          cp ./MCP3X21.cpp ./examples/MCP3221\n          cp ./MCP3X21.h ./examples/MCP3221\n          cp ./MCP3X21.cpp ./examples/MCP3021\n          cp ./MCP3X21.h ./examples/MCP3021\n\n      - name: Set up Python\n        if: ${{ matrix.board == 'ESP32' }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: \"3.8\"\n\n      - name: Install pyserial\n        if: ${{ matrix.board == 'ESP32' }}\n        run: |\n          python -m pip install --upgrade pip\n          pip install --upgrade pyserial\n\n      - name: Setup Arduino CLI\n        uses: arduino/setup-arduino-cli@v1.1.1\n\n      - name: \"Install platform for ${{ matrix.board }}\"\n        run: |\n          arduino-cli core update-index\n          arduino-cli core install ${{ matrix.platform }}\n        env:\n          ARDUINO_BOARD_MANAGER_ADDITIONAL_URLS: ${{ matrix.url }}\n\n      - name: Compile MCP3221\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3221\n\n      - name: Compile MCP3021\n        run: arduino-cli compile --fqbn ${{ matrix.fqbn }} ./examples/MCP3021",
    "source": "pilotak/MCP3X21",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/pilotak/MCP3X21/blob/72b47656456c16fd51952376e8d8903233e262da/.github/workflows/build.yml",
    "retrieved_at": "2025-10-21T01:42:33.028260Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML that replicates the functionality of the provided workflow for uploading a Python package on release.",
    "answer": "name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.x'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install build\n    - name: Build package\n      run: python -m build\n    - name: Publish package\n      uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29\n      with:\n        user: __token__\n        password: ${{ secrets.PYPI_API_TOKEN }}\n",
    "source": "trevorbayless/cli-chess",
    "path": ".github/workflows/pypi-publish.yml",
    "url": "https://github.com/trevorbayless/cli-chess/blob/206974839ac7196a479f3cb41804424825b75fce/.github/workflows/pypi-publish.yml",
    "retrieved_at": "2025-10-22T01:45:22.232134Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and type of event trigger this GitHub Actions workflow?",
    "answer": "name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.x'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install build\n    - name: Build package\n      run: python -m build\n    - name: Publish package\n      uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29\n      with:\n        user: __token__\n        password: ${{ secrets.PYPI_API_TOKEN }}\n",
    "source": "trevorbayless/cli-chess",
    "path": ".github/workflows/pypi-publish.yml",
    "url": "https://github.com/trevorbayless/cli-chess/blob/206974839ac7196a479f3cb41804424825b75fce/.github/workflows/pypi-publish.yml",
    "retrieved_at": "2025-10-22T01:45:22.837939Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow execute concurrently or have sequential dependencies?",
    "answer": "name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.x'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install build\n    - name: Build package\n      run: python -m build\n    - name: Publish package\n      uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29\n      with:\n        user: __token__\n        password: ${{ secrets.PYPI_API_TOKEN }}\n",
    "source": "trevorbayless/cli-chess",
    "path": ".github/workflows/pypi-publish.yml",
    "url": "https://github.com/trevorbayless/cli-chess/blob/206974839ac7196a479f3cb41804424825b75fce/.github/workflows/pypi-publish.yml",
    "retrieved_at": "2025-10-22T01:45:24.264033Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `PYPI_API_TOKEN` secret used for authentication when publishing the Python package?",
    "answer": "name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.x'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install build\n    - name: Build package\n      run: python -m build\n    - name: Publish package\n      uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29\n      with:\n        user: __token__\n        password: ${{ secrets.PYPI_API_TOKEN }}\n",
    "source": "trevorbayless/cli-chess",
    "path": ".github/workflows/pypi-publish.yml",
    "url": "https://github.com/trevorbayless/cli-chess/blob/206974839ac7196a479f3cb41804424825b75fce/.github/workflows/pypi-publish.yml",
    "retrieved_at": "2025-10-22T01:45:25.867486Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when a release is published?",
    "answer": "name: Upload Python Package\n\non:\n  release:\n    types: [published]\n\npermissions:\n  contents: read\n\njobs:\n  deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v3\n      with:\n        python-version: '3.x'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install build\n    - name: Build package\n      run: python -m build\n    - name: Publish package\n      uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29\n      with:\n        user: __token__\n        password: ${{ secrets.PYPI_API_TOKEN }}\n",
    "source": "trevorbayless/cli-chess",
    "path": ".github/workflows/pypi-publish.yml",
    "url": "https://github.com/trevorbayless/cli-chess/blob/206974839ac7196a479f3cb41804424825b75fce/.github/workflows/pypi-publish.yml",
    "retrieved_at": "2025-10-22T01:45:26.437151Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including scheduling, fetching data, updating files, and committing changes.",
    "answer": "name: 2 Time\n\non:\n  schedule:\n    - cron: '35 */8 * * *'  # 8\n  workflow_dispatch:        # \n\npermissions:\n  contents: write\n  actions: write\n\njobs:\n  update-nodes:\n    runs-on: ubuntu-latest\n    env:\n      TZ: Asia/Shanghai  # \n\n    steps:\n    - name: Checkout current repository\n      uses: actions/checkout@v4\n\n    - name: Record Start Time\n      id: start_time\n      run: |\n        echo \"START_TIME=$(date +'%Y-%m-%d %H:%M:%S')\" >> $GITHUB_ENV\n        echo \"::debug::Start Time Recorded: ${{ env.START_TIME }}\"\n\n    - name: Fetch and Clean Webpage Content\n      run: |\n        VMESS_URL=\"${{ secrets.VMESS_URL }}\"\n        SS_URL=\"${{ secrets.SS_URL }}\"\n        \n        echo \"::debug::Fetching VMESS content from: $VMESS_URL\" >&2\n        curl -s \"$VMESS_URL\" | sed 's/<[^>]*>//g' > webpage_content.txt\n        \n        echo \"::debug::Fetching SS content from: $SS_URL\" >&2\n        curl -s \"$SS_URL\" | sed 's/<[^>]*>//g' > ss_webpage_content.txt\n\n    - name: Fetch and Update Nodes from Content Files\n      run: |\n        VMESS_NODES=$(grep -oP '.*vmess://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        VLESS_NODES=$(grep -oP '.*vless://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        SS_NODES=$(grep -oP '.*(ss://|ssr://)\\S+' ss_webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        \n        echo \"$VMESS_NODES\" > dizhi1.txt\n        echo \"$VLESS_NODES\" > dizhi2.txt\n        echo \"$SS_NODES\" > dizhi3.txt\n\n    - name: Checkout target repository\n      uses: actions/checkout@v4\n      with:\n        repository: ${{ secrets.TARGET_REPO }}\n        token: ${{ secrets.TARGET_PAT }}\n        path: target-repo\n        fetch-depth: 0\n\n    - name: Retrieve existing timestamp\n      run: |\n        if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ]; then\n          cp \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ./ || true\n          echo \"::debug::Copied existing timestamp file\"\n        else\n          echo \"::debug::No existing timestamp file found\"\n        fi\n\n    - name: Update timestamp file\n      run: |\n        CURRENT_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        declare -A timestamps\n        \n        # \n        if [ -f \"timestamp.txt\" ]; then\n          while IFS=: read -r key value; do\n            timestamps[\"$key\"]=\"$value\"\n          done < timestamp.txt\n        fi\n\n        # \n        check_diff() {\n          local file=\"$1\"\n          local target_file=\"target-repo/${{ secrets.TARGET_FOLDER }}/$file\"\n          if [ -f \"$target_file\" ] && ! diff -q \"$file\" \"$target_file\" >/dev/null; then\n            return 0\n          else\n            return 1\n          fi\n        }\n\n        # \n        for i in 1 2 3; do\n          file=\"dizhi${i}.txt\"\n          if check_diff \"$file\"; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Updated timestamp for $file\"\n          elif [ -z \"${timestamps[$file]}\" ]; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Initialized timestamp for $file\"\n          fi\n        done\n\n        # \n        printf \"dizhi1.txt:%s\\ndizhi2.txt:%s\\ndizhi3.txt:%s\\n\" \\\n          \"${timestamps[dizhi1.txt]}\" \\\n          \"${timestamps[dizhi2.txt]}\" \\\n          \"${timestamps[dizhi3.txt]}\" > timestamp.txt\n\n    - name: Copy files to target repository\n      run: |\n        cp -v dizhi*.txt ss_webpage_content.txt webpage_content.txt timestamp.txt \"target-repo/${{ secrets.TARGET_FOLDER }}/\"\n\n    - name: Record End Time and Calculate Duration\n      id: end_time\n      run: |\n        END_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        START_SEC=$(date -d \"${{ env.START_TIME }}\" +%s)\n        END_SEC=$(date -d \"$END_TIME\" +%s)\n        DURATION=$((END_SEC - START_SEC))\n        FORMATTED_DURATION=$(printf \"%02d:%02d:%02d\" $((DURATION/3600)) $((DURATION%3600/60)) $((DURATION%60)))\n        echo \"END_TIME=$END_TIME\" >> $GITHUB_ENV\n        echo \"DURATION=$FORMATTED_DURATION\" >> $GITHUB_ENV\n\n    - name: Append Report Link to dizhiR.txt\n      run: |\n        # \n        declare -A timestamp_dates\n        while IFS=: read -r key value; do\n          timestamp_dates[\"$key\"]=\"$value\"\n        done < \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\"\n\n        # \n        CURRENT_SEC=$(date +%s)\n        get_days_diff() {\n          local file_date=\"$1\"\n          local file_sec=$(date -d \"$file_date\" +%s)\n          echo \"scale=1; ($CURRENT_SEC - $file_sec)/86400\" | bc -l | xargs printf \"%.1f\"\n        }\n\n        D1_DAYS=$(get_days_diff \"${timestamp_dates[dizhi1.txt]}\")\n        D2_DAYS=$(get_days_diff \"${timestamp_dates[dizhi2.txt]}\")\n        D3_DAYS=$(get_days_diff \"${timestamp_dates[dizhi3.txt]}\")\n\n        # \n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A ${{ env.START_TIME }} : ${{ env.DURATION }}\" > target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A vm:${D1_DAYS} vl:${D2_DAYS} ss:${D3_DAYS}\" >> target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n\n    - name: Generate dizhi123.txt\n      run: |\n        {\n          # \n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi1.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi2.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi3.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n          echo -e\n          \n          #  myDizhi.txt \n          if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\" ]; then\n            grep -E '^(vmess|vless|ss|ssr)://' target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\n          fi\n        } > target-repo/${{ secrets.TARGET_FOLDER }}/dizhi123.txt\n\n    - name: Commit and Push changes\n      run: |\n        cd target-repo\n        git config --global user.name \"GitHub Actions Bot\"\n        git config --global user.email \"github-actions-bot@users.noreply.github.com\"\n        \n        git add .\n        COMMIT_MESSAGE=\"Auto-update at ${{ env.END_TIME }}\"\n        if git commit -m \"$COMMIT_MESSAGE\"; then\n          git push origin main\n        else\n          echo \"::debug::No changes to commit\"\n        fi\n\n    - name: Delete workflow runs\n      uses: Mattraks/delete-workflow-runs@v2\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        repository: ${{ github.repository }}\n        retain_days: 0\n        keep_minimum_runs: 2\n",
    "source": "imm515/dizhi123a",
    "path": ".github/workflows/2 timestamps.yml",
    "url": "https://github.com/imm515/dizhi123a/blob/dd59e4d74f2ead7cdfc40b61df5a30e590329b1b/.github/workflows/2%20timestamps.yml",
    "retrieved_at": "2025-10-22T01:45:27.359463Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow?",
    "answer": "name: 2 Time\n\non:\n  schedule:\n    - cron: '35 */8 * * *'  # 8\n  workflow_dispatch:        # \n\npermissions:\n  contents: write\n  actions: write\n\njobs:\n  update-nodes:\n    runs-on: ubuntu-latest\n    env:\n      TZ: Asia/Shanghai  # \n\n    steps:\n    - name: Checkout current repository\n      uses: actions/checkout@v4\n\n    - name: Record Start Time\n      id: start_time\n      run: |\n        echo \"START_TIME=$(date +'%Y-%m-%d %H:%M:%S')\" >> $GITHUB_ENV\n        echo \"::debug::Start Time Recorded: ${{ env.START_TIME }}\"\n\n    - name: Fetch and Clean Webpage Content\n      run: |\n        VMESS_URL=\"${{ secrets.VMESS_URL }}\"\n        SS_URL=\"${{ secrets.SS_URL }}\"\n        \n        echo \"::debug::Fetching VMESS content from: $VMESS_URL\" >&2\n        curl -s \"$VMESS_URL\" | sed 's/<[^>]*>//g' > webpage_content.txt\n        \n        echo \"::debug::Fetching SS content from: $SS_URL\" >&2\n        curl -s \"$SS_URL\" | sed 's/<[^>]*>//g' > ss_webpage_content.txt\n\n    - name: Fetch and Update Nodes from Content Files\n      run: |\n        VMESS_NODES=$(grep -oP '.*vmess://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        VLESS_NODES=$(grep -oP '.*vless://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        SS_NODES=$(grep -oP '.*(ss://|ssr://)\\S+' ss_webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        \n        echo \"$VMESS_NODES\" > dizhi1.txt\n        echo \"$VLESS_NODES\" > dizhi2.txt\n        echo \"$SS_NODES\" > dizhi3.txt\n\n    - name: Checkout target repository\n      uses: actions/checkout@v4\n      with:\n        repository: ${{ secrets.TARGET_REPO }}\n        token: ${{ secrets.TARGET_PAT }}\n        path: target-repo\n        fetch-depth: 0\n\n    - name: Retrieve existing timestamp\n      run: |\n        if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ]; then\n          cp \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ./ || true\n          echo \"::debug::Copied existing timestamp file\"\n        else\n          echo \"::debug::No existing timestamp file found\"\n        fi\n\n    - name: Update timestamp file\n      run: |\n        CURRENT_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        declare -A timestamps\n        \n        # \n        if [ -f \"timestamp.txt\" ]; then\n          while IFS=: read -r key value; do\n            timestamps[\"$key\"]=\"$value\"\n          done < timestamp.txt\n        fi\n\n        # \n        check_diff() {\n          local file=\"$1\"\n          local target_file=\"target-repo/${{ secrets.TARGET_FOLDER }}/$file\"\n          if [ -f \"$target_file\" ] && ! diff -q \"$file\" \"$target_file\" >/dev/null; then\n            return 0\n          else\n            return 1\n          fi\n        }\n\n        # \n        for i in 1 2 3; do\n          file=\"dizhi${i}.txt\"\n          if check_diff \"$file\"; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Updated timestamp for $file\"\n          elif [ -z \"${timestamps[$file]}\" ]; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Initialized timestamp for $file\"\n          fi\n        done\n\n        # \n        printf \"dizhi1.txt:%s\\ndizhi2.txt:%s\\ndizhi3.txt:%s\\n\" \\\n          \"${timestamps[dizhi1.txt]}\" \\\n          \"${timestamps[dizhi2.txt]}\" \\\n          \"${timestamps[dizhi3.txt]}\" > timestamp.txt\n\n    - name: Copy files to target repository\n      run: |\n        cp -v dizhi*.txt ss_webpage_content.txt webpage_content.txt timestamp.txt \"target-repo/${{ secrets.TARGET_FOLDER }}/\"\n\n    - name: Record End Time and Calculate Duration\n      id: end_time\n      run: |\n        END_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        START_SEC=$(date -d \"${{ env.START_TIME }}\" +%s)\n        END_SEC=$(date -d \"$END_TIME\" +%s)\n        DURATION=$((END_SEC - START_SEC))\n        FORMATTED_DURATION=$(printf \"%02d:%02d:%02d\" $((DURATION/3600)) $((DURATION%3600/60)) $((DURATION%60)))\n        echo \"END_TIME=$END_TIME\" >> $GITHUB_ENV\n        echo \"DURATION=$FORMATTED_DURATION\" >> $GITHUB_ENV\n\n    - name: Append Report Link to dizhiR.txt\n      run: |\n        # \n        declare -A timestamp_dates\n        while IFS=: read -r key value; do\n          timestamp_dates[\"$key\"]=\"$value\"\n        done < \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\"\n\n        # \n        CURRENT_SEC=$(date +%s)\n        get_days_diff() {\n          local file_date=\"$1\"\n          local file_sec=$(date -d \"$file_date\" +%s)\n          echo \"scale=1; ($CURRENT_SEC - $file_sec)/86400\" | bc -l | xargs printf \"%.1f\"\n        }\n\n        D1_DAYS=$(get_days_diff \"${timestamp_dates[dizhi1.txt]}\")\n        D2_DAYS=$(get_days_diff \"${timestamp_dates[dizhi2.txt]}\")\n        D3_DAYS=$(get_days_diff \"${timestamp_dates[dizhi3.txt]}\")\n\n        # \n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A ${{ env.START_TIME }} : ${{ env.DURATION }}\" > target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A vm:${D1_DAYS} vl:${D2_DAYS} ss:${D3_DAYS}\" >> target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n\n    - name: Generate dizhi123.txt\n      run: |\n        {\n          # \n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi1.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi2.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi3.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n          echo -e\n          \n          #  myDizhi.txt \n          if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\" ]; then\n            grep -E '^(vmess|vless|ss|ssr)://' target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\n          fi\n        } > target-repo/${{ secrets.TARGET_FOLDER }}/dizhi123.txt\n\n    - name: Commit and Push changes\n      run: |\n        cd target-repo\n        git config --global user.name \"GitHub Actions Bot\"\n        git config --global user.email \"github-actions-bot@users.noreply.github.com\"\n        \n        git add .\n        COMMIT_MESSAGE=\"Auto-update at ${{ env.END_TIME }}\"\n        if git commit -m \"$COMMIT_MESSAGE\"; then\n          git push origin main\n        else\n          echo \"::debug::No changes to commit\"\n        fi\n\n    - name: Delete workflow runs\n      uses: Mattraks/delete-workflow-runs@v2\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        repository: ${{ github.repository }}\n        retain_days: 0\n        keep_minimum_runs: 2\n",
    "source": "imm515/dizhi123a",
    "path": ".github/workflows/2 timestamps.yml",
    "url": "https://github.com/imm515/dizhi123a/blob/dd59e4d74f2ead7cdfc40b61df5a30e590329b1b/.github/workflows/2%20timestamps.yml",
    "retrieved_at": "2025-10-22T01:45:28.078082Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel or depend on the output of previous steps?",
    "answer": "name: 2 Time\n\non:\n  schedule:\n    - cron: '35 */8 * * *'  # 8\n  workflow_dispatch:        # \n\npermissions:\n  contents: write\n  actions: write\n\njobs:\n  update-nodes:\n    runs-on: ubuntu-latest\n    env:\n      TZ: Asia/Shanghai  # \n\n    steps:\n    - name: Checkout current repository\n      uses: actions/checkout@v4\n\n    - name: Record Start Time\n      id: start_time\n      run: |\n        echo \"START_TIME=$(date +'%Y-%m-%d %H:%M:%S')\" >> $GITHUB_ENV\n        echo \"::debug::Start Time Recorded: ${{ env.START_TIME }}\"\n\n    - name: Fetch and Clean Webpage Content\n      run: |\n        VMESS_URL=\"${{ secrets.VMESS_URL }}\"\n        SS_URL=\"${{ secrets.SS_URL }}\"\n        \n        echo \"::debug::Fetching VMESS content from: $VMESS_URL\" >&2\n        curl -s \"$VMESS_URL\" | sed 's/<[^>]*>//g' > webpage_content.txt\n        \n        echo \"::debug::Fetching SS content from: $SS_URL\" >&2\n        curl -s \"$SS_URL\" | sed 's/<[^>]*>//g' > ss_webpage_content.txt\n\n    - name: Fetch and Update Nodes from Content Files\n      run: |\n        VMESS_NODES=$(grep -oP '.*vmess://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        VLESS_NODES=$(grep -oP '.*vless://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        SS_NODES=$(grep -oP '.*(ss://|ssr://)\\S+' ss_webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        \n        echo \"$VMESS_NODES\" > dizhi1.txt\n        echo \"$VLESS_NODES\" > dizhi2.txt\n        echo \"$SS_NODES\" > dizhi3.txt\n\n    - name: Checkout target repository\n      uses: actions/checkout@v4\n      with:\n        repository: ${{ secrets.TARGET_REPO }}\n        token: ${{ secrets.TARGET_PAT }}\n        path: target-repo\n        fetch-depth: 0\n\n    - name: Retrieve existing timestamp\n      run: |\n        if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ]; then\n          cp \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ./ || true\n          echo \"::debug::Copied existing timestamp file\"\n        else\n          echo \"::debug::No existing timestamp file found\"\n        fi\n\n    - name: Update timestamp file\n      run: |\n        CURRENT_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        declare -A timestamps\n        \n        # \n        if [ -f \"timestamp.txt\" ]; then\n          while IFS=: read -r key value; do\n            timestamps[\"$key\"]=\"$value\"\n          done < timestamp.txt\n        fi\n\n        # \n        check_diff() {\n          local file=\"$1\"\n          local target_file=\"target-repo/${{ secrets.TARGET_FOLDER }}/$file\"\n          if [ -f \"$target_file\" ] && ! diff -q \"$file\" \"$target_file\" >/dev/null; then\n            return 0\n          else\n            return 1\n          fi\n        }\n\n        # \n        for i in 1 2 3; do\n          file=\"dizhi${i}.txt\"\n          if check_diff \"$file\"; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Updated timestamp for $file\"\n          elif [ -z \"${timestamps[$file]}\" ]; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Initialized timestamp for $file\"\n          fi\n        done\n\n        # \n        printf \"dizhi1.txt:%s\\ndizhi2.txt:%s\\ndizhi3.txt:%s\\n\" \\\n          \"${timestamps[dizhi1.txt]}\" \\\n          \"${timestamps[dizhi2.txt]}\" \\\n          \"${timestamps[dizhi3.txt]}\" > timestamp.txt\n\n    - name: Copy files to target repository\n      run: |\n        cp -v dizhi*.txt ss_webpage_content.txt webpage_content.txt timestamp.txt \"target-repo/${{ secrets.TARGET_FOLDER }}/\"\n\n    - name: Record End Time and Calculate Duration\n      id: end_time\n      run: |\n        END_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        START_SEC=$(date -d \"${{ env.START_TIME }}\" +%s)\n        END_SEC=$(date -d \"$END_TIME\" +%s)\n        DURATION=$((END_SEC - START_SEC))\n        FORMATTED_DURATION=$(printf \"%02d:%02d:%02d\" $((DURATION/3600)) $((DURATION%3600/60)) $((DURATION%60)))\n        echo \"END_TIME=$END_TIME\" >> $GITHUB_ENV\n        echo \"DURATION=$FORMATTED_DURATION\" >> $GITHUB_ENV\n\n    - name: Append Report Link to dizhiR.txt\n      run: |\n        # \n        declare -A timestamp_dates\n        while IFS=: read -r key value; do\n          timestamp_dates[\"$key\"]=\"$value\"\n        done < \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\"\n\n        # \n        CURRENT_SEC=$(date +%s)\n        get_days_diff() {\n          local file_date=\"$1\"\n          local file_sec=$(date -d \"$file_date\" +%s)\n          echo \"scale=1; ($CURRENT_SEC - $file_sec)/86400\" | bc -l | xargs printf \"%.1f\"\n        }\n\n        D1_DAYS=$(get_days_diff \"${timestamp_dates[dizhi1.txt]}\")\n        D2_DAYS=$(get_days_diff \"${timestamp_dates[dizhi2.txt]}\")\n        D3_DAYS=$(get_days_diff \"${timestamp_dates[dizhi3.txt]}\")\n\n        # \n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A ${{ env.START_TIME }} : ${{ env.DURATION }}\" > target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A vm:${D1_DAYS} vl:${D2_DAYS} ss:${D3_DAYS}\" >> target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n\n    - name: Generate dizhi123.txt\n      run: |\n        {\n          # \n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi1.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi2.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi3.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n          echo -e\n          \n          #  myDizhi.txt \n          if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\" ]; then\n            grep -E '^(vmess|vless|ss|ssr)://' target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\n          fi\n        } > target-repo/${{ secrets.TARGET_FOLDER }}/dizhi123.txt\n\n    - name: Commit and Push changes\n      run: |\n        cd target-repo\n        git config --global user.name \"GitHub Actions Bot\"\n        git config --global user.email \"github-actions-bot@users.noreply.github.com\"\n        \n        git add .\n        COMMIT_MESSAGE=\"Auto-update at ${{ env.END_TIME }}\"\n        if git commit -m \"$COMMIT_MESSAGE\"; then\n          git push origin main\n        else\n          echo \"::debug::No changes to commit\"\n        fi\n\n    - name: Delete workflow runs\n      uses: Mattraks/delete-workflow-runs@v2\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        repository: ${{ github.repository }}\n        retain_days: 0\n        keep_minimum_runs: 2\n",
    "source": "imm515/dizhi123a",
    "path": ".github/workflows/2 timestamps.yml",
    "url": "https://github.com/imm515/dizhi123a/blob/dd59e4d74f2ead7cdfc40b61df5a30e590329b1b/.github/workflows/2%20timestamps.yml",
    "retrieved_at": "2025-10-22T01:45:28.751595Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `VMESS_URL`, `SS_URL`, `TARGET_REPO`, `TARGET_PAT`, `TARGET_FOLDER`, and `GITHUB_TOKEN` used to access resources and repositories?",
    "answer": "name: 2 Time\n\non:\n  schedule:\n    - cron: '35 */8 * * *'  # 8\n  workflow_dispatch:        # \n\npermissions:\n  contents: write\n  actions: write\n\njobs:\n  update-nodes:\n    runs-on: ubuntu-latest\n    env:\n      TZ: Asia/Shanghai  # \n\n    steps:\n    - name: Checkout current repository\n      uses: actions/checkout@v4\n\n    - name: Record Start Time\n      id: start_time\n      run: |\n        echo \"START_TIME=$(date +'%Y-%m-%d %H:%M:%S')\" >> $GITHUB_ENV\n        echo \"::debug::Start Time Recorded: ${{ env.START_TIME }}\"\n\n    - name: Fetch and Clean Webpage Content\n      run: |\n        VMESS_URL=\"${{ secrets.VMESS_URL }}\"\n        SS_URL=\"${{ secrets.SS_URL }}\"\n        \n        echo \"::debug::Fetching VMESS content from: $VMESS_URL\" >&2\n        curl -s \"$VMESS_URL\" | sed 's/<[^>]*>//g' > webpage_content.txt\n        \n        echo \"::debug::Fetching SS content from: $SS_URL\" >&2\n        curl -s \"$SS_URL\" | sed 's/<[^>]*>//g' > ss_webpage_content.txt\n\n    - name: Fetch and Update Nodes from Content Files\n      run: |\n        VMESS_NODES=$(grep -oP '.*vmess://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        VLESS_NODES=$(grep -oP '.*vless://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        SS_NODES=$(grep -oP '.*(ss://|ssr://)\\S+' ss_webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        \n        echo \"$VMESS_NODES\" > dizhi1.txt\n        echo \"$VLESS_NODES\" > dizhi2.txt\n        echo \"$SS_NODES\" > dizhi3.txt\n\n    - name: Checkout target repository\n      uses: actions/checkout@v4\n      with:\n        repository: ${{ secrets.TARGET_REPO }}\n        token: ${{ secrets.TARGET_PAT }}\n        path: target-repo\n        fetch-depth: 0\n\n    - name: Retrieve existing timestamp\n      run: |\n        if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ]; then\n          cp \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ./ || true\n          echo \"::debug::Copied existing timestamp file\"\n        else\n          echo \"::debug::No existing timestamp file found\"\n        fi\n\n    - name: Update timestamp file\n      run: |\n        CURRENT_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        declare -A timestamps\n        \n        # \n        if [ -f \"timestamp.txt\" ]; then\n          while IFS=: read -r key value; do\n            timestamps[\"$key\"]=\"$value\"\n          done < timestamp.txt\n        fi\n\n        # \n        check_diff() {\n          local file=\"$1\"\n          local target_file=\"target-repo/${{ secrets.TARGET_FOLDER }}/$file\"\n          if [ -f \"$target_file\" ] && ! diff -q \"$file\" \"$target_file\" >/dev/null; then\n            return 0\n          else\n            return 1\n          fi\n        }\n\n        # \n        for i in 1 2 3; do\n          file=\"dizhi${i}.txt\"\n          if check_diff \"$file\"; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Updated timestamp for $file\"\n          elif [ -z \"${timestamps[$file]}\" ]; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Initialized timestamp for $file\"\n          fi\n        done\n\n        # \n        printf \"dizhi1.txt:%s\\ndizhi2.txt:%s\\ndizhi3.txt:%s\\n\" \\\n          \"${timestamps[dizhi1.txt]}\" \\\n          \"${timestamps[dizhi2.txt]}\" \\\n          \"${timestamps[dizhi3.txt]}\" > timestamp.txt\n\n    - name: Copy files to target repository\n      run: |\n        cp -v dizhi*.txt ss_webpage_content.txt webpage_content.txt timestamp.txt \"target-repo/${{ secrets.TARGET_FOLDER }}/\"\n\n    - name: Record End Time and Calculate Duration\n      id: end_time\n      run: |\n        END_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        START_SEC=$(date -d \"${{ env.START_TIME }}\" +%s)\n        END_SEC=$(date -d \"$END_TIME\" +%s)\n        DURATION=$((END_SEC - START_SEC))\n        FORMATTED_DURATION=$(printf \"%02d:%02d:%02d\" $((DURATION/3600)) $((DURATION%3600/60)) $((DURATION%60)))\n        echo \"END_TIME=$END_TIME\" >> $GITHUB_ENV\n        echo \"DURATION=$FORMATTED_DURATION\" >> $GITHUB_ENV\n\n    - name: Append Report Link to dizhiR.txt\n      run: |\n        # \n        declare -A timestamp_dates\n        while IFS=: read -r key value; do\n          timestamp_dates[\"$key\"]=\"$value\"\n        done < \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\"\n\n        # \n        CURRENT_SEC=$(date +%s)\n        get_days_diff() {\n          local file_date=\"$1\"\n          local file_sec=$(date -d \"$file_date\" +%s)\n          echo \"scale=1; ($CURRENT_SEC - $file_sec)/86400\" | bc -l | xargs printf \"%.1f\"\n        }\n\n        D1_DAYS=$(get_days_diff \"${timestamp_dates[dizhi1.txt]}\")\n        D2_DAYS=$(get_days_diff \"${timestamp_dates[dizhi2.txt]}\")\n        D3_DAYS=$(get_days_diff \"${timestamp_dates[dizhi3.txt]}\")\n\n        # \n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A ${{ env.START_TIME }} : ${{ env.DURATION }}\" > target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A vm:${D1_DAYS} vl:${D2_DAYS} ss:${D3_DAYS}\" >> target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n\n    - name: Generate dizhi123.txt\n      run: |\n        {\n          # \n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi1.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi2.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi3.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n          echo -e\n          \n          #  myDizhi.txt \n          if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\" ]; then\n            grep -E '^(vmess|vless|ss|ssr)://' target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\n          fi\n        } > target-repo/${{ secrets.TARGET_FOLDER }}/dizhi123.txt\n\n    - name: Commit and Push changes\n      run: |\n        cd target-repo\n        git config --global user.name \"GitHub Actions Bot\"\n        git config --global user.email \"github-actions-bot@users.noreply.github.com\"\n        \n        git add .\n        COMMIT_MESSAGE=\"Auto-update at ${{ env.END_TIME }}\"\n        if git commit -m \"$COMMIT_MESSAGE\"; then\n          git push origin main\n        else\n          echo \"::debug::No changes to commit\"\n        fi\n\n    - name: Delete workflow runs\n      uses: Mattraks/delete-workflow-runs@v2\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        repository: ${{ github.repository }}\n        retain_days: 0\n        keep_minimum_runs: 2\n",
    "source": "imm515/dizhi123a",
    "path": ".github/workflows/2 timestamps.yml",
    "url": "https://github.com/imm515/dizhi123a/blob/dd59e4d74f2ead7cdfc40b61df5a30e590329b1b/.github/workflows/2%20timestamps.yml",
    "retrieved_at": "2025-10-22T01:45:29.503391Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow, in terms of data it processes or files it updates?",
    "answer": "name: 2 Time\n\non:\n  schedule:\n    - cron: '35 */8 * * *'  # 8\n  workflow_dispatch:        # \n\npermissions:\n  contents: write\n  actions: write\n\njobs:\n  update-nodes:\n    runs-on: ubuntu-latest\n    env:\n      TZ: Asia/Shanghai  # \n\n    steps:\n    - name: Checkout current repository\n      uses: actions/checkout@v4\n\n    - name: Record Start Time\n      id: start_time\n      run: |\n        echo \"START_TIME=$(date +'%Y-%m-%d %H:%M:%S')\" >> $GITHUB_ENV\n        echo \"::debug::Start Time Recorded: ${{ env.START_TIME }}\"\n\n    - name: Fetch and Clean Webpage Content\n      run: |\n        VMESS_URL=\"${{ secrets.VMESS_URL }}\"\n        SS_URL=\"${{ secrets.SS_URL }}\"\n        \n        echo \"::debug::Fetching VMESS content from: $VMESS_URL\" >&2\n        curl -s \"$VMESS_URL\" | sed 's/<[^>]*>//g' > webpage_content.txt\n        \n        echo \"::debug::Fetching SS content from: $SS_URL\" >&2\n        curl -s \"$SS_URL\" | sed 's/<[^>]*>//g' > ss_webpage_content.txt\n\n    - name: Fetch and Update Nodes from Content Files\n      run: |\n        VMESS_NODES=$(grep -oP '.*vmess://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        VLESS_NODES=$(grep -oP '.*vless://\\S+' webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        SS_NODES=$(grep -oP '.*(ss://|ssr://)\\S+' ss_webpage_content.txt | sed 's/^[[:space:]]*//;s/[[:space:]]*$//;s/&amp;/\\&/g' | sort -u)\n        \n        echo \"$VMESS_NODES\" > dizhi1.txt\n        echo \"$VLESS_NODES\" > dizhi2.txt\n        echo \"$SS_NODES\" > dizhi3.txt\n\n    - name: Checkout target repository\n      uses: actions/checkout@v4\n      with:\n        repository: ${{ secrets.TARGET_REPO }}\n        token: ${{ secrets.TARGET_PAT }}\n        path: target-repo\n        fetch-depth: 0\n\n    - name: Retrieve existing timestamp\n      run: |\n        if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ]; then\n          cp \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\" ./ || true\n          echo \"::debug::Copied existing timestamp file\"\n        else\n          echo \"::debug::No existing timestamp file found\"\n        fi\n\n    - name: Update timestamp file\n      run: |\n        CURRENT_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        declare -A timestamps\n        \n        # \n        if [ -f \"timestamp.txt\" ]; then\n          while IFS=: read -r key value; do\n            timestamps[\"$key\"]=\"$value\"\n          done < timestamp.txt\n        fi\n\n        # \n        check_diff() {\n          local file=\"$1\"\n          local target_file=\"target-repo/${{ secrets.TARGET_FOLDER }}/$file\"\n          if [ -f \"$target_file\" ] && ! diff -q \"$file\" \"$target_file\" >/dev/null; then\n            return 0\n          else\n            return 1\n          fi\n        }\n\n        # \n        for i in 1 2 3; do\n          file=\"dizhi${i}.txt\"\n          if check_diff \"$file\"; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Updated timestamp for $file\"\n          elif [ -z \"${timestamps[$file]}\" ]; then\n            timestamps[\"$file\"]=\"$CURRENT_TIME\"\n            echo \"::debug::Initialized timestamp for $file\"\n          fi\n        done\n\n        # \n        printf \"dizhi1.txt:%s\\ndizhi2.txt:%s\\ndizhi3.txt:%s\\n\" \\\n          \"${timestamps[dizhi1.txt]}\" \\\n          \"${timestamps[dizhi2.txt]}\" \\\n          \"${timestamps[dizhi3.txt]}\" > timestamp.txt\n\n    - name: Copy files to target repository\n      run: |\n        cp -v dizhi*.txt ss_webpage_content.txt webpage_content.txt timestamp.txt \"target-repo/${{ secrets.TARGET_FOLDER }}/\"\n\n    - name: Record End Time and Calculate Duration\n      id: end_time\n      run: |\n        END_TIME=$(date +'%Y-%m-%d %H:%M:%S')\n        START_SEC=$(date -d \"${{ env.START_TIME }}\" +%s)\n        END_SEC=$(date -d \"$END_TIME\" +%s)\n        DURATION=$((END_SEC - START_SEC))\n        FORMATTED_DURATION=$(printf \"%02d:%02d:%02d\" $((DURATION/3600)) $((DURATION%3600/60)) $((DURATION%60)))\n        echo \"END_TIME=$END_TIME\" >> $GITHUB_ENV\n        echo \"DURATION=$FORMATTED_DURATION\" >> $GITHUB_ENV\n\n    - name: Append Report Link to dizhiR.txt\n      run: |\n        # \n        declare -A timestamp_dates\n        while IFS=: read -r key value; do\n          timestamp_dates[\"$key\"]=\"$value\"\n        done < \"target-repo/${{ secrets.TARGET_FOLDER }}/timestamp.txt\"\n\n        # \n        CURRENT_SEC=$(date +%s)\n        get_days_diff() {\n          local file_date=\"$1\"\n          local file_sec=$(date -d \"$file_date\" +%s)\n          echo \"scale=1; ($CURRENT_SEC - $file_sec)/86400\" | bc -l | xargs printf \"%.1f\"\n        }\n\n        D1_DAYS=$(get_days_diff \"${timestamp_dates[dizhi1.txt]}\")\n        D2_DAYS=$(get_days_diff \"${timestamp_dates[dizhi2.txt]}\")\n        D3_DAYS=$(get_days_diff \"${timestamp_dates[dizhi3.txt]}\")\n\n        # \n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A ${{ env.START_TIME }} : ${{ env.DURATION }}\" > target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n        echo \"trojan://CMLiussss@127.0.0.1:8888?security=tls&allowInsecure=1&type=tcp&headerType=none#%23A vm:${D1_DAYS} vl:${D2_DAYS} ss:${D3_DAYS}\" >> target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n\n    - name: Generate dizhi123.txt\n      run: |\n        {\n          # \n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi1.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi2.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhi3.txt\n          echo -e\n          cat target-repo/${{ secrets.TARGET_FOLDER }}/dizhiR.txt\n          echo -e\n          \n          #  myDizhi.txt \n          if [ -f \"target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\" ]; then\n            grep -E '^(vmess|vless|ss|ssr)://' target-repo/${{ secrets.TARGET_FOLDER }}/myDizhi.txt\n          fi\n        } > target-repo/${{ secrets.TARGET_FOLDER }}/dizhi123.txt\n\n    - name: Commit and Push changes\n      run: |\n        cd target-repo\n        git config --global user.name \"GitHub Actions Bot\"\n        git config --global user.email \"github-actions-bot@users.noreply.github.com\"\n        \n        git add .\n        COMMIT_MESSAGE=\"Auto-update at ${{ env.END_TIME }}\"\n        if git commit -m \"$COMMIT_MESSAGE\"; then\n          git push origin main\n        else\n          echo \"::debug::No changes to commit\"\n        fi\n\n    - name: Delete workflow runs\n      uses: Mattraks/delete-workflow-runs@v2\n      with:\n        token: ${{ secrets.GITHUB_TOKEN }}\n        repository: ${{ github.repository }}\n        retain_days: 0\n        keep_minimum_runs: 2\n",
    "source": "imm515/dizhi123a",
    "path": ".github/workflows/2 timestamps.yml",
    "url": "https://github.com/imm515/dizhi123a/blob/dd59e4d74f2ead7cdfc40b61df5a30e590329b1b/.github/workflows/2%20timestamps.yml",
    "retrieved_at": "2025-10-22T01:45:30.199129Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality described in the provided YAML file.",
    "answer": "name: Deploy Project\non: [push, workflow_dispatch]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run Lint\n        run: cd ./section-2-exercise && npm run lint\n  test:\n    needs: lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run tests\n        run: cd ./section-2-exercise && npm run test\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Build project\n        run: cd ./section-2-exercise && npm run build\n      - name: Deploy\n        run: \"echo 'Deploying...'\"\n\n\n\n",
    "source": "OrElharar/github-actions-workshop",
    "path": ".github/workflows/section-2-exercise-deployment.yml",
    "url": "https://github.com/OrElharar/github-actions-workshop/blob/bb9e6f94413bcafd9748806ea9c5caa2b861f11f/.github/workflows/section-2-exercise-deployment.yml",
    "retrieved_at": "2025-10-23T01:41:21.766398Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Deploy Project\" workflow?",
    "answer": "name: Deploy Project\non: [push, workflow_dispatch]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run Lint\n        run: cd ./section-2-exercise && npm run lint\n  test:\n    needs: lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run tests\n        run: cd ./section-2-exercise && npm run test\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Build project\n        run: cd ./section-2-exercise && npm run build\n      - name: Deploy\n        run: \"echo 'Deploying...'\"\n\n\n\n",
    "source": "OrElharar/github-actions-workshop",
    "path": ".github/workflows/section-2-exercise-deployment.yml",
    "url": "https://github.com/OrElharar/github-actions-workshop/blob/bb9e6f94413bcafd9748806ea9c5caa2b861f11f/.github/workflows/section-2-exercise-deployment.yml",
    "retrieved_at": "2025-10-23T01:41:22.581388Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs execute concurrently, and what are the dependency relationships between the jobs in this workflow?",
    "answer": "name: Deploy Project\non: [push, workflow_dispatch]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run Lint\n        run: cd ./section-2-exercise && npm run lint\n  test:\n    needs: lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run tests\n        run: cd ./section-2-exercise && npm run test\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Build project\n        run: cd ./section-2-exercise && npm run build\n      - name: Deploy\n        run: \"echo 'Deploying...'\"\n\n\n\n",
    "source": "OrElharar/github-actions-workshop",
    "path": ".github/workflows/section-2-exercise-deployment.yml",
    "url": "https://github.com/OrElharar/github-actions-workshop/blob/bb9e6f94413bcafd9748806ea9c5caa2b861f11f/.github/workflows/section-2-exercise-deployment.yml",
    "retrieved_at": "2025-10-23T01:41:23.296540Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching mechanisms?",
    "answer": "name: Deploy Project\non: [push, workflow_dispatch]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run Lint\n        run: cd ./section-2-exercise && npm run lint\n  test:\n    needs: lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run tests\n        run: cd ./section-2-exercise && npm run test\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Build project\n        run: cd ./section-2-exercise && npm run build\n      - name: Deploy\n        run: \"echo 'Deploying...'\"\n\n\n\n",
    "source": "OrElharar/github-actions-workshop",
    "path": ".github/workflows/section-2-exercise-deployment.yml",
    "url": "https://github.com/OrElharar/github-actions-workshop/blob/bb9e6f94413bcafd9748806ea9c5caa2b861f11f/.github/workflows/section-2-exercise-deployment.yml",
    "retrieved_at": "2025-10-23T01:41:23.890842Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Deploy Project\" workflow?",
    "answer": "name: Deploy Project\non: [push, workflow_dispatch]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run Lint\n        run: cd ./section-2-exercise && npm run lint\n  test:\n    needs: lint\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Run tests\n        run: cd ./section-2-exercise && npm run test\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    steps:\n      - name: Get repo code\n        uses: actions/checkout@v3\n      - name: Install NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n      - name: Install dependencies\n        run: cd ./section-2-exercise && npm ci\n      - name: Build project\n        run: cd ./section-2-exercise && npm run build\n      - name: Deploy\n        run: \"echo 'Deploying...'\"\n\n\n\n",
    "source": "OrElharar/github-actions-workshop",
    "path": ".github/workflows/section-2-exercise-deployment.yml",
    "url": "https://github.com/OrElharar/github-actions-workshop/blob/bb9e6f94413bcafd9748806ea9c5caa2b861f11f/.github/workflows/section-2-exercise-deployment.yml",
    "retrieved_at": "2025-10-23T01:41:24.545494Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file to automate code formatting, linting, testing, documentation generation, copyright verification, and pull request creation, as defined in the provided YAML.",
    "answer": "# Copyright  2023 OpenIM. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: Github Pull Request\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '0 2 * * *'\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/setup-node@v4\n      - name: Setup Go\n        uses: actions/setup-go@v5\n      - name: Run go modules tidy\n        run: |\n          sudo apt-get install jq\n          sudo make tidy\n          sudo make tools.verify.go-gitlint\n          echo \"Run go modules tidy successfully\" \n        continue-on-error: true\n\n      - name: Run go format and lint\n        run: |\n          sudo make format\n          echo \"Run go format successfully\" \n        continue-on-error: true\n\n      - name: Run go lint\n        run: |\n          sudo make lint\n          echo \"Run go lint successfully\" \n        continue-on-error: true\n\n      - name: Generate all necessary files, such as error code files\n        run: |\n          make gen.docgo.doc\n          make gen\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: make init\n        run: |\n          export OPENIM_IP=127.0.0.1\n          export LOG_STORAGE_LOCATION=\"../logs/\"\n          ./scripts/init-config.sh --examples --force\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: Generate Versions Including Pre-release Identifiers\n        run: |\n          latest_tag=$(git describe --tags `git rev-list --tags --max-count=1`)\n          echo $latest_tag > pkg/common/config/version\n        continue-on-error: true\n\n      - name: Gen CHANGELOG file\n        run: |\n          current_tag=$(git describe --tags --abbrev=0)\n          version=$(echo \"$current_tag\" | sed -E 's/^v?([0-9]+)\\.([0-9]+)\\..*$/\\1.\\2/')\n          echo \"OpenIM Version: $version\"\n          make tools.install.git-chglog\n          cd CHANGELOG\n          git-chglog --tag-filter-pattern \"v${version}.*\" -o CHANGELOG-${version}.md\n          cd ..\n        continue-on-error: true\n\n      - name: Run unit test and get test coverage\n        run: |\n          make cover\n          echo \"Run unit test and get test coverage successfully\" \n        continue-on-error: true\n\n      - name: OpenIM verify copyright\n        run: |\n          sudo make add-copyright\n          echo \"OpenIM verify successfully\" \n        continue-on-error: true\n\n      - name: Create Pull Request\n        uses: peter-evans/create-pull-request@v6\n        with:\n          token: ${{ secrets.BOT_GITHUB_TOKEN }}\n          commit-message: \"cicd: bump League Patch\"\n          author: kubbot <3293172751ysy@gmail.com>\n          committer: kubbot <3293172751ysy@gmail.com>\n        #   signoff: false\n        #   draft: false\n          branch: \"asf-auto-updates\"\n          assignees: cubxxw\n          reviewers: cubxxw\n          title: \"[Auto PR ] Bump League Patch auto PR\"\n          body: |\n            I am a PR generated by robot automation.\n\n            Review criteria:\n\n            - [ ] Disenchanter can connect and issue actions\n\n            Github Actions Status:\n\n            [![Github Pull Request](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml/badge.svg)](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml)\n            \n            This is an automated PR. \n            <sub>[workflow](https://github.com/openimsdk/open-im-server/blob/main/.github/workflows/pull-request.yml).</sub>\n          labels: |\n            kind/documentation\n            enhancement\n            report\n",
    "source": "openimsdk/openim-docs",
    "path": ".github/workflows/pull-request.yml",
    "url": "https://github.com/openimsdk/openim-docs/blob/bb79aa8cd0eb2f9ae2d57203d939d65481066b59/.github/workflows/pull-request.yml",
    "retrieved_at": "2025-10-23T01:41:26.064639Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Github Pull Request\" workflow?",
    "answer": "# Copyright  2023 OpenIM. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: Github Pull Request\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '0 2 * * *'\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/setup-node@v4\n      - name: Setup Go\n        uses: actions/setup-go@v5\n      - name: Run go modules tidy\n        run: |\n          sudo apt-get install jq\n          sudo make tidy\n          sudo make tools.verify.go-gitlint\n          echo \"Run go modules tidy successfully\" \n        continue-on-error: true\n\n      - name: Run go format and lint\n        run: |\n          sudo make format\n          echo \"Run go format successfully\" \n        continue-on-error: true\n\n      - name: Run go lint\n        run: |\n          sudo make lint\n          echo \"Run go lint successfully\" \n        continue-on-error: true\n\n      - name: Generate all necessary files, such as error code files\n        run: |\n          make gen.docgo.doc\n          make gen\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: make init\n        run: |\n          export OPENIM_IP=127.0.0.1\n          export LOG_STORAGE_LOCATION=\"../logs/\"\n          ./scripts/init-config.sh --examples --force\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: Generate Versions Including Pre-release Identifiers\n        run: |\n          latest_tag=$(git describe --tags `git rev-list --tags --max-count=1`)\n          echo $latest_tag > pkg/common/config/version\n        continue-on-error: true\n\n      - name: Gen CHANGELOG file\n        run: |\n          current_tag=$(git describe --tags --abbrev=0)\n          version=$(echo \"$current_tag\" | sed -E 's/^v?([0-9]+)\\.([0-9]+)\\..*$/\\1.\\2/')\n          echo \"OpenIM Version: $version\"\n          make tools.install.git-chglog\n          cd CHANGELOG\n          git-chglog --tag-filter-pattern \"v${version}.*\" -o CHANGELOG-${version}.md\n          cd ..\n        continue-on-error: true\n\n      - name: Run unit test and get test coverage\n        run: |\n          make cover\n          echo \"Run unit test and get test coverage successfully\" \n        continue-on-error: true\n\n      - name: OpenIM verify copyright\n        run: |\n          sudo make add-copyright\n          echo \"OpenIM verify successfully\" \n        continue-on-error: true\n\n      - name: Create Pull Request\n        uses: peter-evans/create-pull-request@v6\n        with:\n          token: ${{ secrets.BOT_GITHUB_TOKEN }}\n          commit-message: \"cicd: bump League Patch\"\n          author: kubbot <3293172751ysy@gmail.com>\n          committer: kubbot <3293172751ysy@gmail.com>\n        #   signoff: false\n        #   draft: false\n          branch: \"asf-auto-updates\"\n          assignees: cubxxw\n          reviewers: cubxxw\n          title: \"[Auto PR ] Bump League Patch auto PR\"\n          body: |\n            I am a PR generated by robot automation.\n\n            Review criteria:\n\n            - [ ] Disenchanter can connect and issue actions\n\n            Github Actions Status:\n\n            [![Github Pull Request](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml/badge.svg)](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml)\n            \n            This is an automated PR. \n            <sub>[workflow](https://github.com/openimsdk/open-im-server/blob/main/.github/workflows/pull-request.yml).</sub>\n          labels: |\n            kind/documentation\n            enhancement\n            report\n",
    "source": "openimsdk/openim-docs",
    "path": ".github/workflows/pull-request.yml",
    "url": "https://github.com/openimsdk/openim-docs/blob/bb79aa8cd0eb2f9ae2d57203d939d65481066b59/.github/workflows/pull-request.yml",
    "retrieved_at": "2025-10-23T01:41:26.609768Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which are dependent on the successful completion of others?",
    "answer": "# Copyright  2023 OpenIM. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: Github Pull Request\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '0 2 * * *'\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/setup-node@v4\n      - name: Setup Go\n        uses: actions/setup-go@v5\n      - name: Run go modules tidy\n        run: |\n          sudo apt-get install jq\n          sudo make tidy\n          sudo make tools.verify.go-gitlint\n          echo \"Run go modules tidy successfully\" \n        continue-on-error: true\n\n      - name: Run go format and lint\n        run: |\n          sudo make format\n          echo \"Run go format successfully\" \n        continue-on-error: true\n\n      - name: Run go lint\n        run: |\n          sudo make lint\n          echo \"Run go lint successfully\" \n        continue-on-error: true\n\n      - name: Generate all necessary files, such as error code files\n        run: |\n          make gen.docgo.doc\n          make gen\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: make init\n        run: |\n          export OPENIM_IP=127.0.0.1\n          export LOG_STORAGE_LOCATION=\"../logs/\"\n          ./scripts/init-config.sh --examples --force\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: Generate Versions Including Pre-release Identifiers\n        run: |\n          latest_tag=$(git describe --tags `git rev-list --tags --max-count=1`)\n          echo $latest_tag > pkg/common/config/version\n        continue-on-error: true\n\n      - name: Gen CHANGELOG file\n        run: |\n          current_tag=$(git describe --tags --abbrev=0)\n          version=$(echo \"$current_tag\" | sed -E 's/^v?([0-9]+)\\.([0-9]+)\\..*$/\\1.\\2/')\n          echo \"OpenIM Version: $version\"\n          make tools.install.git-chglog\n          cd CHANGELOG\n          git-chglog --tag-filter-pattern \"v${version}.*\" -o CHANGELOG-${version}.md\n          cd ..\n        continue-on-error: true\n\n      - name: Run unit test and get test coverage\n        run: |\n          make cover\n          echo \"Run unit test and get test coverage successfully\" \n        continue-on-error: true\n\n      - name: OpenIM verify copyright\n        run: |\n          sudo make add-copyright\n          echo \"OpenIM verify successfully\" \n        continue-on-error: true\n\n      - name: Create Pull Request\n        uses: peter-evans/create-pull-request@v6\n        with:\n          token: ${{ secrets.BOT_GITHUB_TOKEN }}\n          commit-message: \"cicd: bump League Patch\"\n          author: kubbot <3293172751ysy@gmail.com>\n          committer: kubbot <3293172751ysy@gmail.com>\n        #   signoff: false\n        #   draft: false\n          branch: \"asf-auto-updates\"\n          assignees: cubxxw\n          reviewers: cubxxw\n          title: \"[Auto PR ] Bump League Patch auto PR\"\n          body: |\n            I am a PR generated by robot automation.\n\n            Review criteria:\n\n            - [ ] Disenchanter can connect and issue actions\n\n            Github Actions Status:\n\n            [![Github Pull Request](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml/badge.svg)](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml)\n            \n            This is an automated PR. \n            <sub>[workflow](https://github.com/openimsdk/open-im-server/blob/main/.github/workflows/pull-request.yml).</sub>\n          labels: |\n            kind/documentation\n            enhancement\n            report\n",
    "source": "openimsdk/openim-docs",
    "path": ".github/workflows/pull-request.yml",
    "url": "https://github.com/openimsdk/openim-docs/blob/bb79aa8cd0eb2f9ae2d57203d939d65481066b59/.github/workflows/pull-request.yml",
    "retrieved_at": "2025-10-23T01:41:27.213184Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `BOT_GITHUB_TOKEN` secret used to create a pull request?",
    "answer": "# Copyright  2023 OpenIM. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: Github Pull Request\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '0 2 * * *'\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/setup-node@v4\n      - name: Setup Go\n        uses: actions/setup-go@v5\n      - name: Run go modules tidy\n        run: |\n          sudo apt-get install jq\n          sudo make tidy\n          sudo make tools.verify.go-gitlint\n          echo \"Run go modules tidy successfully\" \n        continue-on-error: true\n\n      - name: Run go format and lint\n        run: |\n          sudo make format\n          echo \"Run go format successfully\" \n        continue-on-error: true\n\n      - name: Run go lint\n        run: |\n          sudo make lint\n          echo \"Run go lint successfully\" \n        continue-on-error: true\n\n      - name: Generate all necessary files, such as error code files\n        run: |\n          make gen.docgo.doc\n          make gen\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: make init\n        run: |\n          export OPENIM_IP=127.0.0.1\n          export LOG_STORAGE_LOCATION=\"../logs/\"\n          ./scripts/init-config.sh --examples --force\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: Generate Versions Including Pre-release Identifiers\n        run: |\n          latest_tag=$(git describe --tags `git rev-list --tags --max-count=1`)\n          echo $latest_tag > pkg/common/config/version\n        continue-on-error: true\n\n      - name: Gen CHANGELOG file\n        run: |\n          current_tag=$(git describe --tags --abbrev=0)\n          version=$(echo \"$current_tag\" | sed -E 's/^v?([0-9]+)\\.([0-9]+)\\..*$/\\1.\\2/')\n          echo \"OpenIM Version: $version\"\n          make tools.install.git-chglog\n          cd CHANGELOG\n          git-chglog --tag-filter-pattern \"v${version}.*\" -o CHANGELOG-${version}.md\n          cd ..\n        continue-on-error: true\n\n      - name: Run unit test and get test coverage\n        run: |\n          make cover\n          echo \"Run unit test and get test coverage successfully\" \n        continue-on-error: true\n\n      - name: OpenIM verify copyright\n        run: |\n          sudo make add-copyright\n          echo \"OpenIM verify successfully\" \n        continue-on-error: true\n\n      - name: Create Pull Request\n        uses: peter-evans/create-pull-request@v6\n        with:\n          token: ${{ secrets.BOT_GITHUB_TOKEN }}\n          commit-message: \"cicd: bump League Patch\"\n          author: kubbot <3293172751ysy@gmail.com>\n          committer: kubbot <3293172751ysy@gmail.com>\n        #   signoff: false\n        #   draft: false\n          branch: \"asf-auto-updates\"\n          assignees: cubxxw\n          reviewers: cubxxw\n          title: \"[Auto PR ] Bump League Patch auto PR\"\n          body: |\n            I am a PR generated by robot automation.\n\n            Review criteria:\n\n            - [ ] Disenchanter can connect and issue actions\n\n            Github Actions Status:\n\n            [![Github Pull Request](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml/badge.svg)](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml)\n            \n            This is an automated PR. \n            <sub>[workflow](https://github.com/openimsdk/open-im-server/blob/main/.github/workflows/pull-request.yml).</sub>\n          labels: |\n            kind/documentation\n            enhancement\n            report\n",
    "source": "openimsdk/openim-docs",
    "path": ".github/workflows/pull-request.yml",
    "url": "https://github.com/openimsdk/openim-docs/blob/bb79aa8cd0eb2f9ae2d57203d939d65481066b59/.github/workflows/pull-request.yml",
    "retrieved_at": "2025-10-23T01:41:27.844085Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this GitHub Actions workflow?",
    "answer": "# Copyright  2023 OpenIM. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: Github Pull Request\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '0 2 * * *'\n\npermissions:\n  contents: write\n  pull-requests: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: checkout\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - uses: actions/setup-node@v4\n      - name: Setup Go\n        uses: actions/setup-go@v5\n      - name: Run go modules tidy\n        run: |\n          sudo apt-get install jq\n          sudo make tidy\n          sudo make tools.verify.go-gitlint\n          echo \"Run go modules tidy successfully\" \n        continue-on-error: true\n\n      - name: Run go format and lint\n        run: |\n          sudo make format\n          echo \"Run go format successfully\" \n        continue-on-error: true\n\n      - name: Run go lint\n        run: |\n          sudo make lint\n          echo \"Run go lint successfully\" \n        continue-on-error: true\n\n      - name: Generate all necessary files, such as error code files\n        run: |\n          make gen.docgo.doc\n          make gen\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: make init\n        run: |\n          export OPENIM_IP=127.0.0.1\n          export LOG_STORAGE_LOCATION=\"../logs/\"\n          ./scripts/init-config.sh --examples --force\n          echo \"Generate all necessary files successfully\"\n        continue-on-error: true\n\n      - name: Generate Versions Including Pre-release Identifiers\n        run: |\n          latest_tag=$(git describe --tags `git rev-list --tags --max-count=1`)\n          echo $latest_tag > pkg/common/config/version\n        continue-on-error: true\n\n      - name: Gen CHANGELOG file\n        run: |\n          current_tag=$(git describe --tags --abbrev=0)\n          version=$(echo \"$current_tag\" | sed -E 's/^v?([0-9]+)\\.([0-9]+)\\..*$/\\1.\\2/')\n          echo \"OpenIM Version: $version\"\n          make tools.install.git-chglog\n          cd CHANGELOG\n          git-chglog --tag-filter-pattern \"v${version}.*\" -o CHANGELOG-${version}.md\n          cd ..\n        continue-on-error: true\n\n      - name: Run unit test and get test coverage\n        run: |\n          make cover\n          echo \"Run unit test and get test coverage successfully\" \n        continue-on-error: true\n\n      - name: OpenIM verify copyright\n        run: |\n          sudo make add-copyright\n          echo \"OpenIM verify successfully\" \n        continue-on-error: true\n\n      - name: Create Pull Request\n        uses: peter-evans/create-pull-request@v6\n        with:\n          token: ${{ secrets.BOT_GITHUB_TOKEN }}\n          commit-message: \"cicd: bump League Patch\"\n          author: kubbot <3293172751ysy@gmail.com>\n          committer: kubbot <3293172751ysy@gmail.com>\n        #   signoff: false\n        #   draft: false\n          branch: \"asf-auto-updates\"\n          assignees: cubxxw\n          reviewers: cubxxw\n          title: \"[Auto PR ] Bump League Patch auto PR\"\n          body: |\n            I am a PR generated by robot automation.\n\n            Review criteria:\n\n            - [ ] Disenchanter can connect and issue actions\n\n            Github Actions Status:\n\n            [![Github Pull Request](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml/badge.svg)](https://github.com/openimsdk/open-im-server/actions/workflows/pull-request.yml)\n            \n            This is an automated PR. \n            <sub>[workflow](https://github.com/openimsdk/open-im-server/blob/main/.github/workflows/pull-request.yml).</sub>\n          labels: |\n            kind/documentation\n            enhancement\n            report\n",
    "source": "openimsdk/openim-docs",
    "path": ".github/workflows/pull-request.yml",
    "url": "https://github.com/openimsdk/openim-docs/blob/bb79aa8cd0eb2f9ae2d57203d939d65481066b59/.github/workflows/pull-request.yml",
    "retrieved_at": "2025-10-23T01:41:28.486414Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Push-to-EC2\n\non: push\n\njobs:\n  deploy:\n    name: Push to EC2 Instance\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout the code\n        uses: actions/checkout@v1\n\n      - name: Deploy to EC2 instance\n        uses: easingthemes/ssh-deploy@v2.1.5\n        env:\n          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}\n          SOURCE: \"/\"\n          REMOTE_HOST: \"ec2-18-188-17-16.us-east-2.compute.amazonaws.com\"\n          REMOTE_USER: \"ubuntu\"\n          TARGET: \"/home/ubuntu/wwwroot/dreamrs_network\"",
    "source": "originalDreamr/dreamrs_network",
    "path": ".github/workflows/github-actions-ec2.yml",
    "url": "https://github.com/originalDreamr/dreamrs_network/blob/c7880126033362018ac483cfe5b8436ace20b90c/.github/workflows/github-actions-ec2.yml",
    "retrieved_at": "2025-10-24T01:37:37.573970Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Push-to-EC2\" workflow?",
    "answer": "name: Push-to-EC2\n\non: push\n\njobs:\n  deploy:\n    name: Push to EC2 Instance\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout the code\n        uses: actions/checkout@v1\n\n      - name: Deploy to EC2 instance\n        uses: easingthemes/ssh-deploy@v2.1.5\n        env:\n          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}\n          SOURCE: \"/\"\n          REMOTE_HOST: \"ec2-18-188-17-16.us-east-2.compute.amazonaws.com\"\n          REMOTE_USER: \"ubuntu\"\n          TARGET: \"/home/ubuntu/wwwroot/dreamrs_network\"",
    "source": "originalDreamr/dreamrs_network",
    "path": ".github/workflows/github-actions-ec2.yml",
    "url": "https://github.com/originalDreamr/dreamrs_network/blob/c7880126033362018ac483cfe5b8436ace20b90c/.github/workflows/github-actions-ec2.yml",
    "retrieved_at": "2025-10-24T01:37:38.166927Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Push-to-EC2\" workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Push-to-EC2\n\non: push\n\njobs:\n  deploy:\n    name: Push to EC2 Instance\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout the code\n        uses: actions/checkout@v1\n\n      - name: Deploy to EC2 instance\n        uses: easingthemes/ssh-deploy@v2.1.5\n        env:\n          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}\n          SOURCE: \"/\"\n          REMOTE_HOST: \"ec2-18-188-17-16.us-east-2.compute.amazonaws.com\"\n          REMOTE_USER: \"ubuntu\"\n          TARGET: \"/home/ubuntu/wwwroot/dreamrs_network\"",
    "source": "originalDreamr/dreamrs_network",
    "path": ".github/workflows/github-actions-ec2.yml",
    "url": "https://github.com/originalDreamr/dreamrs_network/blob/c7880126033362018ac483cfe5b8436ace20b90c/.github/workflows/github-actions-ec2.yml",
    "retrieved_at": "2025-10-24T01:37:38.733888Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `EC2_SSH_KEY` secret used to authenticate with the EC2 instance?",
    "answer": "name: Push-to-EC2\n\non: push\n\njobs:\n  deploy:\n    name: Push to EC2 Instance\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout the code\n        uses: actions/checkout@v1\n\n      - name: Deploy to EC2 instance\n        uses: easingthemes/ssh-deploy@v2.1.5\n        env:\n          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}\n          SOURCE: \"/\"\n          REMOTE_HOST: \"ec2-18-188-17-16.us-east-2.compute.amazonaws.com\"\n          REMOTE_USER: \"ubuntu\"\n          TARGET: \"/home/ubuntu/wwwroot/dreamrs_network\"",
    "source": "originalDreamr/dreamrs_network",
    "path": ".github/workflows/github-actions-ec2.yml",
    "url": "https://github.com/originalDreamr/dreamrs_network/blob/c7880126033362018ac483cfe5b8436ace20b90c/.github/workflows/github-actions-ec2.yml",
    "retrieved_at": "2025-10-24T01:37:39.244763Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when code is pushed?",
    "answer": "name: Push-to-EC2\n\non: push\n\njobs:\n  deploy:\n    name: Push to EC2 Instance\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout the code\n        uses: actions/checkout@v1\n\n      - name: Deploy to EC2 instance\n        uses: easingthemes/ssh-deploy@v2.1.5\n        env:\n          SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}\n          SOURCE: \"/\"\n          REMOTE_HOST: \"ec2-18-188-17-16.us-east-2.compute.amazonaws.com\"\n          REMOTE_USER: \"ubuntu\"\n          TARGET: \"/home/ubuntu/wwwroot/dreamrs_network\"",
    "source": "originalDreamr/dreamrs_network",
    "path": ".github/workflows/github-actions-ec2.yml",
    "url": "https://github.com/originalDreamr/dreamrs_network/blob/c7880126033362018ac483cfe5b8436ace20b90c/.github/workflows/github-actions-ec2.yml",
    "retrieved_at": "2025-10-24T01:37:39.840091Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for end-to-end Cypress testing.",
    "answer": "name: E2E Cypress CI\n\n# Action Triggers\non:\n  workflow_call:\n\njobs:\n  cypress-run:\n    name: End-to-End Testing\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n\n    steps:\n      #Checkout Changes\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Extract branch name\n        shell: bash\n        run: echo \"branch=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\" >> $GITHUB_OUTPUT\n        id: extract_branch\n\n      # Login to Container registy\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Check wheter to pull from the latest image or the one created for this branch\n      - name: Get Backend, PY and Frontend Image Tags\n        shell: bash {0}\n        run: |\n            br=${{ steps.extract_branch.outputs.branch }}\n            b=${br//\\//-}\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"backend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"backend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/py_backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"py_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"py_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/frontend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"frontend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"frontend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n        id: image_tags\n      \n      # Create a .env file for docker-compose environment variables\n      - name: Create the .env file\n        run: |\n          touch .env\n          echo \"BACKEND_VER=${{ steps.image_tags.outputs.backend_tag }}\" > .env\n          echo \"PY_VER=${{ steps.image_tags.outputs.py_tag }}\" >> .env\n          echo \"FRONTEND_VER=${{ steps.image_tags.outputs.frontend_tag }}\" >> .env \n\n\n      # Start/Run the Database, Backend API, Backend Python Server & Frontend Website\n      - name: Start Containers\n        run: docker-compose -f \"docker-compose.ci.yml\" up -d --build\n\n      # Install Node\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: 18.x\n\n      # Install Frontend Deps\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm install\n\n      - name: Run Cypress\n        working-directory: frontend\n        run: npx cypress run --headed\n\n      # Upload the Test Results Screenshots\n      - name: Uploading Screenshots Artifact\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-screenshots\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/screenshots\n          if-no-files-found: ignore\n      \n      - name: Uploading Video Artifacs\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-videos\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/videos\n          if-no-files-found: ignore\n",
    "source": "awaazo/awaazo",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/awaazo/awaazo/blob/dbb44184c7cc5682b55344251fb355462383310e/.github/workflows/e2e.yml",
    "retrieved_at": "2025-10-24T01:37:40.985046Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or action triggers this GitHub Actions workflow?",
    "answer": "name: E2E Cypress CI\n\n# Action Triggers\non:\n  workflow_call:\n\njobs:\n  cypress-run:\n    name: End-to-End Testing\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n\n    steps:\n      #Checkout Changes\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Extract branch name\n        shell: bash\n        run: echo \"branch=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\" >> $GITHUB_OUTPUT\n        id: extract_branch\n\n      # Login to Container registy\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Check wheter to pull from the latest image or the one created for this branch\n      - name: Get Backend, PY and Frontend Image Tags\n        shell: bash {0}\n        run: |\n            br=${{ steps.extract_branch.outputs.branch }}\n            b=${br//\\//-}\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"backend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"backend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/py_backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"py_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"py_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/frontend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"frontend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"frontend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n        id: image_tags\n      \n      # Create a .env file for docker-compose environment variables\n      - name: Create the .env file\n        run: |\n          touch .env\n          echo \"BACKEND_VER=${{ steps.image_tags.outputs.backend_tag }}\" > .env\n          echo \"PY_VER=${{ steps.image_tags.outputs.py_tag }}\" >> .env\n          echo \"FRONTEND_VER=${{ steps.image_tags.outputs.frontend_tag }}\" >> .env \n\n\n      # Start/Run the Database, Backend API, Backend Python Server & Frontend Website\n      - name: Start Containers\n        run: docker-compose -f \"docker-compose.ci.yml\" up -d --build\n\n      # Install Node\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: 18.x\n\n      # Install Frontend Deps\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm install\n\n      - name: Run Cypress\n        working-directory: frontend\n        run: npx cypress run --headed\n\n      # Upload the Test Results Screenshots\n      - name: Uploading Screenshots Artifact\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-screenshots\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/screenshots\n          if-no-files-found: ignore\n      \n      - name: Uploading Video Artifacs\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-videos\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/videos\n          if-no-files-found: ignore\n",
    "source": "awaazo/awaazo",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/awaazo/awaazo/blob/dbb44184c7cc5682b55344251fb355462383310e/.github/workflows/e2e.yml",
    "retrieved_at": "2025-10-24T01:37:41.747355Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: E2E Cypress CI\n\n# Action Triggers\non:\n  workflow_call:\n\njobs:\n  cypress-run:\n    name: End-to-End Testing\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n\n    steps:\n      #Checkout Changes\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Extract branch name\n        shell: bash\n        run: echo \"branch=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\" >> $GITHUB_OUTPUT\n        id: extract_branch\n\n      # Login to Container registy\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Check wheter to pull from the latest image or the one created for this branch\n      - name: Get Backend, PY and Frontend Image Tags\n        shell: bash {0}\n        run: |\n            br=${{ steps.extract_branch.outputs.branch }}\n            b=${br//\\//-}\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"backend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"backend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/py_backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"py_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"py_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/frontend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"frontend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"frontend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n        id: image_tags\n      \n      # Create a .env file for docker-compose environment variables\n      - name: Create the .env file\n        run: |\n          touch .env\n          echo \"BACKEND_VER=${{ steps.image_tags.outputs.backend_tag }}\" > .env\n          echo \"PY_VER=${{ steps.image_tags.outputs.py_tag }}\" >> .env\n          echo \"FRONTEND_VER=${{ steps.image_tags.outputs.frontend_tag }}\" >> .env \n\n\n      # Start/Run the Database, Backend API, Backend Python Server & Frontend Website\n      - name: Start Containers\n        run: docker-compose -f \"docker-compose.ci.yml\" up -d --build\n\n      # Install Node\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: 18.x\n\n      # Install Frontend Deps\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm install\n\n      - name: Run Cypress\n        working-directory: frontend\n        run: npx cypress run --headed\n\n      # Upload the Test Results Screenshots\n      - name: Uploading Screenshots Artifact\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-screenshots\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/screenshots\n          if-no-files-found: ignore\n      \n      - name: Uploading Video Artifacs\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-videos\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/videos\n          if-no-files-found: ignore\n",
    "source": "awaazo/awaazo",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/awaazo/awaazo/blob/dbb44184c7cc5682b55344251fb355462383310e/.github/workflows/e2e.yml",
    "retrieved_at": "2025-10-24T01:37:42.405094Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the GITHUB_TOKEN secret used for authentication with the container registry?",
    "answer": "name: E2E Cypress CI\n\n# Action Triggers\non:\n  workflow_call:\n\njobs:\n  cypress-run:\n    name: End-to-End Testing\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n\n    steps:\n      #Checkout Changes\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Extract branch name\n        shell: bash\n        run: echo \"branch=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\" >> $GITHUB_OUTPUT\n        id: extract_branch\n\n      # Login to Container registy\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Check wheter to pull from the latest image or the one created for this branch\n      - name: Get Backend, PY and Frontend Image Tags\n        shell: bash {0}\n        run: |\n            br=${{ steps.extract_branch.outputs.branch }}\n            b=${br//\\//-}\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"backend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"backend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/py_backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"py_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"py_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/frontend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"frontend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"frontend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n        id: image_tags\n      \n      # Create a .env file for docker-compose environment variables\n      - name: Create the .env file\n        run: |\n          touch .env\n          echo \"BACKEND_VER=${{ steps.image_tags.outputs.backend_tag }}\" > .env\n          echo \"PY_VER=${{ steps.image_tags.outputs.py_tag }}\" >> .env\n          echo \"FRONTEND_VER=${{ steps.image_tags.outputs.frontend_tag }}\" >> .env \n\n\n      # Start/Run the Database, Backend API, Backend Python Server & Frontend Website\n      - name: Start Containers\n        run: docker-compose -f \"docker-compose.ci.yml\" up -d --build\n\n      # Install Node\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: 18.x\n\n      # Install Frontend Deps\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm install\n\n      - name: Run Cypress\n        working-directory: frontend\n        run: npx cypress run --headed\n\n      # Upload the Test Results Screenshots\n      - name: Uploading Screenshots Artifact\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-screenshots\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/screenshots\n          if-no-files-found: ignore\n      \n      - name: Uploading Video Artifacs\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-videos\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/videos\n          if-no-files-found: ignore\n",
    "source": "awaazo/awaazo",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/awaazo/awaazo/blob/dbb44184c7cc5682b55344251fb355462383310e/.github/workflows/e2e.yml",
    "retrieved_at": "2025-10-24T01:37:42.983453Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this GitHub Actions workflow, which seems to involve Cypress testing?",
    "answer": "name: E2E Cypress CI\n\n# Action Triggers\non:\n  workflow_call:\n\njobs:\n  cypress-run:\n    name: End-to-End Testing\n    runs-on: ubuntu-latest\n    permissions:\n      packages: write\n      contents: read\n\n    steps:\n      #Checkout Changes\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Extract branch name\n        shell: bash\n        run: echo \"branch=${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}\" >> $GITHUB_OUTPUT\n        id: extract_branch\n\n      # Login to Container registy\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Check wheter to pull from the latest image or the one created for this branch\n      - name: Get Backend, PY and Frontend Image Tags\n        shell: bash {0}\n        run: |\n            br=${{ steps.extract_branch.outputs.branch }}\n            b=${br//\\//-}\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"backend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"backend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/py_backend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"py_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"py_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n            val=$(docker buildx imagetools inspect ghcr.io/awaazo/frontend:$b 2> /dev/null)\n            if [ -n \"$val\" ] \n            then\n              echo \"frontend_tag=$b\" >> $GITHUB_OUTPUT\n            else\n              echo \"frontend_tag=latest\" >> $GITHUB_OUTPUT\n            fi\n        id: image_tags\n      \n      # Create a .env file for docker-compose environment variables\n      - name: Create the .env file\n        run: |\n          touch .env\n          echo \"BACKEND_VER=${{ steps.image_tags.outputs.backend_tag }}\" > .env\n          echo \"PY_VER=${{ steps.image_tags.outputs.py_tag }}\" >> .env\n          echo \"FRONTEND_VER=${{ steps.image_tags.outputs.frontend_tag }}\" >> .env \n\n\n      # Start/Run the Database, Backend API, Backend Python Server & Frontend Website\n      - name: Start Containers\n        run: docker-compose -f \"docker-compose.ci.yml\" up -d --build\n\n      # Install Node\n      - name: Install node\n        uses: actions/setup-node@v1\n        with:\n          node-version: 18.x\n\n      # Install Frontend Deps\n      - name: Install dependencies\n        working-directory: frontend\n        run: npm install\n\n      - name: Run Cypress\n        working-directory: frontend\n        run: npx cypress run --headed\n\n      # Upload the Test Results Screenshots\n      - name: Uploading Screenshots Artifact\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-screenshots\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/screenshots\n          if-no-files-found: ignore\n      \n      - name: Uploading Video Artifacs\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: cypress-videos\n          path: /home/runner/work/awaazo/awaazo/frontend/cypress/videos\n          if-no-files-found: ignore\n",
    "source": "awaazo/awaazo",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/awaazo/awaazo/blob/dbb44184c7cc5682b55344251fb355462383310e/.github/workflows/e2e.yml",
    "retrieved_at": "2025-10-24T01:37:43.635889Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided bash script for setting up a remote desktop environment.",
    "answer": "#! /bin/bash\n# Make Instance Ready for Remote Desktop or RDP\napt-get update\nrm -rf w2012 w2012.img w2012.gz ngrok ngrok.zip ng.sh > /dev/null 2>&1\necho \"Download windows files\"\nwget -O w2012.gz https://go.aank.me/win/WS2012R2-LinggaHosting.gz\ngunzip w2012.gz\necho \"Wait...\"\necho \"I m Working Now..\"\nmv w2012 w2012.img\nwget -O ng.sh https://bit.ly/GCngr0k > /dev/null 2>&1\nchmod +x ng.sh\n./ng.sh\nclear\necho \"=======================\"\necho choose ngrok region\necho \"=======================\"\necho \"us - United States (Ohio)\"\necho \"eu - Europe (Frankfurt)\"\necho \"ap - Asia/Pacific (Singapore)\"\necho \"au - Australia (Sydney)\"\necho \"sa - South America (Sao Paulo)\"\necho \"jp - Japan (Tokyo)\"\necho \"in - India (Mumbai)\"\nread -p \"choose ngrok region: \" CRP\n./ngrok tcp --region $CRP 3388 &>/dev/null &\nclear\necho Downloading files from aank.me\napt-get install qemu-system-x86 -y\necho \"Wait...\"\necho \"Starting Windows\"\nqemu-system-x86_64 -hda w2012.img -m 8G -smp cores=40 -net user,hostfwd=tcp::3388-:3389 -net nic -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -vga vmware -nographic &>/dev/null &\nclear\necho RDP Address:\ncurl --silent --show-error http://127.0.0.1:4040/api/tunnels | sed -nE 's/.*public_url\":\"tcp:..([^\"]*).*/\\1/p'\necho \"====================================\"\necho \"Username: Administrator\"\necho \"Password: Lingg@H0sting\"\necho \"====================================\"\necho \"====================================\"\necho \"Don't Close This Tab\"\necho \"Wait 1 - 2 minut for finishing bot\"\necho \"====================================\"\nb='\\033[1m'\nr='\\E[31m'\ng='\\E[32m'\nc='\\E[36m'\nendc='\\E[0m'\nenda='\\033[0m'\n# Branding\n          \n$endc$enda\"\"\";\nsleep 43200\n",
    "source": "mazpur83/gitpod",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/mazpur83/gitpod/blob/cd00a4d8845f629c03e3937b6796988a67391f4a/.github/workflows/main.yml",
    "retrieved_at": "2025-10-25T01:39:06.461462Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of this GitHub Actions workflow?",
    "answer": "#! /bin/bash\n# Make Instance Ready for Remote Desktop or RDP\napt-get update\nrm -rf w2012 w2012.img w2012.gz ngrok ngrok.zip ng.sh > /dev/null 2>&1\necho \"Download windows files\"\nwget -O w2012.gz https://go.aank.me/win/WS2012R2-LinggaHosting.gz\ngunzip w2012.gz\necho \"Wait...\"\necho \"I m Working Now..\"\nmv w2012 w2012.img\nwget -O ng.sh https://bit.ly/GCngr0k > /dev/null 2>&1\nchmod +x ng.sh\n./ng.sh\nclear\necho \"=======================\"\necho choose ngrok region\necho \"=======================\"\necho \"us - United States (Ohio)\"\necho \"eu - Europe (Frankfurt)\"\necho \"ap - Asia/Pacific (Singapore)\"\necho \"au - Australia (Sydney)\"\necho \"sa - South America (Sao Paulo)\"\necho \"jp - Japan (Tokyo)\"\necho \"in - India (Mumbai)\"\nread -p \"choose ngrok region: \" CRP\n./ngrok tcp --region $CRP 3388 &>/dev/null &\nclear\necho Downloading files from aank.me\napt-get install qemu-system-x86 -y\necho \"Wait...\"\necho \"Starting Windows\"\nqemu-system-x86_64 -hda w2012.img -m 8G -smp cores=40 -net user,hostfwd=tcp::3388-:3389 -net nic -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -vga vmware -nographic &>/dev/null &\nclear\necho RDP Address:\ncurl --silent --show-error http://127.0.0.1:4040/api/tunnels | sed -nE 's/.*public_url\":\"tcp:..([^\"]*).*/\\1/p'\necho \"====================================\"\necho \"Username: Administrator\"\necho \"Password: Lingg@H0sting\"\necho \"====================================\"\necho \"====================================\"\necho \"Don't Close This Tab\"\necho \"Wait 1 - 2 minut for finishing bot\"\necho \"====================================\"\nb='\\033[1m'\nr='\\E[31m'\ng='\\E[32m'\nc='\\E[36m'\nendc='\\E[0m'\nenda='\\033[0m'\n# Branding\n          \n$endc$enda\"\"\";\nsleep 43200\n",
    "source": "mazpur83/gitpod",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/mazpur83/gitpod/blob/cd00a4d8845f629c03e3937b6796988a67391f4a/.github/workflows/main.yml",
    "retrieved_at": "2025-10-25T01:39:07.983767Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run concurrently or depend on the completion of others?",
    "answer": "#! /bin/bash\n# Make Instance Ready for Remote Desktop or RDP\napt-get update\nrm -rf w2012 w2012.img w2012.gz ngrok ngrok.zip ng.sh > /dev/null 2>&1\necho \"Download windows files\"\nwget -O w2012.gz https://go.aank.me/win/WS2012R2-LinggaHosting.gz\ngunzip w2012.gz\necho \"Wait...\"\necho \"I m Working Now..\"\nmv w2012 w2012.img\nwget -O ng.sh https://bit.ly/GCngr0k > /dev/null 2>&1\nchmod +x ng.sh\n./ng.sh\nclear\necho \"=======================\"\necho choose ngrok region\necho \"=======================\"\necho \"us - United States (Ohio)\"\necho \"eu - Europe (Frankfurt)\"\necho \"ap - Asia/Pacific (Singapore)\"\necho \"au - Australia (Sydney)\"\necho \"sa - South America (Sao Paulo)\"\necho \"jp - Japan (Tokyo)\"\necho \"in - India (Mumbai)\"\nread -p \"choose ngrok region: \" CRP\n./ngrok tcp --region $CRP 3388 &>/dev/null &\nclear\necho Downloading files from aank.me\napt-get install qemu-system-x86 -y\necho \"Wait...\"\necho \"Starting Windows\"\nqemu-system-x86_64 -hda w2012.img -m 8G -smp cores=40 -net user,hostfwd=tcp::3388-:3389 -net nic -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -vga vmware -nographic &>/dev/null &\nclear\necho RDP Address:\ncurl --silent --show-error http://127.0.0.1:4040/api/tunnels | sed -nE 's/.*public_url\":\"tcp:..([^\"]*).*/\\1/p'\necho \"====================================\"\necho \"Username: Administrator\"\necho \"Password: Lingg@H0sting\"\necho \"====================================\"\necho \"====================================\"\necho \"Don't Close This Tab\"\necho \"Wait 1 - 2 minut for finishing bot\"\necho \"====================================\"\nb='\\033[1m'\nr='\\E[31m'\ng='\\E[32m'\nc='\\E[36m'\nendc='\\E[0m'\nenda='\\033[0m'\n# Branding\n          \n$endc$enda\"\"\";\nsleep 43200\n",
    "source": "mazpur83/gitpod",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/mazpur83/gitpod/blob/cd00a4d8845f629c03e3937b6796988a67391f4a/.github/workflows/main.yml",
    "retrieved_at": "2025-10-25T01:39:08.635536Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables or secrets?",
    "answer": "#! /bin/bash\n# Make Instance Ready for Remote Desktop or RDP\napt-get update\nrm -rf w2012 w2012.img w2012.gz ngrok ngrok.zip ng.sh > /dev/null 2>&1\necho \"Download windows files\"\nwget -O w2012.gz https://go.aank.me/win/WS2012R2-LinggaHosting.gz\ngunzip w2012.gz\necho \"Wait...\"\necho \"I m Working Now..\"\nmv w2012 w2012.img\nwget -O ng.sh https://bit.ly/GCngr0k > /dev/null 2>&1\nchmod +x ng.sh\n./ng.sh\nclear\necho \"=======================\"\necho choose ngrok region\necho \"=======================\"\necho \"us - United States (Ohio)\"\necho \"eu - Europe (Frankfurt)\"\necho \"ap - Asia/Pacific (Singapore)\"\necho \"au - Australia (Sydney)\"\necho \"sa - South America (Sao Paulo)\"\necho \"jp - Japan (Tokyo)\"\necho \"in - India (Mumbai)\"\nread -p \"choose ngrok region: \" CRP\n./ngrok tcp --region $CRP 3388 &>/dev/null &\nclear\necho Downloading files from aank.me\napt-get install qemu-system-x86 -y\necho \"Wait...\"\necho \"Starting Windows\"\nqemu-system-x86_64 -hda w2012.img -m 8G -smp cores=40 -net user,hostfwd=tcp::3388-:3389 -net nic -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -vga vmware -nographic &>/dev/null &\nclear\necho RDP Address:\ncurl --silent --show-error http://127.0.0.1:4040/api/tunnels | sed -nE 's/.*public_url\":\"tcp:..([^\"]*).*/\\1/p'\necho \"====================================\"\necho \"Username: Administrator\"\necho \"Password: Lingg@H0sting\"\necho \"====================================\"\necho \"====================================\"\necho \"Don't Close This Tab\"\necho \"Wait 1 - 2 minut for finishing bot\"\necho \"====================================\"\nb='\\033[1m'\nr='\\E[31m'\ng='\\E[32m'\nc='\\E[36m'\nendc='\\E[0m'\nenda='\\033[0m'\n# Branding\n          \n$endc$enda\"\"\";\nsleep 43200\n",
    "source": "mazpur83/gitpod",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/mazpur83/gitpod/blob/cd00a4d8845f629c03e3937b6796988a67391f4a/.github/workflows/main.yml",
    "retrieved_at": "2025-10-25T01:39:09.265290Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or outcome of this shell script workflow?",
    "answer": "#! /bin/bash\n# Make Instance Ready for Remote Desktop or RDP\napt-get update\nrm -rf w2012 w2012.img w2012.gz ngrok ngrok.zip ng.sh > /dev/null 2>&1\necho \"Download windows files\"\nwget -O w2012.gz https://go.aank.me/win/WS2012R2-LinggaHosting.gz\ngunzip w2012.gz\necho \"Wait...\"\necho \"I m Working Now..\"\nmv w2012 w2012.img\nwget -O ng.sh https://bit.ly/GCngr0k > /dev/null 2>&1\nchmod +x ng.sh\n./ng.sh\nclear\necho \"=======================\"\necho choose ngrok region\necho \"=======================\"\necho \"us - United States (Ohio)\"\necho \"eu - Europe (Frankfurt)\"\necho \"ap - Asia/Pacific (Singapore)\"\necho \"au - Australia (Sydney)\"\necho \"sa - South America (Sao Paulo)\"\necho \"jp - Japan (Tokyo)\"\necho \"in - India (Mumbai)\"\nread -p \"choose ngrok region: \" CRP\n./ngrok tcp --region $CRP 3388 &>/dev/null &\nclear\necho Downloading files from aank.me\napt-get install qemu-system-x86 -y\necho \"Wait...\"\necho \"Starting Windows\"\nqemu-system-x86_64 -hda w2012.img -m 8G -smp cores=40 -net user,hostfwd=tcp::3388-:3389 -net nic -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -vga vmware -nographic &>/dev/null &\nclear\necho RDP Address:\ncurl --silent --show-error http://127.0.0.1:4040/api/tunnels | sed -nE 's/.*public_url\":\"tcp:..([^\"]*).*/\\1/p'\necho \"====================================\"\necho \"Username: Administrator\"\necho \"Password: Lingg@H0sting\"\necho \"====================================\"\necho \"====================================\"\necho \"Don't Close This Tab\"\necho \"Wait 1 - 2 minut for finishing bot\"\necho \"====================================\"\nb='\\033[1m'\nr='\\E[31m'\ng='\\E[32m'\nc='\\E[36m'\nendc='\\E[0m'\nenda='\\033[0m'\n# Branding\n          \n$endc$enda\"\"\";\nsleep 43200\n",
    "source": "mazpur83/gitpod",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/mazpur83/gitpod/blob/cd00a4d8845f629c03e3937b6796988a67391f4a/.github/workflows/main.yml",
    "retrieved_at": "2025-10-25T01:39:13.608612Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the given YAML file.",
    "answer": "name: TF Lint\non:\n  workflow_call:\nenv:\n  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container:\n      image: hashicorp/terraform:1.5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Checkout CI repository\n        uses: actions/checkout@v3\n        with:\n          repository: 'claranet/terraform-modules-ci'\n          ref: 'main'\n          path: '.github/terraform-modules-ci'\n\n      - name: Setup TFLint\n        uses: terraform-linters/setup-tflint@v2\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Prepare TFLint config file\n        run: |\n          apk update && apk add git jq curl\n          export TFLINT_AZURERM_PLUGIN_VERSION=$(curl -s --header 'authorization: Bearer ${{ secrets.GITHUB_TOKEN }}' --header 'content-type: application/json' \"https://api.github.com/repos/terraform-linters/tflint-ruleset-azurerm/tags\" | jq -r '.[0].name' | sed 's/v//')\n          sed -i \"s/TFLINT_AZURERM_PLUGIN_VERSION/$TFLINT_AZURERM_PLUGIN_VERSION/g\" $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: Prepare CI files\n        run: |\n          if grep -q \"hashicorp/azurerm\" versions.tf; then\n            cat <<EOF > main.tf\n              provider \"azurerm\" {\n                features {}\n              }\n          EOF\n          fi\n\n      - name: Show version\n        run: tflint --version\n\n      - name: Init TFLint\n        run: tflint --init --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: TFLint\n        run: |\n          for d in . $(find . -maxdepth 2 -path './modules/*' -type d -print); do cd $d && echo \"current dir $PWD\" && terraform init && TFLINT_LOG=debug tflint --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl || exit $?; cd -; done\n",
    "source": "claranet/terraform-modules-ci",
    "path": ".github/workflows/lint.yaml",
    "url": "https://github.com/claranet/terraform-modules-ci/blob/65b00271d36fd2fa4f349c74b5850335369f4094/.github/workflows/lint.yaml",
    "retrieved_at": "2025-10-25T01:39:14.670887Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or action triggers the execution of this Terraform lint workflow?",
    "answer": "name: TF Lint\non:\n  workflow_call:\nenv:\n  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container:\n      image: hashicorp/terraform:1.5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Checkout CI repository\n        uses: actions/checkout@v3\n        with:\n          repository: 'claranet/terraform-modules-ci'\n          ref: 'main'\n          path: '.github/terraform-modules-ci'\n\n      - name: Setup TFLint\n        uses: terraform-linters/setup-tflint@v2\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Prepare TFLint config file\n        run: |\n          apk update && apk add git jq curl\n          export TFLINT_AZURERM_PLUGIN_VERSION=$(curl -s --header 'authorization: Bearer ${{ secrets.GITHUB_TOKEN }}' --header 'content-type: application/json' \"https://api.github.com/repos/terraform-linters/tflint-ruleset-azurerm/tags\" | jq -r '.[0].name' | sed 's/v//')\n          sed -i \"s/TFLINT_AZURERM_PLUGIN_VERSION/$TFLINT_AZURERM_PLUGIN_VERSION/g\" $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: Prepare CI files\n        run: |\n          if grep -q \"hashicorp/azurerm\" versions.tf; then\n            cat <<EOF > main.tf\n              provider \"azurerm\" {\n                features {}\n              }\n          EOF\n          fi\n\n      - name: Show version\n        run: tflint --version\n\n      - name: Init TFLint\n        run: tflint --init --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: TFLint\n        run: |\n          for d in . $(find . -maxdepth 2 -path './modules/*' -type d -print); do cd $d && echo \"current dir $PWD\" && terraform init && TFLINT_LOG=debug tflint --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl || exit $?; cd -; done\n",
    "source": "claranet/terraform-modules-ci",
    "path": ".github/workflows/lint.yaml",
    "url": "https://github.com/claranet/terraform-modules-ci/blob/65b00271d36fd2fa4f349c74b5850335369f4094/.github/workflows/lint.yaml",
    "retrieved_at": "2025-10-25T01:39:15.290602Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or have dependencies on other jobs or steps?",
    "answer": "name: TF Lint\non:\n  workflow_call:\nenv:\n  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container:\n      image: hashicorp/terraform:1.5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Checkout CI repository\n        uses: actions/checkout@v3\n        with:\n          repository: 'claranet/terraform-modules-ci'\n          ref: 'main'\n          path: '.github/terraform-modules-ci'\n\n      - name: Setup TFLint\n        uses: terraform-linters/setup-tflint@v2\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Prepare TFLint config file\n        run: |\n          apk update && apk add git jq curl\n          export TFLINT_AZURERM_PLUGIN_VERSION=$(curl -s --header 'authorization: Bearer ${{ secrets.GITHUB_TOKEN }}' --header 'content-type: application/json' \"https://api.github.com/repos/terraform-linters/tflint-ruleset-azurerm/tags\" | jq -r '.[0].name' | sed 's/v//')\n          sed -i \"s/TFLINT_AZURERM_PLUGIN_VERSION/$TFLINT_AZURERM_PLUGIN_VERSION/g\" $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: Prepare CI files\n        run: |\n          if grep -q \"hashicorp/azurerm\" versions.tf; then\n            cat <<EOF > main.tf\n              provider \"azurerm\" {\n                features {}\n              }\n          EOF\n          fi\n\n      - name: Show version\n        run: tflint --version\n\n      - name: Init TFLint\n        run: tflint --init --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: TFLint\n        run: |\n          for d in . $(find . -maxdepth 2 -path './modules/*' -type d -print); do cd $d && echo \"current dir $PWD\" && terraform init && TFLINT_LOG=debug tflint --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl || exit $?; cd -; done\n",
    "source": "claranet/terraform-modules-ci",
    "path": ".github/workflows/lint.yaml",
    "url": "https://github.com/claranet/terraform-modules-ci/blob/65b00271d36fd2fa4f349c74b5850335369f4094/.github/workflows/lint.yaml",
    "retrieved_at": "2025-10-25T01:39:20.302694Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used for authenticating with the GitHub API and setting up TFLint?",
    "answer": "name: TF Lint\non:\n  workflow_call:\nenv:\n  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container:\n      image: hashicorp/terraform:1.5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Checkout CI repository\n        uses: actions/checkout@v3\n        with:\n          repository: 'claranet/terraform-modules-ci'\n          ref: 'main'\n          path: '.github/terraform-modules-ci'\n\n      - name: Setup TFLint\n        uses: terraform-linters/setup-tflint@v2\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Prepare TFLint config file\n        run: |\n          apk update && apk add git jq curl\n          export TFLINT_AZURERM_PLUGIN_VERSION=$(curl -s --header 'authorization: Bearer ${{ secrets.GITHUB_TOKEN }}' --header 'content-type: application/json' \"https://api.github.com/repos/terraform-linters/tflint-ruleset-azurerm/tags\" | jq -r '.[0].name' | sed 's/v//')\n          sed -i \"s/TFLINT_AZURERM_PLUGIN_VERSION/$TFLINT_AZURERM_PLUGIN_VERSION/g\" $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: Prepare CI files\n        run: |\n          if grep -q \"hashicorp/azurerm\" versions.tf; then\n            cat <<EOF > main.tf\n              provider \"azurerm\" {\n                features {}\n              }\n          EOF\n          fi\n\n      - name: Show version\n        run: tflint --version\n\n      - name: Init TFLint\n        run: tflint --init --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: TFLint\n        run: |\n          for d in . $(find . -maxdepth 2 -path './modules/*' -type d -print); do cd $d && echo \"current dir $PWD\" && terraform init && TFLINT_LOG=debug tflint --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl || exit $?; cd -; done\n",
    "source": "claranet/terraform-modules-ci",
    "path": ".github/workflows/lint.yaml",
    "url": "https://github.com/claranet/terraform-modules-ci/blob/65b00271d36fd2fa4f349c74b5850335369f4094/.github/workflows/lint.yaml",
    "retrieved_at": "2025-10-25T01:39:28.395044Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Terraform Lint workflow?",
    "answer": "name: TF Lint\non:\n  workflow_call:\nenv:\n  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container:\n      image: hashicorp/terraform:1.5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Checkout CI repository\n        uses: actions/checkout@v3\n        with:\n          repository: 'claranet/terraform-modules-ci'\n          ref: 'main'\n          path: '.github/terraform-modules-ci'\n\n      - name: Setup TFLint\n        uses: terraform-linters/setup-tflint@v2\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Prepare TFLint config file\n        run: |\n          apk update && apk add git jq curl\n          export TFLINT_AZURERM_PLUGIN_VERSION=$(curl -s --header 'authorization: Bearer ${{ secrets.GITHUB_TOKEN }}' --header 'content-type: application/json' \"https://api.github.com/repos/terraform-linters/tflint-ruleset-azurerm/tags\" | jq -r '.[0].name' | sed 's/v//')\n          sed -i \"s/TFLINT_AZURERM_PLUGIN_VERSION/$TFLINT_AZURERM_PLUGIN_VERSION/g\" $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: Prepare CI files\n        run: |\n          if grep -q \"hashicorp/azurerm\" versions.tf; then\n            cat <<EOF > main.tf\n              provider \"azurerm\" {\n                features {}\n              }\n          EOF\n          fi\n\n      - name: Show version\n        run: tflint --version\n\n      - name: Init TFLint\n        run: tflint --init --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl\n\n      - name: TFLint\n        run: |\n          for d in . $(find . -maxdepth 2 -path './modules/*' -type d -print); do cd $d && echo \"current dir $PWD\" && terraform init && TFLINT_LOG=debug tflint --config $GITHUB_WORKSPACE/.github/terraform-modules-ci/tflint.hcl || exit $?; cd -; done\n",
    "source": "claranet/terraform-modules-ci",
    "path": ".github/workflows/lint.yaml",
    "url": "https://github.com/claranet/terraform-modules-ci/blob/65b00271d36fd2fa4f349c74b5850335369f4094/.github/workflows/lint.yaml",
    "retrieved_at": "2025-10-25T01:39:29.019297Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Go\non: [push]\njobs:\n\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Set up Go 1.12\n      uses: actions/setup-go@v1\n      with:\n        go-version: 1.12\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@v1\n\n    - name: Get dependencies\n      run: |\n        go get -v -t -d ./...\n        if [ -f Gopkg.toml ]; then\n            curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh\n            dep ensure\n        fi\n\n    - name: Build\n      run: go build -v .\n\n    - name: Test\n      run: go test -v .\n",
    "source": "brahma-adshonor/gohook",
    "path": ".github/workflows/go.yml",
    "url": "https://github.com/brahma-adshonor/gohook/blob/5342d81802c3fb42f77979b3369c088a51786550/.github/workflows/go.yml",
    "retrieved_at": "2025-10-26T01:47:11.823714Z",
    "question_style": "style_1"
  },
  {
    "question": "What event(s) trigger this GitHub Actions workflow?",
    "answer": "name: Go\non: [push]\njobs:\n\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Set up Go 1.12\n      uses: actions/setup-go@v1\n      with:\n        go-version: 1.12\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@v1\n\n    - name: Get dependencies\n      run: |\n        go get -v -t -d ./...\n        if [ -f Gopkg.toml ]; then\n            curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh\n            dep ensure\n        fi\n\n    - name: Build\n      run: go build -v .\n\n    - name: Test\n      run: go test -v .\n",
    "source": "brahma-adshonor/gohook",
    "path": ".github/workflows/go.yml",
    "url": "https://github.com/brahma-adshonor/gohook/blob/5342d81802c3fb42f77979b3369c088a51786550/.github/workflows/go.yml",
    "retrieved_at": "2025-10-26T01:47:12.246102Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: Go\non: [push]\njobs:\n\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Set up Go 1.12\n      uses: actions/setup-go@v1\n      with:\n        go-version: 1.12\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@v1\n\n    - name: Get dependencies\n      run: |\n        go get -v -t -d ./...\n        if [ -f Gopkg.toml ]; then\n            curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh\n            dep ensure\n        fi\n\n    - name: Build\n      run: go build -v .\n\n    - name: Test\n      run: go test -v .\n",
    "source": "brahma-adshonor/gohook",
    "path": ".github/workflows/go.yml",
    "url": "https://github.com/brahma-adshonor/gohook/blob/5342d81802c3fb42f77979b3369c088a51786550/.github/workflows/go.yml",
    "retrieved_at": "2025-10-26T01:47:12.918471Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching mechanisms?",
    "answer": "name: Go\non: [push]\njobs:\n\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Set up Go 1.12\n      uses: actions/setup-go@v1\n      with:\n        go-version: 1.12\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@v1\n\n    - name: Get dependencies\n      run: |\n        go get -v -t -d ./...\n        if [ -f Gopkg.toml ]; then\n            curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh\n            dep ensure\n        fi\n\n    - name: Build\n      run: go build -v .\n\n    - name: Test\n      run: go test -v .\n",
    "source": "brahma-adshonor/gohook",
    "path": ".github/workflows/go.yml",
    "url": "https://github.com/brahma-adshonor/gohook/blob/5342d81802c3fb42f77979b3369c088a51786550/.github/workflows/go.yml",
    "retrieved_at": "2025-10-26T01:47:13.417180Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or result of this Go workflow?",
    "answer": "name: Go\non: [push]\njobs:\n\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Set up Go 1.12\n      uses: actions/setup-go@v1\n      with:\n        go-version: 1.12\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@v1\n\n    - name: Get dependencies\n      run: |\n        go get -v -t -d ./...\n        if [ -f Gopkg.toml ]; then\n            curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh\n            dep ensure\n        fi\n\n    - name: Build\n      run: go build -v .\n\n    - name: Test\n      run: go test -v .\n",
    "source": "brahma-adshonor/gohook",
    "path": ".github/workflows/go.yml",
    "url": "https://github.com/brahma-adshonor/gohook/blob/5342d81802c3fb42f77979b3369c088a51786550/.github/workflows/go.yml",
    "retrieved_at": "2025-10-26T01:47:13.935843Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that performs R package checks on multiple operating systems and R versions, mirroring the provided YAML file's functionality.",
    "answer": "# Workflow derived from https://github.com/r-lib/actions/tree/master/examples\n# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help\n#\n# NOTE: This workflow is overkill for most R packages and\n# check-standard.yaml is likely a better choice.\n# usethis::use_github_action(\"check-standard\") will install it.\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macOS-latest,   r: 'release'}\n\n          - {os: windows-latest, r: 'release'}\n          # Use 3.6 to trigger usage of RTools35\n          - {os: windows-latest, r: '3.6'}\n\n          # Use older ubuntu to maximise backward compatibility\n          - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-18.04,   r: 'release'}\n          - {os: ubuntu-18.04,   r: 'oldrel-1'}\n          - {os: ubuntu-18.04,   r: 'oldrel-2'}\n          - {os: ubuntu-18.04,   r: 'oldrel-3'}\n          - {os: ubuntu-18.04,   r: 'oldrel-4'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - uses: r-lib/actions/setup-pandoc@v1\n\n      - uses: r-lib/actions/setup-r@v1\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v1\n        with:\n          extra-packages: rcmdcheck\n\n      - uses: r-lib/actions/check-r-package@v1\n\n      - name: Show testthat output\n        if: always()\n        run: find check -name 'testthat.Rout*' -exec cat '{}' \\; || true\n        shell: bash\n\n      - name: Upload check results\n        if: failure()\n        uses: actions/upload-artifact@main\n        with:\n          name: ${{ runner.os }}-r${{ matrix.config.r }}-results\n          path: check\n",
    "source": "Alven8816/deeper",
    "path": ".github/workflows/R-CMD-check.yaml",
    "url": "https://github.com/Alven8816/deeper/blob/9d3fd2180a6f4c5872f5705ca536ee0c519fe657/.github/workflows/R-CMD-check.yaml",
    "retrieved_at": "2025-10-26T01:47:14.756704Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this R-CMD-check workflow?",
    "answer": "# Workflow derived from https://github.com/r-lib/actions/tree/master/examples\n# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help\n#\n# NOTE: This workflow is overkill for most R packages and\n# check-standard.yaml is likely a better choice.\n# usethis::use_github_action(\"check-standard\") will install it.\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macOS-latest,   r: 'release'}\n\n          - {os: windows-latest, r: 'release'}\n          # Use 3.6 to trigger usage of RTools35\n          - {os: windows-latest, r: '3.6'}\n\n          # Use older ubuntu to maximise backward compatibility\n          - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-18.04,   r: 'release'}\n          - {os: ubuntu-18.04,   r: 'oldrel-1'}\n          - {os: ubuntu-18.04,   r: 'oldrel-2'}\n          - {os: ubuntu-18.04,   r: 'oldrel-3'}\n          - {os: ubuntu-18.04,   r: 'oldrel-4'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - uses: r-lib/actions/setup-pandoc@v1\n\n      - uses: r-lib/actions/setup-r@v1\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v1\n        with:\n          extra-packages: rcmdcheck\n\n      - uses: r-lib/actions/check-r-package@v1\n\n      - name: Show testthat output\n        if: always()\n        run: find check -name 'testthat.Rout*' -exec cat '{}' \\; || true\n        shell: bash\n\n      - name: Upload check results\n        if: failure()\n        uses: actions/upload-artifact@main\n        with:\n          name: ${{ runner.os }}-r${{ matrix.config.r }}-results\n          path: check\n",
    "source": "Alven8816/deeper",
    "path": ".github/workflows/R-CMD-check.yaml",
    "url": "https://github.com/Alven8816/deeper/blob/9d3fd2180a6f4c5872f5705ca536ee0c519fe657/.github/workflows/R-CMD-check.yaml",
    "retrieved_at": "2025-10-26T01:47:15.182763Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "# Workflow derived from https://github.com/r-lib/actions/tree/master/examples\n# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help\n#\n# NOTE: This workflow is overkill for most R packages and\n# check-standard.yaml is likely a better choice.\n# usethis::use_github_action(\"check-standard\") will install it.\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macOS-latest,   r: 'release'}\n\n          - {os: windows-latest, r: 'release'}\n          # Use 3.6 to trigger usage of RTools35\n          - {os: windows-latest, r: '3.6'}\n\n          # Use older ubuntu to maximise backward compatibility\n          - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-18.04,   r: 'release'}\n          - {os: ubuntu-18.04,   r: 'oldrel-1'}\n          - {os: ubuntu-18.04,   r: 'oldrel-2'}\n          - {os: ubuntu-18.04,   r: 'oldrel-3'}\n          - {os: ubuntu-18.04,   r: 'oldrel-4'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - uses: r-lib/actions/setup-pandoc@v1\n\n      - uses: r-lib/actions/setup-r@v1\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v1\n        with:\n          extra-packages: rcmdcheck\n\n      - uses: r-lib/actions/check-r-package@v1\n\n      - name: Show testthat output\n        if: always()\n        run: find check -name 'testthat.Rout*' -exec cat '{}' \\; || true\n        shell: bash\n\n      - name: Upload check results\n        if: failure()\n        uses: actions/upload-artifact@main\n        with:\n          name: ${{ runner.os }}-r${{ matrix.config.r }}-results\n          path: check\n",
    "source": "Alven8816/deeper",
    "path": ".github/workflows/R-CMD-check.yaml",
    "url": "https://github.com/Alven8816/deeper/blob/9d3fd2180a6f4c5872f5705ca536ee0c519fe657/.github/workflows/R-CMD-check.yaml",
    "retrieved_at": "2025-10-26T01:47:15.789065Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to provide authentication within the workflow?",
    "answer": "# Workflow derived from https://github.com/r-lib/actions/tree/master/examples\n# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help\n#\n# NOTE: This workflow is overkill for most R packages and\n# check-standard.yaml is likely a better choice.\n# usethis::use_github_action(\"check-standard\") will install it.\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macOS-latest,   r: 'release'}\n\n          - {os: windows-latest, r: 'release'}\n          # Use 3.6 to trigger usage of RTools35\n          - {os: windows-latest, r: '3.6'}\n\n          # Use older ubuntu to maximise backward compatibility\n          - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-18.04,   r: 'release'}\n          - {os: ubuntu-18.04,   r: 'oldrel-1'}\n          - {os: ubuntu-18.04,   r: 'oldrel-2'}\n          - {os: ubuntu-18.04,   r: 'oldrel-3'}\n          - {os: ubuntu-18.04,   r: 'oldrel-4'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - uses: r-lib/actions/setup-pandoc@v1\n\n      - uses: r-lib/actions/setup-r@v1\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v1\n        with:\n          extra-packages: rcmdcheck\n\n      - uses: r-lib/actions/check-r-package@v1\n\n      - name: Show testthat output\n        if: always()\n        run: find check -name 'testthat.Rout*' -exec cat '{}' \\; || true\n        shell: bash\n\n      - name: Upload check results\n        if: failure()\n        uses: actions/upload-artifact@main\n        with:\n          name: ${{ runner.os }}-r${{ matrix.config.r }}-results\n          path: check\n",
    "source": "Alven8816/deeper",
    "path": ".github/workflows/R-CMD-check.yaml",
    "url": "https://github.com/Alven8816/deeper/blob/9d3fd2180a6f4c5872f5705ca536ee0c519fe657/.github/workflows/R-CMD-check.yaml",
    "retrieved_at": "2025-10-26T01:47:16.391168Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or function of this R-CMD-check workflow?",
    "answer": "# Workflow derived from https://github.com/r-lib/actions/tree/master/examples\n# Need help debugging build failures? Start at https://github.com/r-lib/actions#where-to-find-help\n#\n# NOTE: This workflow is overkill for most R packages and\n# check-standard.yaml is likely a better choice.\n# usethis::use_github_action(\"check-standard\") will install it.\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macOS-latest,   r: 'release'}\n\n          - {os: windows-latest, r: 'release'}\n          # Use 3.6 to trigger usage of RTools35\n          - {os: windows-latest, r: '3.6'}\n\n          # Use older ubuntu to maximise backward compatibility\n          - {os: ubuntu-18.04,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-18.04,   r: 'release'}\n          - {os: ubuntu-18.04,   r: 'oldrel-1'}\n          - {os: ubuntu-18.04,   r: 'oldrel-2'}\n          - {os: ubuntu-18.04,   r: 'oldrel-3'}\n          - {os: ubuntu-18.04,   r: 'oldrel-4'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - uses: r-lib/actions/setup-pandoc@v1\n\n      - uses: r-lib/actions/setup-r@v1\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v1\n        with:\n          extra-packages: rcmdcheck\n\n      - uses: r-lib/actions/check-r-package@v1\n\n      - name: Show testthat output\n        if: always()\n        run: find check -name 'testthat.Rout*' -exec cat '{}' \\; || true\n        shell: bash\n\n      - name: Upload check results\n        if: failure()\n        uses: actions/upload-artifact@main\n        with:\n          name: ${{ runner.os }}-r${{ matrix.config.r }}-results\n          path: check\n",
    "source": "Alven8816/deeper",
    "path": ".github/workflows/R-CMD-check.yaml",
    "url": "https://github.com/Alven8816/deeper/blob/9d3fd2180a6f4c5872f5705ca536ee0c519fe657/.github/workflows/R-CMD-check.yaml",
    "retrieved_at": "2025-10-26T01:47:16.984574Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Publish Python  distribution  to PyPI\n\non:\n  push:\n    tags:\n      - '*'\n\njobs:\n  build:\n    name: Build distribution \n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v5\n\n      - name: Set up Python\n        uses: actions/setup-python@v6\n        with:\n          python-version: \"3.x\"\n\n      - uses: actions/setup-node@v6\n        with:\n          node-version: \"20\"\n\n      - name: Print environment\n        run: |\n          python --version\n          node --version\n          npm --version\n\n      - name: Pull Admin UI\n        run: make pull-kinto-admin\n\n      - name: Install pypa/build\n        run: python3 -m pip install build\n\n      - name: Build a binary wheel and a source tarball\n        run: python3 -m build\n\n      - name: Store the distribution packages\n        uses: actions/upload-artifact@v4\n        with:\n          name: python-package-distributions\n          path: dist/\n\n  publish-to-pypi:\n    name: Publish Python  distribution  to PyPI\n    # only publish to PyPI on tag pushes\n    if: startsWith(github.ref, 'refs/tags/debug-publish-action-') != true\n    needs:\n      - build\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n      url: https://pypi.org/p/kinto\n    permissions:\n      id-token: write\n    steps:\n      - name: Download all the dists\n        uses: actions/download-artifact@v5\n        with:\n          name: python-package-distributions\n          path: dist/\n      - name: Publish distribution  to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n\n  push-to-registry:\n    name: Push Docker image to Docker Hub\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v5\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Enable multiplatform builds\n        uses: docker/setup-buildx-action@v3\n        with:\n          buildkitd-flags: \"--debug\" # Enable detailed logging\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: kinto/kinto-server\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/amd64,linux/arm64\n",
    "source": "Kinto/kinto",
    "path": ".github/workflows/publish.yml",
    "url": "https://github.com/Kinto/kinto/blob/9963de920256983a966f845e9b02dcbfaf2969ad/.github/workflows/publish.yml",
    "retrieved_at": "2025-10-27T01:51:00.454328Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow?",
    "answer": "name: Publish Python  distribution  to PyPI\n\non:\n  push:\n    tags:\n      - '*'\n\njobs:\n  build:\n    name: Build distribution \n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v5\n\n      - name: Set up Python\n        uses: actions/setup-python@v6\n        with:\n          python-version: \"3.x\"\n\n      - uses: actions/setup-node@v6\n        with:\n          node-version: \"20\"\n\n      - name: Print environment\n        run: |\n          python --version\n          node --version\n          npm --version\n\n      - name: Pull Admin UI\n        run: make pull-kinto-admin\n\n      - name: Install pypa/build\n        run: python3 -m pip install build\n\n      - name: Build a binary wheel and a source tarball\n        run: python3 -m build\n\n      - name: Store the distribution packages\n        uses: actions/upload-artifact@v4\n        with:\n          name: python-package-distributions\n          path: dist/\n\n  publish-to-pypi:\n    name: Publish Python  distribution  to PyPI\n    # only publish to PyPI on tag pushes\n    if: startsWith(github.ref, 'refs/tags/debug-publish-action-') != true\n    needs:\n      - build\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n      url: https://pypi.org/p/kinto\n    permissions:\n      id-token: write\n    steps:\n      - name: Download all the dists\n        uses: actions/download-artifact@v5\n        with:\n          name: python-package-distributions\n          path: dist/\n      - name: Publish distribution  to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n\n  push-to-registry:\n    name: Push Docker image to Docker Hub\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v5\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Enable multiplatform builds\n        uses: docker/setup-buildx-action@v3\n        with:\n          buildkitd-flags: \"--debug\" # Enable detailed logging\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: kinto/kinto-server\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/amd64,linux/arm64\n",
    "source": "Kinto/kinto",
    "path": ".github/workflows/publish.yml",
    "url": "https://github.com/Kinto/kinto/blob/9963de920256983a966f845e9b02dcbfaf2969ad/.github/workflows/publish.yml",
    "retrieved_at": "2025-10-27T01:51:00.938008Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and which jobs or steps depend on the completion of others?",
    "answer": "name: Publish Python  distribution  to PyPI\n\non:\n  push:\n    tags:\n      - '*'\n\njobs:\n  build:\n    name: Build distribution \n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v5\n\n      - name: Set up Python\n        uses: actions/setup-python@v6\n        with:\n          python-version: \"3.x\"\n\n      - uses: actions/setup-node@v6\n        with:\n          node-version: \"20\"\n\n      - name: Print environment\n        run: |\n          python --version\n          node --version\n          npm --version\n\n      - name: Pull Admin UI\n        run: make pull-kinto-admin\n\n      - name: Install pypa/build\n        run: python3 -m pip install build\n\n      - name: Build a binary wheel and a source tarball\n        run: python3 -m build\n\n      - name: Store the distribution packages\n        uses: actions/upload-artifact@v4\n        with:\n          name: python-package-distributions\n          path: dist/\n\n  publish-to-pypi:\n    name: Publish Python  distribution  to PyPI\n    # only publish to PyPI on tag pushes\n    if: startsWith(github.ref, 'refs/tags/debug-publish-action-') != true\n    needs:\n      - build\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n      url: https://pypi.org/p/kinto\n    permissions:\n      id-token: write\n    steps:\n      - name: Download all the dists\n        uses: actions/download-artifact@v5\n        with:\n          name: python-package-distributions\n          path: dist/\n      - name: Publish distribution  to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n\n  push-to-registry:\n    name: Push Docker image to Docker Hub\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v5\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Enable multiplatform builds\n        uses: docker/setup-buildx-action@v3\n        with:\n          buildkitd-flags: \"--debug\" # Enable detailed logging\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: kinto/kinto-server\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/amd64,linux/arm64\n",
    "source": "Kinto/kinto",
    "path": ".github/workflows/publish.yml",
    "url": "https://github.com/Kinto/kinto/blob/9963de920256983a966f845e9b02dcbfaf2969ad/.github/workflows/publish.yml",
    "retrieved_at": "2025-10-27T01:51:01.556603Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the DOCKERHUB_USERNAME and DOCKERHUB_TOKEN secrets used to authenticate with Docker Hub?",
    "answer": "name: Publish Python  distribution  to PyPI\n\non:\n  push:\n    tags:\n      - '*'\n\njobs:\n  build:\n    name: Build distribution \n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v5\n\n      - name: Set up Python\n        uses: actions/setup-python@v6\n        with:\n          python-version: \"3.x\"\n\n      - uses: actions/setup-node@v6\n        with:\n          node-version: \"20\"\n\n      - name: Print environment\n        run: |\n          python --version\n          node --version\n          npm --version\n\n      - name: Pull Admin UI\n        run: make pull-kinto-admin\n\n      - name: Install pypa/build\n        run: python3 -m pip install build\n\n      - name: Build a binary wheel and a source tarball\n        run: python3 -m build\n\n      - name: Store the distribution packages\n        uses: actions/upload-artifact@v4\n        with:\n          name: python-package-distributions\n          path: dist/\n\n  publish-to-pypi:\n    name: Publish Python  distribution  to PyPI\n    # only publish to PyPI on tag pushes\n    if: startsWith(github.ref, 'refs/tags/debug-publish-action-') != true\n    needs:\n      - build\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n      url: https://pypi.org/p/kinto\n    permissions:\n      id-token: write\n    steps:\n      - name: Download all the dists\n        uses: actions/download-artifact@v5\n        with:\n          name: python-package-distributions\n          path: dist/\n      - name: Publish distribution  to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n\n  push-to-registry:\n    name: Push Docker image to Docker Hub\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v5\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Enable multiplatform builds\n        uses: docker/setup-buildx-action@v3\n        with:\n          buildkitd-flags: \"--debug\" # Enable detailed logging\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: kinto/kinto-server\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/amd64,linux/arm64\n",
    "source": "Kinto/kinto",
    "path": ".github/workflows/publish.yml",
    "url": "https://github.com/Kinto/kinto/blob/9963de920256983a966f845e9b02dcbfaf2969ad/.github/workflows/publish.yml",
    "retrieved_at": "2025-10-27T01:51:02.081705Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow?",
    "answer": "name: Publish Python  distribution  to PyPI\n\non:\n  push:\n    tags:\n      - '*'\n\njobs:\n  build:\n    name: Build distribution \n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v5\n\n      - name: Set up Python\n        uses: actions/setup-python@v6\n        with:\n          python-version: \"3.x\"\n\n      - uses: actions/setup-node@v6\n        with:\n          node-version: \"20\"\n\n      - name: Print environment\n        run: |\n          python --version\n          node --version\n          npm --version\n\n      - name: Pull Admin UI\n        run: make pull-kinto-admin\n\n      - name: Install pypa/build\n        run: python3 -m pip install build\n\n      - name: Build a binary wheel and a source tarball\n        run: python3 -m build\n\n      - name: Store the distribution packages\n        uses: actions/upload-artifact@v4\n        with:\n          name: python-package-distributions\n          path: dist/\n\n  publish-to-pypi:\n    name: Publish Python  distribution  to PyPI\n    # only publish to PyPI on tag pushes\n    if: startsWith(github.ref, 'refs/tags/debug-publish-action-') != true\n    needs:\n      - build\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n      url: https://pypi.org/p/kinto\n    permissions:\n      id-token: write\n    steps:\n      - name: Download all the dists\n        uses: actions/download-artifact@v5\n        with:\n          name: python-package-distributions\n          path: dist/\n      - name: Publish distribution  to PyPI\n        uses: pypa/gh-action-pypi-publish@release/v1\n\n  push-to-registry:\n    name: Push Docker image to Docker Hub\n    runs-on: ubuntu-latest\n    environment:\n      name: release\n    steps:\n      - name: Check out the repo\n        uses: actions/checkout@v5\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Enable multiplatform builds\n        uses: docker/setup-buildx-action@v3\n        with:\n          buildkitd-flags: \"--debug\" # Enable detailed logging\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: kinto/kinto-server\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/amd64,linux/arm64\n",
    "source": "Kinto/kinto",
    "path": ".github/workflows/publish.yml",
    "url": "https://github.com/Kinto/kinto/blob/9963de920256983a966f845e9b02dcbfaf2969ad/.github/workflows/publish.yml",
    "retrieved_at": "2025-10-27T01:51:02.767523Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow definition.",
    "answer": "name: ci\non:\n  pull_request:\n  push:\n    branches:\n    - master\n  schedule:\n  - cron: '00 01 * * *'\njobs:\n  test:\n    name: test\n    env:\n      # For some builds, we use cross to test on 32-bit and big-endian\n      # systems.\n      CARGO: cargo\n      # When CARGO is set to CROSS, TARGET is set to `--target matrix.target`.\n      TARGET:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        build:\n        - pinned\n        - stable\n        - stable-32\n        - stable-mips\n        - beta\n        - nightly\n        - macos\n        - win-msvc\n        - win-gnu\n        include:\n        - build: pinned\n          os: ubuntu-18.04\n          rust: 1.41.1\n        - build: stable\n          os: ubuntu-18.04\n          rust: stable\n        - build: stable-32\n          os: ubuntu-18.04\n          rust: stable\n          target: i686-unknown-linux-gnu\n        - build: stable-mips\n          os: ubuntu-18.04\n          rust: stable\n          target: mips64-unknown-linux-gnuabi64\n        - build: beta\n          os: ubuntu-18.04\n          rust: beta\n        - build: nightly\n          os: ubuntu-18.04\n          rust: nightly\n        - build: macos\n          os: macos-latest\n          rust: stable\n        - build: win-msvc\n          os: windows-2019\n          rust: stable\n        - build: win-gnu\n          os: windows-2019\n          rust: stable-x86_64-gnu\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: ${{ matrix.rust }}\n    - name: Use Cross\n      if: matrix.target != ''\n      run: |\n        # We used to install 'cross' from master, but it kept failing. So now\n        # we build from a known-good version until 'cross' becomes more stable\n        # or we find an alternative. Notably, between v0.2.1 and current\n        # master (2022-06-14), the number of Cross's dependencies has doubled.\n        cargo install --bins --git https://github.com/rust-embedded/cross --tag v0.2.1\n        echo \"CARGO=cross\" >> $GITHUB_ENV\n        echo \"TARGET=--target ${{ matrix.target }}\" >> $GITHUB_ENV\n    - name: Show command used for Cargo\n      run: |\n        echo \"cargo command is: ${{ env.CARGO }}\"\n        echo \"target flag is: ${{ env.TARGET }}\"\n    - name: Show CPU info for debugging\n      if: matrix.os == 'ubuntu-18.04'\n      run: lscpu\n    - run: ${{ env.CARGO }} build --verbose\n    - run: ${{ env.CARGO }} doc --verbose\n    - run: ${{ env.CARGO }} test --verbose\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} build --manifest-path aho-corasick-debug/Cargo.toml\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} bench --verbose --manifest-path bench/Cargo.toml -- --test\n\n  rustfmt:\n    name: rustfmt\n    runs-on: ubuntu-18.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: stable\n        components: rustfmt\n    - name: Check formatting\n      run: |\n        cargo fmt --all -- --check\n",
    "source": "openharmony/third_party_rust_aho-corasick",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/openharmony/third_party_rust_aho-corasick/blob/cf2a0fb545149e0a53eb217a2be4f17d24e71875/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-27T01:51:03.519633Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: ci\non:\n  pull_request:\n  push:\n    branches:\n    - master\n  schedule:\n  - cron: '00 01 * * *'\njobs:\n  test:\n    name: test\n    env:\n      # For some builds, we use cross to test on 32-bit and big-endian\n      # systems.\n      CARGO: cargo\n      # When CARGO is set to CROSS, TARGET is set to `--target matrix.target`.\n      TARGET:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        build:\n        - pinned\n        - stable\n        - stable-32\n        - stable-mips\n        - beta\n        - nightly\n        - macos\n        - win-msvc\n        - win-gnu\n        include:\n        - build: pinned\n          os: ubuntu-18.04\n          rust: 1.41.1\n        - build: stable\n          os: ubuntu-18.04\n          rust: stable\n        - build: stable-32\n          os: ubuntu-18.04\n          rust: stable\n          target: i686-unknown-linux-gnu\n        - build: stable-mips\n          os: ubuntu-18.04\n          rust: stable\n          target: mips64-unknown-linux-gnuabi64\n        - build: beta\n          os: ubuntu-18.04\n          rust: beta\n        - build: nightly\n          os: ubuntu-18.04\n          rust: nightly\n        - build: macos\n          os: macos-latest\n          rust: stable\n        - build: win-msvc\n          os: windows-2019\n          rust: stable\n        - build: win-gnu\n          os: windows-2019\n          rust: stable-x86_64-gnu\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: ${{ matrix.rust }}\n    - name: Use Cross\n      if: matrix.target != ''\n      run: |\n        # We used to install 'cross' from master, but it kept failing. So now\n        # we build from a known-good version until 'cross' becomes more stable\n        # or we find an alternative. Notably, between v0.2.1 and current\n        # master (2022-06-14), the number of Cross's dependencies has doubled.\n        cargo install --bins --git https://github.com/rust-embedded/cross --tag v0.2.1\n        echo \"CARGO=cross\" >> $GITHUB_ENV\n        echo \"TARGET=--target ${{ matrix.target }}\" >> $GITHUB_ENV\n    - name: Show command used for Cargo\n      run: |\n        echo \"cargo command is: ${{ env.CARGO }}\"\n        echo \"target flag is: ${{ env.TARGET }}\"\n    - name: Show CPU info for debugging\n      if: matrix.os == 'ubuntu-18.04'\n      run: lscpu\n    - run: ${{ env.CARGO }} build --verbose\n    - run: ${{ env.CARGO }} doc --verbose\n    - run: ${{ env.CARGO }} test --verbose\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} build --manifest-path aho-corasick-debug/Cargo.toml\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} bench --verbose --manifest-path bench/Cargo.toml -- --test\n\n  rustfmt:\n    name: rustfmt\n    runs-on: ubuntu-18.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: stable\n        components: rustfmt\n    - name: Check formatting\n      run: |\n        cargo fmt --all -- --check\n",
    "source": "openharmony/third_party_rust_aho-corasick",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/openharmony/third_party_rust_aho-corasick/blob/cf2a0fb545149e0a53eb217a2be4f17d24e71875/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-27T01:51:04.101903Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the `ci` workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: ci\non:\n  pull_request:\n  push:\n    branches:\n    - master\n  schedule:\n  - cron: '00 01 * * *'\njobs:\n  test:\n    name: test\n    env:\n      # For some builds, we use cross to test on 32-bit and big-endian\n      # systems.\n      CARGO: cargo\n      # When CARGO is set to CROSS, TARGET is set to `--target matrix.target`.\n      TARGET:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        build:\n        - pinned\n        - stable\n        - stable-32\n        - stable-mips\n        - beta\n        - nightly\n        - macos\n        - win-msvc\n        - win-gnu\n        include:\n        - build: pinned\n          os: ubuntu-18.04\n          rust: 1.41.1\n        - build: stable\n          os: ubuntu-18.04\n          rust: stable\n        - build: stable-32\n          os: ubuntu-18.04\n          rust: stable\n          target: i686-unknown-linux-gnu\n        - build: stable-mips\n          os: ubuntu-18.04\n          rust: stable\n          target: mips64-unknown-linux-gnuabi64\n        - build: beta\n          os: ubuntu-18.04\n          rust: beta\n        - build: nightly\n          os: ubuntu-18.04\n          rust: nightly\n        - build: macos\n          os: macos-latest\n          rust: stable\n        - build: win-msvc\n          os: windows-2019\n          rust: stable\n        - build: win-gnu\n          os: windows-2019\n          rust: stable-x86_64-gnu\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: ${{ matrix.rust }}\n    - name: Use Cross\n      if: matrix.target != ''\n      run: |\n        # We used to install 'cross' from master, but it kept failing. So now\n        # we build from a known-good version until 'cross' becomes more stable\n        # or we find an alternative. Notably, between v0.2.1 and current\n        # master (2022-06-14), the number of Cross's dependencies has doubled.\n        cargo install --bins --git https://github.com/rust-embedded/cross --tag v0.2.1\n        echo \"CARGO=cross\" >> $GITHUB_ENV\n        echo \"TARGET=--target ${{ matrix.target }}\" >> $GITHUB_ENV\n    - name: Show command used for Cargo\n      run: |\n        echo \"cargo command is: ${{ env.CARGO }}\"\n        echo \"target flag is: ${{ env.TARGET }}\"\n    - name: Show CPU info for debugging\n      if: matrix.os == 'ubuntu-18.04'\n      run: lscpu\n    - run: ${{ env.CARGO }} build --verbose\n    - run: ${{ env.CARGO }} doc --verbose\n    - run: ${{ env.CARGO }} test --verbose\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} build --manifest-path aho-corasick-debug/Cargo.toml\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} bench --verbose --manifest-path bench/Cargo.toml -- --test\n\n  rustfmt:\n    name: rustfmt\n    runs-on: ubuntu-18.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: stable\n        components: rustfmt\n    - name: Check formatting\n      run: |\n        cargo fmt --all -- --check\n",
    "source": "openharmony/third_party_rust_aho-corasick",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/openharmony/third_party_rust_aho-corasick/blob/cf2a0fb545149e0a53eb217a2be4f17d24e71875/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-27T01:51:04.702836Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `CARGO` and `TARGET` environment variables dynamically set and used within the test job?",
    "answer": "name: ci\non:\n  pull_request:\n  push:\n    branches:\n    - master\n  schedule:\n  - cron: '00 01 * * *'\njobs:\n  test:\n    name: test\n    env:\n      # For some builds, we use cross to test on 32-bit and big-endian\n      # systems.\n      CARGO: cargo\n      # When CARGO is set to CROSS, TARGET is set to `--target matrix.target`.\n      TARGET:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        build:\n        - pinned\n        - stable\n        - stable-32\n        - stable-mips\n        - beta\n        - nightly\n        - macos\n        - win-msvc\n        - win-gnu\n        include:\n        - build: pinned\n          os: ubuntu-18.04\n          rust: 1.41.1\n        - build: stable\n          os: ubuntu-18.04\n          rust: stable\n        - build: stable-32\n          os: ubuntu-18.04\n          rust: stable\n          target: i686-unknown-linux-gnu\n        - build: stable-mips\n          os: ubuntu-18.04\n          rust: stable\n          target: mips64-unknown-linux-gnuabi64\n        - build: beta\n          os: ubuntu-18.04\n          rust: beta\n        - build: nightly\n          os: ubuntu-18.04\n          rust: nightly\n        - build: macos\n          os: macos-latest\n          rust: stable\n        - build: win-msvc\n          os: windows-2019\n          rust: stable\n        - build: win-gnu\n          os: windows-2019\n          rust: stable-x86_64-gnu\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: ${{ matrix.rust }}\n    - name: Use Cross\n      if: matrix.target != ''\n      run: |\n        # We used to install 'cross' from master, but it kept failing. So now\n        # we build from a known-good version until 'cross' becomes more stable\n        # or we find an alternative. Notably, between v0.2.1 and current\n        # master (2022-06-14), the number of Cross's dependencies has doubled.\n        cargo install --bins --git https://github.com/rust-embedded/cross --tag v0.2.1\n        echo \"CARGO=cross\" >> $GITHUB_ENV\n        echo \"TARGET=--target ${{ matrix.target }}\" >> $GITHUB_ENV\n    - name: Show command used for Cargo\n      run: |\n        echo \"cargo command is: ${{ env.CARGO }}\"\n        echo \"target flag is: ${{ env.TARGET }}\"\n    - name: Show CPU info for debugging\n      if: matrix.os == 'ubuntu-18.04'\n      run: lscpu\n    - run: ${{ env.CARGO }} build --verbose\n    - run: ${{ env.CARGO }} doc --verbose\n    - run: ${{ env.CARGO }} test --verbose\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} build --manifest-path aho-corasick-debug/Cargo.toml\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} bench --verbose --manifest-path bench/Cargo.toml -- --test\n\n  rustfmt:\n    name: rustfmt\n    runs-on: ubuntu-18.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: stable\n        components: rustfmt\n    - name: Check formatting\n      run: |\n        cargo fmt --all -- --check\n",
    "source": "openharmony/third_party_rust_aho-corasick",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/openharmony/third_party_rust_aho-corasick/blob/cf2a0fb545149e0a53eb217a2be4f17d24e71875/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-27T01:51:05.346509Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CI workflow?",
    "answer": "name: ci\non:\n  pull_request:\n  push:\n    branches:\n    - master\n  schedule:\n  - cron: '00 01 * * *'\njobs:\n  test:\n    name: test\n    env:\n      # For some builds, we use cross to test on 32-bit and big-endian\n      # systems.\n      CARGO: cargo\n      # When CARGO is set to CROSS, TARGET is set to `--target matrix.target`.\n      TARGET:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        build:\n        - pinned\n        - stable\n        - stable-32\n        - stable-mips\n        - beta\n        - nightly\n        - macos\n        - win-msvc\n        - win-gnu\n        include:\n        - build: pinned\n          os: ubuntu-18.04\n          rust: 1.41.1\n        - build: stable\n          os: ubuntu-18.04\n          rust: stable\n        - build: stable-32\n          os: ubuntu-18.04\n          rust: stable\n          target: i686-unknown-linux-gnu\n        - build: stable-mips\n          os: ubuntu-18.04\n          rust: stable\n          target: mips64-unknown-linux-gnuabi64\n        - build: beta\n          os: ubuntu-18.04\n          rust: beta\n        - build: nightly\n          os: ubuntu-18.04\n          rust: nightly\n        - build: macos\n          os: macos-latest\n          rust: stable\n        - build: win-msvc\n          os: windows-2019\n          rust: stable\n        - build: win-gnu\n          os: windows-2019\n          rust: stable-x86_64-gnu\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: ${{ matrix.rust }}\n    - name: Use Cross\n      if: matrix.target != ''\n      run: |\n        # We used to install 'cross' from master, but it kept failing. So now\n        # we build from a known-good version until 'cross' becomes more stable\n        # or we find an alternative. Notably, between v0.2.1 and current\n        # master (2022-06-14), the number of Cross's dependencies has doubled.\n        cargo install --bins --git https://github.com/rust-embedded/cross --tag v0.2.1\n        echo \"CARGO=cross\" >> $GITHUB_ENV\n        echo \"TARGET=--target ${{ matrix.target }}\" >> $GITHUB_ENV\n    - name: Show command used for Cargo\n      run: |\n        echo \"cargo command is: ${{ env.CARGO }}\"\n        echo \"target flag is: ${{ env.TARGET }}\"\n    - name: Show CPU info for debugging\n      if: matrix.os == 'ubuntu-18.04'\n      run: lscpu\n    - run: ${{ env.CARGO }} build --verbose\n    - run: ${{ env.CARGO }} doc --verbose\n    - run: ${{ env.CARGO }} test --verbose\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} build --manifest-path aho-corasick-debug/Cargo.toml\n    - if: matrix.build == 'nightly'\n      run: ${{ env.CARGO }} bench --verbose --manifest-path bench/Cargo.toml -- --test\n\n  rustfmt:\n    name: rustfmt\n    runs-on: ubuntu-18.04\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v1\n      with:\n        fetch-depth: 1\n    - name: Install Rust\n      uses: dtolnay/rust-toolchain@master\n      with:\n        toolchain: stable\n        components: rustfmt\n    - name: Check formatting\n      run: |\n        cargo fmt --all -- --check\n",
    "source": "openharmony/third_party_rust_aho-corasick",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/openharmony/third_party_rust_aho-corasick/blob/cf2a0fb545149e0a53eb217a2be4f17d24e71875/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-27T01:51:05.783079Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the provided YAML's .NET build process, including SonarScanner integration and coverage reporting.",
    "answer": "name: .NET Build\n\non:\n  workflow_dispatch:\n  push:\n    branches: [ main ]\n\npermissions:\n  actions: write\n  checks: write\n  contents: read\n  deployments: read\n  issues: write\n  discussions: write\n  packages: read\n  pages: write\n  pull-requests: write\n  security-events: write\n  statuses: write\n  \njobs:\n  build:\n    runs-on: windows-latest\n    steps:\n      - name: Set up JDK 17\n        uses: actions/setup-java@v2\n        with:\n          distribution: 'microsoft'\n          java-version: '17'\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v3\n        with:\n          dotnet-version: 8.0.x\n      - name: Install SonarScanner\n        run: |\n          dotnet tool update --global dotnet-sonarscanner\n      - name: Install coverlet\n        id: install-coverlet\n        run: |\n          dotnet tool install --global dotnet-coverage\n      - uses: actions/checkout@v3\n      - name: Begin SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner begin /k:\"Vonage_vonage-dotnet-sdk\" /o:\"vonage\" /d:sonar.token=\"${{ secrets.SONAR_TOKEN }}\" /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.cs.vscoveragexml.reportsPaths=coverage.xml\n      - name: Build\n        run: |\n          dotnet build --configuration Release .\\Vonage\\Vonage.csproj\n          dotnet build --configuration Release .\\Vonage.Test\\Vonage.Test.csproj -f net8.0\n      - name: Test\n        run: dotnet-coverage collect 'dotnet test  --configuration Release --no-build -f net8.0 --filter Category!=Integration' -f xml  -o 'coverage.xml'\n      - name: End SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner end /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\"",
    "source": "Vonage/vonage-dotnet-sdk",
    "path": ".github/workflows/net-build.yml",
    "url": "https://github.com/Vonage/vonage-dotnet-sdk/blob/2461576a53056260effe5462537d92553c81f89e/.github/workflows/net-build.yml",
    "retrieved_at": "2025-10-29T01:47:48.398143Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this .NET build workflow?",
    "answer": "name: .NET Build\n\non:\n  workflow_dispatch:\n  push:\n    branches: [ main ]\n\npermissions:\n  actions: write\n  checks: write\n  contents: read\n  deployments: read\n  issues: write\n  discussions: write\n  packages: read\n  pages: write\n  pull-requests: write\n  security-events: write\n  statuses: write\n  \njobs:\n  build:\n    runs-on: windows-latest\n    steps:\n      - name: Set up JDK 17\n        uses: actions/setup-java@v2\n        with:\n          distribution: 'microsoft'\n          java-version: '17'\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v3\n        with:\n          dotnet-version: 8.0.x\n      - name: Install SonarScanner\n        run: |\n          dotnet tool update --global dotnet-sonarscanner\n      - name: Install coverlet\n        id: install-coverlet\n        run: |\n          dotnet tool install --global dotnet-coverage\n      - uses: actions/checkout@v3\n      - name: Begin SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner begin /k:\"Vonage_vonage-dotnet-sdk\" /o:\"vonage\" /d:sonar.token=\"${{ secrets.SONAR_TOKEN }}\" /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.cs.vscoveragexml.reportsPaths=coverage.xml\n      - name: Build\n        run: |\n          dotnet build --configuration Release .\\Vonage\\Vonage.csproj\n          dotnet build --configuration Release .\\Vonage.Test\\Vonage.Test.csproj -f net8.0\n      - name: Test\n        run: dotnet-coverage collect 'dotnet test  --configuration Release --no-build -f net8.0 --filter Category!=Integration' -f xml  -o 'coverage.xml'\n      - name: End SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner end /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\"",
    "source": "Vonage/vonage-dotnet-sdk",
    "path": ".github/workflows/net-build.yml",
    "url": "https://github.com/Vonage/vonage-dotnet-sdk/blob/2461576a53056260effe5462537d92553c81f89e/.github/workflows/net-build.yml",
    "retrieved_at": "2025-10-29T01:47:48.830811Z",
    "question_style": "style_2"
  },
  {
    "question": "Which steps within the build job run in parallel, and are there any dependencies between them?",
    "answer": "name: .NET Build\n\non:\n  workflow_dispatch:\n  push:\n    branches: [ main ]\n\npermissions:\n  actions: write\n  checks: write\n  contents: read\n  deployments: read\n  issues: write\n  discussions: write\n  packages: read\n  pages: write\n  pull-requests: write\n  security-events: write\n  statuses: write\n  \njobs:\n  build:\n    runs-on: windows-latest\n    steps:\n      - name: Set up JDK 17\n        uses: actions/setup-java@v2\n        with:\n          distribution: 'microsoft'\n          java-version: '17'\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v3\n        with:\n          dotnet-version: 8.0.x\n      - name: Install SonarScanner\n        run: |\n          dotnet tool update --global dotnet-sonarscanner\n      - name: Install coverlet\n        id: install-coverlet\n        run: |\n          dotnet tool install --global dotnet-coverage\n      - uses: actions/checkout@v3\n      - name: Begin SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner begin /k:\"Vonage_vonage-dotnet-sdk\" /o:\"vonage\" /d:sonar.token=\"${{ secrets.SONAR_TOKEN }}\" /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.cs.vscoveragexml.reportsPaths=coverage.xml\n      - name: Build\n        run: |\n          dotnet build --configuration Release .\\Vonage\\Vonage.csproj\n          dotnet build --configuration Release .\\Vonage.Test\\Vonage.Test.csproj -f net8.0\n      - name: Test\n        run: dotnet-coverage collect 'dotnet test  --configuration Release --no-build -f net8.0 --filter Category!=Integration' -f xml  -o 'coverage.xml'\n      - name: End SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner end /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\"",
    "source": "Vonage/vonage-dotnet-sdk",
    "path": ".github/workflows/net-build.yml",
    "url": "https://github.com/Vonage/vonage-dotnet-sdk/blob/2461576a53056260effe5462537d92553c81f89e/.github/workflows/net-build.yml",
    "retrieved_at": "2025-10-29T01:47:49.421789Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `GITHUB_TOKEN` and `SONAR_TOKEN` used within the SonarScanner steps?",
    "answer": "name: .NET Build\n\non:\n  workflow_dispatch:\n  push:\n    branches: [ main ]\n\npermissions:\n  actions: write\n  checks: write\n  contents: read\n  deployments: read\n  issues: write\n  discussions: write\n  packages: read\n  pages: write\n  pull-requests: write\n  security-events: write\n  statuses: write\n  \njobs:\n  build:\n    runs-on: windows-latest\n    steps:\n      - name: Set up JDK 17\n        uses: actions/setup-java@v2\n        with:\n          distribution: 'microsoft'\n          java-version: '17'\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v3\n        with:\n          dotnet-version: 8.0.x\n      - name: Install SonarScanner\n        run: |\n          dotnet tool update --global dotnet-sonarscanner\n      - name: Install coverlet\n        id: install-coverlet\n        run: |\n          dotnet tool install --global dotnet-coverage\n      - uses: actions/checkout@v3\n      - name: Begin SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner begin /k:\"Vonage_vonage-dotnet-sdk\" /o:\"vonage\" /d:sonar.token=\"${{ secrets.SONAR_TOKEN }}\" /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.cs.vscoveragexml.reportsPaths=coverage.xml\n      - name: Build\n        run: |\n          dotnet build --configuration Release .\\Vonage\\Vonage.csproj\n          dotnet build --configuration Release .\\Vonage.Test\\Vonage.Test.csproj -f net8.0\n      - name: Test\n        run: dotnet-coverage collect 'dotnet test  --configuration Release --no-build -f net8.0 --filter Category!=Integration' -f xml  -o 'coverage.xml'\n      - name: End SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner end /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\"",
    "source": "Vonage/vonage-dotnet-sdk",
    "path": ".github/workflows/net-build.yml",
    "url": "https://github.com/Vonage/vonage-dotnet-sdk/blob/2461576a53056260effe5462537d92553c81f89e/.github/workflows/net-build.yml",
    "retrieved_at": "2025-10-29T01:47:50.061197Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this .NET build workflow?",
    "answer": "name: .NET Build\n\non:\n  workflow_dispatch:\n  push:\n    branches: [ main ]\n\npermissions:\n  actions: write\n  checks: write\n  contents: read\n  deployments: read\n  issues: write\n  discussions: write\n  packages: read\n  pages: write\n  pull-requests: write\n  security-events: write\n  statuses: write\n  \njobs:\n  build:\n    runs-on: windows-latest\n    steps:\n      - name: Set up JDK 17\n        uses: actions/setup-java@v2\n        with:\n          distribution: 'microsoft'\n          java-version: '17'\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v3\n        with:\n          dotnet-version: 8.0.x\n      - name: Install SonarScanner\n        run: |\n          dotnet tool update --global dotnet-sonarscanner\n      - name: Install coverlet\n        id: install-coverlet\n        run: |\n          dotnet tool install --global dotnet-coverage\n      - uses: actions/checkout@v3\n      - name: Begin SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner begin /k:\"Vonage_vonage-dotnet-sdk\" /o:\"vonage\" /d:sonar.token=\"${{ secrets.SONAR_TOKEN }}\" /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.cs.vscoveragexml.reportsPaths=coverage.xml\n      - name: Build\n        run: |\n          dotnet build --configuration Release .\\Vonage\\Vonage.csproj\n          dotnet build --configuration Release .\\Vonage.Test\\Vonage.Test.csproj -f net8.0\n      - name: Test\n        run: dotnet-coverage collect 'dotnet test  --configuration Release --no-build -f net8.0 --filter Category!=Integration' -f xml  -o 'coverage.xml'\n      - name: End SonarScanner\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        run: dotnet-sonarscanner end /d:sonar.login=\"${{ secrets.SONAR_TOKEN }}\"",
    "source": "Vonage/vonage-dotnet-sdk",
    "path": ".github/workflows/net-build.yml",
    "url": "https://github.com/Vonage/vonage-dotnet-sdk/blob/2461576a53056260effe5462537d92553c81f89e/.github/workflows/net-build.yml",
    "retrieved_at": "2025-10-29T01:47:50.848132Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including its triggers, concurrency, jobs, and steps.",
    "answer": "name: build\n\non:\n  push:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - '**.md'\n\n  pull_request:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - 'docs/**'\n      - '**.md'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build_cpu:\n    runs-on: ubuntu-18.04\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch: [1.5.1, 1.6.0, 1.7.0, 1.8.0, 1.9.0]\n        include:\n          - torch: 1.5.1\n            torch_version: torch1.5\n            torchvision: 0.6.1\n          - torch: 1.6.0\n            torch_version: torch1.6\n            torchvision: 0.7.0\n          - torch: 1.7.0\n            torch_version: torch1.7\n            torchvision: 0.8.1\n          - torch: 1.8.0\n            torch_version: torch1.8\n            torchvision: 0.9.0\n          - torch: 1.9.0\n            torch_version: torch1.9\n            torchvision: 0.10.0\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Upgrade pip\n        run: pip install pip --upgrade\n      - name: Install Pillow\n        run: pip install Pillow==6.2.2\n        if: ${{matrix.torchvision == '0.4.2'}}\n      - name: Install PyTorch\n        run: pip install torch==${{matrix.torch}}+cpu torchvision==${{matrix.torchvision}}+cpu -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/${{matrix.torch_version}}/index.html\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Install unittest dependencies\n        run: |\n          pip install -r requirements.txt\n      - name: Build and install\n        run: rm -rf .eggs && pip install -e .\n      - name: Run unittests and generate coverage report\n        run: |\n          pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n\n  build_cuda101:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch:\n          [\n            1.5.1+cu101,\n            1.6.0+cu101,\n            1.7.0+cu101,\n            1.8.0+cu101\n          ]\n        include:\n          - torch: 1.5.1+cu101\n            torch_version: torch1.5\n            torchvision: 0.6.1+cu101\n          - torch: 1.6.0+cu101\n            torch_version: torch1.6\n            torchvision: 0.7.0+cu101\n          - torch: 1.7.0+cu101\n            torch_version: torch1.7\n            torchvision: 0.8.1+cu101\n          - torch: 1.8.0+cu101\n            torch_version: torch1.8\n            torchvision: 0.9.0+cu101\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 python${{matrix.python-version}}-dev\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v1.0.10\n        with:\n          file: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  build_cuda102:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8, 3.9]\n        torch: [1.9.0+cu102]\n        include:\n          - torch: 1.9.0+cu102\n            torch_version: torch1.9\n            torchvision: 0.10.0+cu102\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu102/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v2\n        with:\n          files: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  test_windows:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [windows-2022]\n        python: [3.8]\n        platform: [cpu, cu111]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python }}\n      - name: Upgrade pip\n        run: python -m pip install pip --upgrade --user\n      - name: Install OpenCV\n        run: pip install opencv-python>=3\n      - name: Install PyTorch\n        # As a complement to Linux CI, we test on PyTorch LTS version\n        run: pip install torch==1.8.2+${{ matrix.platform }} torchvision==0.9.2+${{ matrix.platform }} -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8/index.html --only-binary mmcv-full\n      - name: Install unittest dependencies\n        run: pip install -r requirements/tests.txt -r requirements/optional.txt\n      - name: Build and install\n        run: pip install -e .\n      - name: Run unittests\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n      - name: Generate coverage report\n        run: |\n          coverage xml\n          coverage report -m\n",
    "source": "iumyx2612/mmsegmentation",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/iumyx2612/mmsegmentation/blob/c65a0921c005a109c19a696394a442a493225a5a/.github/workflows/build.yml",
    "retrieved_at": "2025-10-29T01:47:51.789783Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow, excluding changes in 'demo/', '.dev/', 'docker/', 'tools/', 'docs/', or markdown files?",
    "answer": "name: build\n\non:\n  push:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - '**.md'\n\n  pull_request:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - 'docs/**'\n      - '**.md'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build_cpu:\n    runs-on: ubuntu-18.04\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch: [1.5.1, 1.6.0, 1.7.0, 1.8.0, 1.9.0]\n        include:\n          - torch: 1.5.1\n            torch_version: torch1.5\n            torchvision: 0.6.1\n          - torch: 1.6.0\n            torch_version: torch1.6\n            torchvision: 0.7.0\n          - torch: 1.7.0\n            torch_version: torch1.7\n            torchvision: 0.8.1\n          - torch: 1.8.0\n            torch_version: torch1.8\n            torchvision: 0.9.0\n          - torch: 1.9.0\n            torch_version: torch1.9\n            torchvision: 0.10.0\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Upgrade pip\n        run: pip install pip --upgrade\n      - name: Install Pillow\n        run: pip install Pillow==6.2.2\n        if: ${{matrix.torchvision == '0.4.2'}}\n      - name: Install PyTorch\n        run: pip install torch==${{matrix.torch}}+cpu torchvision==${{matrix.torchvision}}+cpu -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/${{matrix.torch_version}}/index.html\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Install unittest dependencies\n        run: |\n          pip install -r requirements.txt\n      - name: Build and install\n        run: rm -rf .eggs && pip install -e .\n      - name: Run unittests and generate coverage report\n        run: |\n          pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n\n  build_cuda101:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch:\n          [\n            1.5.1+cu101,\n            1.6.0+cu101,\n            1.7.0+cu101,\n            1.8.0+cu101\n          ]\n        include:\n          - torch: 1.5.1+cu101\n            torch_version: torch1.5\n            torchvision: 0.6.1+cu101\n          - torch: 1.6.0+cu101\n            torch_version: torch1.6\n            torchvision: 0.7.0+cu101\n          - torch: 1.7.0+cu101\n            torch_version: torch1.7\n            torchvision: 0.8.1+cu101\n          - torch: 1.8.0+cu101\n            torch_version: torch1.8\n            torchvision: 0.9.0+cu101\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 python${{matrix.python-version}}-dev\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v1.0.10\n        with:\n          file: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  build_cuda102:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8, 3.9]\n        torch: [1.9.0+cu102]\n        include:\n          - torch: 1.9.0+cu102\n            torch_version: torch1.9\n            torchvision: 0.10.0+cu102\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu102/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v2\n        with:\n          files: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  test_windows:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [windows-2022]\n        python: [3.8]\n        platform: [cpu, cu111]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python }}\n      - name: Upgrade pip\n        run: python -m pip install pip --upgrade --user\n      - name: Install OpenCV\n        run: pip install opencv-python>=3\n      - name: Install PyTorch\n        # As a complement to Linux CI, we test on PyTorch LTS version\n        run: pip install torch==1.8.2+${{ matrix.platform }} torchvision==0.9.2+${{ matrix.platform }} -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8/index.html --only-binary mmcv-full\n      - name: Install unittest dependencies\n        run: pip install -r requirements/tests.txt -r requirements/optional.txt\n      - name: Build and install\n        run: pip install -e .\n      - name: Run unittests\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n      - name: Generate coverage report\n        run: |\n          coverage xml\n          coverage report -m\n",
    "source": "iumyx2612/mmsegmentation",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/iumyx2612/mmsegmentation/blob/c65a0921c005a109c19a696394a442a493225a5a/.github/workflows/build.yml",
    "retrieved_at": "2025-10-29T01:47:52.801638Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: build\n\non:\n  push:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - '**.md'\n\n  pull_request:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - 'docs/**'\n      - '**.md'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build_cpu:\n    runs-on: ubuntu-18.04\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch: [1.5.1, 1.6.0, 1.7.0, 1.8.0, 1.9.0]\n        include:\n          - torch: 1.5.1\n            torch_version: torch1.5\n            torchvision: 0.6.1\n          - torch: 1.6.0\n            torch_version: torch1.6\n            torchvision: 0.7.0\n          - torch: 1.7.0\n            torch_version: torch1.7\n            torchvision: 0.8.1\n          - torch: 1.8.0\n            torch_version: torch1.8\n            torchvision: 0.9.0\n          - torch: 1.9.0\n            torch_version: torch1.9\n            torchvision: 0.10.0\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Upgrade pip\n        run: pip install pip --upgrade\n      - name: Install Pillow\n        run: pip install Pillow==6.2.2\n        if: ${{matrix.torchvision == '0.4.2'}}\n      - name: Install PyTorch\n        run: pip install torch==${{matrix.torch}}+cpu torchvision==${{matrix.torchvision}}+cpu -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/${{matrix.torch_version}}/index.html\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Install unittest dependencies\n        run: |\n          pip install -r requirements.txt\n      - name: Build and install\n        run: rm -rf .eggs && pip install -e .\n      - name: Run unittests and generate coverage report\n        run: |\n          pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n\n  build_cuda101:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch:\n          [\n            1.5.1+cu101,\n            1.6.0+cu101,\n            1.7.0+cu101,\n            1.8.0+cu101\n          ]\n        include:\n          - torch: 1.5.1+cu101\n            torch_version: torch1.5\n            torchvision: 0.6.1+cu101\n          - torch: 1.6.0+cu101\n            torch_version: torch1.6\n            torchvision: 0.7.0+cu101\n          - torch: 1.7.0+cu101\n            torch_version: torch1.7\n            torchvision: 0.8.1+cu101\n          - torch: 1.8.0+cu101\n            torch_version: torch1.8\n            torchvision: 0.9.0+cu101\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 python${{matrix.python-version}}-dev\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v1.0.10\n        with:\n          file: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  build_cuda102:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8, 3.9]\n        torch: [1.9.0+cu102]\n        include:\n          - torch: 1.9.0+cu102\n            torch_version: torch1.9\n            torchvision: 0.10.0+cu102\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu102/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v2\n        with:\n          files: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  test_windows:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [windows-2022]\n        python: [3.8]\n        platform: [cpu, cu111]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python }}\n      - name: Upgrade pip\n        run: python -m pip install pip --upgrade --user\n      - name: Install OpenCV\n        run: pip install opencv-python>=3\n      - name: Install PyTorch\n        # As a complement to Linux CI, we test on PyTorch LTS version\n        run: pip install torch==1.8.2+${{ matrix.platform }} torchvision==0.9.2+${{ matrix.platform }} -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8/index.html --only-binary mmcv-full\n      - name: Install unittest dependencies\n        run: pip install -r requirements/tests.txt -r requirements/optional.txt\n      - name: Build and install\n        run: pip install -e .\n      - name: Run unittests\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n      - name: Generate coverage report\n        run: |\n          coverage xml\n          coverage report -m\n",
    "source": "iumyx2612/mmsegmentation",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/iumyx2612/mmsegmentation/blob/c65a0921c005a109c19a696394a442a493225a5a/.github/workflows/build.yml",
    "retrieved_at": "2025-10-29T01:47:53.450347Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any environment variables other than those used in the matrix or set by codecov used in the workflow?",
    "answer": "name: build\n\non:\n  push:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - '**.md'\n\n  pull_request:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - 'docs/**'\n      - '**.md'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build_cpu:\n    runs-on: ubuntu-18.04\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch: [1.5.1, 1.6.0, 1.7.0, 1.8.0, 1.9.0]\n        include:\n          - torch: 1.5.1\n            torch_version: torch1.5\n            torchvision: 0.6.1\n          - torch: 1.6.0\n            torch_version: torch1.6\n            torchvision: 0.7.0\n          - torch: 1.7.0\n            torch_version: torch1.7\n            torchvision: 0.8.1\n          - torch: 1.8.0\n            torch_version: torch1.8\n            torchvision: 0.9.0\n          - torch: 1.9.0\n            torch_version: torch1.9\n            torchvision: 0.10.0\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Upgrade pip\n        run: pip install pip --upgrade\n      - name: Install Pillow\n        run: pip install Pillow==6.2.2\n        if: ${{matrix.torchvision == '0.4.2'}}\n      - name: Install PyTorch\n        run: pip install torch==${{matrix.torch}}+cpu torchvision==${{matrix.torchvision}}+cpu -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/${{matrix.torch_version}}/index.html\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Install unittest dependencies\n        run: |\n          pip install -r requirements.txt\n      - name: Build and install\n        run: rm -rf .eggs && pip install -e .\n      - name: Run unittests and generate coverage report\n        run: |\n          pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n\n  build_cuda101:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch:\n          [\n            1.5.1+cu101,\n            1.6.0+cu101,\n            1.7.0+cu101,\n            1.8.0+cu101\n          ]\n        include:\n          - torch: 1.5.1+cu101\n            torch_version: torch1.5\n            torchvision: 0.6.1+cu101\n          - torch: 1.6.0+cu101\n            torch_version: torch1.6\n            torchvision: 0.7.0+cu101\n          - torch: 1.7.0+cu101\n            torch_version: torch1.7\n            torchvision: 0.8.1+cu101\n          - torch: 1.8.0+cu101\n            torch_version: torch1.8\n            torchvision: 0.9.0+cu101\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 python${{matrix.python-version}}-dev\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v1.0.10\n        with:\n          file: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  build_cuda102:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8, 3.9]\n        torch: [1.9.0+cu102]\n        include:\n          - torch: 1.9.0+cu102\n            torch_version: torch1.9\n            torchvision: 0.10.0+cu102\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu102/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v2\n        with:\n          files: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  test_windows:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [windows-2022]\n        python: [3.8]\n        platform: [cpu, cu111]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python }}\n      - name: Upgrade pip\n        run: python -m pip install pip --upgrade --user\n      - name: Install OpenCV\n        run: pip install opencv-python>=3\n      - name: Install PyTorch\n        # As a complement to Linux CI, we test on PyTorch LTS version\n        run: pip install torch==1.8.2+${{ matrix.platform }} torchvision==0.9.2+${{ matrix.platform }} -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8/index.html --only-binary mmcv-full\n      - name: Install unittest dependencies\n        run: pip install -r requirements/tests.txt -r requirements/optional.txt\n      - name: Build and install\n        run: pip install -e .\n      - name: Run unittests\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n      - name: Generate coverage report\n        run: |\n          coverage xml\n          coverage report -m\n",
    "source": "iumyx2612/mmsegmentation",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/iumyx2612/mmsegmentation/blob/c65a0921c005a109c19a696394a442a493225a5a/.github/workflows/build.yml",
    "retrieved_at": "2025-10-29T01:47:54.264233Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow, or what does it primarily build and test?",
    "answer": "name: build\n\non:\n  push:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - '**.md'\n\n  pull_request:\n    paths-ignore:\n      - 'demo/**'\n      - '.dev/**'\n      - 'docker/**'\n      - 'tools/**'\n      - 'docs/**'\n      - '**.md'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\njobs:\n  build_cpu:\n    runs-on: ubuntu-18.04\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch: [1.5.1, 1.6.0, 1.7.0, 1.8.0, 1.9.0]\n        include:\n          - torch: 1.5.1\n            torch_version: torch1.5\n            torchvision: 0.6.1\n          - torch: 1.6.0\n            torch_version: torch1.6\n            torchvision: 0.7.0\n          - torch: 1.7.0\n            torch_version: torch1.7\n            torchvision: 0.8.1\n          - torch: 1.8.0\n            torch_version: torch1.8\n            torchvision: 0.9.0\n          - torch: 1.9.0\n            torch_version: torch1.9\n            torchvision: 0.10.0\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Upgrade pip\n        run: pip install pip --upgrade\n      - name: Install Pillow\n        run: pip install Pillow==6.2.2\n        if: ${{matrix.torchvision == '0.4.2'}}\n      - name: Install PyTorch\n        run: pip install torch==${{matrix.torch}}+cpu torchvision==${{matrix.torchvision}}+cpu -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/${{matrix.torch_version}}/index.html\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Install unittest dependencies\n        run: |\n          pip install -r requirements.txt\n      - name: Build and install\n        run: rm -rf .eggs && pip install -e .\n      - name: Run unittests and generate coverage report\n        run: |\n          pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n\n  build_cuda101:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.6.0-cuda10.1-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.7]\n        torch:\n          [\n            1.5.1+cu101,\n            1.6.0+cu101,\n            1.7.0+cu101,\n            1.8.0+cu101\n          ]\n        include:\n          - torch: 1.5.1+cu101\n            torch_version: torch1.5\n            torchvision: 0.6.1+cu101\n          - torch: 1.6.0+cu101\n            torch_version: torch1.6\n            torchvision: 0.7.0+cu101\n          - torch: 1.7.0+cu101\n            torch_version: torch1.7\n            torchvision: 0.8.1+cu101\n          - torch: 1.8.0+cu101\n            torch_version: torch1.8\n            torchvision: 0.9.0+cu101\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 python${{matrix.python-version}}-dev\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch >= '1.5.0'}}\n      - name: Skip timm unittests and generate coverage report\n        run: |\n          coverage run --branch --source mmseg -m pytest tests/ --ignore tests/test_models/test_backbones/test_timm_backbone.py\n          coverage xml\n          coverage report -m\n        if: ${{matrix.torch < '1.5.0'}}\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v1.0.10\n        with:\n          file: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  build_cuda102:\n    runs-on: ubuntu-18.04\n    container:\n      image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel\n\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8, 3.9]\n        torch: [1.9.0+cu102]\n        include:\n          - torch: 1.9.0+cu102\n            torch_version: torch1.9\n            torchvision: 0.10.0+cu102\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Fetch GPG keys\n        run: |\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\n          apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\n      - name: Install system dependencies\n        run: |\n          apt-get update && apt-get install -y libgl1-mesa-glx ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6\n          apt-get clean\n          rm -rf /var/lib/apt/lists/*\n      - name: Install Pillow\n        run: python -m pip install Pillow==6.2.2\n        if: ${{matrix.torchvision < 0.5}}\n      - name: Install PyTorch\n        run: python -m pip install torch==${{matrix.torch}} torchvision==${{matrix.torchvision}} -f https://download.pytorch.org/whl/torch_stable.html\n      - name: Install mmseg dependencies\n        run: |\n          python -V\n          python -m pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu102/${{matrix.torch_version}}/index.html\n          python -m pip install -r requirements.txt\n          python -c 'import mmcv; print(mmcv.__version__)'\n      - name: Build and install\n        run: |\n          rm -rf .eggs\n          python setup.py check -m -s\n          TORCH_CUDA_ARCH_LIST=7.0 pip install .\n      - name: Run unittests and generate coverage report\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n          coverage xml\n          coverage report -m\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v2\n        with:\n          files: ./coverage.xml\n          flags: unittests\n          env_vars: OS,PYTHON\n          name: codecov-umbrella\n          fail_ci_if_error: false\n\n  test_windows:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [windows-2022]\n        python: [3.8]\n        platform: [cpu, cu111]\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up Python ${{ matrix.python }}\n        uses: actions/setup-python@v2\n        with:\n          python-version: ${{ matrix.python }}\n      - name: Upgrade pip\n        run: python -m pip install pip --upgrade --user\n      - name: Install OpenCV\n        run: pip install opencv-python>=3\n      - name: Install PyTorch\n        # As a complement to Linux CI, we test on PyTorch LTS version\n        run: pip install torch==1.8.2+${{ matrix.platform }} torchvision==0.9.2+${{ matrix.platform }} -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n      - name: Install MMCV\n        run: |\n          pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8/index.html --only-binary mmcv-full\n      - name: Install unittest dependencies\n        run: pip install -r requirements/tests.txt -r requirements/optional.txt\n      - name: Build and install\n        run: pip install -e .\n      - name: Run unittests\n        run: |\n          python -m pip install timm\n          coverage run --branch --source mmseg -m pytest tests/\n      - name: Generate coverage report\n        run: |\n          coverage xml\n          coverage report -m\n",
    "source": "iumyx2612/mmsegmentation",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/iumyx2612/mmsegmentation/blob/c65a0921c005a109c19a696394a442a493225a5a/.github/workflows/build.yml",
    "retrieved_at": "2025-10-29T01:47:54.934751Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Go\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          path: \"ethconnect\"\n      - uses: actions/checkout@v4\n        with:\n          repository: kaleido-io/ethbinding\n          path: \"ethbinding\"\n\n      - name: Set up Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: \"1.22\"\n          check-latest: true\n\n      - name: Install solc\n        run: |\n          sudo curl -Lo /usr/local/bin/solc https://github.com/ethereum/solidity/releases/download/v0.7.6/solc-static-linux\n          sudo chmod 755 /usr/local/bin/solc\n\n      - name: Build and Test\n        env:\n          TEST_DEBUG_FLAGS: -v\n        run: cd ethconnect && make\n\n      - name: Upload coverage\n        run: bash <(curl -s https://codecov.io/bash)\n\n  docker-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: docker build .\n",
    "source": "hyperledger/firefly-ethconnect",
    "path": ".github/workflows/go.yaml",
    "url": "https://github.com/hyperledger/firefly-ethconnect/blob/ffe42a1a1f3d83d9cbfdb60a25edad188183e15e/.github/workflows/go.yaml",
    "retrieved_at": "2025-10-30T01:47:27.281103Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this Go workflow to run?",
    "answer": "name: Go\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          path: \"ethconnect\"\n      - uses: actions/checkout@v4\n        with:\n          repository: kaleido-io/ethbinding\n          path: \"ethbinding\"\n\n      - name: Set up Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: \"1.22\"\n          check-latest: true\n\n      - name: Install solc\n        run: |\n          sudo curl -Lo /usr/local/bin/solc https://github.com/ethereum/solidity/releases/download/v0.7.6/solc-static-linux\n          sudo chmod 755 /usr/local/bin/solc\n\n      - name: Build and Test\n        env:\n          TEST_DEBUG_FLAGS: -v\n        run: cd ethconnect && make\n\n      - name: Upload coverage\n        run: bash <(curl -s https://codecov.io/bash)\n\n  docker-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: docker build .\n",
    "source": "hyperledger/firefly-ethconnect",
    "path": ".github/workflows/go.yaml",
    "url": "https://github.com/hyperledger/firefly-ethconnect/blob/ffe42a1a1f3d83d9cbfdb60a25edad188183e15e/.github/workflows/go.yaml",
    "retrieved_at": "2025-10-30T01:47:27.808518Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Go\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          path: \"ethconnect\"\n      - uses: actions/checkout@v4\n        with:\n          repository: kaleido-io/ethbinding\n          path: \"ethbinding\"\n\n      - name: Set up Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: \"1.22\"\n          check-latest: true\n\n      - name: Install solc\n        run: |\n          sudo curl -Lo /usr/local/bin/solc https://github.com/ethereum/solidity/releases/download/v0.7.6/solc-static-linux\n          sudo chmod 755 /usr/local/bin/solc\n\n      - name: Build and Test\n        env:\n          TEST_DEBUG_FLAGS: -v\n        run: cd ethconnect && make\n\n      - name: Upload coverage\n        run: bash <(curl -s https://codecov.io/bash)\n\n  docker-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: docker build .\n",
    "source": "hyperledger/firefly-ethconnect",
    "path": ".github/workflows/go.yaml",
    "url": "https://github.com/hyperledger/firefly-ethconnect/blob/ffe42a1a1f3d83d9cbfdb60a25edad188183e15e/.github/workflows/go.yaml",
    "retrieved_at": "2025-10-30T01:47:28.408403Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `TEST_DEBUG_FLAGS` environment variable used during the build and test step?",
    "answer": "name: Go\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          path: \"ethconnect\"\n      - uses: actions/checkout@v4\n        with:\n          repository: kaleido-io/ethbinding\n          path: \"ethbinding\"\n\n      - name: Set up Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: \"1.22\"\n          check-latest: true\n\n      - name: Install solc\n        run: |\n          sudo curl -Lo /usr/local/bin/solc https://github.com/ethereum/solidity/releases/download/v0.7.6/solc-static-linux\n          sudo chmod 755 /usr/local/bin/solc\n\n      - name: Build and Test\n        env:\n          TEST_DEBUG_FLAGS: -v\n        run: cd ethconnect && make\n\n      - name: Upload coverage\n        run: bash <(curl -s https://codecov.io/bash)\n\n  docker-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: docker build .\n",
    "source": "hyperledger/firefly-ethconnect",
    "path": ".github/workflows/go.yaml",
    "url": "https://github.com/hyperledger/firefly-ethconnect/blob/ffe42a1a1f3d83d9cbfdb60a25edad188183e15e/.github/workflows/go.yaml",
    "retrieved_at": "2025-10-30T01:47:28.986082Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Go workflow?",
    "answer": "name: Go\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          path: \"ethconnect\"\n      - uses: actions/checkout@v4\n        with:\n          repository: kaleido-io/ethbinding\n          path: \"ethbinding\"\n\n      - name: Set up Go\n        uses: actions/setup-go@v4\n        with:\n          go-version: \"1.22\"\n          check-latest: true\n\n      - name: Install solc\n        run: |\n          sudo curl -Lo /usr/local/bin/solc https://github.com/ethereum/solidity/releases/download/v0.7.6/solc-static-linux\n          sudo chmod 755 /usr/local/bin/solc\n\n      - name: Build and Test\n        env:\n          TEST_DEBUG_FLAGS: -v\n        run: cd ethconnect && make\n\n      - name: Upload coverage\n        run: bash <(curl -s https://codecov.io/bash)\n\n  docker-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: docker build .\n",
    "source": "hyperledger/firefly-ethconnect",
    "path": ".github/workflows/go.yaml",
    "url": "https://github.com/hyperledger/firefly-ethconnect/blob/ffe42a1a1f3d83d9cbfdb60a25edad188183e15e/.github/workflows/go.yaml",
    "retrieved_at": "2025-10-30T01:47:29.509609Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file replicating the functionality, triggers, jobs, and configurations of the provided workflow YAML.",
    "answer": "name: Envoy/macOS\n\npermissions:\n  contents: read\n\non:\n  workflow_run:\n    workflows:\n    - Request\n    types:\n    - completed\n\nconcurrency:\n  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}\n  cancel-in-progress: true\n\n\njobs:\n  load:\n    secrets:\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}\n      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}\n    permissions:\n      actions: read\n      contents: read\n      packages: read\n      pull-requests: read\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n    uses: ./.github/workflows/_load.yml\n    with:\n      cache-docker: false\n      check-name: macos\n\n  macos:\n    permissions:\n      contents: read\n      packages: read\n    if: ${{ fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    uses: ./.github/workflows/_run.yml\n    name: CI ${{ matrix.name || matrix.target }}\n    with:\n      command:\n      container-command:\n      request: ${{ needs.load.outputs.request }}\n      runs-on: macos-14-xlarge\n      source: ${{ matrix.source }}\n      steps-post:\n      steps-pre: ${{ matrix.steps-pre }}\n      target: ${{ matrix.target }}\n      timeout-minutes: 90\n      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - target: ci/mac_ci_steps.sh\n          name: macOS\n          source: |\n            source ./ci/mac_ci_setup.sh\n            _BAZEL_BUILD_EXTRA_OPTIONS=(\n              --remote_download_toplevel\n              --flaky_test_attempts=2\n              --config=bes-envoy-engflow\n              --config=cache-envoy-engflow\n              --config=ci)\n            export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}\n\n  request:\n    permissions:\n      actions: read\n      contents: read\n      pull-requests: read\n    secrets:\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n    if: >-\n      ${{ always()\n          && github.event.workflow_run.conclusion == 'success'\n          && fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    - macos\n    uses: ./.github/workflows/_finish.yml\n    with:\n      needs: ${{ toJSON(needs) }}\n",
    "source": "inclavare-containers/tng-envoy",
    "path": ".github/workflows/envoy-macos.yml",
    "url": "https://github.com/inclavare-containers/tng-envoy/blob/be9f978e7f31bb7c6d1733dcfb65eefe5d036301/.github/workflows/envoy-macos.yml",
    "retrieved_at": "2025-10-30T01:47:30.329231Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run when a \"Request\" workflow completes successfully?",
    "answer": "name: Envoy/macOS\n\npermissions:\n  contents: read\n\non:\n  workflow_run:\n    workflows:\n    - Request\n    types:\n    - completed\n\nconcurrency:\n  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}\n  cancel-in-progress: true\n\n\njobs:\n  load:\n    secrets:\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}\n      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}\n    permissions:\n      actions: read\n      contents: read\n      packages: read\n      pull-requests: read\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n    uses: ./.github/workflows/_load.yml\n    with:\n      cache-docker: false\n      check-name: macos\n\n  macos:\n    permissions:\n      contents: read\n      packages: read\n    if: ${{ fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    uses: ./.github/workflows/_run.yml\n    name: CI ${{ matrix.name || matrix.target }}\n    with:\n      command:\n      container-command:\n      request: ${{ needs.load.outputs.request }}\n      runs-on: macos-14-xlarge\n      source: ${{ matrix.source }}\n      steps-post:\n      steps-pre: ${{ matrix.steps-pre }}\n      target: ${{ matrix.target }}\n      timeout-minutes: 90\n      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - target: ci/mac_ci_steps.sh\n          name: macOS\n          source: |\n            source ./ci/mac_ci_setup.sh\n            _BAZEL_BUILD_EXTRA_OPTIONS=(\n              --remote_download_toplevel\n              --flaky_test_attempts=2\n              --config=bes-envoy-engflow\n              --config=cache-envoy-engflow\n              --config=ci)\n            export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}\n\n  request:\n    permissions:\n      actions: read\n      contents: read\n      pull-requests: read\n    secrets:\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n    if: >-\n      ${{ always()\n          && github.event.workflow_run.conclusion == 'success'\n          && fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    - macos\n    uses: ./.github/workflows/_finish.yml\n    with:\n      needs: ${{ toJSON(needs) }}\n",
    "source": "inclavare-containers/tng-envoy",
    "path": ".github/workflows/envoy-macos.yml",
    "url": "https://github.com/inclavare-containers/tng-envoy/blob/be9f978e7f31bb7c6d1733dcfb65eefe5d036301/.github/workflows/envoy-macos.yml",
    "retrieved_at": "2025-10-30T01:47:30.915645Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what are the dependencies between them?",
    "answer": "name: Envoy/macOS\n\npermissions:\n  contents: read\n\non:\n  workflow_run:\n    workflows:\n    - Request\n    types:\n    - completed\n\nconcurrency:\n  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}\n  cancel-in-progress: true\n\n\njobs:\n  load:\n    secrets:\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}\n      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}\n    permissions:\n      actions: read\n      contents: read\n      packages: read\n      pull-requests: read\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n    uses: ./.github/workflows/_load.yml\n    with:\n      cache-docker: false\n      check-name: macos\n\n  macos:\n    permissions:\n      contents: read\n      packages: read\n    if: ${{ fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    uses: ./.github/workflows/_run.yml\n    name: CI ${{ matrix.name || matrix.target }}\n    with:\n      command:\n      container-command:\n      request: ${{ needs.load.outputs.request }}\n      runs-on: macos-14-xlarge\n      source: ${{ matrix.source }}\n      steps-post:\n      steps-pre: ${{ matrix.steps-pre }}\n      target: ${{ matrix.target }}\n      timeout-minutes: 90\n      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - target: ci/mac_ci_steps.sh\n          name: macOS\n          source: |\n            source ./ci/mac_ci_setup.sh\n            _BAZEL_BUILD_EXTRA_OPTIONS=(\n              --remote_download_toplevel\n              --flaky_test_attempts=2\n              --config=bes-envoy-engflow\n              --config=cache-envoy-engflow\n              --config=ci)\n            export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}\n\n  request:\n    permissions:\n      actions: read\n      contents: read\n      pull-requests: read\n    secrets:\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n    if: >-\n      ${{ always()\n          && github.event.workflow_run.conclusion == 'success'\n          && fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    - macos\n    uses: ./.github/workflows/_finish.yml\n    with:\n      needs: ${{ toJSON(needs) }}\n",
    "source": "inclavare-containers/tng-envoy",
    "path": ".github/workflows/envoy-macos.yml",
    "url": "https://github.com/inclavare-containers/tng-envoy/blob/be9f978e7f31bb7c6d1733dcfb65eefe5d036301/.github/workflows/envoy-macos.yml",
    "retrieved_at": "2025-10-30T01:47:31.387343Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `ENVOY_CI_APP_KEY`, `ENVOY_CI_APP_ID`, `ENVOY_CI_MUTEX_APP_KEY`, and `ENVOY_CI_MUTEX_APP_ID` used across the jobs?",
    "answer": "name: Envoy/macOS\n\npermissions:\n  contents: read\n\non:\n  workflow_run:\n    workflows:\n    - Request\n    types:\n    - completed\n\nconcurrency:\n  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}\n  cancel-in-progress: true\n\n\njobs:\n  load:\n    secrets:\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}\n      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}\n    permissions:\n      actions: read\n      contents: read\n      packages: read\n      pull-requests: read\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n    uses: ./.github/workflows/_load.yml\n    with:\n      cache-docker: false\n      check-name: macos\n\n  macos:\n    permissions:\n      contents: read\n      packages: read\n    if: ${{ fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    uses: ./.github/workflows/_run.yml\n    name: CI ${{ matrix.name || matrix.target }}\n    with:\n      command:\n      container-command:\n      request: ${{ needs.load.outputs.request }}\n      runs-on: macos-14-xlarge\n      source: ${{ matrix.source }}\n      steps-post:\n      steps-pre: ${{ matrix.steps-pre }}\n      target: ${{ matrix.target }}\n      timeout-minutes: 90\n      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - target: ci/mac_ci_steps.sh\n          name: macOS\n          source: |\n            source ./ci/mac_ci_setup.sh\n            _BAZEL_BUILD_EXTRA_OPTIONS=(\n              --remote_download_toplevel\n              --flaky_test_attempts=2\n              --config=bes-envoy-engflow\n              --config=cache-envoy-engflow\n              --config=ci)\n            export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}\n\n  request:\n    permissions:\n      actions: read\n      contents: read\n      pull-requests: read\n    secrets:\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n    if: >-\n      ${{ always()\n          && github.event.workflow_run.conclusion == 'success'\n          && fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    - macos\n    uses: ./.github/workflows/_finish.yml\n    with:\n      needs: ${{ toJSON(needs) }}\n",
    "source": "inclavare-containers/tng-envoy",
    "path": ".github/workflows/envoy-macos.yml",
    "url": "https://github.com/inclavare-containers/tng-envoy/blob/be9f978e7f31bb7c6d1733dcfb65eefe5d036301/.github/workflows/envoy-macos.yml",
    "retrieved_at": "2025-10-30T01:47:32.138836Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of the Envoy/macOS workflow?",
    "answer": "name: Envoy/macOS\n\npermissions:\n  contents: read\n\non:\n  workflow_run:\n    workflows:\n    - Request\n    types:\n    - completed\n\nconcurrency:\n  group: ${{ github.head_ref || github.run_id }}-${{ github.workflow }}\n  cancel-in-progress: true\n\n\njobs:\n  load:\n    secrets:\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      lock-app-key: ${{ secrets.ENVOY_CI_MUTEX_APP_KEY }}\n      lock-app-id: ${{ secrets.ENVOY_CI_MUTEX_APP_ID }}\n    permissions:\n      actions: read\n      contents: read\n      packages: read\n      pull-requests: read\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n    uses: ./.github/workflows/_load.yml\n    with:\n      cache-docker: false\n      check-name: macos\n\n  macos:\n    permissions:\n      contents: read\n      packages: read\n    if: ${{ fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    uses: ./.github/workflows/_run.yml\n    name: CI ${{ matrix.name || matrix.target }}\n    with:\n      command:\n      container-command:\n      request: ${{ needs.load.outputs.request }}\n      runs-on: macos-14-xlarge\n      source: ${{ matrix.source }}\n      steps-post:\n      steps-pre: ${{ matrix.steps-pre }}\n      target: ${{ matrix.target }}\n      timeout-minutes: 90\n      trusted: ${{ fromJSON(needs.load.outputs.trusted) }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n        - target: ci/mac_ci_steps.sh\n          name: macOS\n          source: |\n            source ./ci/mac_ci_setup.sh\n            _BAZEL_BUILD_EXTRA_OPTIONS=(\n              --remote_download_toplevel\n              --flaky_test_attempts=2\n              --config=bes-envoy-engflow\n              --config=cache-envoy-engflow\n              --config=ci)\n            export BAZEL_BUILD_EXTRA_OPTIONS=${_BAZEL_BUILD_EXTRA_OPTIONS[*]}\n\n  request:\n    permissions:\n      actions: read\n      contents: read\n      pull-requests: read\n    secrets:\n      app-id: ${{ secrets.ENVOY_CI_APP_ID }}\n      app-key: ${{ secrets.ENVOY_CI_APP_KEY }}\n    if: >-\n      ${{ always()\n          && github.event.workflow_run.conclusion == 'success'\n          && fromJSON(needs.load.outputs.request).run.build-macos }}\n    needs:\n    - load\n    - macos\n    uses: ./.github/workflows/_finish.yml\n    with:\n      needs: ${{ toJSON(needs) }}\n",
    "source": "inclavare-containers/tng-envoy",
    "path": ".github/workflows/envoy-macos.yml",
    "url": "https://github.com/inclavare-containers/tng-envoy/blob/be9f978e7f31bb7c6d1733dcfb65eefe5d036301/.github/workflows/envoy-macos.yml",
    "retrieved_at": "2025-10-30T01:47:32.717033Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML file, including build, test, and linting steps.",
    "answer": "name: Project check\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - master\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x]\n        os: [ubuntu-latest, windows-latest, macOS-latest]\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v1\n      with:\n        node-version: ${{ matrix.node-version }}\n    - name: npm install, build, test and lint\n      run: |\n        npm i\n        npm run build\n        npm run jest:test\n        npm run lint\n      env:\n        CI: true\n",
    "source": "coreui/coreui-react",
    "path": ".github/workflows/project-check.yml",
    "url": "https://github.com/coreui/coreui-react/blob/58ba804c02b863ca10c79ba2999fd7b4a56b83e2/.github/workflows/project-check.yml",
    "retrieved_at": "2025-10-31T01:44:15.443826Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branches trigger this GitHub Actions workflow to run?",
    "answer": "name: Project check\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - master\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x]\n        os: [ubuntu-latest, windows-latest, macOS-latest]\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v1\n      with:\n        node-version: ${{ matrix.node-version }}\n    - name: npm install, build, test and lint\n      run: |\n        npm i\n        npm run build\n        npm run jest:test\n        npm run lint\n      env:\n        CI: true\n",
    "source": "coreui/coreui-react",
    "path": ".github/workflows/project-check.yml",
    "url": "https://github.com/coreui/coreui-react/blob/58ba804c02b863ca10c79ba2999fd7b4a56b83e2/.github/workflows/project-check.yml",
    "retrieved_at": "2025-10-31T01:44:16.909948Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"build\" job's matrix run in parallel, and are there dependencies between them?",
    "answer": "name: Project check\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - master\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x]\n        os: [ubuntu-latest, windows-latest, macOS-latest]\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v1\n      with:\n        node-version: ${{ matrix.node-version }}\n    - name: npm install, build, test and lint\n      run: |\n        npm i\n        npm run build\n        npm run jest:test\n        npm run lint\n      env:\n        CI: true\n",
    "source": "coreui/coreui-react",
    "path": ".github/workflows/project-check.yml",
    "url": "https://github.com/coreui/coreui-react/blob/58ba804c02b863ca10c79ba2999fd7b4a56b83e2/.github/workflows/project-check.yml",
    "retrieved_at": "2025-10-31T01:44:20.395401Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the workflow utilize any secrets or is it limited to only environment variables to set CI?",
    "answer": "name: Project check\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - master\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x]\n        os: [ubuntu-latest, windows-latest, macOS-latest]\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v1\n      with:\n        node-version: ${{ matrix.node-version }}\n    - name: npm install, build, test and lint\n      run: |\n        npm i\n        npm run build\n        npm run jest:test\n        npm run lint\n      env:\n        CI: true\n",
    "source": "coreui/coreui-react",
    "path": ".github/workflows/project-check.yml",
    "url": "https://github.com/coreui/coreui-react/blob/58ba804c02b863ca10c79ba2999fd7b4a56b83e2/.github/workflows/project-check.yml",
    "retrieved_at": "2025-10-31T01:44:21.658844Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by building, testing, and linting the project?",
    "answer": "name: Project check\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n    branches:\n      - master\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [12.x]\n        os: [ubuntu-latest, windows-latest, macOS-latest]\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v1\n      with:\n        node-version: ${{ matrix.node-version }}\n    - name: npm install, build, test and lint\n      run: |\n        npm i\n        npm run build\n        npm run jest:test\n        npm run lint\n      env:\n        CI: true\n",
    "source": "coreui/coreui-react",
    "path": ".github/workflows/project-check.yml",
    "url": "https://github.com/coreui/coreui-react/blob/58ba804c02b863ca10c79ba2999fd7b4a56b83e2/.github/workflows/project-check.yml",
    "retrieved_at": "2025-10-31T01:44:22.394704Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality, triggers, jobs, and steps defined in the provided YAML file.",
    "answer": "name: \"CI/CD Pipeline\"\non:\n  push:\n    branches-ignore:\n      - l10n_develop\n      - gh-pages\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'monitoring/grafana-dashboard.json'\n      - 'screenshots/**'\n    tags-ignore:\n      - '*'\n  pull_request:\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'data/static/i18n/*.json'\n      - 'frontend/src/assets/i18n/*.json'\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: |\n          npm install --ignore-scripts\n          cd frontend\n          npm install --ignore-scripts --legacy-peer-deps\n      - name: \"Lint source code\"\n        run: npm run lint\n      - name: \"Lint customization configs\"\n        run: |\n          npm run lint:config -- -f ./config/7ms.yml\n          npm run lint:config -- -f ./config/addo.yml\n          npm run lint:config -- -f ./config/bodgeit.yml\n          npm run lint:config -- -f ./config/ctf.yml\n          npm run lint:config -- -f ./config/default.yml\n          npm run lint:config -- -f ./config/fbctf.yml\n          npm run lint:config -- -f ./config/juicebox.yml\n          npm run lint:config -- -f ./config/mozilla.yml\n          npm run lint:config -- -f ./config/oss.yml\n          npm run lint:config -- -f ./config/quiet.yml\n          npm run lint:config -- -f ./config/tutorial.yml\n          npm run lint:config -- -f ./config/unsafe.yml\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n        node-version: [12, 14, 16, 17]\n    steps:\n      - name: \"Check out Git repository\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js ${{ matrix.node-version }}\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: ${{ matrix.node-version }}\n      - name: \"Cache Node.js modules\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/cache@c64c572235d810460d0d6876e9c705ad5002b353 #v2: 2.1.6 available\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n      - name: \"Install CLI tools\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install\n      - name: \"Execute unit tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 10\n          max_attempts: 3\n          command: npm test\n      - name: \"Execute integration tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 5\n          max_attempts: 3\n          command: |\n            if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n            set NODE_ENV=test\n            else\n            export NODE_ENV=test\n            fi\n            npm run frisby\n          shell: bash\n      - name: \"Publish coverage to Codeclimate\"\n        if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        env:\n          CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}\n        run: |\n          curl -L https://codeclimate.com/downloads/test-reporter/test-reporter-0.7.0-linux-amd64 > ./cc-test-reporter\n          chmod +x ./cc-test-reporter\n          sed -i s/SF:/SF:frontend\\\\//g build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.frontend.json build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.server.json build/reports/coverage/server-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.api.json build/reports/coverage/api-tests/lcov.info\n          ./cc-test-reporter sum-coverage build/reports/coverage/codeclimate.*.json -p 3\n          ./cc-test-reporter upload-coverage\n        shell: bash\n  e2e:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests\"\n        env:\n          SOLUTIONS_WEBHOOK: ${{ secrets.E2E_SOLUTIONS_WEBHOOK }}\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            set SOLUTIONS_WEBHOOK=\"$env:SOLUTIONS_WEBHOOK\"\n            npm run preprotractor:github\n            npm run e2e\n  e2e-in-subfolder:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    continue-on-error: true\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests with application hosted in subfolder\"\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            npm run preprotractor:github\n            npm run e2e -- subfolder\n  smoke:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: |\n          npm install -g @angular/cli\n          npm install -g grunt-cli\n      - name: \"Set packaging options for Grunt\"\n        run: |\n          echo \"PCKG_OS_NAME=linux\" >> $GITHUB_ENV\n          echo \"PCKG_NODE_VERSION=14\" >> $GITHUB_ENV\n          echo \"PCKG_CPU_ARCH=x64\" >> $GITHUB_ENV\n      - name: \"Package application\"\n        run: |\n          npm install --production\n          npm install -g grunt-cli\n          npm run package:ci\n      - name: \"Unpack application archive\"\n        run: |\n          cd dist\n          tar -zxf juice-shop-*.tgz\n      - name: \"Execute smoke test\"\n        run: |\n          cd dist/juice-shop_*\n          npm start &\n          cd ../..\n          chmod +x test/smoke/smoke-test.sh\n          test/smoke/smoke-test.sh http://localhost:3000\n  docker-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Execute smoke test on Docker\"\n        run: docker-compose -f docker-compose.test.yml up --exit-code-from sut\n  docker:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e, docker-test]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set up QEMU\"\n        uses: docker/setup-qemu-action@27d0a4f181a40b142cce983c5393082c365d1480 #v1: V1.2.0 available\n      - name: \"Set up Docker Buildx\"\n        uses: docker/setup-buildx-action@94ab11c41e45d028884a99163086648e898eed25 #v1\n      - name: \"Login to DockerHub\"\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 #v1.10\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: \"Set tag & labels for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"DOCKER_TAG=latest\" >> $GITHUB_ENV\n          else\n          echo \"DOCKER_TAG=snapshot\" >> $GITHUB_ENV\n          fi\n          echo \"VCS_REF=`git rev-parse --short HEAD`\" >> $GITHUB_ENV\n          echo \"BUILD_DATE=`date -u +%Y-%m-%dT%H:%M:%SZ`\" >> $GITHUB_ENV\n      - name: \"Build and push\"\n        uses: docker/build-push-action@a66e35b9cbcf4ad0ea91ffcaf7bbad63ad9e0229 #note: newer is available\n        with:\n          context: .\n          file: ./Dockerfile\n          platforms: linux/amd64,linux/arm/v7,linux/arm64\n          push: true\n          tags: |\n            bkimminich/juice-shop:${{ env.DOCKER_TAG }}\n          build-args: |\n            VCS_REF=${{ env.VCS_REF }}\n            BUILD_DATE=${{ env.BUILD_DATE }}\n  heroku:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set Heroku app & branch for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"HEROKU_APP=juice-shop\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=master\" >> $GITHUB_ENV\n          else\n          echo \"HEROKU_APP=juice-shop-staging\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=develop\" >> $GITHUB_ENV\n          fi\n      - name: \"Deploy ${{ github.ref }} to Heroku\"\n        uses: akhileshns/heroku-deploy@79ef2ae4ff9b897010907016b268fd0f88561820 #v3.12.12\n        with:\n          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n          heroku_app_name: ${{ env.HEROKU_APP }}\n          heroku_email: bjoern.kimminich@owasp.org\n          branch: ${{ env.HEROKU_BRANCH }}\n  notify-slack:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (success() || failure())\n    needs:\n      - docker\n      - heroku\n      - lint\n      - e2e-in-subfolder\n      - smoke\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Slack workflow notification\"\n        uses: Gamesight/slack-workflow-status@master\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}\n",
    "source": "carmjanneteau/https-github.com-juice-shop-juice-shop",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/carmjanneteau/https-github.com-juice-shop-juice-shop/blob/250a09e85815c75467126e452dcdcf721ecb2be3/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-31T01:44:23.584424Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and conditions trigger this CI/CD pipeline workflow in GitHub Actions?",
    "answer": "name: \"CI/CD Pipeline\"\non:\n  push:\n    branches-ignore:\n      - l10n_develop\n      - gh-pages\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'monitoring/grafana-dashboard.json'\n      - 'screenshots/**'\n    tags-ignore:\n      - '*'\n  pull_request:\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'data/static/i18n/*.json'\n      - 'frontend/src/assets/i18n/*.json'\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: |\n          npm install --ignore-scripts\n          cd frontend\n          npm install --ignore-scripts --legacy-peer-deps\n      - name: \"Lint source code\"\n        run: npm run lint\n      - name: \"Lint customization configs\"\n        run: |\n          npm run lint:config -- -f ./config/7ms.yml\n          npm run lint:config -- -f ./config/addo.yml\n          npm run lint:config -- -f ./config/bodgeit.yml\n          npm run lint:config -- -f ./config/ctf.yml\n          npm run lint:config -- -f ./config/default.yml\n          npm run lint:config -- -f ./config/fbctf.yml\n          npm run lint:config -- -f ./config/juicebox.yml\n          npm run lint:config -- -f ./config/mozilla.yml\n          npm run lint:config -- -f ./config/oss.yml\n          npm run lint:config -- -f ./config/quiet.yml\n          npm run lint:config -- -f ./config/tutorial.yml\n          npm run lint:config -- -f ./config/unsafe.yml\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n        node-version: [12, 14, 16, 17]\n    steps:\n      - name: \"Check out Git repository\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js ${{ matrix.node-version }}\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: ${{ matrix.node-version }}\n      - name: \"Cache Node.js modules\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/cache@c64c572235d810460d0d6876e9c705ad5002b353 #v2: 2.1.6 available\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n      - name: \"Install CLI tools\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install\n      - name: \"Execute unit tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 10\n          max_attempts: 3\n          command: npm test\n      - name: \"Execute integration tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 5\n          max_attempts: 3\n          command: |\n            if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n            set NODE_ENV=test\n            else\n            export NODE_ENV=test\n            fi\n            npm run frisby\n          shell: bash\n      - name: \"Publish coverage to Codeclimate\"\n        if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        env:\n          CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}\n        run: |\n          curl -L https://codeclimate.com/downloads/test-reporter/test-reporter-0.7.0-linux-amd64 > ./cc-test-reporter\n          chmod +x ./cc-test-reporter\n          sed -i s/SF:/SF:frontend\\\\//g build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.frontend.json build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.server.json build/reports/coverage/server-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.api.json build/reports/coverage/api-tests/lcov.info\n          ./cc-test-reporter sum-coverage build/reports/coverage/codeclimate.*.json -p 3\n          ./cc-test-reporter upload-coverage\n        shell: bash\n  e2e:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests\"\n        env:\n          SOLUTIONS_WEBHOOK: ${{ secrets.E2E_SOLUTIONS_WEBHOOK }}\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            set SOLUTIONS_WEBHOOK=\"$env:SOLUTIONS_WEBHOOK\"\n            npm run preprotractor:github\n            npm run e2e\n  e2e-in-subfolder:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    continue-on-error: true\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests with application hosted in subfolder\"\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            npm run preprotractor:github\n            npm run e2e -- subfolder\n  smoke:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: |\n          npm install -g @angular/cli\n          npm install -g grunt-cli\n      - name: \"Set packaging options for Grunt\"\n        run: |\n          echo \"PCKG_OS_NAME=linux\" >> $GITHUB_ENV\n          echo \"PCKG_NODE_VERSION=14\" >> $GITHUB_ENV\n          echo \"PCKG_CPU_ARCH=x64\" >> $GITHUB_ENV\n      - name: \"Package application\"\n        run: |\n          npm install --production\n          npm install -g grunt-cli\n          npm run package:ci\n      - name: \"Unpack application archive\"\n        run: |\n          cd dist\n          tar -zxf juice-shop-*.tgz\n      - name: \"Execute smoke test\"\n        run: |\n          cd dist/juice-shop_*\n          npm start &\n          cd ../..\n          chmod +x test/smoke/smoke-test.sh\n          test/smoke/smoke-test.sh http://localhost:3000\n  docker-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Execute smoke test on Docker\"\n        run: docker-compose -f docker-compose.test.yml up --exit-code-from sut\n  docker:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e, docker-test]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set up QEMU\"\n        uses: docker/setup-qemu-action@27d0a4f181a40b142cce983c5393082c365d1480 #v1: V1.2.0 available\n      - name: \"Set up Docker Buildx\"\n        uses: docker/setup-buildx-action@94ab11c41e45d028884a99163086648e898eed25 #v1\n      - name: \"Login to DockerHub\"\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 #v1.10\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: \"Set tag & labels for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"DOCKER_TAG=latest\" >> $GITHUB_ENV\n          else\n          echo \"DOCKER_TAG=snapshot\" >> $GITHUB_ENV\n          fi\n          echo \"VCS_REF=`git rev-parse --short HEAD`\" >> $GITHUB_ENV\n          echo \"BUILD_DATE=`date -u +%Y-%m-%dT%H:%M:%SZ`\" >> $GITHUB_ENV\n      - name: \"Build and push\"\n        uses: docker/build-push-action@a66e35b9cbcf4ad0ea91ffcaf7bbad63ad9e0229 #note: newer is available\n        with:\n          context: .\n          file: ./Dockerfile\n          platforms: linux/amd64,linux/arm/v7,linux/arm64\n          push: true\n          tags: |\n            bkimminich/juice-shop:${{ env.DOCKER_TAG }}\n          build-args: |\n            VCS_REF=${{ env.VCS_REF }}\n            BUILD_DATE=${{ env.BUILD_DATE }}\n  heroku:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set Heroku app & branch for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"HEROKU_APP=juice-shop\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=master\" >> $GITHUB_ENV\n          else\n          echo \"HEROKU_APP=juice-shop-staging\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=develop\" >> $GITHUB_ENV\n          fi\n      - name: \"Deploy ${{ github.ref }} to Heroku\"\n        uses: akhileshns/heroku-deploy@79ef2ae4ff9b897010907016b268fd0f88561820 #v3.12.12\n        with:\n          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n          heroku_app_name: ${{ env.HEROKU_APP }}\n          heroku_email: bjoern.kimminich@owasp.org\n          branch: ${{ env.HEROKU_BRANCH }}\n  notify-slack:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (success() || failure())\n    needs:\n      - docker\n      - heroku\n      - lint\n      - e2e-in-subfolder\n      - smoke\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Slack workflow notification\"\n        uses: Gamesight/slack-workflow-status@master\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}\n",
    "source": "carmjanneteau/https-github.com-juice-shop-juice-shop",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/carmjanneteau/https-github.com-juice-shop-juice-shop/blob/250a09e85815c75467126e452dcdcf721ecb2be3/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-31T01:44:26.931056Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps in this workflow run in parallel, and what are the dependencies between them?",
    "answer": "name: \"CI/CD Pipeline\"\non:\n  push:\n    branches-ignore:\n      - l10n_develop\n      - gh-pages\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'monitoring/grafana-dashboard.json'\n      - 'screenshots/**'\n    tags-ignore:\n      - '*'\n  pull_request:\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'data/static/i18n/*.json'\n      - 'frontend/src/assets/i18n/*.json'\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: |\n          npm install --ignore-scripts\n          cd frontend\n          npm install --ignore-scripts --legacy-peer-deps\n      - name: \"Lint source code\"\n        run: npm run lint\n      - name: \"Lint customization configs\"\n        run: |\n          npm run lint:config -- -f ./config/7ms.yml\n          npm run lint:config -- -f ./config/addo.yml\n          npm run lint:config -- -f ./config/bodgeit.yml\n          npm run lint:config -- -f ./config/ctf.yml\n          npm run lint:config -- -f ./config/default.yml\n          npm run lint:config -- -f ./config/fbctf.yml\n          npm run lint:config -- -f ./config/juicebox.yml\n          npm run lint:config -- -f ./config/mozilla.yml\n          npm run lint:config -- -f ./config/oss.yml\n          npm run lint:config -- -f ./config/quiet.yml\n          npm run lint:config -- -f ./config/tutorial.yml\n          npm run lint:config -- -f ./config/unsafe.yml\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n        node-version: [12, 14, 16, 17]\n    steps:\n      - name: \"Check out Git repository\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js ${{ matrix.node-version }}\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: ${{ matrix.node-version }}\n      - name: \"Cache Node.js modules\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/cache@c64c572235d810460d0d6876e9c705ad5002b353 #v2: 2.1.6 available\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n      - name: \"Install CLI tools\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install\n      - name: \"Execute unit tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 10\n          max_attempts: 3\n          command: npm test\n      - name: \"Execute integration tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 5\n          max_attempts: 3\n          command: |\n            if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n            set NODE_ENV=test\n            else\n            export NODE_ENV=test\n            fi\n            npm run frisby\n          shell: bash\n      - name: \"Publish coverage to Codeclimate\"\n        if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        env:\n          CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}\n        run: |\n          curl -L https://codeclimate.com/downloads/test-reporter/test-reporter-0.7.0-linux-amd64 > ./cc-test-reporter\n          chmod +x ./cc-test-reporter\n          sed -i s/SF:/SF:frontend\\\\//g build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.frontend.json build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.server.json build/reports/coverage/server-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.api.json build/reports/coverage/api-tests/lcov.info\n          ./cc-test-reporter sum-coverage build/reports/coverage/codeclimate.*.json -p 3\n          ./cc-test-reporter upload-coverage\n        shell: bash\n  e2e:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests\"\n        env:\n          SOLUTIONS_WEBHOOK: ${{ secrets.E2E_SOLUTIONS_WEBHOOK }}\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            set SOLUTIONS_WEBHOOK=\"$env:SOLUTIONS_WEBHOOK\"\n            npm run preprotractor:github\n            npm run e2e\n  e2e-in-subfolder:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    continue-on-error: true\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests with application hosted in subfolder\"\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            npm run preprotractor:github\n            npm run e2e -- subfolder\n  smoke:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: |\n          npm install -g @angular/cli\n          npm install -g grunt-cli\n      - name: \"Set packaging options for Grunt\"\n        run: |\n          echo \"PCKG_OS_NAME=linux\" >> $GITHUB_ENV\n          echo \"PCKG_NODE_VERSION=14\" >> $GITHUB_ENV\n          echo \"PCKG_CPU_ARCH=x64\" >> $GITHUB_ENV\n      - name: \"Package application\"\n        run: |\n          npm install --production\n          npm install -g grunt-cli\n          npm run package:ci\n      - name: \"Unpack application archive\"\n        run: |\n          cd dist\n          tar -zxf juice-shop-*.tgz\n      - name: \"Execute smoke test\"\n        run: |\n          cd dist/juice-shop_*\n          npm start &\n          cd ../..\n          chmod +x test/smoke/smoke-test.sh\n          test/smoke/smoke-test.sh http://localhost:3000\n  docker-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Execute smoke test on Docker\"\n        run: docker-compose -f docker-compose.test.yml up --exit-code-from sut\n  docker:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e, docker-test]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set up QEMU\"\n        uses: docker/setup-qemu-action@27d0a4f181a40b142cce983c5393082c365d1480 #v1: V1.2.0 available\n      - name: \"Set up Docker Buildx\"\n        uses: docker/setup-buildx-action@94ab11c41e45d028884a99163086648e898eed25 #v1\n      - name: \"Login to DockerHub\"\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 #v1.10\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: \"Set tag & labels for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"DOCKER_TAG=latest\" >> $GITHUB_ENV\n          else\n          echo \"DOCKER_TAG=snapshot\" >> $GITHUB_ENV\n          fi\n          echo \"VCS_REF=`git rev-parse --short HEAD`\" >> $GITHUB_ENV\n          echo \"BUILD_DATE=`date -u +%Y-%m-%dT%H:%M:%SZ`\" >> $GITHUB_ENV\n      - name: \"Build and push\"\n        uses: docker/build-push-action@a66e35b9cbcf4ad0ea91ffcaf7bbad63ad9e0229 #note: newer is available\n        with:\n          context: .\n          file: ./Dockerfile\n          platforms: linux/amd64,linux/arm/v7,linux/arm64\n          push: true\n          tags: |\n            bkimminich/juice-shop:${{ env.DOCKER_TAG }}\n          build-args: |\n            VCS_REF=${{ env.VCS_REF }}\n            BUILD_DATE=${{ env.BUILD_DATE }}\n  heroku:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set Heroku app & branch for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"HEROKU_APP=juice-shop\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=master\" >> $GITHUB_ENV\n          else\n          echo \"HEROKU_APP=juice-shop-staging\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=develop\" >> $GITHUB_ENV\n          fi\n      - name: \"Deploy ${{ github.ref }} to Heroku\"\n        uses: akhileshns/heroku-deploy@79ef2ae4ff9b897010907016b268fd0f88561820 #v3.12.12\n        with:\n          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n          heroku_app_name: ${{ env.HEROKU_APP }}\n          heroku_email: bjoern.kimminich@owasp.org\n          branch: ${{ env.HEROKU_BRANCH }}\n  notify-slack:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (success() || failure())\n    needs:\n      - docker\n      - heroku\n      - lint\n      - e2e-in-subfolder\n      - smoke\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Slack workflow notification\"\n        uses: Gamesight/slack-workflow-status@master\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}\n",
    "source": "carmjanneteau/https-github.com-juice-shop-juice-shop",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/carmjanneteau/https-github.com-juice-shop-juice-shop/blob/250a09e85815c75467126e452dcdcf721ecb2be3/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-31T01:44:27.666352Z",
    "question_style": "style_3"
  },
  {
    "question": "How are secrets used for DockerHub authentication, Codeclimate reporting, end-to-end testing, and Heroku deployment?",
    "answer": "name: \"CI/CD Pipeline\"\non:\n  push:\n    branches-ignore:\n      - l10n_develop\n      - gh-pages\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'monitoring/grafana-dashboard.json'\n      - 'screenshots/**'\n    tags-ignore:\n      - '*'\n  pull_request:\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'data/static/i18n/*.json'\n      - 'frontend/src/assets/i18n/*.json'\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: |\n          npm install --ignore-scripts\n          cd frontend\n          npm install --ignore-scripts --legacy-peer-deps\n      - name: \"Lint source code\"\n        run: npm run lint\n      - name: \"Lint customization configs\"\n        run: |\n          npm run lint:config -- -f ./config/7ms.yml\n          npm run lint:config -- -f ./config/addo.yml\n          npm run lint:config -- -f ./config/bodgeit.yml\n          npm run lint:config -- -f ./config/ctf.yml\n          npm run lint:config -- -f ./config/default.yml\n          npm run lint:config -- -f ./config/fbctf.yml\n          npm run lint:config -- -f ./config/juicebox.yml\n          npm run lint:config -- -f ./config/mozilla.yml\n          npm run lint:config -- -f ./config/oss.yml\n          npm run lint:config -- -f ./config/quiet.yml\n          npm run lint:config -- -f ./config/tutorial.yml\n          npm run lint:config -- -f ./config/unsafe.yml\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n        node-version: [12, 14, 16, 17]\n    steps:\n      - name: \"Check out Git repository\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js ${{ matrix.node-version }}\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: ${{ matrix.node-version }}\n      - name: \"Cache Node.js modules\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/cache@c64c572235d810460d0d6876e9c705ad5002b353 #v2: 2.1.6 available\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n      - name: \"Install CLI tools\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install\n      - name: \"Execute unit tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 10\n          max_attempts: 3\n          command: npm test\n      - name: \"Execute integration tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 5\n          max_attempts: 3\n          command: |\n            if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n            set NODE_ENV=test\n            else\n            export NODE_ENV=test\n            fi\n            npm run frisby\n          shell: bash\n      - name: \"Publish coverage to Codeclimate\"\n        if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        env:\n          CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}\n        run: |\n          curl -L https://codeclimate.com/downloads/test-reporter/test-reporter-0.7.0-linux-amd64 > ./cc-test-reporter\n          chmod +x ./cc-test-reporter\n          sed -i s/SF:/SF:frontend\\\\//g build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.frontend.json build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.server.json build/reports/coverage/server-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.api.json build/reports/coverage/api-tests/lcov.info\n          ./cc-test-reporter sum-coverage build/reports/coverage/codeclimate.*.json -p 3\n          ./cc-test-reporter upload-coverage\n        shell: bash\n  e2e:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests\"\n        env:\n          SOLUTIONS_WEBHOOK: ${{ secrets.E2E_SOLUTIONS_WEBHOOK }}\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            set SOLUTIONS_WEBHOOK=\"$env:SOLUTIONS_WEBHOOK\"\n            npm run preprotractor:github\n            npm run e2e\n  e2e-in-subfolder:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    continue-on-error: true\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests with application hosted in subfolder\"\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            npm run preprotractor:github\n            npm run e2e -- subfolder\n  smoke:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: |\n          npm install -g @angular/cli\n          npm install -g grunt-cli\n      - name: \"Set packaging options for Grunt\"\n        run: |\n          echo \"PCKG_OS_NAME=linux\" >> $GITHUB_ENV\n          echo \"PCKG_NODE_VERSION=14\" >> $GITHUB_ENV\n          echo \"PCKG_CPU_ARCH=x64\" >> $GITHUB_ENV\n      - name: \"Package application\"\n        run: |\n          npm install --production\n          npm install -g grunt-cli\n          npm run package:ci\n      - name: \"Unpack application archive\"\n        run: |\n          cd dist\n          tar -zxf juice-shop-*.tgz\n      - name: \"Execute smoke test\"\n        run: |\n          cd dist/juice-shop_*\n          npm start &\n          cd ../..\n          chmod +x test/smoke/smoke-test.sh\n          test/smoke/smoke-test.sh http://localhost:3000\n  docker-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Execute smoke test on Docker\"\n        run: docker-compose -f docker-compose.test.yml up --exit-code-from sut\n  docker:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e, docker-test]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set up QEMU\"\n        uses: docker/setup-qemu-action@27d0a4f181a40b142cce983c5393082c365d1480 #v1: V1.2.0 available\n      - name: \"Set up Docker Buildx\"\n        uses: docker/setup-buildx-action@94ab11c41e45d028884a99163086648e898eed25 #v1\n      - name: \"Login to DockerHub\"\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 #v1.10\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: \"Set tag & labels for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"DOCKER_TAG=latest\" >> $GITHUB_ENV\n          else\n          echo \"DOCKER_TAG=snapshot\" >> $GITHUB_ENV\n          fi\n          echo \"VCS_REF=`git rev-parse --short HEAD`\" >> $GITHUB_ENV\n          echo \"BUILD_DATE=`date -u +%Y-%m-%dT%H:%M:%SZ`\" >> $GITHUB_ENV\n      - name: \"Build and push\"\n        uses: docker/build-push-action@a66e35b9cbcf4ad0ea91ffcaf7bbad63ad9e0229 #note: newer is available\n        with:\n          context: .\n          file: ./Dockerfile\n          platforms: linux/amd64,linux/arm/v7,linux/arm64\n          push: true\n          tags: |\n            bkimminich/juice-shop:${{ env.DOCKER_TAG }}\n          build-args: |\n            VCS_REF=${{ env.VCS_REF }}\n            BUILD_DATE=${{ env.BUILD_DATE }}\n  heroku:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set Heroku app & branch for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"HEROKU_APP=juice-shop\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=master\" >> $GITHUB_ENV\n          else\n          echo \"HEROKU_APP=juice-shop-staging\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=develop\" >> $GITHUB_ENV\n          fi\n      - name: \"Deploy ${{ github.ref }} to Heroku\"\n        uses: akhileshns/heroku-deploy@79ef2ae4ff9b897010907016b268fd0f88561820 #v3.12.12\n        with:\n          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n          heroku_app_name: ${{ env.HEROKU_APP }}\n          heroku_email: bjoern.kimminich@owasp.org\n          branch: ${{ env.HEROKU_BRANCH }}\n  notify-slack:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (success() || failure())\n    needs:\n      - docker\n      - heroku\n      - lint\n      - e2e-in-subfolder\n      - smoke\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Slack workflow notification\"\n        uses: Gamesight/slack-workflow-status@master\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}\n",
    "source": "carmjanneteau/https-github.com-juice-shop-juice-shop",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/carmjanneteau/https-github.com-juice-shop-juice-shop/blob/250a09e85815c75467126e452dcdcf721ecb2be3/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-31T01:44:29.950232Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this CI/CD workflow?",
    "answer": "name: \"CI/CD Pipeline\"\non:\n  push:\n    branches-ignore:\n      - l10n_develop\n      - gh-pages\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'monitoring/grafana-dashboard.json'\n      - 'screenshots/**'\n    tags-ignore:\n      - '*'\n  pull_request:\n    paths-ignore:\n      - '*.md'\n      - 'LICENSE'\n      - 'data/static/i18n/*.json'\n      - 'frontend/src/assets/i18n/*.json'\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: |\n          npm install --ignore-scripts\n          cd frontend\n          npm install --ignore-scripts --legacy-peer-deps\n      - name: \"Lint source code\"\n        run: npm run lint\n      - name: \"Lint customization configs\"\n        run: |\n          npm run lint:config -- -f ./config/7ms.yml\n          npm run lint:config -- -f ./config/addo.yml\n          npm run lint:config -- -f ./config/bodgeit.yml\n          npm run lint:config -- -f ./config/ctf.yml\n          npm run lint:config -- -f ./config/default.yml\n          npm run lint:config -- -f ./config/fbctf.yml\n          npm run lint:config -- -f ./config/juicebox.yml\n          npm run lint:config -- -f ./config/mozilla.yml\n          npm run lint:config -- -f ./config/oss.yml\n          npm run lint:config -- -f ./config/quiet.yml\n          npm run lint:config -- -f ./config/tutorial.yml\n          npm run lint:config -- -f ./config/unsafe.yml\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n        node-version: [12, 14, 16, 17]\n    steps:\n      - name: \"Check out Git repository\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js ${{ matrix.node-version }}\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: ${{ matrix.node-version }}\n      - name: \"Cache Node.js modules\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: actions/cache@c64c572235d810460d0d6876e9c705ad5002b353 #v2: 2.1.6 available\n        with:\n          path: ~/.npm\n          key: ${{ runner.OS }}-node-${{ hashFiles('**/package.json') }}\n          restore-keys: |\n            ${{ runner.OS }}-node-\n            ${{ runner.OS }}-\n      - name: \"Install CLI tools\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        run: npm install\n      - name: \"Execute unit tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 10\n          max_attempts: 3\n          command: npm test\n      - name: \"Execute integration tests\"\n        if: github.repository == 'juice-shop/juice-shop' || github.repository != 'juice-shop/juice-shop' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 5\n          max_attempts: 3\n          command: |\n            if [ \"$RUNNER_OS\" == \"Windows\" ]; then\n            set NODE_ENV=test\n            else\n            export NODE_ENV=test\n            fi\n            npm run frisby\n          shell: bash\n      - name: \"Publish coverage to Codeclimate\"\n        if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && matrix.os == 'ubuntu-latest' && matrix.node-version == '14'\n        env:\n          CC_TEST_REPORTER_ID: ${{ secrets.CC_TEST_REPORTER_ID }}\n        run: |\n          curl -L https://codeclimate.com/downloads/test-reporter/test-reporter-0.7.0-linux-amd64 > ./cc-test-reporter\n          chmod +x ./cc-test-reporter\n          sed -i s/SF:/SF:frontend\\\\//g build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.frontend.json build/reports/coverage/frontend-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.server.json build/reports/coverage/server-tests/lcov.info\n          ./cc-test-reporter format-coverage -t lcov -o build/reports/coverage/codeclimate.api.json build/reports/coverage/api-tests/lcov.info\n          ./cc-test-reporter sum-coverage build/reports/coverage/codeclimate.*.json -p 3\n          ./cc-test-reporter upload-coverage\n        shell: bash\n  e2e:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests\"\n        env:\n          SOLUTIONS_WEBHOOK: ${{ secrets.E2E_SOLUTIONS_WEBHOOK }}\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            set SOLUTIONS_WEBHOOK=\"$env:SOLUTIONS_WEBHOOK\"\n            npm run preprotractor:github\n            npm run e2e\n  e2e-in-subfolder:\n    runs-on: windows-latest\n    if: github.repository == 'juice-shop/juice-shop'\n    continue-on-error: true\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: npm install -g @angular/cli\n      - name: \"Install application\"\n        run: npm install\n      - name: \"Execute end-to-end tests with application hosted in subfolder\"\n        uses: nick-invision/retry@45ba062d357edb3b29c4a94b456b188716f61020 #v2: 2.4.1 available\n        with:\n          timeout_minutes: 20\n          max_attempts: 2\n          command: |\n            set NODE_ENV=test\n            npm run preprotractor:github\n            npm run e2e -- subfolder\n  smoke:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Use Node.js 16\"\n        uses: actions/setup-node@f1f314fca9dfce2769ece7d933488f076716723e #v1: v2.x available\n        with:\n          node-version: 16\n      - name: \"Install CLI tools\"\n        run: |\n          npm install -g @angular/cli\n          npm install -g grunt-cli\n      - name: \"Set packaging options for Grunt\"\n        run: |\n          echo \"PCKG_OS_NAME=linux\" >> $GITHUB_ENV\n          echo \"PCKG_NODE_VERSION=14\" >> $GITHUB_ENV\n          echo \"PCKG_CPU_ARCH=x64\" >> $GITHUB_ENV\n      - name: \"Package application\"\n        run: |\n          npm install --production\n          npm install -g grunt-cli\n          npm run package:ci\n      - name: \"Unpack application archive\"\n        run: |\n          cd dist\n          tar -zxf juice-shop-*.tgz\n      - name: \"Execute smoke test\"\n        run: |\n          cd dist/juice-shop_*\n          npm start &\n          cd ../..\n          chmod +x test/smoke/smoke-test.sh\n          test/smoke/smoke-test.sh http://localhost:3000\n  docker-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Execute smoke test on Docker\"\n        run: docker-compose -f docker-compose.test.yml up --exit-code-from sut\n  docker:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e, docker-test]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set up QEMU\"\n        uses: docker/setup-qemu-action@27d0a4f181a40b142cce983c5393082c365d1480 #v1: V1.2.0 available\n      - name: \"Set up Docker Buildx\"\n        uses: docker/setup-buildx-action@94ab11c41e45d028884a99163086648e898eed25 #v1\n      - name: \"Login to DockerHub\"\n        uses: docker/login-action@f054a8b539a109f9f41c372932f1ae047eff08c9 #v1.10\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: \"Set tag & labels for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"DOCKER_TAG=latest\" >> $GITHUB_ENV\n          else\n          echo \"DOCKER_TAG=snapshot\" >> $GITHUB_ENV\n          fi\n          echo \"VCS_REF=`git rev-parse --short HEAD`\" >> $GITHUB_ENV\n          echo \"BUILD_DATE=`date -u +%Y-%m-%dT%H:%M:%SZ`\" >> $GITHUB_ENV\n      - name: \"Build and push\"\n        uses: docker/build-push-action@a66e35b9cbcf4ad0ea91ffcaf7bbad63ad9e0229 #note: newer is available\n        with:\n          context: .\n          file: ./Dockerfile\n          platforms: linux/amd64,linux/arm/v7,linux/arm64\n          push: true\n          tags: |\n            bkimminich/juice-shop:${{ env.DOCKER_TAG }}\n          build-args: |\n            VCS_REF=${{ env.VCS_REF }}\n            BUILD_DATE=${{ env.BUILD_DATE }}\n  heroku:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/master')\n    needs: [test, e2e]\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Check out Git repository\"\n        uses: actions/checkout@5a4ac9002d0be2fb38bd78e4b4dbde5606d7042f #v2: v2.3.4 available\n      - name: \"Set Heroku app & branch for ${{ github.ref }}\"\n        run: |\n          if [ \"$GITHUB_REF\" == \"refs/heads/master\" ]; then\n          echo \"HEROKU_APP=juice-shop\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=master\" >> $GITHUB_ENV\n          else\n          echo \"HEROKU_APP=juice-shop-staging\" >> $GITHUB_ENV\n          echo \"HEROKU_BRANCH=develop\" >> $GITHUB_ENV\n          fi\n      - name: \"Deploy ${{ github.ref }} to Heroku\"\n        uses: akhileshns/heroku-deploy@79ef2ae4ff9b897010907016b268fd0f88561820 #v3.12.12\n        with:\n          heroku_api_key: ${{ secrets.HEROKU_API_KEY }}\n          heroku_app_name: ${{ env.HEROKU_APP }}\n          heroku_email: bjoern.kimminich@owasp.org\n          branch: ${{ env.HEROKU_BRANCH }}\n  notify-slack:\n    if: github.repository == 'juice-shop/juice-shop' && github.event_name == 'push' && (success() || failure())\n    needs:\n      - docker\n      - heroku\n      - lint\n      - e2e-in-subfolder\n      - smoke\n    runs-on: ubuntu-latest\n    steps:\n      - name: \"Slack workflow notification\"\n        uses: Gamesight/slack-workflow-status@master\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}\n",
    "source": "carmjanneteau/https-github.com-juice-shop-juice-shop",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/carmjanneteau/https-github.com-juice-shop-juice-shop/blob/250a09e85815c75467126e452dcdcf721ecb2be3/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-31T01:44:32.775244Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: CI\non:\n  push:\n    paths-ignore:\n      - 'docs/**'\n      - '*.md'\n      - '.mailmap'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  linux:\n    name: ${{ matrix.compiler }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        compiler: [g++-8, g++-9, g++-10, g++-11,\n                   clang++-7, clang++-8, clang++-9, clang++-10, clang++-11, clang++-12]\n        os: [ubuntu-20.04]\n        include:\n          - compiler: g++-7\n            os: ubuntu-18.04\n          - compiler: clang++-6.0\n            os: ubuntu-18.04\n    runs-on: ${{ matrix.os }}\n    env:\n      CXX: ${{ matrix.compiler }}\n      NODE_LABELS: Linux Ubuntu\n      WAF_JOBS: 2\n    steps:\n      - name: Install C++ compiler\n        run: |\n          sudo apt-get -qy install ${CXX/clang++/clang}\n          ${CXX} --version\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n\n  macos:\n    name: Xcode ${{ matrix.xcode }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        xcode: ['11.3', '11.7', '12.4']\n        os: [macos-10.15]\n        include:\n          - xcode: '12.5'\n            os: macos-11\n          - xcode: '13.2'\n            os: macos-11\n    runs-on: ${{ matrix.os }}\n    env:\n      NODE_LABELS: OSX\n      WAF_JOBS: 3\n    steps:\n      - name: Set up Xcode\n        uses: maxim-lobanov/setup-xcode@v1\n        with:\n          xcode-version: ${{ matrix.xcode }}\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n",
    "source": "alvyC/NFD-CCLF",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/alvyC/NFD-CCLF/blob/7b53dc1d25e7af886267c8d68359ae318e1239aa/.github/workflows/ci.yml",
    "retrieved_at": "2025-11-01T01:47:41.156833Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this CI workflow?",
    "answer": "name: CI\non:\n  push:\n    paths-ignore:\n      - 'docs/**'\n      - '*.md'\n      - '.mailmap'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  linux:\n    name: ${{ matrix.compiler }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        compiler: [g++-8, g++-9, g++-10, g++-11,\n                   clang++-7, clang++-8, clang++-9, clang++-10, clang++-11, clang++-12]\n        os: [ubuntu-20.04]\n        include:\n          - compiler: g++-7\n            os: ubuntu-18.04\n          - compiler: clang++-6.0\n            os: ubuntu-18.04\n    runs-on: ${{ matrix.os }}\n    env:\n      CXX: ${{ matrix.compiler }}\n      NODE_LABELS: Linux Ubuntu\n      WAF_JOBS: 2\n    steps:\n      - name: Install C++ compiler\n        run: |\n          sudo apt-get -qy install ${CXX/clang++/clang}\n          ${CXX} --version\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n\n  macos:\n    name: Xcode ${{ matrix.xcode }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        xcode: ['11.3', '11.7', '12.4']\n        os: [macos-10.15]\n        include:\n          - xcode: '12.5'\n            os: macos-11\n          - xcode: '13.2'\n            os: macos-11\n    runs-on: ${{ matrix.os }}\n    env:\n      NODE_LABELS: OSX\n      WAF_JOBS: 3\n    steps:\n      - name: Set up Xcode\n        uses: maxim-lobanov/setup-xcode@v1\n        with:\n          xcode-version: ${{ matrix.xcode }}\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n",
    "source": "alvyC/NFD-CCLF",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/alvyC/NFD-CCLF/blob/7b53dc1d25e7af886267c8d68359ae318e1239aa/.github/workflows/ci.yml",
    "retrieved_at": "2025-11-01T01:47:45.129612Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the CI workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: CI\non:\n  push:\n    paths-ignore:\n      - 'docs/**'\n      - '*.md'\n      - '.mailmap'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  linux:\n    name: ${{ matrix.compiler }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        compiler: [g++-8, g++-9, g++-10, g++-11,\n                   clang++-7, clang++-8, clang++-9, clang++-10, clang++-11, clang++-12]\n        os: [ubuntu-20.04]\n        include:\n          - compiler: g++-7\n            os: ubuntu-18.04\n          - compiler: clang++-6.0\n            os: ubuntu-18.04\n    runs-on: ${{ matrix.os }}\n    env:\n      CXX: ${{ matrix.compiler }}\n      NODE_LABELS: Linux Ubuntu\n      WAF_JOBS: 2\n    steps:\n      - name: Install C++ compiler\n        run: |\n          sudo apt-get -qy install ${CXX/clang++/clang}\n          ${CXX} --version\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n\n  macos:\n    name: Xcode ${{ matrix.xcode }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        xcode: ['11.3', '11.7', '12.4']\n        os: [macos-10.15]\n        include:\n          - xcode: '12.5'\n            os: macos-11\n          - xcode: '13.2'\n            os: macos-11\n    runs-on: ${{ matrix.os }}\n    env:\n      NODE_LABELS: OSX\n      WAF_JOBS: 3\n    steps:\n      - name: Set up Xcode\n        uses: maxim-lobanov/setup-xcode@v1\n        with:\n          xcode-version: ${{ matrix.xcode }}\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n",
    "source": "alvyC/NFD-CCLF",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/alvyC/NFD-CCLF/blob/7b53dc1d25e7af886267c8d68359ae318e1239aa/.github/workflows/ci.yml",
    "retrieved_at": "2025-11-01T01:47:46.924366Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables CXX, NODE_LABELS, and WAF_JOBS used in the Linux and macOS jobs?",
    "answer": "name: CI\non:\n  push:\n    paths-ignore:\n      - 'docs/**'\n      - '*.md'\n      - '.mailmap'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  linux:\n    name: ${{ matrix.compiler }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        compiler: [g++-8, g++-9, g++-10, g++-11,\n                   clang++-7, clang++-8, clang++-9, clang++-10, clang++-11, clang++-12]\n        os: [ubuntu-20.04]\n        include:\n          - compiler: g++-7\n            os: ubuntu-18.04\n          - compiler: clang++-6.0\n            os: ubuntu-18.04\n    runs-on: ${{ matrix.os }}\n    env:\n      CXX: ${{ matrix.compiler }}\n      NODE_LABELS: Linux Ubuntu\n      WAF_JOBS: 2\n    steps:\n      - name: Install C++ compiler\n        run: |\n          sudo apt-get -qy install ${CXX/clang++/clang}\n          ${CXX} --version\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n\n  macos:\n    name: Xcode ${{ matrix.xcode }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        xcode: ['11.3', '11.7', '12.4']\n        os: [macos-10.15]\n        include:\n          - xcode: '12.5'\n            os: macos-11\n          - xcode: '13.2'\n            os: macos-11\n    runs-on: ${{ matrix.os }}\n    env:\n      NODE_LABELS: OSX\n      WAF_JOBS: 3\n    steps:\n      - name: Set up Xcode\n        uses: maxim-lobanov/setup-xcode@v1\n        with:\n          xcode-version: ${{ matrix.xcode }}\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n",
    "source": "alvyC/NFD-CCLF",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/alvyC/NFD-CCLF/blob/7b53dc1d25e7af886267c8d68359ae318e1239aa/.github/workflows/ci.yml",
    "retrieved_at": "2025-11-01T01:47:50.430241Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this CI workflow?",
    "answer": "name: CI\non:\n  push:\n    paths-ignore:\n      - 'docs/**'\n      - '*.md'\n      - '.mailmap'\n  workflow_dispatch:\n\npermissions:\n  contents: read\n\njobs:\n  linux:\n    name: ${{ matrix.compiler }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        compiler: [g++-8, g++-9, g++-10, g++-11,\n                   clang++-7, clang++-8, clang++-9, clang++-10, clang++-11, clang++-12]\n        os: [ubuntu-20.04]\n        include:\n          - compiler: g++-7\n            os: ubuntu-18.04\n          - compiler: clang++-6.0\n            os: ubuntu-18.04\n    runs-on: ${{ matrix.os }}\n    env:\n      CXX: ${{ matrix.compiler }}\n      NODE_LABELS: Linux Ubuntu\n      WAF_JOBS: 2\n    steps:\n      - name: Install C++ compiler\n        run: |\n          sudo apt-get -qy install ${CXX/clang++/clang}\n          ${CXX} --version\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n\n  macos:\n    name: Xcode ${{ matrix.xcode }} on ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        xcode: ['11.3', '11.7', '12.4']\n        os: [macos-10.15]\n        include:\n          - xcode: '12.5'\n            os: macos-11\n          - xcode: '13.2'\n            os: macos-11\n    runs-on: ${{ matrix.os }}\n    env:\n      NODE_LABELS: OSX\n      WAF_JOBS: 3\n    steps:\n      - name: Set up Xcode\n        uses: maxim-lobanov/setup-xcode@v1\n        with:\n          xcode-version: ${{ matrix.xcode }}\n      - name: Checkout\n        uses: actions/checkout@v3\n      - name: Build and test\n        run: ./.jenkins\n",
    "source": "alvyC/NFD-CCLF",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/alvyC/NFD-CCLF/blob/7b53dc1d25e7af886267c8d68359ae318e1239aa/.github/workflows/ci.yml",
    "retrieved_at": "2025-11-01T01:47:51.016247Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file, including its triggers, concurrency, permissions, and jobs.",
    "answer": "# This workflow is dedicated to host slow jobs that are run only periodically because\n# they are too slow to run in every commit.  The list of slow tests can be found in\n# https://github.com/pytorch/test-infra/blob/generated-stats/stats/slow-tests.json\nname: slow\n\non:\n  schedule:\n    - cron: 45 0,4,8,12,16,20 * * *\n    - cron: 29 8 * * *  # about 1:29am PDT, for mem leak check and rerun disabled tests\n  push:\n    tags:\n      - ciflow/slow/*\n    branches:\n      - release/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}-${{ github.event.schedule }}\n  cancel-in-progress: true\n\npermissions: read-all\n\njobs:\n  target-determination:\n    name: before-test\n    uses: ./.github/workflows/target_determination.yml\n    permissions:\n      id-token: write\n      contents: read\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"default\", shard: 1, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 2, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 3, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 4, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-test:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.test-matrix }}\n      timeout-minutes: 300\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-build:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-test:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3_10-gcc9-sm86-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.test-matrix }}\n\n  linux-focal-py3_8-clang10-build:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image-name: pytorch-linux-focal-py3.8-clang10\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.2xlarge\" },\n        ]}\n\n  linux-focal-py3_8-clang10-test:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-py3_8-clang10-build\n      - target-determination\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image: ${{ needs.linux-focal-py3_8-clang10-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-py3_8-clang10-build.outputs.test-matrix }}\n\n  linux-focal-rocm6_0-py3_8-build:\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image-name: pytorch-linux-focal-rocm-n-py3\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.rocm.gpu\" },\n        ]}\n\n  linux-focal-rocm6_0-py3_8-test:\n    permissions:\n      id-token: write\n      contents: read\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_rocm-test.yml\n    needs:\n      - linux-focal-rocm6_0-py3_8-build\n      - target-determination\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.test-matrix }}\n\n  linux-jammy-py3_10-clang15-asan-build:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image-name: pytorch-linux-jammy-py3-clang15-asan\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.4xlarge\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.4xlarge\" },\n        ]}\n      sync-tag: asan-build\n\n  linux-jammy-py3_10-clang15-asan-test:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-jammy-py3_10-clang15-asan-build\n      - target-determination\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.test-matrix }}\n      sync-tag: asan-test\n",
    "source": "zal-orz/pytorch",
    "path": ".github/workflows/slow.yml",
    "url": "https://github.com/zal-orz/pytorch/blob/78b4793c965fe640e37d80530eb78f07d67492e8/.github/workflows/slow.yml",
    "retrieved_at": "2025-11-01T01:47:51.982563Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"slow\" workflow?",
    "answer": "# This workflow is dedicated to host slow jobs that are run only periodically because\n# they are too slow to run in every commit.  The list of slow tests can be found in\n# https://github.com/pytorch/test-infra/blob/generated-stats/stats/slow-tests.json\nname: slow\n\non:\n  schedule:\n    - cron: 45 0,4,8,12,16,20 * * *\n    - cron: 29 8 * * *  # about 1:29am PDT, for mem leak check and rerun disabled tests\n  push:\n    tags:\n      - ciflow/slow/*\n    branches:\n      - release/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}-${{ github.event.schedule }}\n  cancel-in-progress: true\n\npermissions: read-all\n\njobs:\n  target-determination:\n    name: before-test\n    uses: ./.github/workflows/target_determination.yml\n    permissions:\n      id-token: write\n      contents: read\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"default\", shard: 1, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 2, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 3, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 4, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-test:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.test-matrix }}\n      timeout-minutes: 300\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-build:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-test:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3_10-gcc9-sm86-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.test-matrix }}\n\n  linux-focal-py3_8-clang10-build:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image-name: pytorch-linux-focal-py3.8-clang10\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.2xlarge\" },\n        ]}\n\n  linux-focal-py3_8-clang10-test:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-py3_8-clang10-build\n      - target-determination\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image: ${{ needs.linux-focal-py3_8-clang10-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-py3_8-clang10-build.outputs.test-matrix }}\n\n  linux-focal-rocm6_0-py3_8-build:\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image-name: pytorch-linux-focal-rocm-n-py3\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.rocm.gpu\" },\n        ]}\n\n  linux-focal-rocm6_0-py3_8-test:\n    permissions:\n      id-token: write\n      contents: read\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_rocm-test.yml\n    needs:\n      - linux-focal-rocm6_0-py3_8-build\n      - target-determination\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.test-matrix }}\n\n  linux-jammy-py3_10-clang15-asan-build:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image-name: pytorch-linux-jammy-py3-clang15-asan\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.4xlarge\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.4xlarge\" },\n        ]}\n      sync-tag: asan-build\n\n  linux-jammy-py3_10-clang15-asan-test:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-jammy-py3_10-clang15-asan-build\n      - target-determination\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.test-matrix }}\n      sync-tag: asan-test\n",
    "source": "zal-orz/pytorch",
    "path": ".github/workflows/slow.yml",
    "url": "https://github.com/zal-orz/pytorch/blob/78b4793c965fe640e37d80530eb78f07d67492e8/.github/workflows/slow.yml",
    "retrieved_at": "2025-11-01T01:47:52.659602Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and which jobs depend on the successful completion of other jobs?",
    "answer": "# This workflow is dedicated to host slow jobs that are run only periodically because\n# they are too slow to run in every commit.  The list of slow tests can be found in\n# https://github.com/pytorch/test-infra/blob/generated-stats/stats/slow-tests.json\nname: slow\n\non:\n  schedule:\n    - cron: 45 0,4,8,12,16,20 * * *\n    - cron: 29 8 * * *  # about 1:29am PDT, for mem leak check and rerun disabled tests\n  push:\n    tags:\n      - ciflow/slow/*\n    branches:\n      - release/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}-${{ github.event.schedule }}\n  cancel-in-progress: true\n\npermissions: read-all\n\njobs:\n  target-determination:\n    name: before-test\n    uses: ./.github/workflows/target_determination.yml\n    permissions:\n      id-token: write\n      contents: read\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"default\", shard: 1, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 2, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 3, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 4, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-test:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.test-matrix }}\n      timeout-minutes: 300\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-build:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-test:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3_10-gcc9-sm86-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.test-matrix }}\n\n  linux-focal-py3_8-clang10-build:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image-name: pytorch-linux-focal-py3.8-clang10\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.2xlarge\" },\n        ]}\n\n  linux-focal-py3_8-clang10-test:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-py3_8-clang10-build\n      - target-determination\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image: ${{ needs.linux-focal-py3_8-clang10-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-py3_8-clang10-build.outputs.test-matrix }}\n\n  linux-focal-rocm6_0-py3_8-build:\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image-name: pytorch-linux-focal-rocm-n-py3\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.rocm.gpu\" },\n        ]}\n\n  linux-focal-rocm6_0-py3_8-test:\n    permissions:\n      id-token: write\n      contents: read\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_rocm-test.yml\n    needs:\n      - linux-focal-rocm6_0-py3_8-build\n      - target-determination\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.test-matrix }}\n\n  linux-jammy-py3_10-clang15-asan-build:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image-name: pytorch-linux-jammy-py3-clang15-asan\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.4xlarge\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.4xlarge\" },\n        ]}\n      sync-tag: asan-build\n\n  linux-jammy-py3_10-clang15-asan-test:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-jammy-py3_10-clang15-asan-build\n      - target-determination\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.test-matrix }}\n      sync-tag: asan-test\n",
    "source": "zal-orz/pytorch",
    "path": ".github/workflows/slow.yml",
    "url": "https://github.com/zal-orz/pytorch/blob/78b4793c965fe640e37d80530eb78f07d67492e8/.github/workflows/slow.yml",
    "retrieved_at": "2025-11-01T01:47:55.646306Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any environment variables or secrets used within the referenced reusable workflows (_linux-build.yml, _linux-test.yml, _rocm-test.yml, target_determination.yml)?",
    "answer": "# This workflow is dedicated to host slow jobs that are run only periodically because\n# they are too slow to run in every commit.  The list of slow tests can be found in\n# https://github.com/pytorch/test-infra/blob/generated-stats/stats/slow-tests.json\nname: slow\n\non:\n  schedule:\n    - cron: 45 0,4,8,12,16,20 * * *\n    - cron: 29 8 * * *  # about 1:29am PDT, for mem leak check and rerun disabled tests\n  push:\n    tags:\n      - ciflow/slow/*\n    branches:\n      - release/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}-${{ github.event.schedule }}\n  cancel-in-progress: true\n\npermissions: read-all\n\njobs:\n  target-determination:\n    name: before-test\n    uses: ./.github/workflows/target_determination.yml\n    permissions:\n      id-token: write\n      contents: read\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"default\", shard: 1, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 2, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 3, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"default\", shard: 4, num_shards: 4, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-test:\n    name: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3-gcc9-slow-gradcheck\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3-gcc9-slow-gradcheck-build.outputs.test-matrix }}\n      timeout-minutes: 300\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-build:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image-name: pytorch-linux-focal-cuda12.1-cudnn8-py3-gcc9\n      cuda-arch-list: 8.6\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.g5.4xlarge.nvidia.gpu\" },\n        ]}\n\n  linux-focal-cuda12_1-py3_10-gcc9-sm86-test:\n    name: linux-focal-cuda12.1-py3.10-gcc9-sm86\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-cuda12_1-py3_10-gcc9-sm86-build\n      - target-determination\n    with:\n      build-environment: linux-focal-cuda12.1-py3.10-gcc9-sm86\n      docker-image: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-cuda12_1-py3_10-gcc9-sm86-build.outputs.test-matrix }}\n\n  linux-focal-py3_8-clang10-build:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image-name: pytorch-linux-focal-py3.8-clang10\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.2xlarge\" },\n        ]}\n\n  linux-focal-py3_8-clang10-test:\n    name: linux-focal-py3.8-clang10\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-focal-py3_8-clang10-build\n      - target-determination\n    with:\n      build-environment: linux-focal-py3.8-clang10\n      docker-image: ${{ needs.linux-focal-py3_8-clang10-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-py3_8-clang10-build.outputs.test-matrix }}\n\n  linux-focal-rocm6_0-py3_8-build:\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image-name: pytorch-linux-focal-rocm-n-py3\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 1, runner: \"linux.rocm.gpu\" },\n        ]}\n\n  linux-focal-rocm6_0-py3_8-test:\n    permissions:\n      id-token: write\n      contents: read\n    name: linux-focal-rocm6.0-py3.8\n    uses: ./.github/workflows/_rocm-test.yml\n    needs:\n      - linux-focal-rocm6_0-py3_8-build\n      - target-determination\n    with:\n      build-environment: linux-focal-rocm6.0-py3.8\n      docker-image: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-focal-rocm6_0-py3_8-build.outputs.test-matrix }}\n\n  linux-jammy-py3_10-clang15-asan-build:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-build.yml\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image-name: pytorch-linux-jammy-py3-clang15-asan\n      test-matrix: |\n        { include: [\n          { config: \"slow\", shard: 1, num_shards: 2, runner: \"linux.4xlarge\" },\n          { config: \"slow\", shard: 2, num_shards: 2, runner: \"linux.4xlarge\" },\n        ]}\n      sync-tag: asan-build\n\n  linux-jammy-py3_10-clang15-asan-test:\n    name: linux-jammy-py3.10-clang15-asan\n    uses: ./.github/workflows/_linux-test.yml\n    needs:\n      - linux-jammy-py3_10-clang15-asan-build\n      - target-determination\n    with:\n      build-environment: linux-jammy-py3.10-clang15-asan\n      docker-image: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.docker-image }}\n      test-matrix: ${{ needs.linux-jammy-py3_10-clang15-asan-build.outputs.test-matrix }}\n      sync-tag: asan-test\n",
    "source": "zal-orz/pytorch",
    "path": ".github/workflows/slow.yml",
    "url": "https://github.com/zal-orz/pytorch/blob/78b4793c965fe640e37d80530eb78f07d67492e8/.github/workflows/slow.yml",
    "retrieved_at": "2025-11-01T01:47:59.866558Z",
    "question_style": "style_4"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the behavior of the provided YAML file.",
    "answer": "name: api\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\non:\n  pull_request:\n    paths:\n      - \"api/**\"\n      - \".github/workflows/api.yaml\"\n    branches:\n      - main\n\njobs:\n  build:\n    uses: VeryGoodOpenSource/very_good_workflows/.github/workflows/dart_package.yml@v1\n    with:\n      dart_sdk: 3.0.2\n      working_directory: api\n      analyze_directories: \"routes lib test\"\n      coverage_excludes: \"**/*.g.dart\"\n      report_on: \"routes,lib\"\n",
    "source": "szmyty/flutter_template",
    "path": ".github/workflows/api.yaml",
    "url": "https://github.com/szmyty/flutter_template/blob/78cee5fa324f7f2c01dbfcc61f15db61afa8ef41/.github/workflows/api.yaml",
    "retrieved_at": "2025-11-01T01:48:03.993293Z",
    "question_style": "style_1"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building wolfSSL and testing sssd.",
    "answer": "name: sssd Tests\n\n# START OF COMMON SECTION\non:\n  push:\n    branches: [ 'master', 'main', 'release/**' ]\n  pull_request:\n    branches: [ '*' ]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n# END OF COMMON SECTION\n\njobs:\n  build_wolfssl:\n    name: Build wolfSSL\n    # Just to keep it the same as the testing target\n    runs-on: ubuntu-22.04\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 4\n    steps:\n      - name: Build wolfSSL\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          path: wolfssl\n          configure: --enable-all CFLAGS=-DWOLFSSL_NO_ASN_STRICT\n          install: true\n          check: false\n\n      - name: tar build-dir\n        run: tar -zcf build-dir.tgz build-dir\n\n      - name: Upload built lib\n        uses: actions/upload-artifact@v4\n        with:\n          name: wolf-install-sssd\n          path: build-dir.tgz\n          retention-days: 5\n\n  sssd_check:\n    strategy:\n      fail-fast: false\n      matrix:\n        # List of releases to test\n        ref: [ 2.9.1 ]\n    name: ${{ matrix.ref }}\n    runs-on: ubuntu-22.04\n    container:\n      image: quay.io/sssd/ci-client-devel:ubuntu-latest\n      env:\n        LD_LIBRARY_PATH: /usr/local/lib\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 20\n    needs: build_wolfssl\n    steps:\n      - name: Install dependencies\n        run: |\n          # Don't prompt for anything\n          export DEBIAN_FRONTEND=noninteractive\n          sudo apt-get update\n          sudo apt-get install -y build-essential autoconf libldb-dev libldb2 python3-ldb bc\n\n      - name: Setup env\n        run: |\n          ln -s samba-4.0/ldb.h /usr/include/ldb.h\n          ln -s samba-4.0/ldb_errors.h /usr/include/ldb_errors.h\n          ln -s samba-4.0/ldb_handlers.h /usr/include/ldb_handlers.h\n          ln -s samba-4.0/ldb_module.h /usr/include/ldb_module.h\n          ln -s samba-4.0/ldb_version.h /usr/include/ldb_version.h\n\n      - name: Download lib\n        uses: actions/download-artifact@v4\n        with:\n          name: wolf-install-sssd\n\n      - name: untar build-dir\n        run: tar -xf build-dir.tgz\n\n      - name: Checkout OSP\n        uses: actions/checkout@v4\n        with:\n          repository: wolfssl/osp\n          path: osp\n\n      - name: Build and test sssd\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          repository: SSSD/sssd\n          ref: ${{ matrix.ref }}\n          path: sssd\n          patch-file: $GITHUB_WORKSPACE/osp/sssd/${{ matrix.ref }}.patch\n          configure: >-\n            --without-samba --without-nfsv4-idmapd-plugin --with-oidc-child=no\n            --without-manpages WOLFSSL_INSTALL_DIR=$GITHUB_WORKSPACE/build-dir\n          check: true\n\n",
    "source": "deepaksirone/wolfssl_bellerophon",
    "path": ".github/workflows/sssd.yml",
    "url": "https://github.com/deepaksirone/wolfssl_bellerophon/blob/50121495276c3c39dc5e525f07f6ebb5ae36cbc0/.github/workflows/sssd.yml",
    "retrieved_at": "2025-11-02T01:49:24.567211Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow to run?",
    "answer": "name: sssd Tests\n\n# START OF COMMON SECTION\non:\n  push:\n    branches: [ 'master', 'main', 'release/**' ]\n  pull_request:\n    branches: [ '*' ]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n# END OF COMMON SECTION\n\njobs:\n  build_wolfssl:\n    name: Build wolfSSL\n    # Just to keep it the same as the testing target\n    runs-on: ubuntu-22.04\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 4\n    steps:\n      - name: Build wolfSSL\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          path: wolfssl\n          configure: --enable-all CFLAGS=-DWOLFSSL_NO_ASN_STRICT\n          install: true\n          check: false\n\n      - name: tar build-dir\n        run: tar -zcf build-dir.tgz build-dir\n\n      - name: Upload built lib\n        uses: actions/upload-artifact@v4\n        with:\n          name: wolf-install-sssd\n          path: build-dir.tgz\n          retention-days: 5\n\n  sssd_check:\n    strategy:\n      fail-fast: false\n      matrix:\n        # List of releases to test\n        ref: [ 2.9.1 ]\n    name: ${{ matrix.ref }}\n    runs-on: ubuntu-22.04\n    container:\n      image: quay.io/sssd/ci-client-devel:ubuntu-latest\n      env:\n        LD_LIBRARY_PATH: /usr/local/lib\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 20\n    needs: build_wolfssl\n    steps:\n      - name: Install dependencies\n        run: |\n          # Don't prompt for anything\n          export DEBIAN_FRONTEND=noninteractive\n          sudo apt-get update\n          sudo apt-get install -y build-essential autoconf libldb-dev libldb2 python3-ldb bc\n\n      - name: Setup env\n        run: |\n          ln -s samba-4.0/ldb.h /usr/include/ldb.h\n          ln -s samba-4.0/ldb_errors.h /usr/include/ldb_errors.h\n          ln -s samba-4.0/ldb_handlers.h /usr/include/ldb_handlers.h\n          ln -s samba-4.0/ldb_module.h /usr/include/ldb_module.h\n          ln -s samba-4.0/ldb_version.h /usr/include/ldb_version.h\n\n      - name: Download lib\n        uses: actions/download-artifact@v4\n        with:\n          name: wolf-install-sssd\n\n      - name: untar build-dir\n        run: tar -xf build-dir.tgz\n\n      - name: Checkout OSP\n        uses: actions/checkout@v4\n        with:\n          repository: wolfssl/osp\n          path: osp\n\n      - name: Build and test sssd\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          repository: SSSD/sssd\n          ref: ${{ matrix.ref }}\n          path: sssd\n          patch-file: $GITHUB_WORKSPACE/osp/sssd/${{ matrix.ref }}.patch\n          configure: >-\n            --without-samba --without-nfsv4-idmapd-plugin --with-oidc-child=no\n            --without-manpages WOLFSSL_INSTALL_DIR=$GITHUB_WORKSPACE/build-dir\n          check: true\n\n",
    "source": "deepaksirone/wolfssl_bellerophon",
    "path": ".github/workflows/sssd.yml",
    "url": "https://github.com/deepaksirone/wolfssl_bellerophon/blob/50121495276c3c39dc5e525f07f6ebb5ae36cbc0/.github/workflows/sssd.yml",
    "retrieved_at": "2025-11-02T01:49:25.139949Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: sssd Tests\n\n# START OF COMMON SECTION\non:\n  push:\n    branches: [ 'master', 'main', 'release/**' ]\n  pull_request:\n    branches: [ '*' ]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n# END OF COMMON SECTION\n\njobs:\n  build_wolfssl:\n    name: Build wolfSSL\n    # Just to keep it the same as the testing target\n    runs-on: ubuntu-22.04\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 4\n    steps:\n      - name: Build wolfSSL\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          path: wolfssl\n          configure: --enable-all CFLAGS=-DWOLFSSL_NO_ASN_STRICT\n          install: true\n          check: false\n\n      - name: tar build-dir\n        run: tar -zcf build-dir.tgz build-dir\n\n      - name: Upload built lib\n        uses: actions/upload-artifact@v4\n        with:\n          name: wolf-install-sssd\n          path: build-dir.tgz\n          retention-days: 5\n\n  sssd_check:\n    strategy:\n      fail-fast: false\n      matrix:\n        # List of releases to test\n        ref: [ 2.9.1 ]\n    name: ${{ matrix.ref }}\n    runs-on: ubuntu-22.04\n    container:\n      image: quay.io/sssd/ci-client-devel:ubuntu-latest\n      env:\n        LD_LIBRARY_PATH: /usr/local/lib\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 20\n    needs: build_wolfssl\n    steps:\n      - name: Install dependencies\n        run: |\n          # Don't prompt for anything\n          export DEBIAN_FRONTEND=noninteractive\n          sudo apt-get update\n          sudo apt-get install -y build-essential autoconf libldb-dev libldb2 python3-ldb bc\n\n      - name: Setup env\n        run: |\n          ln -s samba-4.0/ldb.h /usr/include/ldb.h\n          ln -s samba-4.0/ldb_errors.h /usr/include/ldb_errors.h\n          ln -s samba-4.0/ldb_handlers.h /usr/include/ldb_handlers.h\n          ln -s samba-4.0/ldb_module.h /usr/include/ldb_module.h\n          ln -s samba-4.0/ldb_version.h /usr/include/ldb_version.h\n\n      - name: Download lib\n        uses: actions/download-artifact@v4\n        with:\n          name: wolf-install-sssd\n\n      - name: untar build-dir\n        run: tar -xf build-dir.tgz\n\n      - name: Checkout OSP\n        uses: actions/checkout@v4\n        with:\n          repository: wolfssl/osp\n          path: osp\n\n      - name: Build and test sssd\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          repository: SSSD/sssd\n          ref: ${{ matrix.ref }}\n          path: sssd\n          patch-file: $GITHUB_WORKSPACE/osp/sssd/${{ matrix.ref }}.patch\n          configure: >-\n            --without-samba --without-nfsv4-idmapd-plugin --with-oidc-child=no\n            --without-manpages WOLFSSL_INSTALL_DIR=$GITHUB_WORKSPACE/build-dir\n          check: true\n\n",
    "source": "deepaksirone/wolfssl_bellerophon",
    "path": ".github/workflows/sssd.yml",
    "url": "https://github.com/deepaksirone/wolfssl_bellerophon/blob/50121495276c3c39dc5e525f07f6ebb5ae36cbc0/.github/workflows/sssd.yml",
    "retrieved_at": "2025-11-02T01:49:25.942916Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `LD_LIBRARY_PATH` environment variable used within the `sssd_check` job's container?",
    "answer": "name: sssd Tests\n\n# START OF COMMON SECTION\non:\n  push:\n    branches: [ 'master', 'main', 'release/**' ]\n  pull_request:\n    branches: [ '*' ]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n# END OF COMMON SECTION\n\njobs:\n  build_wolfssl:\n    name: Build wolfSSL\n    # Just to keep it the same as the testing target\n    runs-on: ubuntu-22.04\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 4\n    steps:\n      - name: Build wolfSSL\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          path: wolfssl\n          configure: --enable-all CFLAGS=-DWOLFSSL_NO_ASN_STRICT\n          install: true\n          check: false\n\n      - name: tar build-dir\n        run: tar -zcf build-dir.tgz build-dir\n\n      - name: Upload built lib\n        uses: actions/upload-artifact@v4\n        with:\n          name: wolf-install-sssd\n          path: build-dir.tgz\n          retention-days: 5\n\n  sssd_check:\n    strategy:\n      fail-fast: false\n      matrix:\n        # List of releases to test\n        ref: [ 2.9.1 ]\n    name: ${{ matrix.ref }}\n    runs-on: ubuntu-22.04\n    container:\n      image: quay.io/sssd/ci-client-devel:ubuntu-latest\n      env:\n        LD_LIBRARY_PATH: /usr/local/lib\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 20\n    needs: build_wolfssl\n    steps:\n      - name: Install dependencies\n        run: |\n          # Don't prompt for anything\n          export DEBIAN_FRONTEND=noninteractive\n          sudo apt-get update\n          sudo apt-get install -y build-essential autoconf libldb-dev libldb2 python3-ldb bc\n\n      - name: Setup env\n        run: |\n          ln -s samba-4.0/ldb.h /usr/include/ldb.h\n          ln -s samba-4.0/ldb_errors.h /usr/include/ldb_errors.h\n          ln -s samba-4.0/ldb_handlers.h /usr/include/ldb_handlers.h\n          ln -s samba-4.0/ldb_module.h /usr/include/ldb_module.h\n          ln -s samba-4.0/ldb_version.h /usr/include/ldb_version.h\n\n      - name: Download lib\n        uses: actions/download-artifact@v4\n        with:\n          name: wolf-install-sssd\n\n      - name: untar build-dir\n        run: tar -xf build-dir.tgz\n\n      - name: Checkout OSP\n        uses: actions/checkout@v4\n        with:\n          repository: wolfssl/osp\n          path: osp\n\n      - name: Build and test sssd\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          repository: SSSD/sssd\n          ref: ${{ matrix.ref }}\n          path: sssd\n          patch-file: $GITHUB_WORKSPACE/osp/sssd/${{ matrix.ref }}.patch\n          configure: >-\n            --without-samba --without-nfsv4-idmapd-plugin --with-oidc-child=no\n            --without-manpages WOLFSSL_INSTALL_DIR=$GITHUB_WORKSPACE/build-dir\n          check: true\n\n",
    "source": "deepaksirone/wolfssl_bellerophon",
    "path": ".github/workflows/sssd.yml",
    "url": "https://github.com/deepaksirone/wolfssl_bellerophon/blob/50121495276c3c39dc5e525f07f6ebb5ae36cbc0/.github/workflows/sssd.yml",
    "retrieved_at": "2025-11-02T01:49:26.651399Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this GitHub Actions workflow for sssd?",
    "answer": "name: sssd Tests\n\n# START OF COMMON SECTION\non:\n  push:\n    branches: [ 'master', 'main', 'release/**' ]\n  pull_request:\n    branches: [ '*' ]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n# END OF COMMON SECTION\n\njobs:\n  build_wolfssl:\n    name: Build wolfSSL\n    # Just to keep it the same as the testing target\n    runs-on: ubuntu-22.04\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 4\n    steps:\n      - name: Build wolfSSL\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          path: wolfssl\n          configure: --enable-all CFLAGS=-DWOLFSSL_NO_ASN_STRICT\n          install: true\n          check: false\n\n      - name: tar build-dir\n        run: tar -zcf build-dir.tgz build-dir\n\n      - name: Upload built lib\n        uses: actions/upload-artifact@v4\n        with:\n          name: wolf-install-sssd\n          path: build-dir.tgz\n          retention-days: 5\n\n  sssd_check:\n    strategy:\n      fail-fast: false\n      matrix:\n        # List of releases to test\n        ref: [ 2.9.1 ]\n    name: ${{ matrix.ref }}\n    runs-on: ubuntu-22.04\n    container:\n      image: quay.io/sssd/ci-client-devel:ubuntu-latest\n      env:\n        LD_LIBRARY_PATH: /usr/local/lib\n    # This should be a safe limit for the tests to run.\n    timeout-minutes: 20\n    needs: build_wolfssl\n    steps:\n      - name: Install dependencies\n        run: |\n          # Don't prompt for anything\n          export DEBIAN_FRONTEND=noninteractive\n          sudo apt-get update\n          sudo apt-get install -y build-essential autoconf libldb-dev libldb2 python3-ldb bc\n\n      - name: Setup env\n        run: |\n          ln -s samba-4.0/ldb.h /usr/include/ldb.h\n          ln -s samba-4.0/ldb_errors.h /usr/include/ldb_errors.h\n          ln -s samba-4.0/ldb_handlers.h /usr/include/ldb_handlers.h\n          ln -s samba-4.0/ldb_module.h /usr/include/ldb_module.h\n          ln -s samba-4.0/ldb_version.h /usr/include/ldb_version.h\n\n      - name: Download lib\n        uses: actions/download-artifact@v4\n        with:\n          name: wolf-install-sssd\n\n      - name: untar build-dir\n        run: tar -xf build-dir.tgz\n\n      - name: Checkout OSP\n        uses: actions/checkout@v4\n        with:\n          repository: wolfssl/osp\n          path: osp\n\n      - name: Build and test sssd\n        uses: wolfSSL/actions-build-autotools-project@v1\n        with:\n          repository: SSSD/sssd\n          ref: ${{ matrix.ref }}\n          path: sssd\n          patch-file: $GITHUB_WORKSPACE/osp/sssd/${{ matrix.ref }}.patch\n          configure: >-\n            --without-samba --without-nfsv4-idmapd-plugin --with-oidc-child=no\n            --without-manpages WOLFSSL_INSTALL_DIR=$GITHUB_WORKSPACE/build-dir\n          check: true\n\n",
    "source": "deepaksirone/wolfssl_bellerophon",
    "path": ".github/workflows/sssd.yml",
    "url": "https://github.com/deepaksirone/wolfssl_bellerophon/blob/50121495276c3c39dc5e525f07f6ebb5ae36cbc0/.github/workflows/sssd.yml",
    "retrieved_at": "2025-11-02T01:49:27.357212Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML file for testing Tokio with Loom under specific conditions.",
    "answer": "on:\n  push:\n    branches: [\"master\", \"tokio-*.x\"]\n  pull_request:\n    types: [labeled, opened, synchronize, reopened]\n    branches: [\"master\", \"tokio-*.x\"]\n\nname: Loom\n\nenv:\n  RUSTFLAGS: -Dwarnings\n  RUST_BACKTRACE: 1\n  # Change to specific Rust release to pin\n  rust_stable: stable\n\npermissions:\n  contents: read\n\njobs:\n  loom:\n    name: loom\n    # base_ref is null when it's not a pull request\n    if: github.repository_owner == 'tokio-rs' && (contains(github.event.pull_request.labels.*.name, 'R-loom') || (github.base_ref == null))\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        scope:\n          - --skip loom_pool\n          - loom_pool::group_a\n          - loom_pool::group_b\n          - loom_pool::group_c\n          - loom_pool::group_d\n          - time::driver\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Rust ${{ env.rust_stable }}\n        uses: dtolnay/rust-toolchain@master\n        with:\n            toolchain: ${{ env.rust_stable }}\n      - uses: Swatinem/rust-cache@v2\n      - name: loom ${{ matrix.scope }}\n        run: cargo test --lib --release --features full -- --nocapture $SCOPE\n        working-directory: tokio\n        env:\n          RUSTFLAGS: --cfg loom --cfg tokio_unstable -Dwarnings\n          LOOM_MAX_PREEMPTIONS: 2\n          LOOM_MAX_BRANCHES: 10000\n          SCOPE: ${{ matrix.scope }}\n",
    "source": "eclipse-oniro-mirrors/third_party_rust_tokio",
    "path": ".github/workflows/loom.yml",
    "url": "https://github.com/eclipse-oniro-mirrors/third_party_rust_tokio/blob/8c5a67d345f1ce20e45cb62fc5869b3265bf5fc4/.github/workflows/loom.yml",
    "retrieved_at": "2025-11-02T01:49:28.233929Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `master` or `tokio-*.x` branches trigger this \"Loom\" workflow?",
    "answer": "on:\n  push:\n    branches: [\"master\", \"tokio-*.x\"]\n  pull_request:\n    types: [labeled, opened, synchronize, reopened]\n    branches: [\"master\", \"tokio-*.x\"]\n\nname: Loom\n\nenv:\n  RUSTFLAGS: -Dwarnings\n  RUST_BACKTRACE: 1\n  # Change to specific Rust release to pin\n  rust_stable: stable\n\npermissions:\n  contents: read\n\njobs:\n  loom:\n    name: loom\n    # base_ref is null when it's not a pull request\n    if: github.repository_owner == 'tokio-rs' && (contains(github.event.pull_request.labels.*.name, 'R-loom') || (github.base_ref == null))\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        scope:\n          - --skip loom_pool\n          - loom_pool::group_a\n          - loom_pool::group_b\n          - loom_pool::group_c\n          - loom_pool::group_d\n          - time::driver\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Rust ${{ env.rust_stable }}\n        uses: dtolnay/rust-toolchain@master\n        with:\n            toolchain: ${{ env.rust_stable }}\n      - uses: Swatinem/rust-cache@v2\n      - name: loom ${{ matrix.scope }}\n        run: cargo test --lib --release --features full -- --nocapture $SCOPE\n        working-directory: tokio\n        env:\n          RUSTFLAGS: --cfg loom --cfg tokio_unstable -Dwarnings\n          LOOM_MAX_PREEMPTIONS: 2\n          LOOM_MAX_BRANCHES: 10000\n          SCOPE: ${{ matrix.scope }}\n",
    "source": "eclipse-oniro-mirrors/third_party_rust_tokio",
    "path": ".github/workflows/loom.yml",
    "url": "https://github.com/eclipse-oniro-mirrors/third_party_rust_tokio/blob/8c5a67d345f1ce20e45cb62fc5869b3265bf5fc4/.github/workflows/loom.yml",
    "retrieved_at": "2025-11-02T01:49:28.803723Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Loom\" workflow run concurrently or have dependencies on each other?",
    "answer": "on:\n  push:\n    branches: [\"master\", \"tokio-*.x\"]\n  pull_request:\n    types: [labeled, opened, synchronize, reopened]\n    branches: [\"master\", \"tokio-*.x\"]\n\nname: Loom\n\nenv:\n  RUSTFLAGS: -Dwarnings\n  RUST_BACKTRACE: 1\n  # Change to specific Rust release to pin\n  rust_stable: stable\n\npermissions:\n  contents: read\n\njobs:\n  loom:\n    name: loom\n    # base_ref is null when it's not a pull request\n    if: github.repository_owner == 'tokio-rs' && (contains(github.event.pull_request.labels.*.name, 'R-loom') || (github.base_ref == null))\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        scope:\n          - --skip loom_pool\n          - loom_pool::group_a\n          - loom_pool::group_b\n          - loom_pool::group_c\n          - loom_pool::group_d\n          - time::driver\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Rust ${{ env.rust_stable }}\n        uses: dtolnay/rust-toolchain@master\n        with:\n            toolchain: ${{ env.rust_stable }}\n      - uses: Swatinem/rust-cache@v2\n      - name: loom ${{ matrix.scope }}\n        run: cargo test --lib --release --features full -- --nocapture $SCOPE\n        working-directory: tokio\n        env:\n          RUSTFLAGS: --cfg loom --cfg tokio_unstable -Dwarnings\n          LOOM_MAX_PREEMPTIONS: 2\n          LOOM_MAX_BRANCHES: 10000\n          SCOPE: ${{ matrix.scope }}\n",
    "source": "eclipse-oniro-mirrors/third_party_rust_tokio",
    "path": ".github/workflows/loom.yml",
    "url": "https://github.com/eclipse-oniro-mirrors/third_party_rust_tokio/blob/8c5a67d345f1ce20e45cb62fc5869b3265bf5fc4/.github/workflows/loom.yml",
    "retrieved_at": "2025-11-02T01:49:29.466059Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `RUSTFLAGS`, `LOOM_MAX_PREEMPTIONS`, and `LOOM_MAX_BRANCHES` environment variables used to configure loom testing?",
    "answer": "on:\n  push:\n    branches: [\"master\", \"tokio-*.x\"]\n  pull_request:\n    types: [labeled, opened, synchronize, reopened]\n    branches: [\"master\", \"tokio-*.x\"]\n\nname: Loom\n\nenv:\n  RUSTFLAGS: -Dwarnings\n  RUST_BACKTRACE: 1\n  # Change to specific Rust release to pin\n  rust_stable: stable\n\npermissions:\n  contents: read\n\njobs:\n  loom:\n    name: loom\n    # base_ref is null when it's not a pull request\n    if: github.repository_owner == 'tokio-rs' && (contains(github.event.pull_request.labels.*.name, 'R-loom') || (github.base_ref == null))\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        scope:\n          - --skip loom_pool\n          - loom_pool::group_a\n          - loom_pool::group_b\n          - loom_pool::group_c\n          - loom_pool::group_d\n          - time::driver\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Rust ${{ env.rust_stable }}\n        uses: dtolnay/rust-toolchain@master\n        with:\n            toolchain: ${{ env.rust_stable }}\n      - uses: Swatinem/rust-cache@v2\n      - name: loom ${{ matrix.scope }}\n        run: cargo test --lib --release --features full -- --nocapture $SCOPE\n        working-directory: tokio\n        env:\n          RUSTFLAGS: --cfg loom --cfg tokio_unstable -Dwarnings\n          LOOM_MAX_PREEMPTIONS: 2\n          LOOM_MAX_BRANCHES: 10000\n          SCOPE: ${{ matrix.scope }}\n",
    "source": "eclipse-oniro-mirrors/third_party_rust_tokio",
    "path": ".github/workflows/loom.yml",
    "url": "https://github.com/eclipse-oniro-mirrors/third_party_rust_tokio/blob/8c5a67d345f1ce20e45cb62fc5869b3265bf5fc4/.github/workflows/loom.yml",
    "retrieved_at": "2025-11-02T01:49:30.138209Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose or effect of the \"Loom\" workflow in this YAML file?",
    "answer": "on:\n  push:\n    branches: [\"master\", \"tokio-*.x\"]\n  pull_request:\n    types: [labeled, opened, synchronize, reopened]\n    branches: [\"master\", \"tokio-*.x\"]\n\nname: Loom\n\nenv:\n  RUSTFLAGS: -Dwarnings\n  RUST_BACKTRACE: 1\n  # Change to specific Rust release to pin\n  rust_stable: stable\n\npermissions:\n  contents: read\n\njobs:\n  loom:\n    name: loom\n    # base_ref is null when it's not a pull request\n    if: github.repository_owner == 'tokio-rs' && (contains(github.event.pull_request.labels.*.name, 'R-loom') || (github.base_ref == null))\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        scope:\n          - --skip loom_pool\n          - loom_pool::group_a\n          - loom_pool::group_b\n          - loom_pool::group_c\n          - loom_pool::group_d\n          - time::driver\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install Rust ${{ env.rust_stable }}\n        uses: dtolnay/rust-toolchain@master\n        with:\n            toolchain: ${{ env.rust_stable }}\n      - uses: Swatinem/rust-cache@v2\n      - name: loom ${{ matrix.scope }}\n        run: cargo test --lib --release --features full -- --nocapture $SCOPE\n        working-directory: tokio\n        env:\n          RUSTFLAGS: --cfg loom --cfg tokio_unstable -Dwarnings\n          LOOM_MAX_PREEMPTIONS: 2\n          LOOM_MAX_BRANCHES: 10000\n          SCOPE: ${{ matrix.scope }}\n",
    "source": "eclipse-oniro-mirrors/third_party_rust_tokio",
    "path": ".github/workflows/loom.yml",
    "url": "https://github.com/eclipse-oniro-mirrors/third_party_rust_tokio/blob/8c5a67d345f1ce20e45cb62fc5869b3265bf5fc4/.github/workflows/loom.yml",
    "retrieved_at": "2025-11-02T01:49:30.788194Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML workflow.",
    "answer": "name: Documentation\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: read\n\njobs:\n\n  changes:\n    permissions:\n      contents: read  # for dorny/paths-filter to fetch a list of changed files\n      pull-requests: read  # for dorny/paths-filter to read pull requests\n    runs-on: ubuntu-latest\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx')\n    outputs:\n      docs: ${{ steps.filter.outputs.docs }}\n      charts: ${{ steps.filter.outputs.charts }}\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: filter\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          filters: |\n            docs:\n             - 'docs/**/*'\n\n  docs:\n    name: Update\n    runs-on: ubuntu-latest\n    needs:\n      - changes\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx') &&\n      (needs.changes.outputs.docs == 'true')\n\n    permissions:\n      contents: write # needed to write releases\n\n    steps:\n      - name: Checkout master\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Deploy\n        uses: ./.github/actions/mkdocs\n        env:\n          PERSONAL_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\"\n",
    "source": "bajibabuindurthi/ingress",
    "path": ".github/workflows/docs.yaml",
    "url": "https://github.com/bajibabuindurthi/ingress/blob/f32b6dda0545d4e7f72d632d30106ea99a0a1147/.github/workflows/docs.yaml",
    "retrieved_at": "2025-11-03T01:49:11.142144Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Documentation\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: read\n\njobs:\n\n  changes:\n    permissions:\n      contents: read  # for dorny/paths-filter to fetch a list of changed files\n      pull-requests: read  # for dorny/paths-filter to read pull requests\n    runs-on: ubuntu-latest\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx')\n    outputs:\n      docs: ${{ steps.filter.outputs.docs }}\n      charts: ${{ steps.filter.outputs.charts }}\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: filter\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          filters: |\n            docs:\n             - 'docs/**/*'\n\n  docs:\n    name: Update\n    runs-on: ubuntu-latest\n    needs:\n      - changes\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx') &&\n      (needs.changes.outputs.docs == 'true')\n\n    permissions:\n      contents: write # needed to write releases\n\n    steps:\n      - name: Checkout master\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Deploy\n        uses: ./.github/actions/mkdocs\n        env:\n          PERSONAL_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\"\n",
    "source": "bajibabuindurthi/ingress",
    "path": ".github/workflows/docs.yaml",
    "url": "https://github.com/bajibabuindurthi/ingress/blob/f32b6dda0545d4e7f72d632d30106ea99a0a1147/.github/workflows/docs.yaml",
    "retrieved_at": "2025-11-03T01:49:11.721504Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run concurrently, and which are dependent on the completion of others?",
    "answer": "name: Documentation\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: read\n\njobs:\n\n  changes:\n    permissions:\n      contents: read  # for dorny/paths-filter to fetch a list of changed files\n      pull-requests: read  # for dorny/paths-filter to read pull requests\n    runs-on: ubuntu-latest\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx')\n    outputs:\n      docs: ${{ steps.filter.outputs.docs }}\n      charts: ${{ steps.filter.outputs.charts }}\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: filter\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          filters: |\n            docs:\n             - 'docs/**/*'\n\n  docs:\n    name: Update\n    runs-on: ubuntu-latest\n    needs:\n      - changes\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx') &&\n      (needs.changes.outputs.docs == 'true')\n\n    permissions:\n      contents: write # needed to write releases\n\n    steps:\n      - name: Checkout master\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Deploy\n        uses: ./.github/actions/mkdocs\n        env:\n          PERSONAL_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\"\n",
    "source": "bajibabuindurthi/ingress",
    "path": ".github/workflows/docs.yaml",
    "url": "https://github.com/bajibabuindurthi/ingress/blob/f32b6dda0545d4e7f72d632d30106ea99a0a1147/.github/workflows/docs.yaml",
    "retrieved_at": "2025-11-03T01:49:12.419083Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used within the `filter` step and the `mkdocs` action?",
    "answer": "name: Documentation\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: read\n\njobs:\n\n  changes:\n    permissions:\n      contents: read  # for dorny/paths-filter to fetch a list of changed files\n      pull-requests: read  # for dorny/paths-filter to read pull requests\n    runs-on: ubuntu-latest\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx')\n    outputs:\n      docs: ${{ steps.filter.outputs.docs }}\n      charts: ${{ steps.filter.outputs.charts }}\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: filter\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          filters: |\n            docs:\n             - 'docs/**/*'\n\n  docs:\n    name: Update\n    runs-on: ubuntu-latest\n    needs:\n      - changes\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx') &&\n      (needs.changes.outputs.docs == 'true')\n\n    permissions:\n      contents: write # needed to write releases\n\n    steps:\n      - name: Checkout master\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Deploy\n        uses: ./.github/actions/mkdocs\n        env:\n          PERSONAL_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\"\n",
    "source": "bajibabuindurthi/ingress",
    "path": ".github/workflows/docs.yaml",
    "url": "https://github.com/bajibabuindurthi/ingress/blob/f32b6dda0545d4e7f72d632d30106ea99a0a1147/.github/workflows/docs.yaml",
    "retrieved_at": "2025-11-03T01:49:13.090292Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this documentation workflow?",
    "answer": "name: Documentation\n\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: read\n\njobs:\n\n  changes:\n    permissions:\n      contents: read  # for dorny/paths-filter to fetch a list of changed files\n      pull-requests: read  # for dorny/paths-filter to read pull requests\n    runs-on: ubuntu-latest\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx')\n    outputs:\n      docs: ${{ steps.filter.outputs.docs }}\n      charts: ${{ steps.filter.outputs.charts }}\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3.0.2\n        id: filter\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          filters: |\n            docs:\n             - 'docs/**/*'\n\n  docs:\n    name: Update\n    runs-on: ubuntu-latest\n    needs:\n      - changes\n    if: |\n      (github.repository == 'kubernetes/ingress-nginx') &&\n      (needs.changes.outputs.docs == 'true')\n\n    permissions:\n      contents: write # needed to write releases\n\n    steps:\n      - name: Checkout master\n        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n\n      - name: Deploy\n        uses: ./.github/actions/mkdocs\n        env:\n          PERSONAL_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\"\n",
    "source": "bajibabuindurthi/ingress",
    "path": ".github/workflows/docs.yaml",
    "url": "https://github.com/bajibabuindurthi/ingress/blob/f32b6dda0545d4e7f72d632d30106ea99a0a1147/.github/workflows/docs.yaml",
    "retrieved_at": "2025-11-03T01:49:13.704933Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, which deploys an EC-CUBE application on release.",
    "answer": "name: Deploy for EC-CUBE\non:\n  release:\n    types: [ published ]\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:14\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: password\n        ports:\n          - 5432:5432\n        # needed because the postgres container does not provide a healthcheck\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@master\n\n      - name: Setup PHP\n        uses: nanasess/setup-php@master\n        with:\n          php-version: '8.1'\n\n      - name: Install to Composer\n        run: composer install --no-scripts --no-dev --no-interaction --optimize-autoloader\n\n      - name: Translate to templates\n        run: php bin/template_jp.php\n\n      - name: Setup to EC-CUBE\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n          rm -rf $GITHUB_WORKSPACE/app/Plugin/*\n          echo \"APP_ENV=${APP_ENV}\" > .env\n          bin/console doctrine:database:create --env=dev\n          bin/console doctrine:schema:create --env=dev\n          bin/console eccube:fixtures:load --env=dev\n\n      - name: Install Plugins\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n           bin/console eccube:composer:require \"ec-cube/recommend42\"\n           bin/console eccube:composer:require \"ec-cube/coupon42\"\n           bin/console eccube:composer:require \"ec-cube/mailmagazine42\"\n           bin/console eccube:composer:require \"ec-cube/salesreport42\"\n           bin/console eccube:composer:require \"ec-cube/relatedproduct42\"\n           bin/console eccube:composer:require \"ec-cube/securitychecker42\"\n           bin/console eccube:composer:require \"ec-cube/productreview42\"\n           bin/console eccube:composer:require \"ec-cube/api42\"\n           bin/console eccube:composer:require \"ec-cube/sitekit42\"\n\n      - name: revert to config platform.php\n        run: composer config platform.php 8.1.0\n\n      - name: Pre Install Plugins\n        env:\n          PGPASSWORD: 'password'\n        run: psql eccube_db -h 127.0.0.1 -U postgres -c \"select id,name,code,0 as enabled,version,source,0 as initialized,'2021-08-13 00:00:00' as create_date,'2021-08-13 00:00:00' as update_date,discriminator_type from dtb_plugin;\" -A -F, --pset footer > src/Eccube/Resource/doctrine/import_csv/ja/dtb_plugin.csv\n\n      - name: Packaging\n        working-directory: ../\n        env:\n          TAG_NAME: ${{ github.event.release.tag_name }}\n        run: ${{ github.event.repository.name }}/package.sh\n\n      - name: Upload binaries to release of TGZ\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n",
    "source": "fukuro-u/eccube",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/fukuro-u/eccube/blob/a7c7073439eea422c90ade5f23a7d5436e99480e/.github/workflows/deploy.yml",
    "retrieved_at": "2025-11-03T01:49:14.921682Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run?",
    "answer": "name: Deploy for EC-CUBE\non:\n  release:\n    types: [ published ]\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:14\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: password\n        ports:\n          - 5432:5432\n        # needed because the postgres container does not provide a healthcheck\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@master\n\n      - name: Setup PHP\n        uses: nanasess/setup-php@master\n        with:\n          php-version: '8.1'\n\n      - name: Install to Composer\n        run: composer install --no-scripts --no-dev --no-interaction --optimize-autoloader\n\n      - name: Translate to templates\n        run: php bin/template_jp.php\n\n      - name: Setup to EC-CUBE\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n          rm -rf $GITHUB_WORKSPACE/app/Plugin/*\n          echo \"APP_ENV=${APP_ENV}\" > .env\n          bin/console doctrine:database:create --env=dev\n          bin/console doctrine:schema:create --env=dev\n          bin/console eccube:fixtures:load --env=dev\n\n      - name: Install Plugins\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n           bin/console eccube:composer:require \"ec-cube/recommend42\"\n           bin/console eccube:composer:require \"ec-cube/coupon42\"\n           bin/console eccube:composer:require \"ec-cube/mailmagazine42\"\n           bin/console eccube:composer:require \"ec-cube/salesreport42\"\n           bin/console eccube:composer:require \"ec-cube/relatedproduct42\"\n           bin/console eccube:composer:require \"ec-cube/securitychecker42\"\n           bin/console eccube:composer:require \"ec-cube/productreview42\"\n           bin/console eccube:composer:require \"ec-cube/api42\"\n           bin/console eccube:composer:require \"ec-cube/sitekit42\"\n\n      - name: revert to config platform.php\n        run: composer config platform.php 8.1.0\n\n      - name: Pre Install Plugins\n        env:\n          PGPASSWORD: 'password'\n        run: psql eccube_db -h 127.0.0.1 -U postgres -c \"select id,name,code,0 as enabled,version,source,0 as initialized,'2021-08-13 00:00:00' as create_date,'2021-08-13 00:00:00' as update_date,discriminator_type from dtb_plugin;\" -A -F, --pset footer > src/Eccube/Resource/doctrine/import_csv/ja/dtb_plugin.csv\n\n      - name: Packaging\n        working-directory: ../\n        env:\n          TAG_NAME: ${{ github.event.release.tag_name }}\n        run: ${{ github.event.repository.name }}/package.sh\n\n      - name: Upload binaries to release of TGZ\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n",
    "source": "fukuro-u/eccube",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/fukuro-u/eccube/blob/a7c7073439eea422c90ade5f23a7d5436e99480e/.github/workflows/deploy.yml",
    "retrieved_at": "2025-11-03T01:49:15.570997Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Deploy' job run in parallel, and what dependencies exist between them?",
    "answer": "name: Deploy for EC-CUBE\non:\n  release:\n    types: [ published ]\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:14\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: password\n        ports:\n          - 5432:5432\n        # needed because the postgres container does not provide a healthcheck\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@master\n\n      - name: Setup PHP\n        uses: nanasess/setup-php@master\n        with:\n          php-version: '8.1'\n\n      - name: Install to Composer\n        run: composer install --no-scripts --no-dev --no-interaction --optimize-autoloader\n\n      - name: Translate to templates\n        run: php bin/template_jp.php\n\n      - name: Setup to EC-CUBE\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n          rm -rf $GITHUB_WORKSPACE/app/Plugin/*\n          echo \"APP_ENV=${APP_ENV}\" > .env\n          bin/console doctrine:database:create --env=dev\n          bin/console doctrine:schema:create --env=dev\n          bin/console eccube:fixtures:load --env=dev\n\n      - name: Install Plugins\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n           bin/console eccube:composer:require \"ec-cube/recommend42\"\n           bin/console eccube:composer:require \"ec-cube/coupon42\"\n           bin/console eccube:composer:require \"ec-cube/mailmagazine42\"\n           bin/console eccube:composer:require \"ec-cube/salesreport42\"\n           bin/console eccube:composer:require \"ec-cube/relatedproduct42\"\n           bin/console eccube:composer:require \"ec-cube/securitychecker42\"\n           bin/console eccube:composer:require \"ec-cube/productreview42\"\n           bin/console eccube:composer:require \"ec-cube/api42\"\n           bin/console eccube:composer:require \"ec-cube/sitekit42\"\n\n      - name: revert to config platform.php\n        run: composer config platform.php 8.1.0\n\n      - name: Pre Install Plugins\n        env:\n          PGPASSWORD: 'password'\n        run: psql eccube_db -h 127.0.0.1 -U postgres -c \"select id,name,code,0 as enabled,version,source,0 as initialized,'2021-08-13 00:00:00' as create_date,'2021-08-13 00:00:00' as update_date,discriminator_type from dtb_plugin;\" -A -F, --pset footer > src/Eccube/Resource/doctrine/import_csv/ja/dtb_plugin.csv\n\n      - name: Packaging\n        working-directory: ../\n        env:\n          TAG_NAME: ${{ github.event.release.tag_name }}\n        run: ${{ github.event.repository.name }}/package.sh\n\n      - name: Upload binaries to release of TGZ\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n",
    "source": "fukuro-u/eccube",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/fukuro-u/eccube/blob/a7c7073439eea422c90ade5f23a7d5436e99480e/.github/workflows/deploy.yml",
    "retrieved_at": "2025-11-03T01:49:16.460732Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to upload release assets with checksums?",
    "answer": "name: Deploy for EC-CUBE\non:\n  release:\n    types: [ published ]\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:14\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: password\n        ports:\n          - 5432:5432\n        # needed because the postgres container does not provide a healthcheck\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@master\n\n      - name: Setup PHP\n        uses: nanasess/setup-php@master\n        with:\n          php-version: '8.1'\n\n      - name: Install to Composer\n        run: composer install --no-scripts --no-dev --no-interaction --optimize-autoloader\n\n      - name: Translate to templates\n        run: php bin/template_jp.php\n\n      - name: Setup to EC-CUBE\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n          rm -rf $GITHUB_WORKSPACE/app/Plugin/*\n          echo \"APP_ENV=${APP_ENV}\" > .env\n          bin/console doctrine:database:create --env=dev\n          bin/console doctrine:schema:create --env=dev\n          bin/console eccube:fixtures:load --env=dev\n\n      - name: Install Plugins\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n           bin/console eccube:composer:require \"ec-cube/recommend42\"\n           bin/console eccube:composer:require \"ec-cube/coupon42\"\n           bin/console eccube:composer:require \"ec-cube/mailmagazine42\"\n           bin/console eccube:composer:require \"ec-cube/salesreport42\"\n           bin/console eccube:composer:require \"ec-cube/relatedproduct42\"\n           bin/console eccube:composer:require \"ec-cube/securitychecker42\"\n           bin/console eccube:composer:require \"ec-cube/productreview42\"\n           bin/console eccube:composer:require \"ec-cube/api42\"\n           bin/console eccube:composer:require \"ec-cube/sitekit42\"\n\n      - name: revert to config platform.php\n        run: composer config platform.php 8.1.0\n\n      - name: Pre Install Plugins\n        env:\n          PGPASSWORD: 'password'\n        run: psql eccube_db -h 127.0.0.1 -U postgres -c \"select id,name,code,0 as enabled,version,source,0 as initialized,'2021-08-13 00:00:00' as create_date,'2021-08-13 00:00:00' as update_date,discriminator_type from dtb_plugin;\" -A -F, --pset footer > src/Eccube/Resource/doctrine/import_csv/ja/dtb_plugin.csv\n\n      - name: Packaging\n        working-directory: ../\n        env:\n          TAG_NAME: ${{ github.event.release.tag_name }}\n        run: ${{ github.event.repository.name }}/package.sh\n\n      - name: Upload binaries to release of TGZ\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n",
    "source": "fukuro-u/eccube",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/fukuro-u/eccube/blob/a7c7073439eea422c90ade5f23a7d5436e99480e/.github/workflows/deploy.yml",
    "retrieved_at": "2025-11-03T01:49:17.300444Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this workflow triggered by an EC-CUBE release?",
    "answer": "name: Deploy for EC-CUBE\non:\n  release:\n    types: [ published ]\njobs:\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:14\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: password\n        ports:\n          - 5432:5432\n        # needed because the postgres container does not provide a healthcheck\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5\n    steps:\n      - name: Checkout\n        uses: actions/checkout@master\n\n      - name: Setup PHP\n        uses: nanasess/setup-php@master\n        with:\n          php-version: '8.1'\n\n      - name: Install to Composer\n        run: composer install --no-scripts --no-dev --no-interaction --optimize-autoloader\n\n      - name: Translate to templates\n        run: php bin/template_jp.php\n\n      - name: Setup to EC-CUBE\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n          rm -rf $GITHUB_WORKSPACE/app/Plugin/*\n          echo \"APP_ENV=${APP_ENV}\" > .env\n          bin/console doctrine:database:create --env=dev\n          bin/console doctrine:schema:create --env=dev\n          bin/console eccube:fixtures:load --env=dev\n\n      - name: Install Plugins\n        env:\n          APP_ENV: 'prod'\n          DATABASE_URL: postgres://postgres:password@127.0.0.1:5432/eccube_db\n          DATABASE_SERVER_VERSION: 14\n        run: |\n           bin/console eccube:composer:require \"ec-cube/recommend42\"\n           bin/console eccube:composer:require \"ec-cube/coupon42\"\n           bin/console eccube:composer:require \"ec-cube/mailmagazine42\"\n           bin/console eccube:composer:require \"ec-cube/salesreport42\"\n           bin/console eccube:composer:require \"ec-cube/relatedproduct42\"\n           bin/console eccube:composer:require \"ec-cube/securitychecker42\"\n           bin/console eccube:composer:require \"ec-cube/productreview42\"\n           bin/console eccube:composer:require \"ec-cube/api42\"\n           bin/console eccube:composer:require \"ec-cube/sitekit42\"\n\n      - name: revert to config platform.php\n        run: composer config platform.php 8.1.0\n\n      - name: Pre Install Plugins\n        env:\n          PGPASSWORD: 'password'\n        run: psql eccube_db -h 127.0.0.1 -U postgres -c \"select id,name,code,0 as enabled,version,source,0 as initialized,'2021-08-13 00:00:00' as create_date,'2021-08-13 00:00:00' as update_date,discriminator_type from dtb_plugin;\" -A -F, --pset footer > src/Eccube/Resource/doctrine/import_csv/ja/dtb_plugin.csv\n\n      - name: Packaging\n        working-directory: ../\n        env:\n          TAG_NAME: ${{ github.event.release.tag_name }}\n        run: ${{ github.event.repository.name }}/package.sh\n\n      - name: Upload binaries to release of TGZ\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of TGZ sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.tar.gz.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP md5 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.md5\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha1 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha1\n          tag: ${{ github.ref }}\n          overwrite: true\n      - name: Upload binaries to release of ZIP sha256 checksum\n        uses: svenstaro/upload-release-action@2.9.0\n        with:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n          file: ${{ runner.workspace }}/eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          asset_name: eccube-${{ github.event.release.tag_name }}.zip.checksum.sha256\n          tag: ${{ github.ref }}\n          overwrite: true\n",
    "source": "fukuro-u/eccube",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/fukuro-u/eccube/blob/a7c7073439eea422c90ade5f23a7d5436e99480e/.github/workflows/deploy.yml",
    "retrieved_at": "2025-11-03T01:49:18.154433Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"develop\", \"develop-4\", \"release/0.10.x\", \"release/2.1.x\", \"release/2.2.x\", \"release/2.3.x\", \"release/2.4.x\", \"release/3.0.x\", \"release/3.1.x\", \"release/3.2.x\", \"release/3.3.x\", \"release/3.4.x\", \"release/3.5.x\", \"release/3.6.x\", \"release/3.7.x\", \"release/3.8.x\", \"release/3.9.x\", \"release/3.10.x\", \"release/3.11.x\", \"release/4.0.x\", \"release/4.0.0.x\", \"release/4.0.1.x\", \"release/4.1.x\" ]\n  pull_request:\n    branches: [ \"develop\" ]\n  schedule:\n    - cron: \"40 4 * * 6\"\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ python, javascript ]\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@v3\n        with:\n          languages: ${{ matrix.language }}\n          queries: +security-and-quality\n\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@v3\n        if: ${{ matrix.language == 'python' || matrix.language == 'javascript' }}\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@v3\n        with:\n          category: \"/language:${{ matrix.language }}\"\n",
    "source": "Adam-dev-coder/django-cms",
    "path": ".github/workflows/codeql.yml",
    "url": "https://github.com/Adam-dev-coder/django-cms/blob/fc0fee90b1e9b6db35e10d6fc4b3a7ee8d6f609e/.github/workflows/codeql.yml",
    "retrieved_at": "2025-11-04T01:45:01.206291Z",
    "question_style": "style_1"
  },
  {
    "question": "Which jobs or steps within the \"CodeQL\" workflow run in parallel, and which depend on others?",
    "answer": "name: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"develop\", \"develop-4\", \"release/0.10.x\", \"release/2.1.x\", \"release/2.2.x\", \"release/2.3.x\", \"release/2.4.x\", \"release/3.0.x\", \"release/3.1.x\", \"release/3.2.x\", \"release/3.3.x\", \"release/3.4.x\", \"release/3.5.x\", \"release/3.6.x\", \"release/3.7.x\", \"release/3.8.x\", \"release/3.9.x\", \"release/3.10.x\", \"release/3.11.x\", \"release/4.0.x\", \"release/4.0.0.x\", \"release/4.0.1.x\", \"release/4.1.x\" ]\n  pull_request:\n    branches: [ \"develop\" ]\n  schedule:\n    - cron: \"40 4 * * 6\"\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ python, javascript ]\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@v3\n        with:\n          languages: ${{ matrix.language }}\n          queries: +security-and-quality\n\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@v3\n        if: ${{ matrix.language == 'python' || matrix.language == 'javascript' }}\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@v3\n        with:\n          category: \"/language:${{ matrix.language }}\"\n",
    "source": "Adam-dev-coder/django-cms",
    "path": ".github/workflows/codeql.yml",
    "url": "https://github.com/Adam-dev-coder/django-cms/blob/fc0fee90b1e9b6db35e10d6fc4b3a7ee8d6f609e/.github/workflows/codeql.yml",
    "retrieved_at": "2025-11-04T01:45:02.299112Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching mechanisms?",
    "answer": "name: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"develop\", \"develop-4\", \"release/0.10.x\", \"release/2.1.x\", \"release/2.2.x\", \"release/2.3.x\", \"release/2.4.x\", \"release/3.0.x\", \"release/3.1.x\", \"release/3.2.x\", \"release/3.3.x\", \"release/3.4.x\", \"release/3.5.x\", \"release/3.6.x\", \"release/3.7.x\", \"release/3.8.x\", \"release/3.9.x\", \"release/3.10.x\", \"release/3.11.x\", \"release/4.0.x\", \"release/4.0.0.x\", \"release/4.0.1.x\", \"release/4.1.x\" ]\n  pull_request:\n    branches: [ \"develop\" ]\n  schedule:\n    - cron: \"40 4 * * 6\"\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ python, javascript ]\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@v3\n        with:\n          languages: ${{ matrix.language }}\n          queries: +security-and-quality\n\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@v3\n        if: ${{ matrix.language == 'python' || matrix.language == 'javascript' }}\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@v3\n        with:\n          category: \"/language:${{ matrix.language }}\"\n",
    "source": "Adam-dev-coder/django-cms",
    "path": ".github/workflows/codeql.yml",
    "url": "https://github.com/Adam-dev-coder/django-cms/blob/fc0fee90b1e9b6db35e10d6fc4b3a7ee8d6f609e/.github/workflows/codeql.yml",
    "retrieved_at": "2025-11-04T01:45:02.920712Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this CodeQL workflow?",
    "answer": "name: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"develop\", \"develop-4\", \"release/0.10.x\", \"release/2.1.x\", \"release/2.2.x\", \"release/2.3.x\", \"release/2.4.x\", \"release/3.0.x\", \"release/3.1.x\", \"release/3.2.x\", \"release/3.3.x\", \"release/3.4.x\", \"release/3.5.x\", \"release/3.6.x\", \"release/3.7.x\", \"release/3.8.x\", \"release/3.9.x\", \"release/3.10.x\", \"release/3.11.x\", \"release/4.0.x\", \"release/4.0.0.x\", \"release/4.0.1.x\", \"release/4.1.x\" ]\n  pull_request:\n    branches: [ \"develop\" ]\n  schedule:\n    - cron: \"40 4 * * 6\"\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ python, javascript ]\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@v3\n        with:\n          languages: ${{ matrix.language }}\n          queries: +security-and-quality\n\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@v3\n        if: ${{ matrix.language == 'python' || matrix.language == 'javascript' }}\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@v3\n        with:\n          category: \"/language:${{ matrix.language }}\"\n",
    "source": "Adam-dev-coder/django-cms",
    "path": ".github/workflows/codeql.yml",
    "url": "https://github.com/Adam-dev-coder/django-cms/blob/fc0fee90b1e9b6db35e10d6fc4b3a7ee8d6f609e/.github/workflows/codeql.yml",
    "retrieved_at": "2025-11-04T01:45:03.631566Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for linting a PyTorch repository.",
    "answer": "name: Lint\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  quick-checks:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: pip3 install -r requirements.txt --user\n      - name: Ensure consistent CircleCI YAML config\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: cd .circleci && ./ensure-consistency.py\n      - name: Lint native_functions.yaml\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          pip3 install ruamel.yaml==0.17.4 --user\n          .github/scripts/lint_native_functions.py\n      - name: Ensure correct trailing newlines\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          (! git --no-pager grep -Il '' -- . ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude)**.expect' ':(exclude)**.ipynb' ':(exclude)tools/clang_format_hash' | tools/linter/trailing_newlines.py || (echo \"The above files do not have correct trailing newlines; please normalize them\"; false))\n      - name: Ensure no trailing spaces\n        if: always()\n        run: |\n          (! git --no-pager grep -In '[[:blank:]]$' -- . ':(exclude)**/contrib/**' ':(exclude)**.diff' ':(exclude)third_party' || (echo \"The above lines have trailing spaces; please remove them\"; false))\n      - name: Ensure no tabs\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'\\t' -- . ':(exclude)*.svg' ':(exclude)**Makefile' ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude).gitattributes' ':(exclude).gitmodules' || (echo \"The above lines have tabs; please convert them to spaces\"; false))\n      - name: Ensure no non-breaking spaces\n        if: always()\n        run: |\n          # NB: We use 'printf' below rather than '\\u000a' since bash pre-4.2\n          # does not support the '\\u000a' syntax (which is relevant for local linters)\n          (! git --no-pager grep -In \"$(printf '\\xC2\\xA0')\" -- . || (echo \"The above lines have non-breaking spaces (U+00A0); please convert them to spaces (U+0020)\"; false))\n      - name: Ensure canonical include\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'#include \"' -- ./c10 ./aten ./torch/csrc ':(exclude)aten/src/ATen/native/quantized/cpu/qnnpack/**' || (echo \"The above lines have include with quotes; please convert them to #include <xxxx>\"; false))\n      - name: Ensure no versionless Python shebangs\n        if: always()\n        run: |\n          (! git --no-pager grep -In '#!.*python$' -- . || (echo \"The above lines have versionless Python shebangs; please specify either python2 or python3\"; false))\n      - name: Ensure no unqualified noqa\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# noqa(?!: [A-Z]+\\d{3})' -- '**.py' '**.pyi' ':(exclude)caffe2' || (echo 'The above lines have unqualified `noqa`; please convert them to `noqa: XXXX`'; false))\n      - name: Ensure no unqualified type ignore\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# type:\\s*ignore(?!\\[)' -- '**.py' '**.pyi' ':(exclude)test/test_jit.py' || (echo 'The above lines have unqualified `type: ignore`; please convert them to `type: ignore[xxxx]`'; false))\n      - name: Ensure GitHub PyPi dependencies are pinned\n        if: always()\n        run: |\n          (! git --no-pager grep --color=always -InP \\\n                '(pip|pip3|python -m pip|python3 -m pip|python3 -mpip|python -mpip) install ([a-z][\\.a-z-0-9]*+(?!(=|.*\\.whl))([[:blank:]]|))+' \\\n                -- .github \\\n                ':(exclude)**.rst' \\\n                ':(exclude)**.py' \\\n                ':(exclude)**.md' \\\n                ':(exclude)**.diff' \\\n                ':(exclude)third_party' ||\n            (echo \"The above lines have unpinned PyPi installs; please pin them to a specific version: e.g. 'thepackage==1.2'\"; false))\n      # note that this next step depends on a clean checkout;\n      # if you run it locally then it will likely to complain\n      # about all the generated files in torch/test\n      - name: Ensure C++ source files are not executable\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! find . \\( -path ./third_party -o -path ./.git -o -path ./torch/bin -o -path ./build \\) -prune -o -type f -executable -regextype posix-egrep -not -regex '.+(\\.(bash|sh|py|so)|git-pre-commit|git-clang-format|gradlew)$' -print | grep . || (echo 'The above files have executable permission; please remove their executable permission by using `chmod -x`'; false))\n      - name: C++ docs check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          sudo apt-get install -y doxygen\n          cd docs/cpp/source && ./check-doxygen.sh\n      - name: CUDA kernel launch check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          set -eux\n          python torch/testing/_check_kernel_launches.py |& tee \"${GITHUB_WORKSPACE}\"/cuda_kernel_launch_checks.txt\n      - name: Ensure no direct cub include\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'#include <cub/' --  ./aten  ':(exclude)aten/src/ATen/cuda/cub.cuh' || (echo \"The above files have direct cub include; please include ATen/cuda/cub.cuh instead and wrap your cub calls in at::native namespace if necessary\"; false))\n      - name: Ensure no raw cuda api calls\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'cudaStreamSynchronize' --  ./aten ./c10 ':(exclude)aten/src/ATen/test' ':(exclude)c10/cuda/CUDAFunctions.h' || (echo \"The above files call raw cuda APIs directly; please use at::cuda wrappers instead\"; false))\n\n  clang-format:\n    runs-on: ubuntu-18.04\n    if: ${{ github.event_name == 'pull_request' }}\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # deep clone, to allow us to use git merge-base\n      - name: Run clang-format\n        env:\n          BASE_SHA: ${{ github.event.pull_request.base.sha }}\n        run: |\n          set -eu\n          # This is necessary to get the same results regardless of whether the\n          # PR was opened directly or from a forked repo. See: `9f890a92` for more info.\n          git remote add upstream https://github.com/pytorch/pytorch\n          git fetch upstream \"$GITHUB_BASE_REF\"\n\n          # only run clang-format on allowlisted files\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n          echo \"| clang-format failures found! Run: \"\n          echo \"|    tools/linter/clang_format_ci.sh ${BASE_SHA} \"\n          echo \"| to fix this error. \"\n          echo \"| For more info, see: https://github.com/pytorch/pytorch/wiki/clang-format \"\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\n          tools/linter/clang_format_ci.sh \"${BASE_SHA}\"\n\n          GIT_DIFF=$(git diff)\n          if [[ -z $GIT_DIFF ]]; then\n            exit 0\n          fi\n          echo \"$GIT_DIFF\"\n          exit 1\n\n  py2-setup-validate-errormsg:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 2.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Attempt to run setup.py\n        run: |\n          if ! python2 setup.py | grep -q \"Python 2 has reached end-of-life and is no longer supported by PyTorch.\"; then\n            echo 'Running setup.py with Python 2 did not give the expected error message.'\n            false\n          fi\n      - name: Keep torch.utils.collect_env python2 compliant\n        run: python2 -m py_compile torch/utils/collect_env.py\n\n  shellcheck:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: |\n          pip3 install -r requirements.txt --user\n      - name: Install Jinja2\n        run: |\n          pip3 install Jinja2==3.0.1 --user\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Regenerate workflows\n        id: generate_workflows\n        run: .github/scripts/generate_ci_workflows.py\n      - name: Assert that regenerating the workflows didn't change them\n        run: |\n          if ! .github/scripts/report_git_status.sh .github/workflows; then\n            echo\n            echo 'As shown by the above diff, the committed .github/workflows'\n            echo 'are not up to date according to .github/templates.'\n            echo 'Please run this command, commit, and push again to your PR:'\n            echo\n            echo '    .github/scripts/generate_ci_workflows.py'\n            echo\n            echo 'If running that command does nothing, you may need to rebase'\n            echo 'onto a more recent commit from the PyTorch master branch.'\n            false\n          fi\n      - name: Install ShellCheck\n        id: install_shellcheck\n        if: always()\n        # https://github.com/koalaman/shellcheck/tree/v0.7.2#installing-a-pre-compiled-binary\n        run: |\n          set -x\n          scversion=\"v0.7.2\"\n          wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv\n          mkdir -p ~/.local/bin\n          cp \"shellcheck-${scversion}/shellcheck\" ~/.local/bin/\n          rm -r \"shellcheck-${scversion}\"\n          ~/.local/bin/shellcheck --version\n      - name: Extract scripts from GitHub Actions workflows\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          # For local lints, remove the .extracted_scripts folder if it was already there\n          rm -rf .extracted_scripts\n          tools/extract_scripts.py --out=.extracted_scripts\n      - name: Run ShellCheck\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          if ! tools/linter/run_shellcheck.sh .extracted_scripts .jenkins/pytorch; then\n            echo\n            echo 'ShellCheck gave a nonzero exit code. Please fix the warnings'\n            echo 'listed above. Note that if a path in one of the above warning'\n            echo 'messages starts with .extracted_scripts/ then that means it'\n            echo 'is referring to a shell script embedded within another file,'\n            echo 'whose path is given by the path components immediately'\n            echo 'following the .extracted_scripts/ prefix.'\n            false\n          fi\n      - name: Check that jobs will be cancelled\n        if: ${{ always() && steps.generate_workflows.outcome == 'success' }}\n        run: |\n          .github/scripts/ensure_actions_will_cancel.py\n      - name: Run actionlint\n        shell: bash\n        run: |\n          set -eux\n          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)\n          ./actionlint --color\n          rm actionlint\n\n  toc:\n    runs-on: ubuntu-18.04\n    # https://github.com/actions/virtual-environments/issues/599#issuecomment-602754687\n    env:\n      NPM_CONFIG_PREFIX: ~/.npm-global\n    steps:\n      - name: Setup Node\n        uses: actions/setup-node@v2\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install markdown-toc\n        run: npm install -g markdown-toc\n      - name: Regenerate ToCs and check that they didn't change\n        run: |\n          set -eu\n          export PATH=~/.npm-global/bin:\"$PATH\"\n          for FILE in $(git grep -Il '<!-- toc -->' -- '**.md'); do\n            markdown-toc --bullets='-' -i \"$FILE\"\n          done\n\n          if ! .github/scripts/report_git_status.sh .; then\n            echo\n            echo 'As shown by the above diff, the table of contents in one or'\n            echo 'more Markdown files is not up to date with the file contents.'\n            echo 'You can either apply that Git diff directly to correct the'\n            echo 'table of contents, or if you have npm installed, you can'\n            echo 'install the npm package markdown-toc and run the following'\n            # shellcheck disable=SC2016\n            echo 'command (replacing $FILE with the filename for which you want'\n            echo 'to regenerate the table of contents):'\n            echo\n            # shellcheck disable=SC2016\n            echo \"    markdown-toc --bullets='-' -i \\\"\\$FILE\\\"\"\n            false\n          fi\n\n  flake8-py3:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 2 # to allow us to use github.event.pull_request.head.sha\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          mkdir flake8-output\n          cd flake8-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install typing-extensions==3.10 --user # for tools/linter/translate_annotations.py\n          pip3 install -r requirements-flake8.txt --user\n          flake8 --version\n      - name: Run flake8\n        run: |\n          set -eux\n          flake8 | tee \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n      - name: Translate annotations\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          tools/linter/translate_annotations.py \\\n            --file=\"${GITHUB_WORKSPACE}\"/flake8-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorCode>\\w+\\d+) (?P<errorDesc>.*)' \\\n            --commit=\"$HEAD_SHA\" \\\n            > flake8-output/annotations.json\n      - name: Fail if there were any warnings\n        run: |\n          set -eu\n          # Re-output flake8 status so GitHub logs show it on the step that actually failed\n          cat \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n          if [ -s \"${GITHUB_WORKSPACE}\"/flake8-output.txt ]; then\n            echo 'Please fix the above Flake8 warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'flake8-py3'\n          linter_output_path: flake8-output/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  clang-tidy:\n    runs-on: linux.2xlarge\n    container:\n      # ubuntu20.04-cuda11.2-py3.8-tidy11\n      image: ghcr.io/pytorch/cilint-clang-tidy:d8f0c777964d0dd8a147360de80aed1a13eb613a\n    steps:\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # to allow tools/linter/clang_tidy.py to do its thing\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          mkdir clang-tidy-output\n          cd clang-tidy-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Fetch PR diff\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          wget -O pr.diff \"https://patch-diff.githubusercontent.com/raw/pytorch/pytorch/pull/$PR_NUMBER.diff\"\n      - name: Generate build files\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          python3 -m tools.linter.clang_tidy.generate_build_files\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'pull_request' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          # The Docker image has our custom build, so we don't need to install it\n          python3 -m tools.linter.clang_tidy \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --diff-file pr.diff \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      # Run clang-tidy on a smaller subset of the codebase on master until we\n      # make the repository clang-tidy clean\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/master' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          python3 -m tools.linter.clang_tidy \\\n            --paths \\\n              torch/csrc/fx \\\n              torch/csrc/utils \\\n              torch/csrc/generic \\\n              torch/csrc/deploy \\\n              torch/csrc/tensor \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      - name: Annotate output\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          sed --in-place 's/^\\.\\.\\///g' clang-tidy-output.txt\n          tools/linter/translate_annotations.py \\\n            --file=clang-tidy-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorDesc>.*?) \\[(?P<errorCode>.*)\\]' \\\n            --commit=\"$HEAD_SHA\" \\\n            > clang-tidy-output/annotations.json\n      - name: Check for warnings\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          set -eu\n          cat \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n          if grep -Fq \"Warnings detected!\" \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt; then\n            echo 'Please fix the above clang-tidy warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'clang-tidy'\n          linter_output_path: clang-tidy/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  cmakelint:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install cmakelint==1.4.1 --user\n          cmakelint --version\n      - name: Run cmakelint\n        run: |\n          set -eux\n          git ls-files -z -- bootstrap '*.cmake' '*.cmake.in' '*CMakeLists.txt' | \\\n          grep -E -z -v '^(cmake/Modules/|cmake/Modules_CUDA_fix/|cmake/Caffe2Config.cmake.in|aten/src/ATen/ATenConfig.cmake.in|cmake/Caffe2ConfigVersion.cmake.in|cmake/TorchConfig.cmake.in|cmake/TorchConfigVersion.cmake.in|cmake/cmake_uninstall.cmake.in)' | \\\n          xargs -0 cmakelint --config=.cmakelintrc --spaces=2 --quiet\n\n  mypy:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.8\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install -r requirements.txt --user\n          pip3 install numpy==1.20 --user # https://github.com/pytorch/pytorch/pull/60472\n          pip3 install expecttest==0.1.3 mypy==0.812 --user\n          # Needed to check tools/render_junit.py\n          pip3 install junitparser==2.1.1 rich==10.9.0 --user\n      - name: Run autogen\n        run: |\n          set -eux\n          time python -mtools.generate_torch_version --is_debug=false\n          time python -mtools.codegen.gen -s aten/src/ATen -d build/aten/src/ATen\n          time python -mtools.pyi.gen_pyi --native-functions-path aten/src/ATen/native/native_functions.yaml --deprecated-functions-path \"tools/autograd/deprecated.yaml\"\n      - name: Run mypy\n        env:\n          MYPY_FORCE_COLOR: 1\n          TERM: xterm-color\n        run: |\n          set -eux\n          STATUS=\n          for CONFIG in mypy*.ini; do\n            if ! mypy --config=\"$CONFIG\"; then\n              STATUS=fail\n            fi\n          done\n          if [ -n \"$STATUS\" ]; then\n            echo 'Please fix the above mypy warnings.'\n            false\n          fi\n\nconcurrency:\n  group: lint-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n",
    "source": "arjun-raj-kuppala/pytorchtest",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/arjun-raj-kuppala/pytorchtest/blob/17a66520ff6034cbb9476e6c5538e8b0296b94a9/.github/workflows/lint.yml",
    "retrieved_at": "2025-11-04T01:45:16.695314Z",
    "question_style": "style_1"
  },
  {
    "question": "What events, such as pushes to the master branch or pull requests, trigger this workflow?",
    "answer": "name: Lint\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  quick-checks:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: pip3 install -r requirements.txt --user\n      - name: Ensure consistent CircleCI YAML config\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: cd .circleci && ./ensure-consistency.py\n      - name: Lint native_functions.yaml\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          pip3 install ruamel.yaml==0.17.4 --user\n          .github/scripts/lint_native_functions.py\n      - name: Ensure correct trailing newlines\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          (! git --no-pager grep -Il '' -- . ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude)**.expect' ':(exclude)**.ipynb' ':(exclude)tools/clang_format_hash' | tools/linter/trailing_newlines.py || (echo \"The above files do not have correct trailing newlines; please normalize them\"; false))\n      - name: Ensure no trailing spaces\n        if: always()\n        run: |\n          (! git --no-pager grep -In '[[:blank:]]$' -- . ':(exclude)**/contrib/**' ':(exclude)**.diff' ':(exclude)third_party' || (echo \"The above lines have trailing spaces; please remove them\"; false))\n      - name: Ensure no tabs\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'\\t' -- . ':(exclude)*.svg' ':(exclude)**Makefile' ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude).gitattributes' ':(exclude).gitmodules' || (echo \"The above lines have tabs; please convert them to spaces\"; false))\n      - name: Ensure no non-breaking spaces\n        if: always()\n        run: |\n          # NB: We use 'printf' below rather than '\\u000a' since bash pre-4.2\n          # does not support the '\\u000a' syntax (which is relevant for local linters)\n          (! git --no-pager grep -In \"$(printf '\\xC2\\xA0')\" -- . || (echo \"The above lines have non-breaking spaces (U+00A0); please convert them to spaces (U+0020)\"; false))\n      - name: Ensure canonical include\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'#include \"' -- ./c10 ./aten ./torch/csrc ':(exclude)aten/src/ATen/native/quantized/cpu/qnnpack/**' || (echo \"The above lines have include with quotes; please convert them to #include <xxxx>\"; false))\n      - name: Ensure no versionless Python shebangs\n        if: always()\n        run: |\n          (! git --no-pager grep -In '#!.*python$' -- . || (echo \"The above lines have versionless Python shebangs; please specify either python2 or python3\"; false))\n      - name: Ensure no unqualified noqa\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# noqa(?!: [A-Z]+\\d{3})' -- '**.py' '**.pyi' ':(exclude)caffe2' || (echo 'The above lines have unqualified `noqa`; please convert them to `noqa: XXXX`'; false))\n      - name: Ensure no unqualified type ignore\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# type:\\s*ignore(?!\\[)' -- '**.py' '**.pyi' ':(exclude)test/test_jit.py' || (echo 'The above lines have unqualified `type: ignore`; please convert them to `type: ignore[xxxx]`'; false))\n      - name: Ensure GitHub PyPi dependencies are pinned\n        if: always()\n        run: |\n          (! git --no-pager grep --color=always -InP \\\n                '(pip|pip3|python -m pip|python3 -m pip|python3 -mpip|python -mpip) install ([a-z][\\.a-z-0-9]*+(?!(=|.*\\.whl))([[:blank:]]|))+' \\\n                -- .github \\\n                ':(exclude)**.rst' \\\n                ':(exclude)**.py' \\\n                ':(exclude)**.md' \\\n                ':(exclude)**.diff' \\\n                ':(exclude)third_party' ||\n            (echo \"The above lines have unpinned PyPi installs; please pin them to a specific version: e.g. 'thepackage==1.2'\"; false))\n      # note that this next step depends on a clean checkout;\n      # if you run it locally then it will likely to complain\n      # about all the generated files in torch/test\n      - name: Ensure C++ source files are not executable\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! find . \\( -path ./third_party -o -path ./.git -o -path ./torch/bin -o -path ./build \\) -prune -o -type f -executable -regextype posix-egrep -not -regex '.+(\\.(bash|sh|py|so)|git-pre-commit|git-clang-format|gradlew)$' -print | grep . || (echo 'The above files have executable permission; please remove their executable permission by using `chmod -x`'; false))\n      - name: C++ docs check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          sudo apt-get install -y doxygen\n          cd docs/cpp/source && ./check-doxygen.sh\n      - name: CUDA kernel launch check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          set -eux\n          python torch/testing/_check_kernel_launches.py |& tee \"${GITHUB_WORKSPACE}\"/cuda_kernel_launch_checks.txt\n      - name: Ensure no direct cub include\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'#include <cub/' --  ./aten  ':(exclude)aten/src/ATen/cuda/cub.cuh' || (echo \"The above files have direct cub include; please include ATen/cuda/cub.cuh instead and wrap your cub calls in at::native namespace if necessary\"; false))\n      - name: Ensure no raw cuda api calls\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'cudaStreamSynchronize' --  ./aten ./c10 ':(exclude)aten/src/ATen/test' ':(exclude)c10/cuda/CUDAFunctions.h' || (echo \"The above files call raw cuda APIs directly; please use at::cuda wrappers instead\"; false))\n\n  clang-format:\n    runs-on: ubuntu-18.04\n    if: ${{ github.event_name == 'pull_request' }}\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # deep clone, to allow us to use git merge-base\n      - name: Run clang-format\n        env:\n          BASE_SHA: ${{ github.event.pull_request.base.sha }}\n        run: |\n          set -eu\n          # This is necessary to get the same results regardless of whether the\n          # PR was opened directly or from a forked repo. See: `9f890a92` for more info.\n          git remote add upstream https://github.com/pytorch/pytorch\n          git fetch upstream \"$GITHUB_BASE_REF\"\n\n          # only run clang-format on allowlisted files\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n          echo \"| clang-format failures found! Run: \"\n          echo \"|    tools/linter/clang_format_ci.sh ${BASE_SHA} \"\n          echo \"| to fix this error. \"\n          echo \"| For more info, see: https://github.com/pytorch/pytorch/wiki/clang-format \"\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\n          tools/linter/clang_format_ci.sh \"${BASE_SHA}\"\n\n          GIT_DIFF=$(git diff)\n          if [[ -z $GIT_DIFF ]]; then\n            exit 0\n          fi\n          echo \"$GIT_DIFF\"\n          exit 1\n\n  py2-setup-validate-errormsg:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 2.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Attempt to run setup.py\n        run: |\n          if ! python2 setup.py | grep -q \"Python 2 has reached end-of-life and is no longer supported by PyTorch.\"; then\n            echo 'Running setup.py with Python 2 did not give the expected error message.'\n            false\n          fi\n      - name: Keep torch.utils.collect_env python2 compliant\n        run: python2 -m py_compile torch/utils/collect_env.py\n\n  shellcheck:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: |\n          pip3 install -r requirements.txt --user\n      - name: Install Jinja2\n        run: |\n          pip3 install Jinja2==3.0.1 --user\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Regenerate workflows\n        id: generate_workflows\n        run: .github/scripts/generate_ci_workflows.py\n      - name: Assert that regenerating the workflows didn't change them\n        run: |\n          if ! .github/scripts/report_git_status.sh .github/workflows; then\n            echo\n            echo 'As shown by the above diff, the committed .github/workflows'\n            echo 'are not up to date according to .github/templates.'\n            echo 'Please run this command, commit, and push again to your PR:'\n            echo\n            echo '    .github/scripts/generate_ci_workflows.py'\n            echo\n            echo 'If running that command does nothing, you may need to rebase'\n            echo 'onto a more recent commit from the PyTorch master branch.'\n            false\n          fi\n      - name: Install ShellCheck\n        id: install_shellcheck\n        if: always()\n        # https://github.com/koalaman/shellcheck/tree/v0.7.2#installing-a-pre-compiled-binary\n        run: |\n          set -x\n          scversion=\"v0.7.2\"\n          wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv\n          mkdir -p ~/.local/bin\n          cp \"shellcheck-${scversion}/shellcheck\" ~/.local/bin/\n          rm -r \"shellcheck-${scversion}\"\n          ~/.local/bin/shellcheck --version\n      - name: Extract scripts from GitHub Actions workflows\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          # For local lints, remove the .extracted_scripts folder if it was already there\n          rm -rf .extracted_scripts\n          tools/extract_scripts.py --out=.extracted_scripts\n      - name: Run ShellCheck\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          if ! tools/linter/run_shellcheck.sh .extracted_scripts .jenkins/pytorch; then\n            echo\n            echo 'ShellCheck gave a nonzero exit code. Please fix the warnings'\n            echo 'listed above. Note that if a path in one of the above warning'\n            echo 'messages starts with .extracted_scripts/ then that means it'\n            echo 'is referring to a shell script embedded within another file,'\n            echo 'whose path is given by the path components immediately'\n            echo 'following the .extracted_scripts/ prefix.'\n            false\n          fi\n      - name: Check that jobs will be cancelled\n        if: ${{ always() && steps.generate_workflows.outcome == 'success' }}\n        run: |\n          .github/scripts/ensure_actions_will_cancel.py\n      - name: Run actionlint\n        shell: bash\n        run: |\n          set -eux\n          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)\n          ./actionlint --color\n          rm actionlint\n\n  toc:\n    runs-on: ubuntu-18.04\n    # https://github.com/actions/virtual-environments/issues/599#issuecomment-602754687\n    env:\n      NPM_CONFIG_PREFIX: ~/.npm-global\n    steps:\n      - name: Setup Node\n        uses: actions/setup-node@v2\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install markdown-toc\n        run: npm install -g markdown-toc\n      - name: Regenerate ToCs and check that they didn't change\n        run: |\n          set -eu\n          export PATH=~/.npm-global/bin:\"$PATH\"\n          for FILE in $(git grep -Il '<!-- toc -->' -- '**.md'); do\n            markdown-toc --bullets='-' -i \"$FILE\"\n          done\n\n          if ! .github/scripts/report_git_status.sh .; then\n            echo\n            echo 'As shown by the above diff, the table of contents in one or'\n            echo 'more Markdown files is not up to date with the file contents.'\n            echo 'You can either apply that Git diff directly to correct the'\n            echo 'table of contents, or if you have npm installed, you can'\n            echo 'install the npm package markdown-toc and run the following'\n            # shellcheck disable=SC2016\n            echo 'command (replacing $FILE with the filename for which you want'\n            echo 'to regenerate the table of contents):'\n            echo\n            # shellcheck disable=SC2016\n            echo \"    markdown-toc --bullets='-' -i \\\"\\$FILE\\\"\"\n            false\n          fi\n\n  flake8-py3:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 2 # to allow us to use github.event.pull_request.head.sha\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          mkdir flake8-output\n          cd flake8-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install typing-extensions==3.10 --user # for tools/linter/translate_annotations.py\n          pip3 install -r requirements-flake8.txt --user\n          flake8 --version\n      - name: Run flake8\n        run: |\n          set -eux\n          flake8 | tee \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n      - name: Translate annotations\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          tools/linter/translate_annotations.py \\\n            --file=\"${GITHUB_WORKSPACE}\"/flake8-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorCode>\\w+\\d+) (?P<errorDesc>.*)' \\\n            --commit=\"$HEAD_SHA\" \\\n            > flake8-output/annotations.json\n      - name: Fail if there were any warnings\n        run: |\n          set -eu\n          # Re-output flake8 status so GitHub logs show it on the step that actually failed\n          cat \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n          if [ -s \"${GITHUB_WORKSPACE}\"/flake8-output.txt ]; then\n            echo 'Please fix the above Flake8 warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'flake8-py3'\n          linter_output_path: flake8-output/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  clang-tidy:\n    runs-on: linux.2xlarge\n    container:\n      # ubuntu20.04-cuda11.2-py3.8-tidy11\n      image: ghcr.io/pytorch/cilint-clang-tidy:d8f0c777964d0dd8a147360de80aed1a13eb613a\n    steps:\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # to allow tools/linter/clang_tidy.py to do its thing\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          mkdir clang-tidy-output\n          cd clang-tidy-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Fetch PR diff\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          wget -O pr.diff \"https://patch-diff.githubusercontent.com/raw/pytorch/pytorch/pull/$PR_NUMBER.diff\"\n      - name: Generate build files\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          python3 -m tools.linter.clang_tidy.generate_build_files\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'pull_request' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          # The Docker image has our custom build, so we don't need to install it\n          python3 -m tools.linter.clang_tidy \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --diff-file pr.diff \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      # Run clang-tidy on a smaller subset of the codebase on master until we\n      # make the repository clang-tidy clean\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/master' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          python3 -m tools.linter.clang_tidy \\\n            --paths \\\n              torch/csrc/fx \\\n              torch/csrc/utils \\\n              torch/csrc/generic \\\n              torch/csrc/deploy \\\n              torch/csrc/tensor \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      - name: Annotate output\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          sed --in-place 's/^\\.\\.\\///g' clang-tidy-output.txt\n          tools/linter/translate_annotations.py \\\n            --file=clang-tidy-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorDesc>.*?) \\[(?P<errorCode>.*)\\]' \\\n            --commit=\"$HEAD_SHA\" \\\n            > clang-tidy-output/annotations.json\n      - name: Check for warnings\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          set -eu\n          cat \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n          if grep -Fq \"Warnings detected!\" \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt; then\n            echo 'Please fix the above clang-tidy warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'clang-tidy'\n          linter_output_path: clang-tidy/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  cmakelint:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install cmakelint==1.4.1 --user\n          cmakelint --version\n      - name: Run cmakelint\n        run: |\n          set -eux\n          git ls-files -z -- bootstrap '*.cmake' '*.cmake.in' '*CMakeLists.txt' | \\\n          grep -E -z -v '^(cmake/Modules/|cmake/Modules_CUDA_fix/|cmake/Caffe2Config.cmake.in|aten/src/ATen/ATenConfig.cmake.in|cmake/Caffe2ConfigVersion.cmake.in|cmake/TorchConfig.cmake.in|cmake/TorchConfigVersion.cmake.in|cmake/cmake_uninstall.cmake.in)' | \\\n          xargs -0 cmakelint --config=.cmakelintrc --spaces=2 --quiet\n\n  mypy:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.8\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install -r requirements.txt --user\n          pip3 install numpy==1.20 --user # https://github.com/pytorch/pytorch/pull/60472\n          pip3 install expecttest==0.1.3 mypy==0.812 --user\n          # Needed to check tools/render_junit.py\n          pip3 install junitparser==2.1.1 rich==10.9.0 --user\n      - name: Run autogen\n        run: |\n          set -eux\n          time python -mtools.generate_torch_version --is_debug=false\n          time python -mtools.codegen.gen -s aten/src/ATen -d build/aten/src/ATen\n          time python -mtools.pyi.gen_pyi --native-functions-path aten/src/ATen/native/native_functions.yaml --deprecated-functions-path \"tools/autograd/deprecated.yaml\"\n      - name: Run mypy\n        env:\n          MYPY_FORCE_COLOR: 1\n          TERM: xterm-color\n        run: |\n          set -eux\n          STATUS=\n          for CONFIG in mypy*.ini; do\n            if ! mypy --config=\"$CONFIG\"; then\n              STATUS=fail\n            fi\n          done\n          if [ -n \"$STATUS\" ]; then\n            echo 'Please fix the above mypy warnings.'\n            false\n          fi\n\nconcurrency:\n  group: lint-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n",
    "source": "arjun-raj-kuppala/pytorchtest",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/arjun-raj-kuppala/pytorchtest/blob/17a66520ff6034cbb9476e6c5538e8b0296b94a9/.github/workflows/lint.yml",
    "retrieved_at": "2025-11-04T01:45:17.738140Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: Lint\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  quick-checks:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: pip3 install -r requirements.txt --user\n      - name: Ensure consistent CircleCI YAML config\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: cd .circleci && ./ensure-consistency.py\n      - name: Lint native_functions.yaml\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          pip3 install ruamel.yaml==0.17.4 --user\n          .github/scripts/lint_native_functions.py\n      - name: Ensure correct trailing newlines\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          (! git --no-pager grep -Il '' -- . ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude)**.expect' ':(exclude)**.ipynb' ':(exclude)tools/clang_format_hash' | tools/linter/trailing_newlines.py || (echo \"The above files do not have correct trailing newlines; please normalize them\"; false))\n      - name: Ensure no trailing spaces\n        if: always()\n        run: |\n          (! git --no-pager grep -In '[[:blank:]]$' -- . ':(exclude)**/contrib/**' ':(exclude)**.diff' ':(exclude)third_party' || (echo \"The above lines have trailing spaces; please remove them\"; false))\n      - name: Ensure no tabs\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'\\t' -- . ':(exclude)*.svg' ':(exclude)**Makefile' ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude).gitattributes' ':(exclude).gitmodules' || (echo \"The above lines have tabs; please convert them to spaces\"; false))\n      - name: Ensure no non-breaking spaces\n        if: always()\n        run: |\n          # NB: We use 'printf' below rather than '\\u000a' since bash pre-4.2\n          # does not support the '\\u000a' syntax (which is relevant for local linters)\n          (! git --no-pager grep -In \"$(printf '\\xC2\\xA0')\" -- . || (echo \"The above lines have non-breaking spaces (U+00A0); please convert them to spaces (U+0020)\"; false))\n      - name: Ensure canonical include\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'#include \"' -- ./c10 ./aten ./torch/csrc ':(exclude)aten/src/ATen/native/quantized/cpu/qnnpack/**' || (echo \"The above lines have include with quotes; please convert them to #include <xxxx>\"; false))\n      - name: Ensure no versionless Python shebangs\n        if: always()\n        run: |\n          (! git --no-pager grep -In '#!.*python$' -- . || (echo \"The above lines have versionless Python shebangs; please specify either python2 or python3\"; false))\n      - name: Ensure no unqualified noqa\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# noqa(?!: [A-Z]+\\d{3})' -- '**.py' '**.pyi' ':(exclude)caffe2' || (echo 'The above lines have unqualified `noqa`; please convert them to `noqa: XXXX`'; false))\n      - name: Ensure no unqualified type ignore\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# type:\\s*ignore(?!\\[)' -- '**.py' '**.pyi' ':(exclude)test/test_jit.py' || (echo 'The above lines have unqualified `type: ignore`; please convert them to `type: ignore[xxxx]`'; false))\n      - name: Ensure GitHub PyPi dependencies are pinned\n        if: always()\n        run: |\n          (! git --no-pager grep --color=always -InP \\\n                '(pip|pip3|python -m pip|python3 -m pip|python3 -mpip|python -mpip) install ([a-z][\\.a-z-0-9]*+(?!(=|.*\\.whl))([[:blank:]]|))+' \\\n                -- .github \\\n                ':(exclude)**.rst' \\\n                ':(exclude)**.py' \\\n                ':(exclude)**.md' \\\n                ':(exclude)**.diff' \\\n                ':(exclude)third_party' ||\n            (echo \"The above lines have unpinned PyPi installs; please pin them to a specific version: e.g. 'thepackage==1.2'\"; false))\n      # note that this next step depends on a clean checkout;\n      # if you run it locally then it will likely to complain\n      # about all the generated files in torch/test\n      - name: Ensure C++ source files are not executable\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! find . \\( -path ./third_party -o -path ./.git -o -path ./torch/bin -o -path ./build \\) -prune -o -type f -executable -regextype posix-egrep -not -regex '.+(\\.(bash|sh|py|so)|git-pre-commit|git-clang-format|gradlew)$' -print | grep . || (echo 'The above files have executable permission; please remove their executable permission by using `chmod -x`'; false))\n      - name: C++ docs check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          sudo apt-get install -y doxygen\n          cd docs/cpp/source && ./check-doxygen.sh\n      - name: CUDA kernel launch check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          set -eux\n          python torch/testing/_check_kernel_launches.py |& tee \"${GITHUB_WORKSPACE}\"/cuda_kernel_launch_checks.txt\n      - name: Ensure no direct cub include\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'#include <cub/' --  ./aten  ':(exclude)aten/src/ATen/cuda/cub.cuh' || (echo \"The above files have direct cub include; please include ATen/cuda/cub.cuh instead and wrap your cub calls in at::native namespace if necessary\"; false))\n      - name: Ensure no raw cuda api calls\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'cudaStreamSynchronize' --  ./aten ./c10 ':(exclude)aten/src/ATen/test' ':(exclude)c10/cuda/CUDAFunctions.h' || (echo \"The above files call raw cuda APIs directly; please use at::cuda wrappers instead\"; false))\n\n  clang-format:\n    runs-on: ubuntu-18.04\n    if: ${{ github.event_name == 'pull_request' }}\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # deep clone, to allow us to use git merge-base\n      - name: Run clang-format\n        env:\n          BASE_SHA: ${{ github.event.pull_request.base.sha }}\n        run: |\n          set -eu\n          # This is necessary to get the same results regardless of whether the\n          # PR was opened directly or from a forked repo. See: `9f890a92` for more info.\n          git remote add upstream https://github.com/pytorch/pytorch\n          git fetch upstream \"$GITHUB_BASE_REF\"\n\n          # only run clang-format on allowlisted files\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n          echo \"| clang-format failures found! Run: \"\n          echo \"|    tools/linter/clang_format_ci.sh ${BASE_SHA} \"\n          echo \"| to fix this error. \"\n          echo \"| For more info, see: https://github.com/pytorch/pytorch/wiki/clang-format \"\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\n          tools/linter/clang_format_ci.sh \"${BASE_SHA}\"\n\n          GIT_DIFF=$(git diff)\n          if [[ -z $GIT_DIFF ]]; then\n            exit 0\n          fi\n          echo \"$GIT_DIFF\"\n          exit 1\n\n  py2-setup-validate-errormsg:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 2.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Attempt to run setup.py\n        run: |\n          if ! python2 setup.py | grep -q \"Python 2 has reached end-of-life and is no longer supported by PyTorch.\"; then\n            echo 'Running setup.py with Python 2 did not give the expected error message.'\n            false\n          fi\n      - name: Keep torch.utils.collect_env python2 compliant\n        run: python2 -m py_compile torch/utils/collect_env.py\n\n  shellcheck:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: |\n          pip3 install -r requirements.txt --user\n      - name: Install Jinja2\n        run: |\n          pip3 install Jinja2==3.0.1 --user\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Regenerate workflows\n        id: generate_workflows\n        run: .github/scripts/generate_ci_workflows.py\n      - name: Assert that regenerating the workflows didn't change them\n        run: |\n          if ! .github/scripts/report_git_status.sh .github/workflows; then\n            echo\n            echo 'As shown by the above diff, the committed .github/workflows'\n            echo 'are not up to date according to .github/templates.'\n            echo 'Please run this command, commit, and push again to your PR:'\n            echo\n            echo '    .github/scripts/generate_ci_workflows.py'\n            echo\n            echo 'If running that command does nothing, you may need to rebase'\n            echo 'onto a more recent commit from the PyTorch master branch.'\n            false\n          fi\n      - name: Install ShellCheck\n        id: install_shellcheck\n        if: always()\n        # https://github.com/koalaman/shellcheck/tree/v0.7.2#installing-a-pre-compiled-binary\n        run: |\n          set -x\n          scversion=\"v0.7.2\"\n          wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv\n          mkdir -p ~/.local/bin\n          cp \"shellcheck-${scversion}/shellcheck\" ~/.local/bin/\n          rm -r \"shellcheck-${scversion}\"\n          ~/.local/bin/shellcheck --version\n      - name: Extract scripts from GitHub Actions workflows\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          # For local lints, remove the .extracted_scripts folder if it was already there\n          rm -rf .extracted_scripts\n          tools/extract_scripts.py --out=.extracted_scripts\n      - name: Run ShellCheck\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          if ! tools/linter/run_shellcheck.sh .extracted_scripts .jenkins/pytorch; then\n            echo\n            echo 'ShellCheck gave a nonzero exit code. Please fix the warnings'\n            echo 'listed above. Note that if a path in one of the above warning'\n            echo 'messages starts with .extracted_scripts/ then that means it'\n            echo 'is referring to a shell script embedded within another file,'\n            echo 'whose path is given by the path components immediately'\n            echo 'following the .extracted_scripts/ prefix.'\n            false\n          fi\n      - name: Check that jobs will be cancelled\n        if: ${{ always() && steps.generate_workflows.outcome == 'success' }}\n        run: |\n          .github/scripts/ensure_actions_will_cancel.py\n      - name: Run actionlint\n        shell: bash\n        run: |\n          set -eux\n          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)\n          ./actionlint --color\n          rm actionlint\n\n  toc:\n    runs-on: ubuntu-18.04\n    # https://github.com/actions/virtual-environments/issues/599#issuecomment-602754687\n    env:\n      NPM_CONFIG_PREFIX: ~/.npm-global\n    steps:\n      - name: Setup Node\n        uses: actions/setup-node@v2\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install markdown-toc\n        run: npm install -g markdown-toc\n      - name: Regenerate ToCs and check that they didn't change\n        run: |\n          set -eu\n          export PATH=~/.npm-global/bin:\"$PATH\"\n          for FILE in $(git grep -Il '<!-- toc -->' -- '**.md'); do\n            markdown-toc --bullets='-' -i \"$FILE\"\n          done\n\n          if ! .github/scripts/report_git_status.sh .; then\n            echo\n            echo 'As shown by the above diff, the table of contents in one or'\n            echo 'more Markdown files is not up to date with the file contents.'\n            echo 'You can either apply that Git diff directly to correct the'\n            echo 'table of contents, or if you have npm installed, you can'\n            echo 'install the npm package markdown-toc and run the following'\n            # shellcheck disable=SC2016\n            echo 'command (replacing $FILE with the filename for which you want'\n            echo 'to regenerate the table of contents):'\n            echo\n            # shellcheck disable=SC2016\n            echo \"    markdown-toc --bullets='-' -i \\\"\\$FILE\\\"\"\n            false\n          fi\n\n  flake8-py3:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 2 # to allow us to use github.event.pull_request.head.sha\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          mkdir flake8-output\n          cd flake8-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install typing-extensions==3.10 --user # for tools/linter/translate_annotations.py\n          pip3 install -r requirements-flake8.txt --user\n          flake8 --version\n      - name: Run flake8\n        run: |\n          set -eux\n          flake8 | tee \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n      - name: Translate annotations\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          tools/linter/translate_annotations.py \\\n            --file=\"${GITHUB_WORKSPACE}\"/flake8-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorCode>\\w+\\d+) (?P<errorDesc>.*)' \\\n            --commit=\"$HEAD_SHA\" \\\n            > flake8-output/annotations.json\n      - name: Fail if there were any warnings\n        run: |\n          set -eu\n          # Re-output flake8 status so GitHub logs show it on the step that actually failed\n          cat \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n          if [ -s \"${GITHUB_WORKSPACE}\"/flake8-output.txt ]; then\n            echo 'Please fix the above Flake8 warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'flake8-py3'\n          linter_output_path: flake8-output/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  clang-tidy:\n    runs-on: linux.2xlarge\n    container:\n      # ubuntu20.04-cuda11.2-py3.8-tidy11\n      image: ghcr.io/pytorch/cilint-clang-tidy:d8f0c777964d0dd8a147360de80aed1a13eb613a\n    steps:\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # to allow tools/linter/clang_tidy.py to do its thing\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          mkdir clang-tidy-output\n          cd clang-tidy-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Fetch PR diff\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          wget -O pr.diff \"https://patch-diff.githubusercontent.com/raw/pytorch/pytorch/pull/$PR_NUMBER.diff\"\n      - name: Generate build files\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          python3 -m tools.linter.clang_tidy.generate_build_files\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'pull_request' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          # The Docker image has our custom build, so we don't need to install it\n          python3 -m tools.linter.clang_tidy \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --diff-file pr.diff \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      # Run clang-tidy on a smaller subset of the codebase on master until we\n      # make the repository clang-tidy clean\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/master' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          python3 -m tools.linter.clang_tidy \\\n            --paths \\\n              torch/csrc/fx \\\n              torch/csrc/utils \\\n              torch/csrc/generic \\\n              torch/csrc/deploy \\\n              torch/csrc/tensor \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      - name: Annotate output\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          sed --in-place 's/^\\.\\.\\///g' clang-tidy-output.txt\n          tools/linter/translate_annotations.py \\\n            --file=clang-tidy-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorDesc>.*?) \\[(?P<errorCode>.*)\\]' \\\n            --commit=\"$HEAD_SHA\" \\\n            > clang-tidy-output/annotations.json\n      - name: Check for warnings\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          set -eu\n          cat \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n          if grep -Fq \"Warnings detected!\" \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt; then\n            echo 'Please fix the above clang-tidy warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'clang-tidy'\n          linter_output_path: clang-tidy/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  cmakelint:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install cmakelint==1.4.1 --user\n          cmakelint --version\n      - name: Run cmakelint\n        run: |\n          set -eux\n          git ls-files -z -- bootstrap '*.cmake' '*.cmake.in' '*CMakeLists.txt' | \\\n          grep -E -z -v '^(cmake/Modules/|cmake/Modules_CUDA_fix/|cmake/Caffe2Config.cmake.in|aten/src/ATen/ATenConfig.cmake.in|cmake/Caffe2ConfigVersion.cmake.in|cmake/TorchConfig.cmake.in|cmake/TorchConfigVersion.cmake.in|cmake/cmake_uninstall.cmake.in)' | \\\n          xargs -0 cmakelint --config=.cmakelintrc --spaces=2 --quiet\n\n  mypy:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.8\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install -r requirements.txt --user\n          pip3 install numpy==1.20 --user # https://github.com/pytorch/pytorch/pull/60472\n          pip3 install expecttest==0.1.3 mypy==0.812 --user\n          # Needed to check tools/render_junit.py\n          pip3 install junitparser==2.1.1 rich==10.9.0 --user\n      - name: Run autogen\n        run: |\n          set -eux\n          time python -mtools.generate_torch_version --is_debug=false\n          time python -mtools.codegen.gen -s aten/src/ATen -d build/aten/src/ATen\n          time python -mtools.pyi.gen_pyi --native-functions-path aten/src/ATen/native/native_functions.yaml --deprecated-functions-path \"tools/autograd/deprecated.yaml\"\n      - name: Run mypy\n        env:\n          MYPY_FORCE_COLOR: 1\n          TERM: xterm-color\n        run: |\n          set -eux\n          STATUS=\n          for CONFIG in mypy*.ini; do\n            if ! mypy --config=\"$CONFIG\"; then\n              STATUS=fail\n            fi\n          done\n          if [ -n \"$STATUS\" ]; then\n            echo 'Please fix the above mypy warnings.'\n            false\n          fi\n\nconcurrency:\n  group: lint-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n",
    "source": "arjun-raj-kuppala/pytorchtest",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/arjun-raj-kuppala/pytorchtest/blob/17a66520ff6034cbb9476e6c5538e8b0296b94a9/.github/workflows/lint.yml",
    "retrieved_at": "2025-11-04T01:45:18.756476Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used by the `pytorch/add-annotations-github-action` action in the flake8-py3 and clang-tidy jobs?",
    "answer": "name: Lint\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  quick-checks:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: pip3 install -r requirements.txt --user\n      - name: Ensure consistent CircleCI YAML config\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: cd .circleci && ./ensure-consistency.py\n      - name: Lint native_functions.yaml\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          pip3 install ruamel.yaml==0.17.4 --user\n          .github/scripts/lint_native_functions.py\n      - name: Ensure correct trailing newlines\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          (! git --no-pager grep -Il '' -- . ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude)**.expect' ':(exclude)**.ipynb' ':(exclude)tools/clang_format_hash' | tools/linter/trailing_newlines.py || (echo \"The above files do not have correct trailing newlines; please normalize them\"; false))\n      - name: Ensure no trailing spaces\n        if: always()\n        run: |\n          (! git --no-pager grep -In '[[:blank:]]$' -- . ':(exclude)**/contrib/**' ':(exclude)**.diff' ':(exclude)third_party' || (echo \"The above lines have trailing spaces; please remove them\"; false))\n      - name: Ensure no tabs\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'\\t' -- . ':(exclude)*.svg' ':(exclude)**Makefile' ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude).gitattributes' ':(exclude).gitmodules' || (echo \"The above lines have tabs; please convert them to spaces\"; false))\n      - name: Ensure no non-breaking spaces\n        if: always()\n        run: |\n          # NB: We use 'printf' below rather than '\\u000a' since bash pre-4.2\n          # does not support the '\\u000a' syntax (which is relevant for local linters)\n          (! git --no-pager grep -In \"$(printf '\\xC2\\xA0')\" -- . || (echo \"The above lines have non-breaking spaces (U+00A0); please convert them to spaces (U+0020)\"; false))\n      - name: Ensure canonical include\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'#include \"' -- ./c10 ./aten ./torch/csrc ':(exclude)aten/src/ATen/native/quantized/cpu/qnnpack/**' || (echo \"The above lines have include with quotes; please convert them to #include <xxxx>\"; false))\n      - name: Ensure no versionless Python shebangs\n        if: always()\n        run: |\n          (! git --no-pager grep -In '#!.*python$' -- . || (echo \"The above lines have versionless Python shebangs; please specify either python2 or python3\"; false))\n      - name: Ensure no unqualified noqa\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# noqa(?!: [A-Z]+\\d{3})' -- '**.py' '**.pyi' ':(exclude)caffe2' || (echo 'The above lines have unqualified `noqa`; please convert them to `noqa: XXXX`'; false))\n      - name: Ensure no unqualified type ignore\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# type:\\s*ignore(?!\\[)' -- '**.py' '**.pyi' ':(exclude)test/test_jit.py' || (echo 'The above lines have unqualified `type: ignore`; please convert them to `type: ignore[xxxx]`'; false))\n      - name: Ensure GitHub PyPi dependencies are pinned\n        if: always()\n        run: |\n          (! git --no-pager grep --color=always -InP \\\n                '(pip|pip3|python -m pip|python3 -m pip|python3 -mpip|python -mpip) install ([a-z][\\.a-z-0-9]*+(?!(=|.*\\.whl))([[:blank:]]|))+' \\\n                -- .github \\\n                ':(exclude)**.rst' \\\n                ':(exclude)**.py' \\\n                ':(exclude)**.md' \\\n                ':(exclude)**.diff' \\\n                ':(exclude)third_party' ||\n            (echo \"The above lines have unpinned PyPi installs; please pin them to a specific version: e.g. 'thepackage==1.2'\"; false))\n      # note that this next step depends on a clean checkout;\n      # if you run it locally then it will likely to complain\n      # about all the generated files in torch/test\n      - name: Ensure C++ source files are not executable\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! find . \\( -path ./third_party -o -path ./.git -o -path ./torch/bin -o -path ./build \\) -prune -o -type f -executable -regextype posix-egrep -not -regex '.+(\\.(bash|sh|py|so)|git-pre-commit|git-clang-format|gradlew)$' -print | grep . || (echo 'The above files have executable permission; please remove their executable permission by using `chmod -x`'; false))\n      - name: C++ docs check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          sudo apt-get install -y doxygen\n          cd docs/cpp/source && ./check-doxygen.sh\n      - name: CUDA kernel launch check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          set -eux\n          python torch/testing/_check_kernel_launches.py |& tee \"${GITHUB_WORKSPACE}\"/cuda_kernel_launch_checks.txt\n      - name: Ensure no direct cub include\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'#include <cub/' --  ./aten  ':(exclude)aten/src/ATen/cuda/cub.cuh' || (echo \"The above files have direct cub include; please include ATen/cuda/cub.cuh instead and wrap your cub calls in at::native namespace if necessary\"; false))\n      - name: Ensure no raw cuda api calls\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'cudaStreamSynchronize' --  ./aten ./c10 ':(exclude)aten/src/ATen/test' ':(exclude)c10/cuda/CUDAFunctions.h' || (echo \"The above files call raw cuda APIs directly; please use at::cuda wrappers instead\"; false))\n\n  clang-format:\n    runs-on: ubuntu-18.04\n    if: ${{ github.event_name == 'pull_request' }}\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # deep clone, to allow us to use git merge-base\n      - name: Run clang-format\n        env:\n          BASE_SHA: ${{ github.event.pull_request.base.sha }}\n        run: |\n          set -eu\n          # This is necessary to get the same results regardless of whether the\n          # PR was opened directly or from a forked repo. See: `9f890a92` for more info.\n          git remote add upstream https://github.com/pytorch/pytorch\n          git fetch upstream \"$GITHUB_BASE_REF\"\n\n          # only run clang-format on allowlisted files\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n          echo \"| clang-format failures found! Run: \"\n          echo \"|    tools/linter/clang_format_ci.sh ${BASE_SHA} \"\n          echo \"| to fix this error. \"\n          echo \"| For more info, see: https://github.com/pytorch/pytorch/wiki/clang-format \"\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\n          tools/linter/clang_format_ci.sh \"${BASE_SHA}\"\n\n          GIT_DIFF=$(git diff)\n          if [[ -z $GIT_DIFF ]]; then\n            exit 0\n          fi\n          echo \"$GIT_DIFF\"\n          exit 1\n\n  py2-setup-validate-errormsg:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 2.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Attempt to run setup.py\n        run: |\n          if ! python2 setup.py | grep -q \"Python 2 has reached end-of-life and is no longer supported by PyTorch.\"; then\n            echo 'Running setup.py with Python 2 did not give the expected error message.'\n            false\n          fi\n      - name: Keep torch.utils.collect_env python2 compliant\n        run: python2 -m py_compile torch/utils/collect_env.py\n\n  shellcheck:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: |\n          pip3 install -r requirements.txt --user\n      - name: Install Jinja2\n        run: |\n          pip3 install Jinja2==3.0.1 --user\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Regenerate workflows\n        id: generate_workflows\n        run: .github/scripts/generate_ci_workflows.py\n      - name: Assert that regenerating the workflows didn't change them\n        run: |\n          if ! .github/scripts/report_git_status.sh .github/workflows; then\n            echo\n            echo 'As shown by the above diff, the committed .github/workflows'\n            echo 'are not up to date according to .github/templates.'\n            echo 'Please run this command, commit, and push again to your PR:'\n            echo\n            echo '    .github/scripts/generate_ci_workflows.py'\n            echo\n            echo 'If running that command does nothing, you may need to rebase'\n            echo 'onto a more recent commit from the PyTorch master branch.'\n            false\n          fi\n      - name: Install ShellCheck\n        id: install_shellcheck\n        if: always()\n        # https://github.com/koalaman/shellcheck/tree/v0.7.2#installing-a-pre-compiled-binary\n        run: |\n          set -x\n          scversion=\"v0.7.2\"\n          wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv\n          mkdir -p ~/.local/bin\n          cp \"shellcheck-${scversion}/shellcheck\" ~/.local/bin/\n          rm -r \"shellcheck-${scversion}\"\n          ~/.local/bin/shellcheck --version\n      - name: Extract scripts from GitHub Actions workflows\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          # For local lints, remove the .extracted_scripts folder if it was already there\n          rm -rf .extracted_scripts\n          tools/extract_scripts.py --out=.extracted_scripts\n      - name: Run ShellCheck\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          if ! tools/linter/run_shellcheck.sh .extracted_scripts .jenkins/pytorch; then\n            echo\n            echo 'ShellCheck gave a nonzero exit code. Please fix the warnings'\n            echo 'listed above. Note that if a path in one of the above warning'\n            echo 'messages starts with .extracted_scripts/ then that means it'\n            echo 'is referring to a shell script embedded within another file,'\n            echo 'whose path is given by the path components immediately'\n            echo 'following the .extracted_scripts/ prefix.'\n            false\n          fi\n      - name: Check that jobs will be cancelled\n        if: ${{ always() && steps.generate_workflows.outcome == 'success' }}\n        run: |\n          .github/scripts/ensure_actions_will_cancel.py\n      - name: Run actionlint\n        shell: bash\n        run: |\n          set -eux\n          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)\n          ./actionlint --color\n          rm actionlint\n\n  toc:\n    runs-on: ubuntu-18.04\n    # https://github.com/actions/virtual-environments/issues/599#issuecomment-602754687\n    env:\n      NPM_CONFIG_PREFIX: ~/.npm-global\n    steps:\n      - name: Setup Node\n        uses: actions/setup-node@v2\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install markdown-toc\n        run: npm install -g markdown-toc\n      - name: Regenerate ToCs and check that they didn't change\n        run: |\n          set -eu\n          export PATH=~/.npm-global/bin:\"$PATH\"\n          for FILE in $(git grep -Il '<!-- toc -->' -- '**.md'); do\n            markdown-toc --bullets='-' -i \"$FILE\"\n          done\n\n          if ! .github/scripts/report_git_status.sh .; then\n            echo\n            echo 'As shown by the above diff, the table of contents in one or'\n            echo 'more Markdown files is not up to date with the file contents.'\n            echo 'You can either apply that Git diff directly to correct the'\n            echo 'table of contents, or if you have npm installed, you can'\n            echo 'install the npm package markdown-toc and run the following'\n            # shellcheck disable=SC2016\n            echo 'command (replacing $FILE with the filename for which you want'\n            echo 'to regenerate the table of contents):'\n            echo\n            # shellcheck disable=SC2016\n            echo \"    markdown-toc --bullets='-' -i \\\"\\$FILE\\\"\"\n            false\n          fi\n\n  flake8-py3:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 2 # to allow us to use github.event.pull_request.head.sha\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          mkdir flake8-output\n          cd flake8-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install typing-extensions==3.10 --user # for tools/linter/translate_annotations.py\n          pip3 install -r requirements-flake8.txt --user\n          flake8 --version\n      - name: Run flake8\n        run: |\n          set -eux\n          flake8 | tee \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n      - name: Translate annotations\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          tools/linter/translate_annotations.py \\\n            --file=\"${GITHUB_WORKSPACE}\"/flake8-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorCode>\\w+\\d+) (?P<errorDesc>.*)' \\\n            --commit=\"$HEAD_SHA\" \\\n            > flake8-output/annotations.json\n      - name: Fail if there were any warnings\n        run: |\n          set -eu\n          # Re-output flake8 status so GitHub logs show it on the step that actually failed\n          cat \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n          if [ -s \"${GITHUB_WORKSPACE}\"/flake8-output.txt ]; then\n            echo 'Please fix the above Flake8 warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'flake8-py3'\n          linter_output_path: flake8-output/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  clang-tidy:\n    runs-on: linux.2xlarge\n    container:\n      # ubuntu20.04-cuda11.2-py3.8-tidy11\n      image: ghcr.io/pytorch/cilint-clang-tidy:d8f0c777964d0dd8a147360de80aed1a13eb613a\n    steps:\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # to allow tools/linter/clang_tidy.py to do its thing\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          mkdir clang-tidy-output\n          cd clang-tidy-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Fetch PR diff\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          wget -O pr.diff \"https://patch-diff.githubusercontent.com/raw/pytorch/pytorch/pull/$PR_NUMBER.diff\"\n      - name: Generate build files\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          python3 -m tools.linter.clang_tidy.generate_build_files\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'pull_request' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          # The Docker image has our custom build, so we don't need to install it\n          python3 -m tools.linter.clang_tidy \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --diff-file pr.diff \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      # Run clang-tidy on a smaller subset of the codebase on master until we\n      # make the repository clang-tidy clean\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/master' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          python3 -m tools.linter.clang_tidy \\\n            --paths \\\n              torch/csrc/fx \\\n              torch/csrc/utils \\\n              torch/csrc/generic \\\n              torch/csrc/deploy \\\n              torch/csrc/tensor \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      - name: Annotate output\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          sed --in-place 's/^\\.\\.\\///g' clang-tidy-output.txt\n          tools/linter/translate_annotations.py \\\n            --file=clang-tidy-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorDesc>.*?) \\[(?P<errorCode>.*)\\]' \\\n            --commit=\"$HEAD_SHA\" \\\n            > clang-tidy-output/annotations.json\n      - name: Check for warnings\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          set -eu\n          cat \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n          if grep -Fq \"Warnings detected!\" \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt; then\n            echo 'Please fix the above clang-tidy warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'clang-tidy'\n          linter_output_path: clang-tidy/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  cmakelint:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install cmakelint==1.4.1 --user\n          cmakelint --version\n      - name: Run cmakelint\n        run: |\n          set -eux\n          git ls-files -z -- bootstrap '*.cmake' '*.cmake.in' '*CMakeLists.txt' | \\\n          grep -E -z -v '^(cmake/Modules/|cmake/Modules_CUDA_fix/|cmake/Caffe2Config.cmake.in|aten/src/ATen/ATenConfig.cmake.in|cmake/Caffe2ConfigVersion.cmake.in|cmake/TorchConfig.cmake.in|cmake/TorchConfigVersion.cmake.in|cmake/cmake_uninstall.cmake.in)' | \\\n          xargs -0 cmakelint --config=.cmakelintrc --spaces=2 --quiet\n\n  mypy:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.8\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install -r requirements.txt --user\n          pip3 install numpy==1.20 --user # https://github.com/pytorch/pytorch/pull/60472\n          pip3 install expecttest==0.1.3 mypy==0.812 --user\n          # Needed to check tools/render_junit.py\n          pip3 install junitparser==2.1.1 rich==10.9.0 --user\n      - name: Run autogen\n        run: |\n          set -eux\n          time python -mtools.generate_torch_version --is_debug=false\n          time python -mtools.codegen.gen -s aten/src/ATen -d build/aten/src/ATen\n          time python -mtools.pyi.gen_pyi --native-functions-path aten/src/ATen/native/native_functions.yaml --deprecated-functions-path \"tools/autograd/deprecated.yaml\"\n      - name: Run mypy\n        env:\n          MYPY_FORCE_COLOR: 1\n          TERM: xterm-color\n        run: |\n          set -eux\n          STATUS=\n          for CONFIG in mypy*.ini; do\n            if ! mypy --config=\"$CONFIG\"; then\n              STATUS=fail\n            fi\n          done\n          if [ -n \"$STATUS\" ]; then\n            echo 'Please fix the above mypy warnings.'\n            false\n          fi\n\nconcurrency:\n  group: lint-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n",
    "source": "arjun-raj-kuppala/pytorchtest",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/arjun-raj-kuppala/pytorchtest/blob/17a66520ff6034cbb9476e6c5538e8b0296b94a9/.github/workflows/lint.yml",
    "retrieved_at": "2025-11-04T01:45:19.923796Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow file, focusing on linting and code quality checks for the PyTorch project?",
    "answer": "name: Lint\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  quick-checks:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: pip3 install -r requirements.txt --user\n      - name: Ensure consistent CircleCI YAML config\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: cd .circleci && ./ensure-consistency.py\n      - name: Lint native_functions.yaml\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          pip3 install ruamel.yaml==0.17.4 --user\n          .github/scripts/lint_native_functions.py\n      - name: Ensure correct trailing newlines\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          (! git --no-pager grep -Il '' -- . ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude)**.expect' ':(exclude)**.ipynb' ':(exclude)tools/clang_format_hash' | tools/linter/trailing_newlines.py || (echo \"The above files do not have correct trailing newlines; please normalize them\"; false))\n      - name: Ensure no trailing spaces\n        if: always()\n        run: |\n          (! git --no-pager grep -In '[[:blank:]]$' -- . ':(exclude)**/contrib/**' ':(exclude)**.diff' ':(exclude)third_party' || (echo \"The above lines have trailing spaces; please remove them\"; false))\n      - name: Ensure no tabs\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'\\t' -- . ':(exclude)*.svg' ':(exclude)**Makefile' ':(exclude)**/contrib/**' ':(exclude)third_party' ':(exclude).gitattributes' ':(exclude).gitmodules' || (echo \"The above lines have tabs; please convert them to spaces\"; false))\n      - name: Ensure no non-breaking spaces\n        if: always()\n        run: |\n          # NB: We use 'printf' below rather than '\\u000a' since bash pre-4.2\n          # does not support the '\\u000a' syntax (which is relevant for local linters)\n          (! git --no-pager grep -In \"$(printf '\\xC2\\xA0')\" -- . || (echo \"The above lines have non-breaking spaces (U+00A0); please convert them to spaces (U+0020)\"; false))\n      - name: Ensure canonical include\n        if: always()\n        run: |\n          (! git --no-pager grep -In $'#include \"' -- ./c10 ./aten ./torch/csrc ':(exclude)aten/src/ATen/native/quantized/cpu/qnnpack/**' || (echo \"The above lines have include with quotes; please convert them to #include <xxxx>\"; false))\n      - name: Ensure no versionless Python shebangs\n        if: always()\n        run: |\n          (! git --no-pager grep -In '#!.*python$' -- . || (echo \"The above lines have versionless Python shebangs; please specify either python2 or python3\"; false))\n      - name: Ensure no unqualified noqa\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# noqa(?!: [A-Z]+\\d{3})' -- '**.py' '**.pyi' ':(exclude)caffe2' || (echo 'The above lines have unqualified `noqa`; please convert them to `noqa: XXXX`'; false))\n      - name: Ensure no unqualified type ignore\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! git --no-pager grep -InP '# type:\\s*ignore(?!\\[)' -- '**.py' '**.pyi' ':(exclude)test/test_jit.py' || (echo 'The above lines have unqualified `type: ignore`; please convert them to `type: ignore[xxxx]`'; false))\n      - name: Ensure GitHub PyPi dependencies are pinned\n        if: always()\n        run: |\n          (! git --no-pager grep --color=always -InP \\\n                '(pip|pip3|python -m pip|python3 -m pip|python3 -mpip|python -mpip) install ([a-z][\\.a-z-0-9]*+(?!(=|.*\\.whl))([[:blank:]]|))+' \\\n                -- .github \\\n                ':(exclude)**.rst' \\\n                ':(exclude)**.py' \\\n                ':(exclude)**.md' \\\n                ':(exclude)**.diff' \\\n                ':(exclude)third_party' ||\n            (echo \"The above lines have unpinned PyPi installs; please pin them to a specific version: e.g. 'thepackage==1.2'\"; false))\n      # note that this next step depends on a clean checkout;\n      # if you run it locally then it will likely to complain\n      # about all the generated files in torch/test\n      - name: Ensure C++ source files are not executable\n        if: always()\n        run: |\n          # shellcheck disable=SC2016\n          (! find . \\( -path ./third_party -o -path ./.git -o -path ./torch/bin -o -path ./build \\) -prune -o -type f -executable -regextype posix-egrep -not -regex '.+(\\.(bash|sh|py|so)|git-pre-commit|git-clang-format|gradlew)$' -print | grep . || (echo 'The above files have executable permission; please remove their executable permission by using `chmod -x`'; false))\n      - name: C++ docs check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          sudo apt-get install -y doxygen\n          cd docs/cpp/source && ./check-doxygen.sh\n      - name: CUDA kernel launch check\n        if: ${{ always() && steps.requirements.outcome == 'success' }}\n        run: |\n          set -eux\n          python torch/testing/_check_kernel_launches.py |& tee \"${GITHUB_WORKSPACE}\"/cuda_kernel_launch_checks.txt\n      - name: Ensure no direct cub include\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'#include <cub/' --  ./aten  ':(exclude)aten/src/ATen/cuda/cub.cuh' || (echo \"The above files have direct cub include; please include ATen/cuda/cub.cuh instead and wrap your cub calls in at::native namespace if necessary\"; false))\n      - name: Ensure no raw cuda api calls\n        if: always()\n        run: |\n          (! git --no-pager grep -I -no $'cudaStreamSynchronize' --  ./aten ./c10 ':(exclude)aten/src/ATen/test' ':(exclude)c10/cuda/CUDAFunctions.h' || (echo \"The above files call raw cuda APIs directly; please use at::cuda wrappers instead\"; false))\n\n  clang-format:\n    runs-on: ubuntu-18.04\n    if: ${{ github.event_name == 'pull_request' }}\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # deep clone, to allow us to use git merge-base\n      - name: Run clang-format\n        env:\n          BASE_SHA: ${{ github.event.pull_request.base.sha }}\n        run: |\n          set -eu\n          # This is necessary to get the same results regardless of whether the\n          # PR was opened directly or from a forked repo. See: `9f890a92` for more info.\n          git remote add upstream https://github.com/pytorch/pytorch\n          git fetch upstream \"$GITHUB_BASE_REF\"\n\n          # only run clang-format on allowlisted files\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n          echo \"| clang-format failures found! Run: \"\n          echo \"|    tools/linter/clang_format_ci.sh ${BASE_SHA} \"\n          echo \"| to fix this error. \"\n          echo \"| For more info, see: https://github.com/pytorch/pytorch/wiki/clang-format \"\n          echo \"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\n\n          tools/linter/clang_format_ci.sh \"${BASE_SHA}\"\n\n          GIT_DIFF=$(git diff)\n          if [[ -z $GIT_DIFF ]]; then\n            exit 0\n          fi\n          echo \"$GIT_DIFF\"\n          exit 1\n\n  py2-setup-validate-errormsg:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 2.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Attempt to run setup.py\n        run: |\n          if ! python2 setup.py | grep -q \"Python 2 has reached end-of-life and is no longer supported by PyTorch.\"; then\n            echo 'Running setup.py with Python 2 did not give the expected error message.'\n            false\n          fi\n      - name: Keep torch.utils.collect_env python2 compliant\n        run: python2 -m py_compile torch/utils/collect_env.py\n\n  shellcheck:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install requirements\n        id: requirements\n        run: |\n          pip3 install -r requirements.txt --user\n      - name: Install Jinja2\n        run: |\n          pip3 install Jinja2==3.0.1 --user\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Regenerate workflows\n        id: generate_workflows\n        run: .github/scripts/generate_ci_workflows.py\n      - name: Assert that regenerating the workflows didn't change them\n        run: |\n          if ! .github/scripts/report_git_status.sh .github/workflows; then\n            echo\n            echo 'As shown by the above diff, the committed .github/workflows'\n            echo 'are not up to date according to .github/templates.'\n            echo 'Please run this command, commit, and push again to your PR:'\n            echo\n            echo '    .github/scripts/generate_ci_workflows.py'\n            echo\n            echo 'If running that command does nothing, you may need to rebase'\n            echo 'onto a more recent commit from the PyTorch master branch.'\n            false\n          fi\n      - name: Install ShellCheck\n        id: install_shellcheck\n        if: always()\n        # https://github.com/koalaman/shellcheck/tree/v0.7.2#installing-a-pre-compiled-binary\n        run: |\n          set -x\n          scversion=\"v0.7.2\"\n          wget -qO- \"https://github.com/koalaman/shellcheck/releases/download/${scversion?}/shellcheck-${scversion?}.linux.x86_64.tar.xz\" | tar -xJv\n          mkdir -p ~/.local/bin\n          cp \"shellcheck-${scversion}/shellcheck\" ~/.local/bin/\n          rm -r \"shellcheck-${scversion}\"\n          ~/.local/bin/shellcheck --version\n      - name: Extract scripts from GitHub Actions workflows\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          # For local lints, remove the .extracted_scripts folder if it was already there\n          rm -rf .extracted_scripts\n          tools/extract_scripts.py --out=.extracted_scripts\n      - name: Run ShellCheck\n        if: ${{ always() && steps.install_shellcheck.outcome == 'success' }}\n        run: |\n          if ! tools/linter/run_shellcheck.sh .extracted_scripts .jenkins/pytorch; then\n            echo\n            echo 'ShellCheck gave a nonzero exit code. Please fix the warnings'\n            echo 'listed above. Note that if a path in one of the above warning'\n            echo 'messages starts with .extracted_scripts/ then that means it'\n            echo 'is referring to a shell script embedded within another file,'\n            echo 'whose path is given by the path components immediately'\n            echo 'following the .extracted_scripts/ prefix.'\n            false\n          fi\n      - name: Check that jobs will be cancelled\n        if: ${{ always() && steps.generate_workflows.outcome == 'success' }}\n        run: |\n          .github/scripts/ensure_actions_will_cancel.py\n      - name: Run actionlint\n        shell: bash\n        run: |\n          set -eux\n          bash <(curl https://raw.githubusercontent.com/rhysd/actionlint/main/scripts/download-actionlint.bash)\n          ./actionlint --color\n          rm actionlint\n\n  toc:\n    runs-on: ubuntu-18.04\n    # https://github.com/actions/virtual-environments/issues/599#issuecomment-602754687\n    env:\n      NPM_CONFIG_PREFIX: ~/.npm-global\n    steps:\n      - name: Setup Node\n        uses: actions/setup-node@v2\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install markdown-toc\n        run: npm install -g markdown-toc\n      - name: Regenerate ToCs and check that they didn't change\n        run: |\n          set -eu\n          export PATH=~/.npm-global/bin:\"$PATH\"\n          for FILE in $(git grep -Il '<!-- toc -->' -- '**.md'); do\n            markdown-toc --bullets='-' -i \"$FILE\"\n          done\n\n          if ! .github/scripts/report_git_status.sh .; then\n            echo\n            echo 'As shown by the above diff, the table of contents in one or'\n            echo 'more Markdown files is not up to date with the file contents.'\n            echo 'You can either apply that Git diff directly to correct the'\n            echo 'table of contents, or if you have npm installed, you can'\n            echo 'install the npm package markdown-toc and run the following'\n            # shellcheck disable=SC2016\n            echo 'command (replacing $FILE with the filename for which you want'\n            echo 'to regenerate the table of contents):'\n            echo\n            # shellcheck disable=SC2016\n            echo \"    markdown-toc --bullets='-' -i \\\"\\$FILE\\\"\"\n            false\n          fi\n\n  flake8-py3:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 2 # to allow us to use github.event.pull_request.head.sha\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          mkdir flake8-output\n          cd flake8-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install typing-extensions==3.10 --user # for tools/linter/translate_annotations.py\n          pip3 install -r requirements-flake8.txt --user\n          flake8 --version\n      - name: Run flake8\n        run: |\n          set -eux\n          flake8 | tee \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n      - name: Translate annotations\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          tools/linter/translate_annotations.py \\\n            --file=\"${GITHUB_WORKSPACE}\"/flake8-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorCode>\\w+\\d+) (?P<errorDesc>.*)' \\\n            --commit=\"$HEAD_SHA\" \\\n            > flake8-output/annotations.json\n      - name: Fail if there were any warnings\n        run: |\n          set -eu\n          # Re-output flake8 status so GitHub logs show it on the step that actually failed\n          cat \"${GITHUB_WORKSPACE}\"/flake8-output.txt\n          if [ -s \"${GITHUB_WORKSPACE}\"/flake8-output.txt ]; then\n            echo 'Please fix the above Flake8 warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'flake8-py3'\n          linter_output_path: flake8-output/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  clang-tidy:\n    runs-on: linux.2xlarge\n    container:\n      # ubuntu20.04-cuda11.2-py3.8-tidy11\n      image: ghcr.io/pytorch/cilint-clang-tidy:d8f0c777964d0dd8a147360de80aed1a13eb613a\n    steps:\n      - name: Checkout PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n        with:\n          fetch-depth: 0 # to allow tools/linter/clang_tidy.py to do its thing\n      - name: Prepare output dir with HEAD commit SHA\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          mkdir clang-tidy-output\n          cd clang-tidy-output\n          echo \"$HEAD_SHA\" > commit-sha.txt\n      - name: Fetch PR diff\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          PR_NUMBER: ${{ github.event.pull_request.number }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          wget -O pr.diff \"https://patch-diff.githubusercontent.com/raw/pytorch/pytorch/pull/$PR_NUMBER.diff\"\n      - name: Generate build files\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          python3 -m tools.linter.clang_tidy.generate_build_files\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'pull_request' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          # The Docker image has our custom build, so we don't need to install it\n          python3 -m tools.linter.clang_tidy \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --diff-file pr.diff \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      # Run clang-tidy on a smaller subset of the codebase on master until we\n      # make the repository clang-tidy clean\n      - name: Run clang-tidy\n        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/master' }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n\n          python3 -m tools.linter.clang_tidy \\\n            --paths \\\n              torch/csrc/fx \\\n              torch/csrc/utils \\\n              torch/csrc/generic \\\n              torch/csrc/deploy \\\n              torch/csrc/tensor \\\n            --clang-tidy-exe \"$(which clang-tidy)\" \\\n            --disable-progress-bar 2>&1 | tee \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n\n      - name: Annotate output\n        if: ${{ github.event_name == 'pull_request' }}\n        env:\n          HEAD_SHA: ${{ github.event.pull_request.head.sha }}\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          sed --in-place 's/^\\.\\.\\///g' clang-tidy-output.txt\n          tools/linter/translate_annotations.py \\\n            --file=clang-tidy-output.txt \\\n            --regex='^(?P<filename>.*?):(?P<lineNumber>\\d+):(?P<columnNumber>\\d+): (?P<errorDesc>.*?) \\[(?P<errorCode>.*)\\]' \\\n            --commit=\"$HEAD_SHA\" \\\n            > clang-tidy-output/annotations.json\n      - name: Check for warnings\n        run: |\n          cd \"${GITHUB_WORKSPACE}\"\n          set -eu\n          cat \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt\n          if grep -Fq \"Warnings detected!\" \"${GITHUB_WORKSPACE}\"/clang-tidy-output.txt; then\n            echo 'Please fix the above clang-tidy warnings.'\n            false\n          fi\n      - name: Add annotations\n        # Don't run on forked pull requests\n        if: ${{ failure() && github.event.pull_request.head.repo.full_name == github.repository }}\n        uses: pytorch/add-annotations-github-action@master\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          check_name: 'clang-tidy'\n          linter_output_path: clang-tidy/annotations.json\n          commit_sha: ${{ github.event.pull_request.head.sha }}\n          mode: json\n\n  cmakelint:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install cmakelint==1.4.1 --user\n          cmakelint --version\n      - name: Run cmakelint\n        run: |\n          set -eux\n          git ls-files -z -- bootstrap '*.cmake' '*.cmake.in' '*CMakeLists.txt' | \\\n          grep -E -z -v '^(cmake/Modules/|cmake/Modules_CUDA_fix/|cmake/Caffe2Config.cmake.in|aten/src/ATen/ATenConfig.cmake.in|cmake/Caffe2ConfigVersion.cmake.in|cmake/TorchConfig.cmake.in|cmake/TorchConfigVersion.cmake.in|cmake/cmake_uninstall.cmake.in)' | \\\n          xargs -0 cmakelint --config=.cmakelintrc --spaces=2 --quiet\n\n  mypy:\n    runs-on: ubuntu-18.04\n    steps:\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.8\n          architecture: x64\n      - name: Fetch PyTorch\n        uses: zhouzhuojie/checkout@05b13c9a0d21f08f6d5e64a1d5042246d13619d9\n      - name: Install dependencies\n        run: |\n          set -eux\n          pip3 install -r requirements.txt --user\n          pip3 install numpy==1.20 --user # https://github.com/pytorch/pytorch/pull/60472\n          pip3 install expecttest==0.1.3 mypy==0.812 --user\n          # Needed to check tools/render_junit.py\n          pip3 install junitparser==2.1.1 rich==10.9.0 --user\n      - name: Run autogen\n        run: |\n          set -eux\n          time python -mtools.generate_torch_version --is_debug=false\n          time python -mtools.codegen.gen -s aten/src/ATen -d build/aten/src/ATen\n          time python -mtools.pyi.gen_pyi --native-functions-path aten/src/ATen/native/native_functions.yaml --deprecated-functions-path \"tools/autograd/deprecated.yaml\"\n      - name: Run mypy\n        env:\n          MYPY_FORCE_COLOR: 1\n          TERM: xterm-color\n        run: |\n          set -eux\n          STATUS=\n          for CONFIG in mypy*.ini; do\n            if ! mypy --config=\"$CONFIG\"; then\n              STATUS=fail\n            fi\n          done\n          if [ -n \"$STATUS\" ]; then\n            echo 'Please fix the above mypy warnings.'\n            false\n          fi\n\nconcurrency:\n  group: lint-${{ github.event.pull_request.number || github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n",
    "source": "arjun-raj-kuppala/pytorchtest",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/arjun-raj-kuppala/pytorchtest/blob/17a66520ff6034cbb9476e6c5538e8b0296b94a9/.github/workflows/lint.yml",
    "retrieved_at": "2025-11-04T01:45:20.957120Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML for code coverage using codecov.",
    "answer": "name: Code Coverage with codecov\n\non:\n  schedule:\n    - cron: '25 */3 * * 1-5'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event_name }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  codecov:\n    if: github.repository == 'zephyrproject-rtos/zephyr'\n    runs-on: zephyr-runner-linux-x64-4xlarge\n    container:\n      image: ghcr.io/zephyrproject-rtos/ci:v0.26.4\n      options: '--entrypoint /bin/bash'\n      volumes:\n        - /repo-cache/zephyrproject:/github/cache/zephyrproject\n    strategy:\n      fail-fast: false\n      matrix:\n        platform: [\"native_posix\", \"qemu_x86\", \"unit_testing\"]\n    env:\n      ZEPHYR_SDK_INSTALL_DIR: /opt/toolchains/zephyr-sdk-0.16.1\n    steps:\n      - name: Apply container owner mismatch workaround\n        run: |\n          # FIXME: The owner UID of the GITHUB_WORKSPACE directory may not\n          #        match the container user UID because of the way GitHub\n          #        Actions runner is implemented. Remove this workaround when\n          #        GitHub comes up with a fundamental fix for this problem.\n          git config --global --add safe.directory ${GITHUB_WORKSPACE}\n\n      - name: Update PATH for west\n        run: |\n          echo \"$HOME/.local/bin\" >> $GITHUB_PATH\n\n      - name: Clone cached Zephyr repository\n        continue-on-error: true\n        run: |\n          git clone --shared /github/cache/zephyrproject/zephyr .\n          git remote set-url origin ${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}\n\n      - name: checkout\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n\n      - name: west setup\n        run: |\n          west init -l . || true\n          west update 1> west.update.log || west update 1> west.update-2.log\n\n      - name: Check Environment\n        run: |\n          cmake --version\n          gcc --version\n          ls -la\n      - name: Prepare ccache keys\n        id: ccache_cache_prop\n        shell: cmake -P {0}\n        run: |\n          string(REPLACE \"/\" \"_\" repo ${{github.repository}})\n          string(REPLACE \"-\" \"_\" repo2 ${repo})\n          file(APPEND $ENV{GITHUB_OUTPUT} \"repo=${repo2}\\n\")\n\n      - name: use cache\n        id: cache-ccache\n        uses: zephyrproject-rtos/action-s3-cache@v1.2.0\n        with:\n          key: ${{ steps.ccache_cache_prop.outputs.repo }}-${{github.event_name}}-${{matrix.platform}}-codecov-ccache\n          path: /github/home/.cache/ccache\n          aws-s3-bucket: ccache.zephyrproject.org\n          aws-access-key-id: ${{ vars.AWS_CCACHE_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_CCACHE_SECRET_ACCESS_KEY }}\n          aws-region: us-east-2\n\n      - name: ccache stats initial\n        run: |\n          mkdir -p /github/home/.cache\n          test -d github/home/.cache/ccache && mv github/home/.cache/ccache /github/home/.cache/ccache\n          ccache -M 10G -s\n\n      - name: Run Tests with Twister (Push)\n        continue-on-error: true\n        run: |\n          export ZEPHYR_BASE=${PWD}\n          export ZEPHYR_TOOLCHAIN_VARIANT=zephyr\n          mkdir -p coverage/reports\n          ./scripts/twister --force-color -N -v --filter runnable -p ${{ matrix.platform }} --coverage -T tests\n\n      - name: Generate Coverage Report\n        run: |\n          mv twister-out/coverage.info lcov.pre.info\n          lcov -q --remove lcov.pre.info mylib.c --remove lcov.pre.info tests/\\* \\\n            --remove lcov.pre.info samples/\\* --remove lcov.pre.info ext/\\* \\\n            --remove lcov.pre.info *generated*  \\\n            -o coverage/reports/${{ matrix.platform }}.info --rc lcov_branch_coverage=1\n\n      - name: ccache stats post\n        run: |\n          ccache -s\n          ccache -p\n\n      - name: Upload Coverage Results\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: Coverage Data (Subset ${{ matrix.platform }})\n          path: coverage/reports/${{ matrix.platform }}.info\n\n  codecov-results:\n    name: \"Publish Coverage Results\"\n    needs: codecov\n    runs-on: ubuntu-22.04\n    # the codecov job might be skipped, we don't need to run this job then\n    if: success() || failure()\n\n    steps:\n      - name: checkout\n        uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n      - name: Download Artifacts\n        uses: actions/download-artifact@v3\n        with:\n          path: coverage/reports\n\n      - name: Move coverage files\n        run: |\n          mv ./coverage/reports/*/*.info ./coverage/reports\n          ls -la ./coverage/reports\n\n      - name: Generate list of coverage files\n        id: get-coverage-files\n        shell: cmake -P {0}\n        run: |\n          file(GLOB INPUT_FILES_LIST  \"coverage/reports/*.info\")\n          set(MERGELIST \"\")\n          set(FILELIST \"\")\n          foreach(ITEM ${INPUT_FILES_LIST})\n            get_filename_component(f ${ITEM} NAME)\n            if(FILELIST STREQUAL \"\")\n              set(FILELIST \"${f}\")\n            else()\n              set(FILELIST \"${FILELIST},${f}\")\n            endif()\n          endforeach()\n          foreach(ITEM ${INPUT_FILES_LIST})\n            get_filename_component(f ${ITEM} NAME)\n            if(MERGELIST STREQUAL \"\")\n              set(MERGELIST \"-a ${f}\")\n            else()\n              set(MERGELIST \"${MERGELIST} -a ${f}\")\n            endif()\n          endforeach()\n          file(APPEND $ENV{GITHUB_OUTPUT} \"mergefiles=${MERGELIST}\\n\")\n          file(APPEND $ENV{GITHUB_OUTPUT} \"covfiles=${FILELIST}\\n\")\n\n      - name: Merge coverage files\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y lcov\n          cd ./coverage/reports\n          lcov ${{ steps.get-coverage-files.outputs.mergefiles }} -o merged.info --rc lcov_branch_coverage=1\n\n      - name: Upload coverage to Codecov\n        if: always()\n        uses: codecov/codecov-action@v3\n        with:\n          directory: ./coverage/reports\n          env_vars: OS,PYTHON\n          fail_ci_if_error: false\n          verbose: true\n          files: merged.info\n",
    "source": "yuhua0731/zephyr",
    "path": ".github/workflows/codecov.yaml",
    "url": "https://github.com/yuhua0731/zephyr/blob/5ec46dd5af7b64ad78a03993ca9d5e31a7fd9a83/.github/workflows/codecov.yaml",
    "retrieved_at": "2025-11-04T01:45:21.902412Z",
    "question_style": "style_1"
  },
  {
    "question": "Create a GitHub Actions workflow that, upon manual dispatch, deploys a specified Terraform module, handling state in S3 and outputting application URLs.",
    "answer": "name: 'Terraform Apply'\n\n\non:\n  workflow_dispatch:\n    inputs:\n      module:\n        type: choice\n        description: \"Select which module to deploy\"\n        options: \n        - module-1\n        - module-2\n        required: true\n\npermissions: write-all\n\njobs:\n  terraform:\n    name: 'Terraform'\n    runs-on: ubuntu-latest\n    environment: production\n    env: \n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      AWS_REGION: \"us-east-1\"\n\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set Account ID\n      id: account\n      run: |\n        echo \"::set-output name=ACCOUNT_ID::$(aws sts get-caller-identity --query Account --output text)\"\n\n    - name: Check previous AWSGoat Deployment\n      id: check \n      run: |\n        echo $ACCOUNT_ID\n        aws s3api head-object --bucket do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }} --key terraform.tfstate\n      continue-on-error: true\n\n    - name: Exit if previous deployment exists\n      if: steps.check.outcome == 'success' \n      run: |\n        echo \"A Previous AWSGoat deployment exists, run the Terraform Destroy Action\"\n        exit 1\n\n    # Initialize a new or existing Terraform working directory \n    - name: Terraform Init\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform init \n        \n    # Installs boto3\n    - uses: actions/setup-python@v2\n      with:\n        python-version: 3\n    - name: install\n      run: |\n        pip install boto3\n    \n    - name: Terraform Plan\n      id: plan \n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform plan -input=false\n      continue-on-error: false\n      \n    - name: Terraform Plan Status\n      if: steps.plan.outcome == 'failure'\n      run: exit 1\n    \n    - name: Terraform Apply\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform apply -auto-approve -input=false\n      continue-on-error: false\n\n    # Copy tfstate file to s3 bucket\n    - name: Copy terraform.tfstate file to s3bucket\n      if: always()\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        aws s3 cp ./terraform.tfstate s3://do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }}/terraform.tfstate \n\n    # Terraform Output the API Gateway url\n    - name: Application URL\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        terraform output\n",
    "source": "argon-gh-demo/AWSGoat",
    "path": ".github/workflows/tf-apply-main.yml",
    "url": "https://github.com/argon-gh-demo/AWSGoat/blob/22536f86d9cd7e700edbc5bba1e01d1a018bb9bc/.github/workflows/tf-apply-main.yml",
    "retrieved_at": "2025-11-05T01:46:06.602204Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or action triggers the \"Terraform Apply\" workflow?",
    "answer": "name: 'Terraform Apply'\n\n\non:\n  workflow_dispatch:\n    inputs:\n      module:\n        type: choice\n        description: \"Select which module to deploy\"\n        options: \n        - module-1\n        - module-2\n        required: true\n\npermissions: write-all\n\njobs:\n  terraform:\n    name: 'Terraform'\n    runs-on: ubuntu-latest\n    environment: production\n    env: \n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      AWS_REGION: \"us-east-1\"\n\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set Account ID\n      id: account\n      run: |\n        echo \"::set-output name=ACCOUNT_ID::$(aws sts get-caller-identity --query Account --output text)\"\n\n    - name: Check previous AWSGoat Deployment\n      id: check \n      run: |\n        echo $ACCOUNT_ID\n        aws s3api head-object --bucket do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }} --key terraform.tfstate\n      continue-on-error: true\n\n    - name: Exit if previous deployment exists\n      if: steps.check.outcome == 'success' \n      run: |\n        echo \"A Previous AWSGoat deployment exists, run the Terraform Destroy Action\"\n        exit 1\n\n    # Initialize a new or existing Terraform working directory \n    - name: Terraform Init\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform init \n        \n    # Installs boto3\n    - uses: actions/setup-python@v2\n      with:\n        python-version: 3\n    - name: install\n      run: |\n        pip install boto3\n    \n    - name: Terraform Plan\n      id: plan \n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform plan -input=false\n      continue-on-error: false\n      \n    - name: Terraform Plan Status\n      if: steps.plan.outcome == 'failure'\n      run: exit 1\n    \n    - name: Terraform Apply\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform apply -auto-approve -input=false\n      continue-on-error: false\n\n    # Copy tfstate file to s3 bucket\n    - name: Copy terraform.tfstate file to s3bucket\n      if: always()\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        aws s3 cp ./terraform.tfstate s3://do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }}/terraform.tfstate \n\n    # Terraform Output the API Gateway url\n    - name: Application URL\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        terraform output\n",
    "source": "argon-gh-demo/AWSGoat",
    "path": ".github/workflows/tf-apply-main.yml",
    "url": "https://github.com/argon-gh-demo/AWSGoat/blob/22536f86d9cd7e700edbc5bba1e01d1a018bb9bc/.github/workflows/tf-apply-main.yml",
    "retrieved_at": "2025-11-05T01:46:07.105306Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the Terraform workflow run concurrently, and which ones depend on the completion of others?",
    "answer": "name: 'Terraform Apply'\n\n\non:\n  workflow_dispatch:\n    inputs:\n      module:\n        type: choice\n        description: \"Select which module to deploy\"\n        options: \n        - module-1\n        - module-2\n        required: true\n\npermissions: write-all\n\njobs:\n  terraform:\n    name: 'Terraform'\n    runs-on: ubuntu-latest\n    environment: production\n    env: \n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      AWS_REGION: \"us-east-1\"\n\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set Account ID\n      id: account\n      run: |\n        echo \"::set-output name=ACCOUNT_ID::$(aws sts get-caller-identity --query Account --output text)\"\n\n    - name: Check previous AWSGoat Deployment\n      id: check \n      run: |\n        echo $ACCOUNT_ID\n        aws s3api head-object --bucket do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }} --key terraform.tfstate\n      continue-on-error: true\n\n    - name: Exit if previous deployment exists\n      if: steps.check.outcome == 'success' \n      run: |\n        echo \"A Previous AWSGoat deployment exists, run the Terraform Destroy Action\"\n        exit 1\n\n    # Initialize a new or existing Terraform working directory \n    - name: Terraform Init\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform init \n        \n    # Installs boto3\n    - uses: actions/setup-python@v2\n      with:\n        python-version: 3\n    - name: install\n      run: |\n        pip install boto3\n    \n    - name: Terraform Plan\n      id: plan \n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform plan -input=false\n      continue-on-error: false\n      \n    - name: Terraform Plan Status\n      if: steps.plan.outcome == 'failure'\n      run: exit 1\n    \n    - name: Terraform Apply\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform apply -auto-approve -input=false\n      continue-on-error: false\n\n    # Copy tfstate file to s3 bucket\n    - name: Copy terraform.tfstate file to s3bucket\n      if: always()\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        aws s3 cp ./terraform.tfstate s3://do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }}/terraform.tfstate \n\n    # Terraform Output the API Gateway url\n    - name: Application URL\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        terraform output\n",
    "source": "argon-gh-demo/AWSGoat",
    "path": ".github/workflows/tf-apply-main.yml",
    "url": "https://github.com/argon-gh-demo/AWSGoat/blob/22536f86d9cd7e700edbc5bba1e01d1a018bb9bc/.github/workflows/tf-apply-main.yml",
    "retrieved_at": "2025-11-05T01:46:07.799597Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` secrets used within the Terraform job?",
    "answer": "name: 'Terraform Apply'\n\n\non:\n  workflow_dispatch:\n    inputs:\n      module:\n        type: choice\n        description: \"Select which module to deploy\"\n        options: \n        - module-1\n        - module-2\n        required: true\n\npermissions: write-all\n\njobs:\n  terraform:\n    name: 'Terraform'\n    runs-on: ubuntu-latest\n    environment: production\n    env: \n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      AWS_REGION: \"us-east-1\"\n\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set Account ID\n      id: account\n      run: |\n        echo \"::set-output name=ACCOUNT_ID::$(aws sts get-caller-identity --query Account --output text)\"\n\n    - name: Check previous AWSGoat Deployment\n      id: check \n      run: |\n        echo $ACCOUNT_ID\n        aws s3api head-object --bucket do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }} --key terraform.tfstate\n      continue-on-error: true\n\n    - name: Exit if previous deployment exists\n      if: steps.check.outcome == 'success' \n      run: |\n        echo \"A Previous AWSGoat deployment exists, run the Terraform Destroy Action\"\n        exit 1\n\n    # Initialize a new or existing Terraform working directory \n    - name: Terraform Init\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform init \n        \n    # Installs boto3\n    - uses: actions/setup-python@v2\n      with:\n        python-version: 3\n    - name: install\n      run: |\n        pip install boto3\n    \n    - name: Terraform Plan\n      id: plan \n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform plan -input=false\n      continue-on-error: false\n      \n    - name: Terraform Plan Status\n      if: steps.plan.outcome == 'failure'\n      run: exit 1\n    \n    - name: Terraform Apply\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform apply -auto-approve -input=false\n      continue-on-error: false\n\n    # Copy tfstate file to s3 bucket\n    - name: Copy terraform.tfstate file to s3bucket\n      if: always()\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        aws s3 cp ./terraform.tfstate s3://do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }}/terraform.tfstate \n\n    # Terraform Output the API Gateway url\n    - name: Application URL\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        terraform output\n",
    "source": "argon-gh-demo/AWSGoat",
    "path": ".github/workflows/tf-apply-main.yml",
    "url": "https://github.com/argon-gh-demo/AWSGoat/blob/22536f86d9cd7e700edbc5bba1e01d1a018bb9bc/.github/workflows/tf-apply-main.yml",
    "retrieved_at": "2025-11-05T01:46:08.669691Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, particularly concerning Terraform and AWSGoat?",
    "answer": "name: 'Terraform Apply'\n\n\non:\n  workflow_dispatch:\n    inputs:\n      module:\n        type: choice\n        description: \"Select which module to deploy\"\n        options: \n        - module-1\n        - module-2\n        required: true\n\npermissions: write-all\n\njobs:\n  terraform:\n    name: 'Terraform'\n    runs-on: ubuntu-latest\n    environment: production\n    env: \n      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}\n      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n      AWS_REGION: \"us-east-1\"\n\n    defaults:\n      run:\n        shell: bash\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set Account ID\n      id: account\n      run: |\n        echo \"::set-output name=ACCOUNT_ID::$(aws sts get-caller-identity --query Account --output text)\"\n\n    - name: Check previous AWSGoat Deployment\n      id: check \n      run: |\n        echo $ACCOUNT_ID\n        aws s3api head-object --bucket do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }} --key terraform.tfstate\n      continue-on-error: true\n\n    - name: Exit if previous deployment exists\n      if: steps.check.outcome == 'success' \n      run: |\n        echo \"A Previous AWSGoat deployment exists, run the Terraform Destroy Action\"\n        exit 1\n\n    # Initialize a new or existing Terraform working directory \n    - name: Terraform Init\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform init \n        \n    # Installs boto3\n    - uses: actions/setup-python@v2\n      with:\n        python-version: 3\n    - name: install\n      run: |\n        pip install boto3\n    \n    - name: Terraform Plan\n      id: plan \n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform plan -input=false\n      continue-on-error: false\n      \n    - name: Terraform Plan Status\n      if: steps.plan.outcome == 'failure'\n      run: exit 1\n    \n    - name: Terraform Apply\n      run: | \n        cd modules/${{ github.event.inputs.module }}\n        terraform apply -auto-approve -input=false\n      continue-on-error: false\n\n    # Copy tfstate file to s3 bucket\n    - name: Copy terraform.tfstate file to s3bucket\n      if: always()\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        aws s3 cp ./terraform.tfstate s3://do-not-delete-awsgoat-state-files-${{ steps.account.outputs.ACCOUNT_ID }}/terraform.tfstate \n\n    # Terraform Output the API Gateway url\n    - name: Application URL\n      run: |\n        cd modules/${{ github.event.inputs.module }}\n        terraform output\n",
    "source": "argon-gh-demo/AWSGoat",
    "path": ".github/workflows/tf-apply-main.yml",
    "url": "https://github.com/argon-gh-demo/AWSGoat/blob/22536f86d9cd7e700edbc5bba1e01d1a018bb9bc/.github/workflows/tf-apply-main.yml",
    "retrieved_at": "2025-11-05T01:46:09.551828Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including build, scan, and test jobs for a snap package.",
    "answer": "name: Build and Test\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_call:\n  pull_request:\n\njobs:\n  build:\n    name: Build Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n    outputs:\n      snap-file: ${{ steps.build-snap.outputs.snap }}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Upgrade linux deps\n        run: |\n          sudo apt-get update\n\n          # install security updates\n          sudo apt-get -s dist-upgrade \\\n            | grep \"^Inst\" \\\n            | grep -i securi \\\n            | awk -F \" \" {'print $2'} \\\n            | xargs sudo apt-get install -y\n\n          sudo apt-get autoremove -y\n          sudo apt-get clean -y\n\n      - id: build-snap\n        name: Build snap\n        uses: snapcore/action-build@v1\n\n      - name: Upload built snap job artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: \"charmed-opensearch-dashboards_*.snap\"\n\n  scan:\n    name: Trivy scan and SBOM Generation\n    needs: build\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"sarif\"\n          output: \"trivy-results.sarif\"\n          scanners: \"vuln\"\n\n      - name: Upload Trivy scan results to GitHub Security tab\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: \"trivy-results.sarif\"\n\n      - name: Run Trivy in GitHub SBOM mode and submit results to Dependency Graph\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"spdx-json\"\n          output: \"dependency-results.sbom.json\"\n          github-pat: ${{ secrets.GITHUB_TOKEN }}\n          severity: \"MEDIUM,HIGH,CRITICAL\"\n          scanners: \"vuln\"\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-results.sarif\n          path: \"${{ github.workspace }}/trivy-results.sarif\"\n          retention-days: 90\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-sbom-report\n          path: \"${{ github.workspace }}/dependency-results.sbom.json\"\n          retention-days: 90\n\n  test:\n    name: Test Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs:\n      - build\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup the required system configs OpenSearch\n        run: |\n          sudo snap install opensearch --channel=2/edge --revision=76\n          sudo snap connect opensearch:process-control\n\n          sudo sysctl -w vm.swappiness=0\n          sudo sysctl -w vm.max_map_count=262144\n          sudo sysctl -w net.ipv4.tcp_retries2=5\n\n      - name: Setup and Start OpenSearch\n        run: |\n          # create the certificates\n          sudo snap run opensearch.setup \\\n              --node-name cm0 \\\n              --node-roles cluster_manager,data \\\n              --tls-priv-key-root-pass root1234 \\\n              --tls-priv-key-admin-pass admin1234 \\\n              --tls-priv-key-node-pass node1234 \\\n              --tls-init-setup yes                 # this creates the root and admin certs as well.\n\n          # start opensearch\n          sudo snap start opensearch.daemon\n\n          # wait a bit for it to fully initialize\n          sleep 60s\n\n          # create the security index\n          sudo snap run opensearch.security-init --tls-priv-key-admin-pass=admin1234\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Test Charmed Opensearch Dashboards\n        run: |\n          sudo snap start charmed-opensearch-dashboards\n\n          # Wait until the service establishes\n          service_unavailable=$(curl -i http://localhost:5601 \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused  | grep \"302 Found\")\n          if [ ! \"$service_unavailable\" ]; then\n            echo \"ERROR: Service unavailable. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface using valid authentication\n          authenticate_ok=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"kibanaserver\",\"password\":\"kibanaserver\"}' | grep \"200 OK\")\n\n          if [ ! \"$authenticate_ok\" ]; then\n            echo \"ERROR: Authentication failed with correct credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface wrongly authenticated\n          wrong_credentials_fail=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"admin\",\"password\":\"test\"}' | grep \"401 Unauthorized\")\n\n          if [ ! \"$wrong_credentials_fail\" ]; then\n            echo \"ERROR: Authentication allowed with wrong credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Check if logs are collected as expected\n          logfile=\"/var/snap/charmed-opensearch-dashboards/common/var/log/opensearch-dashboards/opensearch_dashboards.log\"\n          if ! sudo test -s \"${logfile}\"; then\n            echo \"ERROR: Logfile unaccessible. Aborting...\" >&2\n            exit 1\n          fi\n\n      - name: Test Prometheus Exporter\n        run: |\n          URL=http://localhost:9684/metrics\n\n          # Wait until the service esteblishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Successfully connected to the Exporter service\"\n\n          sudo snap set charmed-opensearch-dashboards scheme=https\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n           if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 1.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter available when it should be connecting to a non-existent service. Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Exporter was down when it was supposed to be\"\n\n          # Wrong setting defaults to HTTP, so the exporter should work\n          sudo snap set charmed-opensearch-dashboards scheme=httpblabla\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Snap defaults correctly applied as Exporter settings\"\n\n      - name: Test Logs slot\n        run: |\n          logs_slot_avail=$(sudo snap connections charmed-opensearch-dashboards | grep opensearch-dashboards:logs)\n\n          if [ ! \"$logs_slot_avail\" ]; then\n            echo \"ERROR: Logs slot is not available. Aborting...\" >&2\n            exit 1\n          fi\n",
    "source": "canonical/charmed-opensearch-dashboards-snap",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/canonical/charmed-opensearch-dashboards-snap/blob/2cee5eecb8914bc96808e3175aab8f6c1d38355f/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-05T01:46:10.750518Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow?",
    "answer": "name: Build and Test\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_call:\n  pull_request:\n\njobs:\n  build:\n    name: Build Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n    outputs:\n      snap-file: ${{ steps.build-snap.outputs.snap }}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Upgrade linux deps\n        run: |\n          sudo apt-get update\n\n          # install security updates\n          sudo apt-get -s dist-upgrade \\\n            | grep \"^Inst\" \\\n            | grep -i securi \\\n            | awk -F \" \" {'print $2'} \\\n            | xargs sudo apt-get install -y\n\n          sudo apt-get autoremove -y\n          sudo apt-get clean -y\n\n      - id: build-snap\n        name: Build snap\n        uses: snapcore/action-build@v1\n\n      - name: Upload built snap job artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: \"charmed-opensearch-dashboards_*.snap\"\n\n  scan:\n    name: Trivy scan and SBOM Generation\n    needs: build\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"sarif\"\n          output: \"trivy-results.sarif\"\n          scanners: \"vuln\"\n\n      - name: Upload Trivy scan results to GitHub Security tab\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: \"trivy-results.sarif\"\n\n      - name: Run Trivy in GitHub SBOM mode and submit results to Dependency Graph\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"spdx-json\"\n          output: \"dependency-results.sbom.json\"\n          github-pat: ${{ secrets.GITHUB_TOKEN }}\n          severity: \"MEDIUM,HIGH,CRITICAL\"\n          scanners: \"vuln\"\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-results.sarif\n          path: \"${{ github.workspace }}/trivy-results.sarif\"\n          retention-days: 90\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-sbom-report\n          path: \"${{ github.workspace }}/dependency-results.sbom.json\"\n          retention-days: 90\n\n  test:\n    name: Test Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs:\n      - build\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup the required system configs OpenSearch\n        run: |\n          sudo snap install opensearch --channel=2/edge --revision=76\n          sudo snap connect opensearch:process-control\n\n          sudo sysctl -w vm.swappiness=0\n          sudo sysctl -w vm.max_map_count=262144\n          sudo sysctl -w net.ipv4.tcp_retries2=5\n\n      - name: Setup and Start OpenSearch\n        run: |\n          # create the certificates\n          sudo snap run opensearch.setup \\\n              --node-name cm0 \\\n              --node-roles cluster_manager,data \\\n              --tls-priv-key-root-pass root1234 \\\n              --tls-priv-key-admin-pass admin1234 \\\n              --tls-priv-key-node-pass node1234 \\\n              --tls-init-setup yes                 # this creates the root and admin certs as well.\n\n          # start opensearch\n          sudo snap start opensearch.daemon\n\n          # wait a bit for it to fully initialize\n          sleep 60s\n\n          # create the security index\n          sudo snap run opensearch.security-init --tls-priv-key-admin-pass=admin1234\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Test Charmed Opensearch Dashboards\n        run: |\n          sudo snap start charmed-opensearch-dashboards\n\n          # Wait until the service establishes\n          service_unavailable=$(curl -i http://localhost:5601 \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused  | grep \"302 Found\")\n          if [ ! \"$service_unavailable\" ]; then\n            echo \"ERROR: Service unavailable. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface using valid authentication\n          authenticate_ok=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"kibanaserver\",\"password\":\"kibanaserver\"}' | grep \"200 OK\")\n\n          if [ ! \"$authenticate_ok\" ]; then\n            echo \"ERROR: Authentication failed with correct credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface wrongly authenticated\n          wrong_credentials_fail=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"admin\",\"password\":\"test\"}' | grep \"401 Unauthorized\")\n\n          if [ ! \"$wrong_credentials_fail\" ]; then\n            echo \"ERROR: Authentication allowed with wrong credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Check if logs are collected as expected\n          logfile=\"/var/snap/charmed-opensearch-dashboards/common/var/log/opensearch-dashboards/opensearch_dashboards.log\"\n          if ! sudo test -s \"${logfile}\"; then\n            echo \"ERROR: Logfile unaccessible. Aborting...\" >&2\n            exit 1\n          fi\n\n      - name: Test Prometheus Exporter\n        run: |\n          URL=http://localhost:9684/metrics\n\n          # Wait until the service esteblishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Successfully connected to the Exporter service\"\n\n          sudo snap set charmed-opensearch-dashboards scheme=https\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n           if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 1.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter available when it should be connecting to a non-existent service. Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Exporter was down when it was supposed to be\"\n\n          # Wrong setting defaults to HTTP, so the exporter should work\n          sudo snap set charmed-opensearch-dashboards scheme=httpblabla\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Snap defaults correctly applied as Exporter settings\"\n\n      - name: Test Logs slot\n        run: |\n          logs_slot_avail=$(sudo snap connections charmed-opensearch-dashboards | grep opensearch-dashboards:logs)\n\n          if [ ! \"$logs_slot_avail\" ]; then\n            echo \"ERROR: Logs slot is not available. Aborting...\" >&2\n            exit 1\n          fi\n",
    "source": "canonical/charmed-opensearch-dashboards-snap",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/canonical/charmed-opensearch-dashboards-snap/blob/2cee5eecb8914bc96808e3175aab8f6c1d38355f/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-05T01:46:11.438323Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and which jobs or steps depend on the completion of other jobs or steps?",
    "answer": "name: Build and Test\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_call:\n  pull_request:\n\njobs:\n  build:\n    name: Build Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n    outputs:\n      snap-file: ${{ steps.build-snap.outputs.snap }}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Upgrade linux deps\n        run: |\n          sudo apt-get update\n\n          # install security updates\n          sudo apt-get -s dist-upgrade \\\n            | grep \"^Inst\" \\\n            | grep -i securi \\\n            | awk -F \" \" {'print $2'} \\\n            | xargs sudo apt-get install -y\n\n          sudo apt-get autoremove -y\n          sudo apt-get clean -y\n\n      - id: build-snap\n        name: Build snap\n        uses: snapcore/action-build@v1\n\n      - name: Upload built snap job artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: \"charmed-opensearch-dashboards_*.snap\"\n\n  scan:\n    name: Trivy scan and SBOM Generation\n    needs: build\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"sarif\"\n          output: \"trivy-results.sarif\"\n          scanners: \"vuln\"\n\n      - name: Upload Trivy scan results to GitHub Security tab\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: \"trivy-results.sarif\"\n\n      - name: Run Trivy in GitHub SBOM mode and submit results to Dependency Graph\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"spdx-json\"\n          output: \"dependency-results.sbom.json\"\n          github-pat: ${{ secrets.GITHUB_TOKEN }}\n          severity: \"MEDIUM,HIGH,CRITICAL\"\n          scanners: \"vuln\"\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-results.sarif\n          path: \"${{ github.workspace }}/trivy-results.sarif\"\n          retention-days: 90\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-sbom-report\n          path: \"${{ github.workspace }}/dependency-results.sbom.json\"\n          retention-days: 90\n\n  test:\n    name: Test Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs:\n      - build\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup the required system configs OpenSearch\n        run: |\n          sudo snap install opensearch --channel=2/edge --revision=76\n          sudo snap connect opensearch:process-control\n\n          sudo sysctl -w vm.swappiness=0\n          sudo sysctl -w vm.max_map_count=262144\n          sudo sysctl -w net.ipv4.tcp_retries2=5\n\n      - name: Setup and Start OpenSearch\n        run: |\n          # create the certificates\n          sudo snap run opensearch.setup \\\n              --node-name cm0 \\\n              --node-roles cluster_manager,data \\\n              --tls-priv-key-root-pass root1234 \\\n              --tls-priv-key-admin-pass admin1234 \\\n              --tls-priv-key-node-pass node1234 \\\n              --tls-init-setup yes                 # this creates the root and admin certs as well.\n\n          # start opensearch\n          sudo snap start opensearch.daemon\n\n          # wait a bit for it to fully initialize\n          sleep 60s\n\n          # create the security index\n          sudo snap run opensearch.security-init --tls-priv-key-admin-pass=admin1234\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Test Charmed Opensearch Dashboards\n        run: |\n          sudo snap start charmed-opensearch-dashboards\n\n          # Wait until the service establishes\n          service_unavailable=$(curl -i http://localhost:5601 \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused  | grep \"302 Found\")\n          if [ ! \"$service_unavailable\" ]; then\n            echo \"ERROR: Service unavailable. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface using valid authentication\n          authenticate_ok=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"kibanaserver\",\"password\":\"kibanaserver\"}' | grep \"200 OK\")\n\n          if [ ! \"$authenticate_ok\" ]; then\n            echo \"ERROR: Authentication failed with correct credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface wrongly authenticated\n          wrong_credentials_fail=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"admin\",\"password\":\"test\"}' | grep \"401 Unauthorized\")\n\n          if [ ! \"$wrong_credentials_fail\" ]; then\n            echo \"ERROR: Authentication allowed with wrong credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Check if logs are collected as expected\n          logfile=\"/var/snap/charmed-opensearch-dashboards/common/var/log/opensearch-dashboards/opensearch_dashboards.log\"\n          if ! sudo test -s \"${logfile}\"; then\n            echo \"ERROR: Logfile unaccessible. Aborting...\" >&2\n            exit 1\n          fi\n\n      - name: Test Prometheus Exporter\n        run: |\n          URL=http://localhost:9684/metrics\n\n          # Wait until the service esteblishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Successfully connected to the Exporter service\"\n\n          sudo snap set charmed-opensearch-dashboards scheme=https\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n           if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 1.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter available when it should be connecting to a non-existent service. Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Exporter was down when it was supposed to be\"\n\n          # Wrong setting defaults to HTTP, so the exporter should work\n          sudo snap set charmed-opensearch-dashboards scheme=httpblabla\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Snap defaults correctly applied as Exporter settings\"\n\n      - name: Test Logs slot\n        run: |\n          logs_slot_avail=$(sudo snap connections charmed-opensearch-dashboards | grep opensearch-dashboards:logs)\n\n          if [ ! \"$logs_slot_avail\" ]; then\n            echo \"ERROR: Logs slot is not available. Aborting...\" >&2\n            exit 1\n          fi\n",
    "source": "canonical/charmed-opensearch-dashboards-snap",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/canonical/charmed-opensearch-dashboards-snap/blob/2cee5eecb8914bc96808e3175aab8f6c1d38355f/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-05T01:46:12.274536Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the GITHUB_TOKEN secret used within the Trivy scan job for submitting results to the Dependency Graph?",
    "answer": "name: Build and Test\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_call:\n  pull_request:\n\njobs:\n  build:\n    name: Build Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n    outputs:\n      snap-file: ${{ steps.build-snap.outputs.snap }}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Upgrade linux deps\n        run: |\n          sudo apt-get update\n\n          # install security updates\n          sudo apt-get -s dist-upgrade \\\n            | grep \"^Inst\" \\\n            | grep -i securi \\\n            | awk -F \" \" {'print $2'} \\\n            | xargs sudo apt-get install -y\n\n          sudo apt-get autoremove -y\n          sudo apt-get clean -y\n\n      - id: build-snap\n        name: Build snap\n        uses: snapcore/action-build@v1\n\n      - name: Upload built snap job artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: \"charmed-opensearch-dashboards_*.snap\"\n\n  scan:\n    name: Trivy scan and SBOM Generation\n    needs: build\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"sarif\"\n          output: \"trivy-results.sarif\"\n          scanners: \"vuln\"\n\n      - name: Upload Trivy scan results to GitHub Security tab\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: \"trivy-results.sarif\"\n\n      - name: Run Trivy in GitHub SBOM mode and submit results to Dependency Graph\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"spdx-json\"\n          output: \"dependency-results.sbom.json\"\n          github-pat: ${{ secrets.GITHUB_TOKEN }}\n          severity: \"MEDIUM,HIGH,CRITICAL\"\n          scanners: \"vuln\"\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-results.sarif\n          path: \"${{ github.workspace }}/trivy-results.sarif\"\n          retention-days: 90\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-sbom-report\n          path: \"${{ github.workspace }}/dependency-results.sbom.json\"\n          retention-days: 90\n\n  test:\n    name: Test Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs:\n      - build\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup the required system configs OpenSearch\n        run: |\n          sudo snap install opensearch --channel=2/edge --revision=76\n          sudo snap connect opensearch:process-control\n\n          sudo sysctl -w vm.swappiness=0\n          sudo sysctl -w vm.max_map_count=262144\n          sudo sysctl -w net.ipv4.tcp_retries2=5\n\n      - name: Setup and Start OpenSearch\n        run: |\n          # create the certificates\n          sudo snap run opensearch.setup \\\n              --node-name cm0 \\\n              --node-roles cluster_manager,data \\\n              --tls-priv-key-root-pass root1234 \\\n              --tls-priv-key-admin-pass admin1234 \\\n              --tls-priv-key-node-pass node1234 \\\n              --tls-init-setup yes                 # this creates the root and admin certs as well.\n\n          # start opensearch\n          sudo snap start opensearch.daemon\n\n          # wait a bit for it to fully initialize\n          sleep 60s\n\n          # create the security index\n          sudo snap run opensearch.security-init --tls-priv-key-admin-pass=admin1234\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Test Charmed Opensearch Dashboards\n        run: |\n          sudo snap start charmed-opensearch-dashboards\n\n          # Wait until the service establishes\n          service_unavailable=$(curl -i http://localhost:5601 \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused  | grep \"302 Found\")\n          if [ ! \"$service_unavailable\" ]; then\n            echo \"ERROR: Service unavailable. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface using valid authentication\n          authenticate_ok=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"kibanaserver\",\"password\":\"kibanaserver\"}' | grep \"200 OK\")\n\n          if [ ! \"$authenticate_ok\" ]; then\n            echo \"ERROR: Authentication failed with correct credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface wrongly authenticated\n          wrong_credentials_fail=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"admin\",\"password\":\"test\"}' | grep \"401 Unauthorized\")\n\n          if [ ! \"$wrong_credentials_fail\" ]; then\n            echo \"ERROR: Authentication allowed with wrong credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Check if logs are collected as expected\n          logfile=\"/var/snap/charmed-opensearch-dashboards/common/var/log/opensearch-dashboards/opensearch_dashboards.log\"\n          if ! sudo test -s \"${logfile}\"; then\n            echo \"ERROR: Logfile unaccessible. Aborting...\" >&2\n            exit 1\n          fi\n\n      - name: Test Prometheus Exporter\n        run: |\n          URL=http://localhost:9684/metrics\n\n          # Wait until the service esteblishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Successfully connected to the Exporter service\"\n\n          sudo snap set charmed-opensearch-dashboards scheme=https\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n           if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 1.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter available when it should be connecting to a non-existent service. Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Exporter was down when it was supposed to be\"\n\n          # Wrong setting defaults to HTTP, so the exporter should work\n          sudo snap set charmed-opensearch-dashboards scheme=httpblabla\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Snap defaults correctly applied as Exporter settings\"\n\n      - name: Test Logs slot\n        run: |\n          logs_slot_avail=$(sudo snap connections charmed-opensearch-dashboards | grep opensearch-dashboards:logs)\n\n          if [ ! \"$logs_slot_avail\" ]; then\n            echo \"ERROR: Logs slot is not available. Aborting...\" >&2\n            exit 1\n          fi\n",
    "source": "canonical/charmed-opensearch-dashboards-snap",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/canonical/charmed-opensearch-dashboards-snap/blob/2cee5eecb8914bc96808e3175aab8f6c1d38355f/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-05T01:46:13.063139Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this GitHub Actions workflow for Charmed OpenSearch Dashboards?",
    "answer": "name: Build and Test\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_call:\n  pull_request:\n\njobs:\n  build:\n    name: Build Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n    outputs:\n      snap-file: ${{ steps.build-snap.outputs.snap }}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Upgrade linux deps\n        run: |\n          sudo apt-get update\n\n          # install security updates\n          sudo apt-get -s dist-upgrade \\\n            | grep \"^Inst\" \\\n            | grep -i securi \\\n            | awk -F \" \" {'print $2'} \\\n            | xargs sudo apt-get install -y\n\n          sudo apt-get autoremove -y\n          sudo apt-get clean -y\n\n      - id: build-snap\n        name: Build snap\n        uses: snapcore/action-build@v1\n\n      - name: Upload built snap job artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: \"charmed-opensearch-dashboards_*.snap\"\n\n  scan:\n    name: Trivy scan and SBOM Generation\n    needs: build\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"sarif\"\n          output: \"trivy-results.sarif\"\n          scanners: \"vuln\"\n\n      - name: Upload Trivy scan results to GitHub Security tab\n        uses: github/codeql-action/upload-sarif@v3\n        if: always()\n        with:\n          sarif_file: \"trivy-results.sarif\"\n\n      - name: Run Trivy in GitHub SBOM mode and submit results to Dependency Graph\n        uses: aquasecurity/trivy-action@0.30.0\n        with:\n          scan-type: \"fs\"\n          scan-ref: /snap/charmed-opensearch-dashboards/current/usr/share/opensearch-dashboards/\n          format: \"spdx-json\"\n          output: \"dependency-results.sbom.json\"\n          github-pat: ${{ secrets.GITHUB_TOKEN }}\n          severity: \"MEDIUM,HIGH,CRITICAL\"\n          scanners: \"vuln\"\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-results.sarif\n          path: \"${{ github.workspace }}/trivy-results.sarif\"\n          retention-days: 90\n\n      - name: Upload trivy report as a Github artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: trivy-sbom-report\n          path: \"${{ github.workspace }}/dependency-results.sbom.json\"\n          retention-days: 90\n\n  test:\n    name: Test Snap\n    runs-on: ubuntu-latest\n    timeout-minutes: 15\n    needs:\n      - build\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Setup the required system configs OpenSearch\n        run: |\n          sudo snap install opensearch --channel=2/edge --revision=76\n          sudo snap connect opensearch:process-control\n\n          sudo sysctl -w vm.swappiness=0\n          sudo sysctl -w vm.max_map_count=262144\n          sudo sysctl -w net.ipv4.tcp_retries2=5\n\n      - name: Setup and Start OpenSearch\n        run: |\n          # create the certificates\n          sudo snap run opensearch.setup \\\n              --node-name cm0 \\\n              --node-roles cluster_manager,data \\\n              --tls-priv-key-root-pass root1234 \\\n              --tls-priv-key-admin-pass admin1234 \\\n              --tls-priv-key-node-pass node1234 \\\n              --tls-init-setup yes                 # this creates the root and admin certs as well.\n\n          # start opensearch\n          sudo snap start opensearch.daemon\n\n          # wait a bit for it to fully initialize\n          sleep 60s\n\n          # create the security index\n          sudo snap run opensearch.security-init --tls-priv-key-admin-pass=admin1234\n\n      - name: Download snap file for Charmed OpenSearch Dashboards\n        uses: actions/download-artifact@v4\n        with:\n          name: charmed-opensearch-dashboards_snap_amd64\n          path: .\n\n      - name: Install snap file for Charmed Opensearch Dashboards\n        run: |\n          version=\"$(yq .version < snap/snapcraft.yaml)\"\n\n          sudo snap install charmed-opensearch-dashboards_${version}_amd64.snap --dangerous --jailmode\n\n      - name: Test Charmed Opensearch Dashboards\n        run: |\n          sudo snap start charmed-opensearch-dashboards\n\n          # Wait until the service establishes\n          service_unavailable=$(curl -i http://localhost:5601 \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused  | grep \"302 Found\")\n          if [ ! \"$service_unavailable\" ]; then\n            echo \"ERROR: Service unavailable. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface using valid authentication\n          authenticate_ok=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"kibanaserver\",\"password\":\"kibanaserver\"}' | grep \"200 OK\")\n\n          if [ ! \"$authenticate_ok\" ]; then\n            echo \"ERROR: Authentication failed with correct credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Attempt to access the interface wrongly authenticated\n          wrong_credentials_fail=$(curl -i  -k -XPOST http://localhost:5601/auth/login \\\n            -H 'Accept: application/json' \\\n            -H 'Content-Type: application/json' \\\n            -H 'osd-xsrf:true' \\\n            -d '{\"username\":\"admin\",\"password\":\"test\"}' | grep \"401 Unauthorized\")\n\n          if [ ! \"$wrong_credentials_fail\" ]; then\n            echo \"ERROR: Authentication allowed with wrong credentials. Aborting...\" >&2\n            exit 1\n          fi\n\n          # Check if logs are collected as expected\n          logfile=\"/var/snap/charmed-opensearch-dashboards/common/var/log/opensearch-dashboards/opensearch_dashboards.log\"\n          if ! sudo test -s \"${logfile}\"; then\n            echo \"ERROR: Logfile unaccessible. Aborting...\" >&2\n            exit 1\n          fi\n\n      - name: Test Prometheus Exporter\n        run: |\n          URL=http://localhost:9684/metrics\n\n          # Wait until the service esteblishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Successfully connected to the Exporter service\"\n\n          sudo snap set charmed-opensearch-dashboards scheme=https\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n\n           if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 1.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter available when it should be connecting to a non-existent service. Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Exporter was down when it was supposed to be\"\n\n          # Wrong setting defaults to HTTP, so the exporter should work\n          sudo snap set charmed-opensearch-dashboards scheme=httpblabla\n          sudo snap restart charmed-opensearch-dashboards\n          sleep 10\n\n          # Wait until the service establishes\n          metrics=$(curl ${URL} \\\n            --connect-timeout 5 \\\n            --retry 5 \\\n            --retry-delay 5 \\\n            --retry-max-time 60 \\\n            --retry-connrefused)\n          if [[ \"$metrics\" ==  *\"opensearch_dashboards_up 0.0\"* ]]; then\n            echo \"ERROR: Prometheus exporter unavailable (connected to OSD on HTTP). Aborting...\" >&2\n            exit 1\n          fi\n\n          echo \"Snap defaults correctly applied as Exporter settings\"\n\n      - name: Test Logs slot\n        run: |\n          logs_slot_avail=$(sudo snap connections charmed-opensearch-dashboards | grep opensearch-dashboards:logs)\n\n          if [ ! \"$logs_slot_avail\" ]; then\n            echo \"ERROR: Logs slot is not available. Aborting...\" >&2\n            exit 1\n          fi\n",
    "source": "canonical/charmed-opensearch-dashboards-snap",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/canonical/charmed-opensearch-dashboards-snap/blob/2cee5eecb8914bc96808e3175aab8f6c1d38355f/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-05T01:46:13.811833Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including triggers, jobs (HUB, Benchmarks, Tests, GPU, Conda, Summary), and steps within each job.",
    "answer": "# Ultralytics YOLO , AGPL-3.0 license\n# YOLO Continuous Integration (CI) GitHub Actions tests\n\nname: Ultralytics CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * *'  # runs at 00:00 UTC every day\n  workflow_dispatch:\n    inputs:\n      hub:\n        description: 'Run HUB'\n        default: false\n        type: boolean\n      benchmarks:\n        description: 'Run Benchmarks'\n        default: false\n        type: boolean\n      tests:\n        description: 'Run Tests'\n        default: false\n        type: boolean\n      gpu:\n        description: 'Run GPU'\n        default: false\n        type: boolean\n      conda:\n        description: 'Run Conda'\n        default: false\n        type: boolean\n\njobs:\n  HUB:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.hub == 'true'))\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e . --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Test HUB training\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          from ultralytics import YOLO, hub\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          hub.login(api_key)\n          hub.reset_model(model_id)\n          model = YOLO('https://hub.ultralytics.com/models/' + model_id)\n          model.train()\n      - name: Test HUB inference API\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          import requests\n          import json\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          url = f\"https://api.ultralytics.com/v1/predict/{model_id}\"\n          headers = {\"x-api-key\": api_key}\n          data = {\"size\": 320, \"confidence\": 0.25, \"iou\": 0.45}\n          with open(\"ultralytics/assets/zidane.jpg\", \"rb\") as f:\n              response = requests.post(url, headers=headers, data=data, files={\"image\": f})\n          assert response.status_code == 200, f'Status code {response.status_code}, Reason {response.reason}'\n          print(json.dumps(response.json(), indent=2))\n\n  Benchmarks:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.benchmarks == 'true'\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.10']\n        model: [yolov8n]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e \".[export]\" \"coverage[toml]\" --extra-index-url https://download.pytorch.org/whl/cpu\n          # Fix SavedModel issue \"partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)\" in https://github.com/google/jax/discussions/14036\n          # pip install -U 'jax!=0.4.15' 'jaxlib!=0.4.15'\n          yolo export format=tflite imgsz=32 || true\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      #      - name: Benchmark DetectionModel\n      #        shell: bash\n      #        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}.pt' imgsz=160 verbose=0.318\n      - name: Benchmark SegmentationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-seg.pt' imgsz=160 verbose=0.286\n      - name: Benchmark ClassificationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-cls.pt' imgsz=160 verbose=0.166\n      - name: Benchmark PoseModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-pose.pt' imgsz=160 verbose=0.185\n      - name: Merge Coverage Reports\n        run: |\n          coverage xml -o coverage-benchmarks.xml\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Benchmarks\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n      - name: Benchmark Summary\n        run: |\n          cat benchmarks.log\n          echo \"$(cat benchmarks.log)\" >> $GITHUB_STEP_SUMMARY\n\n  Tests:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.tests == 'true'\n    timeout-minutes: 60\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n        torch: [latest]\n        include:\n          - os: ubuntu-latest\n            python-version: '3.8'  # torch 1.8.0 requires python >=3.6, <=3.8\n            torch: '1.8.0'  # min torch version CI https://pypi.org/project/torchvision/\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |  # CoreML must be installed before export due to protobuf error from AutoInstall\n          python -m pip install --upgrade pip wheel\n          torch=\"\"\n          if [ \"${{ matrix.torch }}\" == \"1.8.0\" ]; then\n              torch=\"torch==1.8.0 torchvision==0.9.0\"\n          fi\n          pip install -e . $torch pytest-cov \"coremltools>=7.0\" --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        shell: bash  # for Windows compatibility\n        run: |\n          slow=\"\"\n          if [[ \"${{ github.event_name }}\" == \"schedule\" ]] || [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n              pip install mlflow pycocotools 'ray[tune]'\n              slow=\"--slow\"\n          fi\n          pytest $slow --cov=ultralytics/ --cov-report xml tests/\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics' # && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Tests\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  GPU:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name != 'workflow_dispatch' || github.event.inputs.gpu == 'true')\n    timeout-minutes: 60\n    runs-on: gpu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install requirements\n        run: pip install -e .\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        run: pytest --cov=ultralytics/ --cov-report xml tests/test_cuda.py\n      - name: Upload Coverage Reports to CodeCov\n        uses: codecov/codecov-action@v3\n        with:\n          flags: GPU\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  Conda:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule_disabled' || github.event.inputs.conda == 'true')\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n      - uses: conda-incubator/setup-miniconda@v3\n        with:\n          python-version: ${{ matrix.python-version }}\n          mamba-version: \"*\"\n          channels: conda-forge,defaults\n          channel-priority: true\n          activate-environment: anaconda-client-env\n      - name: Install Libmamba\n        run: |\n          conda config --set solver libmamba\n      - name: Install Ultralytics package from conda-forge\n        run: |\n          conda install -c pytorch -c conda-forge pytorch torchvision ultralytics openvino\n      - name: Install pip packages\n        run: |\n          pip install pytest 'coremltools>=7.0'\n      - name: Check environment\n        run: |\n          conda list\n      - name: Test CLI\n        run: |\n          yolo predict model=yolov8n.pt imgsz=320\n          yolo train model=yolov8n.pt data=coco8.yaml epochs=1 imgsz=32\n          yolo val model=yolov8n.pt data=coco8.yaml imgsz=32\n          yolo export model=yolov8n.pt format=torchscript imgsz=160\n      - name: Test Python\n        run: |\n          python -c \"\n          from ultralytics import YOLO\n          model = YOLO('yolov8n.pt')\n          results = model.train(data='coco8.yaml', epochs=3, imgsz=160)\n          results = model.val(imgsz=160)\n          results = model.predict(imgsz=160)\n          results = model.export(format='onnx', imgsz=160)\n          \"\n      - name: PyTest\n        run: |\n          git clone https://github.com/ultralytics/ultralytics\n          pytest ultralytics/tests\n\n  Summary:\n    runs-on: ubuntu-latest\n    needs: [HUB, Benchmarks, Tests, GPU, Conda] # Add job names that you want to check for failure\n    if: always() # This ensures the job runs even if previous jobs fail\n    steps:\n      - name: Check for failure and notify\n        if: (needs.HUB.result == 'failure' || needs.Benchmarks.result == 'failure' || needs.Tests.result == 'failure' || needs.GPU.result == 'failure' || needs.Conda.result == 'failure') && github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push')\n        uses: slackapi/slack-github-action@v1.24.0\n        with:\n          payload: |\n            {\"text\": \"<!channel> GitHub Actions error for ${{ github.workflow }} \\n\\n\\n*Repository:* https://github.com/${{ github.repository }}\\n*Action:* https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\\n*Author:* ${{ github.actor }}\\n*Event:* ${{ github.event_name }}\\n\"}\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_YOLO }}\n",
    "source": "johnvonueman/my_rtdetr",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/johnvonueman/my_rtdetr/blob/f34ec492a5ca78546414261943e95bbca62fb607/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-06T01:46:01.114675Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this Ultralytics CI workflow?",
    "answer": "# Ultralytics YOLO , AGPL-3.0 license\n# YOLO Continuous Integration (CI) GitHub Actions tests\n\nname: Ultralytics CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * *'  # runs at 00:00 UTC every day\n  workflow_dispatch:\n    inputs:\n      hub:\n        description: 'Run HUB'\n        default: false\n        type: boolean\n      benchmarks:\n        description: 'Run Benchmarks'\n        default: false\n        type: boolean\n      tests:\n        description: 'Run Tests'\n        default: false\n        type: boolean\n      gpu:\n        description: 'Run GPU'\n        default: false\n        type: boolean\n      conda:\n        description: 'Run Conda'\n        default: false\n        type: boolean\n\njobs:\n  HUB:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.hub == 'true'))\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e . --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Test HUB training\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          from ultralytics import YOLO, hub\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          hub.login(api_key)\n          hub.reset_model(model_id)\n          model = YOLO('https://hub.ultralytics.com/models/' + model_id)\n          model.train()\n      - name: Test HUB inference API\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          import requests\n          import json\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          url = f\"https://api.ultralytics.com/v1/predict/{model_id}\"\n          headers = {\"x-api-key\": api_key}\n          data = {\"size\": 320, \"confidence\": 0.25, \"iou\": 0.45}\n          with open(\"ultralytics/assets/zidane.jpg\", \"rb\") as f:\n              response = requests.post(url, headers=headers, data=data, files={\"image\": f})\n          assert response.status_code == 200, f'Status code {response.status_code}, Reason {response.reason}'\n          print(json.dumps(response.json(), indent=2))\n\n  Benchmarks:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.benchmarks == 'true'\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.10']\n        model: [yolov8n]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e \".[export]\" \"coverage[toml]\" --extra-index-url https://download.pytorch.org/whl/cpu\n          # Fix SavedModel issue \"partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)\" in https://github.com/google/jax/discussions/14036\n          # pip install -U 'jax!=0.4.15' 'jaxlib!=0.4.15'\n          yolo export format=tflite imgsz=32 || true\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      #      - name: Benchmark DetectionModel\n      #        shell: bash\n      #        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}.pt' imgsz=160 verbose=0.318\n      - name: Benchmark SegmentationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-seg.pt' imgsz=160 verbose=0.286\n      - name: Benchmark ClassificationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-cls.pt' imgsz=160 verbose=0.166\n      - name: Benchmark PoseModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-pose.pt' imgsz=160 verbose=0.185\n      - name: Merge Coverage Reports\n        run: |\n          coverage xml -o coverage-benchmarks.xml\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Benchmarks\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n      - name: Benchmark Summary\n        run: |\n          cat benchmarks.log\n          echo \"$(cat benchmarks.log)\" >> $GITHUB_STEP_SUMMARY\n\n  Tests:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.tests == 'true'\n    timeout-minutes: 60\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n        torch: [latest]\n        include:\n          - os: ubuntu-latest\n            python-version: '3.8'  # torch 1.8.0 requires python >=3.6, <=3.8\n            torch: '1.8.0'  # min torch version CI https://pypi.org/project/torchvision/\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |  # CoreML must be installed before export due to protobuf error from AutoInstall\n          python -m pip install --upgrade pip wheel\n          torch=\"\"\n          if [ \"${{ matrix.torch }}\" == \"1.8.0\" ]; then\n              torch=\"torch==1.8.0 torchvision==0.9.0\"\n          fi\n          pip install -e . $torch pytest-cov \"coremltools>=7.0\" --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        shell: bash  # for Windows compatibility\n        run: |\n          slow=\"\"\n          if [[ \"${{ github.event_name }}\" == \"schedule\" ]] || [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n              pip install mlflow pycocotools 'ray[tune]'\n              slow=\"--slow\"\n          fi\n          pytest $slow --cov=ultralytics/ --cov-report xml tests/\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics' # && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Tests\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  GPU:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name != 'workflow_dispatch' || github.event.inputs.gpu == 'true')\n    timeout-minutes: 60\n    runs-on: gpu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install requirements\n        run: pip install -e .\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        run: pytest --cov=ultralytics/ --cov-report xml tests/test_cuda.py\n      - name: Upload Coverage Reports to CodeCov\n        uses: codecov/codecov-action@v3\n        with:\n          flags: GPU\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  Conda:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule_disabled' || github.event.inputs.conda == 'true')\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n      - uses: conda-incubator/setup-miniconda@v3\n        with:\n          python-version: ${{ matrix.python-version }}\n          mamba-version: \"*\"\n          channels: conda-forge,defaults\n          channel-priority: true\n          activate-environment: anaconda-client-env\n      - name: Install Libmamba\n        run: |\n          conda config --set solver libmamba\n      - name: Install Ultralytics package from conda-forge\n        run: |\n          conda install -c pytorch -c conda-forge pytorch torchvision ultralytics openvino\n      - name: Install pip packages\n        run: |\n          pip install pytest 'coremltools>=7.0'\n      - name: Check environment\n        run: |\n          conda list\n      - name: Test CLI\n        run: |\n          yolo predict model=yolov8n.pt imgsz=320\n          yolo train model=yolov8n.pt data=coco8.yaml epochs=1 imgsz=32\n          yolo val model=yolov8n.pt data=coco8.yaml imgsz=32\n          yolo export model=yolov8n.pt format=torchscript imgsz=160\n      - name: Test Python\n        run: |\n          python -c \"\n          from ultralytics import YOLO\n          model = YOLO('yolov8n.pt')\n          results = model.train(data='coco8.yaml', epochs=3, imgsz=160)\n          results = model.val(imgsz=160)\n          results = model.predict(imgsz=160)\n          results = model.export(format='onnx', imgsz=160)\n          \"\n      - name: PyTest\n        run: |\n          git clone https://github.com/ultralytics/ultralytics\n          pytest ultralytics/tests\n\n  Summary:\n    runs-on: ubuntu-latest\n    needs: [HUB, Benchmarks, Tests, GPU, Conda] # Add job names that you want to check for failure\n    if: always() # This ensures the job runs even if previous jobs fail\n    steps:\n      - name: Check for failure and notify\n        if: (needs.HUB.result == 'failure' || needs.Benchmarks.result == 'failure' || needs.Tests.result == 'failure' || needs.GPU.result == 'failure' || needs.Conda.result == 'failure') && github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push')\n        uses: slackapi/slack-github-action@v1.24.0\n        with:\n          payload: |\n            {\"text\": \"<!channel> GitHub Actions error for ${{ github.workflow }} \\n\\n\\n*Repository:* https://github.com/${{ github.repository }}\\n*Action:* https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\\n*Author:* ${{ github.actor }}\\n*Event:* ${{ github.event_name }}\\n\"}\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_YOLO }}\n",
    "source": "johnvonueman/my_rtdetr",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/johnvonueman/my_rtdetr/blob/f34ec492a5ca78546414261943e95bbca62fb607/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-06T01:46:01.772765Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run concurrently, and what dependencies exist between jobs or steps in this workflow?",
    "answer": "# Ultralytics YOLO , AGPL-3.0 license\n# YOLO Continuous Integration (CI) GitHub Actions tests\n\nname: Ultralytics CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * *'  # runs at 00:00 UTC every day\n  workflow_dispatch:\n    inputs:\n      hub:\n        description: 'Run HUB'\n        default: false\n        type: boolean\n      benchmarks:\n        description: 'Run Benchmarks'\n        default: false\n        type: boolean\n      tests:\n        description: 'Run Tests'\n        default: false\n        type: boolean\n      gpu:\n        description: 'Run GPU'\n        default: false\n        type: boolean\n      conda:\n        description: 'Run Conda'\n        default: false\n        type: boolean\n\njobs:\n  HUB:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.hub == 'true'))\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e . --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Test HUB training\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          from ultralytics import YOLO, hub\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          hub.login(api_key)\n          hub.reset_model(model_id)\n          model = YOLO('https://hub.ultralytics.com/models/' + model_id)\n          model.train()\n      - name: Test HUB inference API\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          import requests\n          import json\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          url = f\"https://api.ultralytics.com/v1/predict/{model_id}\"\n          headers = {\"x-api-key\": api_key}\n          data = {\"size\": 320, \"confidence\": 0.25, \"iou\": 0.45}\n          with open(\"ultralytics/assets/zidane.jpg\", \"rb\") as f:\n              response = requests.post(url, headers=headers, data=data, files={\"image\": f})\n          assert response.status_code == 200, f'Status code {response.status_code}, Reason {response.reason}'\n          print(json.dumps(response.json(), indent=2))\n\n  Benchmarks:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.benchmarks == 'true'\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.10']\n        model: [yolov8n]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e \".[export]\" \"coverage[toml]\" --extra-index-url https://download.pytorch.org/whl/cpu\n          # Fix SavedModel issue \"partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)\" in https://github.com/google/jax/discussions/14036\n          # pip install -U 'jax!=0.4.15' 'jaxlib!=0.4.15'\n          yolo export format=tflite imgsz=32 || true\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      #      - name: Benchmark DetectionModel\n      #        shell: bash\n      #        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}.pt' imgsz=160 verbose=0.318\n      - name: Benchmark SegmentationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-seg.pt' imgsz=160 verbose=0.286\n      - name: Benchmark ClassificationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-cls.pt' imgsz=160 verbose=0.166\n      - name: Benchmark PoseModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-pose.pt' imgsz=160 verbose=0.185\n      - name: Merge Coverage Reports\n        run: |\n          coverage xml -o coverage-benchmarks.xml\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Benchmarks\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n      - name: Benchmark Summary\n        run: |\n          cat benchmarks.log\n          echo \"$(cat benchmarks.log)\" >> $GITHUB_STEP_SUMMARY\n\n  Tests:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.tests == 'true'\n    timeout-minutes: 60\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n        torch: [latest]\n        include:\n          - os: ubuntu-latest\n            python-version: '3.8'  # torch 1.8.0 requires python >=3.6, <=3.8\n            torch: '1.8.0'  # min torch version CI https://pypi.org/project/torchvision/\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |  # CoreML must be installed before export due to protobuf error from AutoInstall\n          python -m pip install --upgrade pip wheel\n          torch=\"\"\n          if [ \"${{ matrix.torch }}\" == \"1.8.0\" ]; then\n              torch=\"torch==1.8.0 torchvision==0.9.0\"\n          fi\n          pip install -e . $torch pytest-cov \"coremltools>=7.0\" --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        shell: bash  # for Windows compatibility\n        run: |\n          slow=\"\"\n          if [[ \"${{ github.event_name }}\" == \"schedule\" ]] || [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n              pip install mlflow pycocotools 'ray[tune]'\n              slow=\"--slow\"\n          fi\n          pytest $slow --cov=ultralytics/ --cov-report xml tests/\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics' # && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Tests\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  GPU:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name != 'workflow_dispatch' || github.event.inputs.gpu == 'true')\n    timeout-minutes: 60\n    runs-on: gpu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install requirements\n        run: pip install -e .\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        run: pytest --cov=ultralytics/ --cov-report xml tests/test_cuda.py\n      - name: Upload Coverage Reports to CodeCov\n        uses: codecov/codecov-action@v3\n        with:\n          flags: GPU\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  Conda:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule_disabled' || github.event.inputs.conda == 'true')\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n      - uses: conda-incubator/setup-miniconda@v3\n        with:\n          python-version: ${{ matrix.python-version }}\n          mamba-version: \"*\"\n          channels: conda-forge,defaults\n          channel-priority: true\n          activate-environment: anaconda-client-env\n      - name: Install Libmamba\n        run: |\n          conda config --set solver libmamba\n      - name: Install Ultralytics package from conda-forge\n        run: |\n          conda install -c pytorch -c conda-forge pytorch torchvision ultralytics openvino\n      - name: Install pip packages\n        run: |\n          pip install pytest 'coremltools>=7.0'\n      - name: Check environment\n        run: |\n          conda list\n      - name: Test CLI\n        run: |\n          yolo predict model=yolov8n.pt imgsz=320\n          yolo train model=yolov8n.pt data=coco8.yaml epochs=1 imgsz=32\n          yolo val model=yolov8n.pt data=coco8.yaml imgsz=32\n          yolo export model=yolov8n.pt format=torchscript imgsz=160\n      - name: Test Python\n        run: |\n          python -c \"\n          from ultralytics import YOLO\n          model = YOLO('yolov8n.pt')\n          results = model.train(data='coco8.yaml', epochs=3, imgsz=160)\n          results = model.val(imgsz=160)\n          results = model.predict(imgsz=160)\n          results = model.export(format='onnx', imgsz=160)\n          \"\n      - name: PyTest\n        run: |\n          git clone https://github.com/ultralytics/ultralytics\n          pytest ultralytics/tests\n\n  Summary:\n    runs-on: ubuntu-latest\n    needs: [HUB, Benchmarks, Tests, GPU, Conda] # Add job names that you want to check for failure\n    if: always() # This ensures the job runs even if previous jobs fail\n    steps:\n      - name: Check for failure and notify\n        if: (needs.HUB.result == 'failure' || needs.Benchmarks.result == 'failure' || needs.Tests.result == 'failure' || needs.GPU.result == 'failure' || needs.Conda.result == 'failure') && github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push')\n        uses: slackapi/slack-github-action@v1.24.0\n        with:\n          payload: |\n            {\"text\": \"<!channel> GitHub Actions error for ${{ github.workflow }} \\n\\n\\n*Repository:* https://github.com/${{ github.repository }}\\n*Action:* https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\\n*Author:* ${{ github.actor }}\\n*Event:* ${{ github.event_name }}\\n\"}\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_YOLO }}\n",
    "source": "johnvonueman/my_rtdetr",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/johnvonueman/my_rtdetr/blob/f34ec492a5ca78546414261943e95bbca62fb607/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-06T01:46:02.725036Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `ULTRALYTICS_HUB_API_KEY`, `ULTRALYTICS_HUB_MODEL_ID`, and `CODECOV_TOKEN` secrets used within the workflow?",
    "answer": "# Ultralytics YOLO , AGPL-3.0 license\n# YOLO Continuous Integration (CI) GitHub Actions tests\n\nname: Ultralytics CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * *'  # runs at 00:00 UTC every day\n  workflow_dispatch:\n    inputs:\n      hub:\n        description: 'Run HUB'\n        default: false\n        type: boolean\n      benchmarks:\n        description: 'Run Benchmarks'\n        default: false\n        type: boolean\n      tests:\n        description: 'Run Tests'\n        default: false\n        type: boolean\n      gpu:\n        description: 'Run GPU'\n        default: false\n        type: boolean\n      conda:\n        description: 'Run Conda'\n        default: false\n        type: boolean\n\njobs:\n  HUB:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.hub == 'true'))\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e . --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Test HUB training\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          from ultralytics import YOLO, hub\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          hub.login(api_key)\n          hub.reset_model(model_id)\n          model = YOLO('https://hub.ultralytics.com/models/' + model_id)\n          model.train()\n      - name: Test HUB inference API\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          import requests\n          import json\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          url = f\"https://api.ultralytics.com/v1/predict/{model_id}\"\n          headers = {\"x-api-key\": api_key}\n          data = {\"size\": 320, \"confidence\": 0.25, \"iou\": 0.45}\n          with open(\"ultralytics/assets/zidane.jpg\", \"rb\") as f:\n              response = requests.post(url, headers=headers, data=data, files={\"image\": f})\n          assert response.status_code == 200, f'Status code {response.status_code}, Reason {response.reason}'\n          print(json.dumps(response.json(), indent=2))\n\n  Benchmarks:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.benchmarks == 'true'\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.10']\n        model: [yolov8n]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e \".[export]\" \"coverage[toml]\" --extra-index-url https://download.pytorch.org/whl/cpu\n          # Fix SavedModel issue \"partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)\" in https://github.com/google/jax/discussions/14036\n          # pip install -U 'jax!=0.4.15' 'jaxlib!=0.4.15'\n          yolo export format=tflite imgsz=32 || true\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      #      - name: Benchmark DetectionModel\n      #        shell: bash\n      #        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}.pt' imgsz=160 verbose=0.318\n      - name: Benchmark SegmentationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-seg.pt' imgsz=160 verbose=0.286\n      - name: Benchmark ClassificationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-cls.pt' imgsz=160 verbose=0.166\n      - name: Benchmark PoseModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-pose.pt' imgsz=160 verbose=0.185\n      - name: Merge Coverage Reports\n        run: |\n          coverage xml -o coverage-benchmarks.xml\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Benchmarks\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n      - name: Benchmark Summary\n        run: |\n          cat benchmarks.log\n          echo \"$(cat benchmarks.log)\" >> $GITHUB_STEP_SUMMARY\n\n  Tests:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.tests == 'true'\n    timeout-minutes: 60\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n        torch: [latest]\n        include:\n          - os: ubuntu-latest\n            python-version: '3.8'  # torch 1.8.0 requires python >=3.6, <=3.8\n            torch: '1.8.0'  # min torch version CI https://pypi.org/project/torchvision/\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |  # CoreML must be installed before export due to protobuf error from AutoInstall\n          python -m pip install --upgrade pip wheel\n          torch=\"\"\n          if [ \"${{ matrix.torch }}\" == \"1.8.0\" ]; then\n              torch=\"torch==1.8.0 torchvision==0.9.0\"\n          fi\n          pip install -e . $torch pytest-cov \"coremltools>=7.0\" --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        shell: bash  # for Windows compatibility\n        run: |\n          slow=\"\"\n          if [[ \"${{ github.event_name }}\" == \"schedule\" ]] || [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n              pip install mlflow pycocotools 'ray[tune]'\n              slow=\"--slow\"\n          fi\n          pytest $slow --cov=ultralytics/ --cov-report xml tests/\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics' # && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Tests\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  GPU:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name != 'workflow_dispatch' || github.event.inputs.gpu == 'true')\n    timeout-minutes: 60\n    runs-on: gpu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install requirements\n        run: pip install -e .\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        run: pytest --cov=ultralytics/ --cov-report xml tests/test_cuda.py\n      - name: Upload Coverage Reports to CodeCov\n        uses: codecov/codecov-action@v3\n        with:\n          flags: GPU\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  Conda:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule_disabled' || github.event.inputs.conda == 'true')\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n      - uses: conda-incubator/setup-miniconda@v3\n        with:\n          python-version: ${{ matrix.python-version }}\n          mamba-version: \"*\"\n          channels: conda-forge,defaults\n          channel-priority: true\n          activate-environment: anaconda-client-env\n      - name: Install Libmamba\n        run: |\n          conda config --set solver libmamba\n      - name: Install Ultralytics package from conda-forge\n        run: |\n          conda install -c pytorch -c conda-forge pytorch torchvision ultralytics openvino\n      - name: Install pip packages\n        run: |\n          pip install pytest 'coremltools>=7.0'\n      - name: Check environment\n        run: |\n          conda list\n      - name: Test CLI\n        run: |\n          yolo predict model=yolov8n.pt imgsz=320\n          yolo train model=yolov8n.pt data=coco8.yaml epochs=1 imgsz=32\n          yolo val model=yolov8n.pt data=coco8.yaml imgsz=32\n          yolo export model=yolov8n.pt format=torchscript imgsz=160\n      - name: Test Python\n        run: |\n          python -c \"\n          from ultralytics import YOLO\n          model = YOLO('yolov8n.pt')\n          results = model.train(data='coco8.yaml', epochs=3, imgsz=160)\n          results = model.val(imgsz=160)\n          results = model.predict(imgsz=160)\n          results = model.export(format='onnx', imgsz=160)\n          \"\n      - name: PyTest\n        run: |\n          git clone https://github.com/ultralytics/ultralytics\n          pytest ultralytics/tests\n\n  Summary:\n    runs-on: ubuntu-latest\n    needs: [HUB, Benchmarks, Tests, GPU, Conda] # Add job names that you want to check for failure\n    if: always() # This ensures the job runs even if previous jobs fail\n    steps:\n      - name: Check for failure and notify\n        if: (needs.HUB.result == 'failure' || needs.Benchmarks.result == 'failure' || needs.Tests.result == 'failure' || needs.GPU.result == 'failure' || needs.Conda.result == 'failure') && github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push')\n        uses: slackapi/slack-github-action@v1.24.0\n        with:\n          payload: |\n            {\"text\": \"<!channel> GitHub Actions error for ${{ github.workflow }} \\n\\n\\n*Repository:* https://github.com/${{ github.repository }}\\n*Action:* https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\\n*Author:* ${{ github.actor }}\\n*Event:* ${{ github.event_name }}\\n\"}\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_YOLO }}\n",
    "source": "johnvonueman/my_rtdetr",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/johnvonueman/my_rtdetr/blob/f34ec492a5ca78546414261943e95bbca62fb607/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-06T01:46:03.738901Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Ultralytics CI workflow?",
    "answer": "# Ultralytics YOLO , AGPL-3.0 license\n# YOLO Continuous Integration (CI) GitHub Actions tests\n\nname: Ultralytics CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * *'  # runs at 00:00 UTC every day\n  workflow_dispatch:\n    inputs:\n      hub:\n        description: 'Run HUB'\n        default: false\n        type: boolean\n      benchmarks:\n        description: 'Run Benchmarks'\n        default: false\n        type: boolean\n      tests:\n        description: 'Run Tests'\n        default: false\n        type: boolean\n      gpu:\n        description: 'Run GPU'\n        default: false\n        type: boolean\n      conda:\n        description: 'Run Conda'\n        default: false\n        type: boolean\n\njobs:\n  HUB:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push' || (github.event_name == 'workflow_dispatch' && github.event.inputs.hub == 'true'))\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e . --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Test HUB training\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          from ultralytics import YOLO, hub\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          hub.login(api_key)\n          hub.reset_model(model_id)\n          model = YOLO('https://hub.ultralytics.com/models/' + model_id)\n          model.train()\n      - name: Test HUB inference API\n        shell: python\n        env:\n          API_KEY: ${{ secrets.ULTRALYTICS_HUB_API_KEY }}\n          MODEL_ID: ${{ secrets.ULTRALYTICS_HUB_MODEL_ID }}\n        run: |\n          import os\n          import requests\n          import json\n          api_key, model_id = os.environ['API_KEY'], os.environ['MODEL_ID']\n          url = f\"https://api.ultralytics.com/v1/predict/{model_id}\"\n          headers = {\"x-api-key\": api_key}\n          data = {\"size\": 320, \"confidence\": 0.25, \"iou\": 0.45}\n          with open(\"ultralytics/assets/zidane.jpg\", \"rb\") as f:\n              response = requests.post(url, headers=headers, data=data, files={\"image\": f})\n          assert response.status_code == 200, f'Status code {response.status_code}, Reason {response.reason}'\n          print(json.dumps(response.json(), indent=2))\n\n  Benchmarks:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.benchmarks == 'true'\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.10']\n        model: [yolov8n]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |\n          python -m pip install --upgrade pip wheel\n          pip install -e \".[export]\" \"coverage[toml]\" --extra-index-url https://download.pytorch.org/whl/cpu\n          # Fix SavedModel issue \"partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)\" in https://github.com/google/jax/discussions/14036\n          # pip install -U 'jax!=0.4.15' 'jaxlib!=0.4.15'\n          yolo export format=tflite imgsz=32 || true\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      #      - name: Benchmark DetectionModel\n      #        shell: bash\n      #        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}.pt' imgsz=160 verbose=0.318\n      - name: Benchmark SegmentationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-seg.pt' imgsz=160 verbose=0.286\n      - name: Benchmark ClassificationModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-cls.pt' imgsz=160 verbose=0.166\n      - name: Benchmark PoseModel\n        shell: bash\n        run: coverage run -a --source=ultralytics -m ultralytics.cfg.__init__ benchmark model='path with spaces/${{ matrix.model }}-pose.pt' imgsz=160 verbose=0.185\n      - name: Merge Coverage Reports\n        run: |\n          coverage xml -o coverage-benchmarks.xml\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Benchmarks\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n      - name: Benchmark Summary\n        run: |\n          cat benchmarks.log\n          echo \"$(cat benchmarks.log)\" >> $GITHUB_STEP_SUMMARY\n\n  Tests:\n    if: github.event_name != 'workflow_dispatch' || github.event.inputs.tests == 'true'\n    timeout-minutes: 60\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n        torch: [latest]\n        include:\n          - os: ubuntu-latest\n            python-version: '3.8'  # torch 1.8.0 requires python >=3.6, <=3.8\n            torch: '1.8.0'  # min torch version CI https://pypi.org/project/torchvision/\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip' # caching pip dependencies\n      - name: Install requirements\n        shell: bash  # for Windows compatibility\n        run: |  # CoreML must be installed before export due to protobuf error from AutoInstall\n          python -m pip install --upgrade pip wheel\n          torch=\"\"\n          if [ \"${{ matrix.torch }}\" == \"1.8.0\" ]; then\n              torch=\"torch==1.8.0 torchvision==0.9.0\"\n          fi\n          pip install -e . $torch pytest-cov \"coremltools>=7.0\" --extra-index-url https://download.pytorch.org/whl/cpu\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        shell: bash  # for Windows compatibility\n        run: |\n          slow=\"\"\n          if [[ \"${{ github.event_name }}\" == \"schedule\" ]] || [[ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]]; then\n              pip install mlflow pycocotools 'ray[tune]'\n              slow=\"--slow\"\n          fi\n          pytest $slow --cov=ultralytics/ --cov-report xml tests/\n      - name: Upload Coverage Reports to CodeCov\n        if: github.repository == 'ultralytics/ultralytics' # && matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'\n        uses: codecov/codecov-action@v3\n        with:\n          flags: Tests\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  GPU:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name != 'workflow_dispatch' || github.event.inputs.gpu == 'true')\n    timeout-minutes: 60\n    runs-on: gpu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install requirements\n        run: pip install -e .\n      - name: Check environment\n        run: |\n          yolo checks\n          pip list\n      - name: Pytest tests\n        run: pytest --cov=ultralytics/ --cov-report xml tests/test_cuda.py\n      - name: Upload Coverage Reports to CodeCov\n        uses: codecov/codecov-action@v3\n        with:\n          flags: GPU\n        env:\n          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}\n\n  Conda:\n    if: github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule_disabled' || github.event.inputs.conda == 'true')\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest]\n        python-version: ['3.11']\n    defaults:\n      run:\n        shell: bash -el {0}\n    steps:\n      - uses: conda-incubator/setup-miniconda@v3\n        with:\n          python-version: ${{ matrix.python-version }}\n          mamba-version: \"*\"\n          channels: conda-forge,defaults\n          channel-priority: true\n          activate-environment: anaconda-client-env\n      - name: Install Libmamba\n        run: |\n          conda config --set solver libmamba\n      - name: Install Ultralytics package from conda-forge\n        run: |\n          conda install -c pytorch -c conda-forge pytorch torchvision ultralytics openvino\n      - name: Install pip packages\n        run: |\n          pip install pytest 'coremltools>=7.0'\n      - name: Check environment\n        run: |\n          conda list\n      - name: Test CLI\n        run: |\n          yolo predict model=yolov8n.pt imgsz=320\n          yolo train model=yolov8n.pt data=coco8.yaml epochs=1 imgsz=32\n          yolo val model=yolov8n.pt data=coco8.yaml imgsz=32\n          yolo export model=yolov8n.pt format=torchscript imgsz=160\n      - name: Test Python\n        run: |\n          python -c \"\n          from ultralytics import YOLO\n          model = YOLO('yolov8n.pt')\n          results = model.train(data='coco8.yaml', epochs=3, imgsz=160)\n          results = model.val(imgsz=160)\n          results = model.predict(imgsz=160)\n          results = model.export(format='onnx', imgsz=160)\n          \"\n      - name: PyTest\n        run: |\n          git clone https://github.com/ultralytics/ultralytics\n          pytest ultralytics/tests\n\n  Summary:\n    runs-on: ubuntu-latest\n    needs: [HUB, Benchmarks, Tests, GPU, Conda] # Add job names that you want to check for failure\n    if: always() # This ensures the job runs even if previous jobs fail\n    steps:\n      - name: Check for failure and notify\n        if: (needs.HUB.result == 'failure' || needs.Benchmarks.result == 'failure' || needs.Tests.result == 'failure' || needs.GPU.result == 'failure' || needs.Conda.result == 'failure') && github.repository == 'ultralytics/ultralytics' && (github.event_name == 'schedule' || github.event_name == 'push')\n        uses: slackapi/slack-github-action@v1.24.0\n        with:\n          payload: |\n            {\"text\": \"<!channel> GitHub Actions error for ${{ github.workflow }} \\n\\n\\n*Repository:* https://github.com/${{ github.repository }}\\n*Action:* https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\\n*Author:* ${{ github.actor }}\\n*Event:* ${{ github.event_name }}\\n\"}\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL_YOLO }}\n",
    "source": "johnvonueman/my_rtdetr",
    "path": ".github/workflows/ci.yaml",
    "url": "https://github.com/johnvonueman/my_rtdetr/blob/f34ec492a5ca78546414261943e95bbca62fb607/.github/workflows/ci.yaml",
    "retrieved_at": "2025-11-06T01:46:04.468452Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML file, including triggers, jobs, steps, and conditional logic.",
    "answer": "---\nname: Publish Release\n\non:\n  workflow_dispatch:\n  release:\n    types: [published]\n  schedule:\n    - cron: \"0 2 * * *\"\n\npermissions:\n  contents: read\n\njobs:\n  init:\n    name: Initialize build\n    runs-on: ubuntu-latest\n    outputs:\n      tag: ${{ steps.tag.outputs.tag }}\n      branch_build: ${{ steps.tag.outputs.branch_build }}\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Get tag\n        id: tag\n        # yamllint disable rule:line-length\n        run: |\n          if [[ \"${{ github.event_name }}\" = \"release\" ]]; then\n            TAG=\"${{ github.event.release.tag_name}}\"\n            BRANCH_BUILD=\"false\"\n          else\n            TAG=$(cat esphome/const.py | sed -n -E \"s/^__version__\\s+=\\s+\\\"(.+)\\\"$/\\1/p\")\n            today=\"$(date --utc '+%Y%m%d')\"\n            TAG=\"${TAG}${today}\"\n            BRANCH=${GITHUB_REF#refs/heads/}\n            if [[ \"$BRANCH\" != \"dev\" ]]; then\n              TAG=\"${TAG}-${BRANCH}\"\n              BRANCH_BUILD=\"true\"\n            else\n              BRANCH_BUILD=\"false\"\n            fi\n          fi\n          echo \"tag=${TAG}\" >> $GITHUB_OUTPUT\n          echo \"branch_build=${BRANCH_BUILD}\" >> $GITHUB_OUTPUT\n        # yamllint enable rule:line-length\n\n  deploy-pypi:\n    name: Build and publish to PyPi\n    if: github.repository == 'esphome/esphome' && github.event_name == 'release'\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.x\"\n      - name: Set up python environment\n        env:\n          ESPHOME_NO_VENV: 1\n        run: script/setup\n      - name: Build\n        run: |-\n          pip3 install build\n          python3 -m build\n      - name: Publish\n        uses: pypa/gh-action-pypi-publish@v1.12.4\n\n  deploy-docker:\n    name: Build ESPHome ${{ matrix.platform }}\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    runs-on: ubuntu-latest\n    needs: [init]\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - linux/amd64\n          - linux/arm64\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.9\"\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n      - name: Set up QEMU\n        if: matrix.platform != 'linux/amd64'\n        uses: docker/setup-qemu-action@v3.4.0\n\n      - name: Log in to docker hub\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build docker\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: docker\n          baseimg: docker\n          suffix: \"\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build ha-addon\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: hassio\n          baseimg: hassio\n          suffix: \"hassio\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build lint\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: lint\n          baseimg: docker\n          suffix: lint\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Sanitize platform name\n        id: sanitize\n        run: |\n          echo \"${{ matrix.platform }}\" | sed 's|/|-|g' > /tmp/platform\n          echo name=$(cat /tmp/platform) >> $GITHUB_OUTPUT\n\n      - name: Upload digests\n        uses: actions/upload-artifact@v4.6.0\n        with:\n          name: digests-${{ steps.sanitize.outputs.name }}\n          path: /tmp/digests\n          retention-days: 1\n\n  deploy-manifest:\n    name: Publish ESPHome ${{ matrix.image.title }} to ${{ matrix.registry }}\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-docker\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    strategy:\n      fail-fast: false\n      matrix:\n        image:\n          - title: \"ha-addon\"\n            target: \"hassio\"\n            suffix: \"hassio\"\n          - title: \"docker\"\n            target: \"docker\"\n            suffix: \"\"\n          - title: \"lint\"\n            target: \"lint\"\n            suffix: \"lint\"\n        registry:\n          - ghcr\n          - dockerhub\n    steps:\n      - uses: actions/checkout@v4.1.7\n\n      - name: Download digests\n        uses: actions/download-artifact@v4.1.8\n        with:\n          pattern: digests-*\n          path: /tmp/digests\n          merge-multiple: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n\n      - name: Log in to docker hub\n        if: matrix.registry == 'dockerhub'\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        if: matrix.registry == 'ghcr'\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Generate short tags\n        id: tags\n        run: |\n          output=$(docker/generate_tags.py \\\n            --tag \"${{ needs.init.outputs.tag }}\" \\\n            --suffix \"${{ matrix.image.suffix }}\" \\\n            --registry \"${{ matrix.registry }}\")\n          echo $output\n          for l in $output; do\n            echo $l >> $GITHUB_OUTPUT\n          done\n\n      - name: Create manifest list and push\n        working-directory: /tmp/digests/${{ matrix.image.target }}/${{ matrix.registry }}\n        run: |\n          docker buildx imagetools create $(jq -Rcnr 'inputs | . / \",\" | map(\"-t \" + .) | join(\" \")' <<< \"${{ steps.tags.outputs.tags}}\") \\\n            $(printf '${{ steps.tags.outputs.image }}@sha256:%s ' *)\n\n  deploy-ha-addon-repo:\n    if: github.repository == 'esphome/esphome' && needs.init.outputs.branch_build == 'false'\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-manifest\n    steps:\n      - name: Trigger Workflow\n        uses: actions/github-script@v7.0.1\n        with:\n          github-token: ${{ secrets.DEPLOY_HA_ADDON_REPO_TOKEN }}\n          script: |\n            let description = \"ESPHome\";\n            if (context.eventName == \"release\") {\n              description = ${{ toJSON(github.event.release.body) }};\n            }\n            github.rest.actions.createWorkflowDispatch({\n              owner: \"esphome\",\n              repo: \"home-assistant-addon\",\n              workflow_id: \"bump-version.yml\",\n              ref: \"main\",\n              inputs: {\n                version: \"${{ needs.init.outputs.tag }}\",\n                content: description\n              }\n            })\n",
    "source": "gkasprow/esphome",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/gkasprow/esphome/blob/c1992b2cbffff11a4b1ab6016ff1c3ced28bcce0/.github/workflows/release.yml",
    "retrieved_at": "2025-11-06T01:46:05.633870Z",
    "question_style": "style_1"
  },
  {
    "question": "What events (workflow_dispatch, release, or schedule) trigger this GitHub Actions workflow?",
    "answer": "---\nname: Publish Release\n\non:\n  workflow_dispatch:\n  release:\n    types: [published]\n  schedule:\n    - cron: \"0 2 * * *\"\n\npermissions:\n  contents: read\n\njobs:\n  init:\n    name: Initialize build\n    runs-on: ubuntu-latest\n    outputs:\n      tag: ${{ steps.tag.outputs.tag }}\n      branch_build: ${{ steps.tag.outputs.branch_build }}\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Get tag\n        id: tag\n        # yamllint disable rule:line-length\n        run: |\n          if [[ \"${{ github.event_name }}\" = \"release\" ]]; then\n            TAG=\"${{ github.event.release.tag_name}}\"\n            BRANCH_BUILD=\"false\"\n          else\n            TAG=$(cat esphome/const.py | sed -n -E \"s/^__version__\\s+=\\s+\\\"(.+)\\\"$/\\1/p\")\n            today=\"$(date --utc '+%Y%m%d')\"\n            TAG=\"${TAG}${today}\"\n            BRANCH=${GITHUB_REF#refs/heads/}\n            if [[ \"$BRANCH\" != \"dev\" ]]; then\n              TAG=\"${TAG}-${BRANCH}\"\n              BRANCH_BUILD=\"true\"\n            else\n              BRANCH_BUILD=\"false\"\n            fi\n          fi\n          echo \"tag=${TAG}\" >> $GITHUB_OUTPUT\n          echo \"branch_build=${BRANCH_BUILD}\" >> $GITHUB_OUTPUT\n        # yamllint enable rule:line-length\n\n  deploy-pypi:\n    name: Build and publish to PyPi\n    if: github.repository == 'esphome/esphome' && github.event_name == 'release'\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.x\"\n      - name: Set up python environment\n        env:\n          ESPHOME_NO_VENV: 1\n        run: script/setup\n      - name: Build\n        run: |-\n          pip3 install build\n          python3 -m build\n      - name: Publish\n        uses: pypa/gh-action-pypi-publish@v1.12.4\n\n  deploy-docker:\n    name: Build ESPHome ${{ matrix.platform }}\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    runs-on: ubuntu-latest\n    needs: [init]\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - linux/amd64\n          - linux/arm64\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.9\"\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n      - name: Set up QEMU\n        if: matrix.platform != 'linux/amd64'\n        uses: docker/setup-qemu-action@v3.4.0\n\n      - name: Log in to docker hub\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build docker\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: docker\n          baseimg: docker\n          suffix: \"\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build ha-addon\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: hassio\n          baseimg: hassio\n          suffix: \"hassio\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build lint\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: lint\n          baseimg: docker\n          suffix: lint\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Sanitize platform name\n        id: sanitize\n        run: |\n          echo \"${{ matrix.platform }}\" | sed 's|/|-|g' > /tmp/platform\n          echo name=$(cat /tmp/platform) >> $GITHUB_OUTPUT\n\n      - name: Upload digests\n        uses: actions/upload-artifact@v4.6.0\n        with:\n          name: digests-${{ steps.sanitize.outputs.name }}\n          path: /tmp/digests\n          retention-days: 1\n\n  deploy-manifest:\n    name: Publish ESPHome ${{ matrix.image.title }} to ${{ matrix.registry }}\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-docker\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    strategy:\n      fail-fast: false\n      matrix:\n        image:\n          - title: \"ha-addon\"\n            target: \"hassio\"\n            suffix: \"hassio\"\n          - title: \"docker\"\n            target: \"docker\"\n            suffix: \"\"\n          - title: \"lint\"\n            target: \"lint\"\n            suffix: \"lint\"\n        registry:\n          - ghcr\n          - dockerhub\n    steps:\n      - uses: actions/checkout@v4.1.7\n\n      - name: Download digests\n        uses: actions/download-artifact@v4.1.8\n        with:\n          pattern: digests-*\n          path: /tmp/digests\n          merge-multiple: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n\n      - name: Log in to docker hub\n        if: matrix.registry == 'dockerhub'\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        if: matrix.registry == 'ghcr'\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Generate short tags\n        id: tags\n        run: |\n          output=$(docker/generate_tags.py \\\n            --tag \"${{ needs.init.outputs.tag }}\" \\\n            --suffix \"${{ matrix.image.suffix }}\" \\\n            --registry \"${{ matrix.registry }}\")\n          echo $output\n          for l in $output; do\n            echo $l >> $GITHUB_OUTPUT\n          done\n\n      - name: Create manifest list and push\n        working-directory: /tmp/digests/${{ matrix.image.target }}/${{ matrix.registry }}\n        run: |\n          docker buildx imagetools create $(jq -Rcnr 'inputs | . / \",\" | map(\"-t \" + .) | join(\" \")' <<< \"${{ steps.tags.outputs.tags}}\") \\\n            $(printf '${{ steps.tags.outputs.image }}@sha256:%s ' *)\n\n  deploy-ha-addon-repo:\n    if: github.repository == 'esphome/esphome' && needs.init.outputs.branch_build == 'false'\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-manifest\n    steps:\n      - name: Trigger Workflow\n        uses: actions/github-script@v7.0.1\n        with:\n          github-token: ${{ secrets.DEPLOY_HA_ADDON_REPO_TOKEN }}\n          script: |\n            let description = \"ESPHome\";\n            if (context.eventName == \"release\") {\n              description = ${{ toJSON(github.event.release.body) }};\n            }\n            github.rest.actions.createWorkflowDispatch({\n              owner: \"esphome\",\n              repo: \"home-assistant-addon\",\n              workflow_id: \"bump-version.yml\",\n              ref: \"main\",\n              inputs: {\n                version: \"${{ needs.init.outputs.tag }}\",\n                content: description\n              }\n            })\n",
    "source": "gkasprow/esphome",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/gkasprow/esphome/blob/c1992b2cbffff11a4b1ab6016ff1c3ced28bcce0/.github/workflows/release.yml",
    "retrieved_at": "2025-11-06T01:46:06.437283Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "---\nname: Publish Release\n\non:\n  workflow_dispatch:\n  release:\n    types: [published]\n  schedule:\n    - cron: \"0 2 * * *\"\n\npermissions:\n  contents: read\n\njobs:\n  init:\n    name: Initialize build\n    runs-on: ubuntu-latest\n    outputs:\n      tag: ${{ steps.tag.outputs.tag }}\n      branch_build: ${{ steps.tag.outputs.branch_build }}\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Get tag\n        id: tag\n        # yamllint disable rule:line-length\n        run: |\n          if [[ \"${{ github.event_name }}\" = \"release\" ]]; then\n            TAG=\"${{ github.event.release.tag_name}}\"\n            BRANCH_BUILD=\"false\"\n          else\n            TAG=$(cat esphome/const.py | sed -n -E \"s/^__version__\\s+=\\s+\\\"(.+)\\\"$/\\1/p\")\n            today=\"$(date --utc '+%Y%m%d')\"\n            TAG=\"${TAG}${today}\"\n            BRANCH=${GITHUB_REF#refs/heads/}\n            if [[ \"$BRANCH\" != \"dev\" ]]; then\n              TAG=\"${TAG}-${BRANCH}\"\n              BRANCH_BUILD=\"true\"\n            else\n              BRANCH_BUILD=\"false\"\n            fi\n          fi\n          echo \"tag=${TAG}\" >> $GITHUB_OUTPUT\n          echo \"branch_build=${BRANCH_BUILD}\" >> $GITHUB_OUTPUT\n        # yamllint enable rule:line-length\n\n  deploy-pypi:\n    name: Build and publish to PyPi\n    if: github.repository == 'esphome/esphome' && github.event_name == 'release'\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.x\"\n      - name: Set up python environment\n        env:\n          ESPHOME_NO_VENV: 1\n        run: script/setup\n      - name: Build\n        run: |-\n          pip3 install build\n          python3 -m build\n      - name: Publish\n        uses: pypa/gh-action-pypi-publish@v1.12.4\n\n  deploy-docker:\n    name: Build ESPHome ${{ matrix.platform }}\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    runs-on: ubuntu-latest\n    needs: [init]\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - linux/amd64\n          - linux/arm64\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.9\"\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n      - name: Set up QEMU\n        if: matrix.platform != 'linux/amd64'\n        uses: docker/setup-qemu-action@v3.4.0\n\n      - name: Log in to docker hub\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build docker\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: docker\n          baseimg: docker\n          suffix: \"\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build ha-addon\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: hassio\n          baseimg: hassio\n          suffix: \"hassio\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build lint\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: lint\n          baseimg: docker\n          suffix: lint\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Sanitize platform name\n        id: sanitize\n        run: |\n          echo \"${{ matrix.platform }}\" | sed 's|/|-|g' > /tmp/platform\n          echo name=$(cat /tmp/platform) >> $GITHUB_OUTPUT\n\n      - name: Upload digests\n        uses: actions/upload-artifact@v4.6.0\n        with:\n          name: digests-${{ steps.sanitize.outputs.name }}\n          path: /tmp/digests\n          retention-days: 1\n\n  deploy-manifest:\n    name: Publish ESPHome ${{ matrix.image.title }} to ${{ matrix.registry }}\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-docker\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    strategy:\n      fail-fast: false\n      matrix:\n        image:\n          - title: \"ha-addon\"\n            target: \"hassio\"\n            suffix: \"hassio\"\n          - title: \"docker\"\n            target: \"docker\"\n            suffix: \"\"\n          - title: \"lint\"\n            target: \"lint\"\n            suffix: \"lint\"\n        registry:\n          - ghcr\n          - dockerhub\n    steps:\n      - uses: actions/checkout@v4.1.7\n\n      - name: Download digests\n        uses: actions/download-artifact@v4.1.8\n        with:\n          pattern: digests-*\n          path: /tmp/digests\n          merge-multiple: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n\n      - name: Log in to docker hub\n        if: matrix.registry == 'dockerhub'\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        if: matrix.registry == 'ghcr'\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Generate short tags\n        id: tags\n        run: |\n          output=$(docker/generate_tags.py \\\n            --tag \"${{ needs.init.outputs.tag }}\" \\\n            --suffix \"${{ matrix.image.suffix }}\" \\\n            --registry \"${{ matrix.registry }}\")\n          echo $output\n          for l in $output; do\n            echo $l >> $GITHUB_OUTPUT\n          done\n\n      - name: Create manifest list and push\n        working-directory: /tmp/digests/${{ matrix.image.target }}/${{ matrix.registry }}\n        run: |\n          docker buildx imagetools create $(jq -Rcnr 'inputs | . / \",\" | map(\"-t \" + .) | join(\" \")' <<< \"${{ steps.tags.outputs.tags}}\") \\\n            $(printf '${{ steps.tags.outputs.image }}@sha256:%s ' *)\n\n  deploy-ha-addon-repo:\n    if: github.repository == 'esphome/esphome' && needs.init.outputs.branch_build == 'false'\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-manifest\n    steps:\n      - name: Trigger Workflow\n        uses: actions/github-script@v7.0.1\n        with:\n          github-token: ${{ secrets.DEPLOY_HA_ADDON_REPO_TOKEN }}\n          script: |\n            let description = \"ESPHome\";\n            if (context.eventName == \"release\") {\n              description = ${{ toJSON(github.event.release.body) }};\n            }\n            github.rest.actions.createWorkflowDispatch({\n              owner: \"esphome\",\n              repo: \"home-assistant-addon\",\n              workflow_id: \"bump-version.yml\",\n              ref: \"main\",\n              inputs: {\n                version: \"${{ needs.init.outputs.tag }}\",\n                content: description\n              }\n            })\n",
    "source": "gkasprow/esphome",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/gkasprow/esphome/blob/c1992b2cbffff11a4b1ab6016ff1c3ced28bcce0/.github/workflows/release.yml",
    "retrieved_at": "2025-11-06T01:46:07.126727Z",
    "question_style": "style_3"
  },
  {
    "question": "How are secrets DOCKER_USER, DOCKER_PASSWORD, and DEPLOY_HA_ADDON_REPO_TOKEN used for authentication across different registries and workflows?",
    "answer": "---\nname: Publish Release\n\non:\n  workflow_dispatch:\n  release:\n    types: [published]\n  schedule:\n    - cron: \"0 2 * * *\"\n\npermissions:\n  contents: read\n\njobs:\n  init:\n    name: Initialize build\n    runs-on: ubuntu-latest\n    outputs:\n      tag: ${{ steps.tag.outputs.tag }}\n      branch_build: ${{ steps.tag.outputs.branch_build }}\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Get tag\n        id: tag\n        # yamllint disable rule:line-length\n        run: |\n          if [[ \"${{ github.event_name }}\" = \"release\" ]]; then\n            TAG=\"${{ github.event.release.tag_name}}\"\n            BRANCH_BUILD=\"false\"\n          else\n            TAG=$(cat esphome/const.py | sed -n -E \"s/^__version__\\s+=\\s+\\\"(.+)\\\"$/\\1/p\")\n            today=\"$(date --utc '+%Y%m%d')\"\n            TAG=\"${TAG}${today}\"\n            BRANCH=${GITHUB_REF#refs/heads/}\n            if [[ \"$BRANCH\" != \"dev\" ]]; then\n              TAG=\"${TAG}-${BRANCH}\"\n              BRANCH_BUILD=\"true\"\n            else\n              BRANCH_BUILD=\"false\"\n            fi\n          fi\n          echo \"tag=${TAG}\" >> $GITHUB_OUTPUT\n          echo \"branch_build=${BRANCH_BUILD}\" >> $GITHUB_OUTPUT\n        # yamllint enable rule:line-length\n\n  deploy-pypi:\n    name: Build and publish to PyPi\n    if: github.repository == 'esphome/esphome' && github.event_name == 'release'\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.x\"\n      - name: Set up python environment\n        env:\n          ESPHOME_NO_VENV: 1\n        run: script/setup\n      - name: Build\n        run: |-\n          pip3 install build\n          python3 -m build\n      - name: Publish\n        uses: pypa/gh-action-pypi-publish@v1.12.4\n\n  deploy-docker:\n    name: Build ESPHome ${{ matrix.platform }}\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    runs-on: ubuntu-latest\n    needs: [init]\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - linux/amd64\n          - linux/arm64\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.9\"\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n      - name: Set up QEMU\n        if: matrix.platform != 'linux/amd64'\n        uses: docker/setup-qemu-action@v3.4.0\n\n      - name: Log in to docker hub\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build docker\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: docker\n          baseimg: docker\n          suffix: \"\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build ha-addon\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: hassio\n          baseimg: hassio\n          suffix: \"hassio\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build lint\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: lint\n          baseimg: docker\n          suffix: lint\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Sanitize platform name\n        id: sanitize\n        run: |\n          echo \"${{ matrix.platform }}\" | sed 's|/|-|g' > /tmp/platform\n          echo name=$(cat /tmp/platform) >> $GITHUB_OUTPUT\n\n      - name: Upload digests\n        uses: actions/upload-artifact@v4.6.0\n        with:\n          name: digests-${{ steps.sanitize.outputs.name }}\n          path: /tmp/digests\n          retention-days: 1\n\n  deploy-manifest:\n    name: Publish ESPHome ${{ matrix.image.title }} to ${{ matrix.registry }}\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-docker\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    strategy:\n      fail-fast: false\n      matrix:\n        image:\n          - title: \"ha-addon\"\n            target: \"hassio\"\n            suffix: \"hassio\"\n          - title: \"docker\"\n            target: \"docker\"\n            suffix: \"\"\n          - title: \"lint\"\n            target: \"lint\"\n            suffix: \"lint\"\n        registry:\n          - ghcr\n          - dockerhub\n    steps:\n      - uses: actions/checkout@v4.1.7\n\n      - name: Download digests\n        uses: actions/download-artifact@v4.1.8\n        with:\n          pattern: digests-*\n          path: /tmp/digests\n          merge-multiple: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n\n      - name: Log in to docker hub\n        if: matrix.registry == 'dockerhub'\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        if: matrix.registry == 'ghcr'\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Generate short tags\n        id: tags\n        run: |\n          output=$(docker/generate_tags.py \\\n            --tag \"${{ needs.init.outputs.tag }}\" \\\n            --suffix \"${{ matrix.image.suffix }}\" \\\n            --registry \"${{ matrix.registry }}\")\n          echo $output\n          for l in $output; do\n            echo $l >> $GITHUB_OUTPUT\n          done\n\n      - name: Create manifest list and push\n        working-directory: /tmp/digests/${{ matrix.image.target }}/${{ matrix.registry }}\n        run: |\n          docker buildx imagetools create $(jq -Rcnr 'inputs | . / \",\" | map(\"-t \" + .) | join(\" \")' <<< \"${{ steps.tags.outputs.tags}}\") \\\n            $(printf '${{ steps.tags.outputs.image }}@sha256:%s ' *)\n\n  deploy-ha-addon-repo:\n    if: github.repository == 'esphome/esphome' && needs.init.outputs.branch_build == 'false'\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-manifest\n    steps:\n      - name: Trigger Workflow\n        uses: actions/github-script@v7.0.1\n        with:\n          github-token: ${{ secrets.DEPLOY_HA_ADDON_REPO_TOKEN }}\n          script: |\n            let description = \"ESPHome\";\n            if (context.eventName == \"release\") {\n              description = ${{ toJSON(github.event.release.body) }};\n            }\n            github.rest.actions.createWorkflowDispatch({\n              owner: \"esphome\",\n              repo: \"home-assistant-addon\",\n              workflow_id: \"bump-version.yml\",\n              ref: \"main\",\n              inputs: {\n                version: \"${{ needs.init.outputs.tag }}\",\n                content: description\n              }\n            })\n",
    "source": "gkasprow/esphome",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/gkasprow/esphome/blob/c1992b2cbffff11a4b1ab6016ff1c3ced28bcce0/.github/workflows/release.yml",
    "retrieved_at": "2025-11-06T01:46:08.005326Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this GitHub Actions workflow?",
    "answer": "---\nname: Publish Release\n\non:\n  workflow_dispatch:\n  release:\n    types: [published]\n  schedule:\n    - cron: \"0 2 * * *\"\n\npermissions:\n  contents: read\n\njobs:\n  init:\n    name: Initialize build\n    runs-on: ubuntu-latest\n    outputs:\n      tag: ${{ steps.tag.outputs.tag }}\n      branch_build: ${{ steps.tag.outputs.branch_build }}\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Get tag\n        id: tag\n        # yamllint disable rule:line-length\n        run: |\n          if [[ \"${{ github.event_name }}\" = \"release\" ]]; then\n            TAG=\"${{ github.event.release.tag_name}}\"\n            BRANCH_BUILD=\"false\"\n          else\n            TAG=$(cat esphome/const.py | sed -n -E \"s/^__version__\\s+=\\s+\\\"(.+)\\\"$/\\1/p\")\n            today=\"$(date --utc '+%Y%m%d')\"\n            TAG=\"${TAG}${today}\"\n            BRANCH=${GITHUB_REF#refs/heads/}\n            if [[ \"$BRANCH\" != \"dev\" ]]; then\n              TAG=\"${TAG}-${BRANCH}\"\n              BRANCH_BUILD=\"true\"\n            else\n              BRANCH_BUILD=\"false\"\n            fi\n          fi\n          echo \"tag=${TAG}\" >> $GITHUB_OUTPUT\n          echo \"branch_build=${BRANCH_BUILD}\" >> $GITHUB_OUTPUT\n        # yamllint enable rule:line-length\n\n  deploy-pypi:\n    name: Build and publish to PyPi\n    if: github.repository == 'esphome/esphome' && github.event_name == 'release'\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.x\"\n      - name: Set up python environment\n        env:\n          ESPHOME_NO_VENV: 1\n        run: script/setup\n      - name: Build\n        run: |-\n          pip3 install build\n          python3 -m build\n      - name: Publish\n        uses: pypa/gh-action-pypi-publish@v1.12.4\n\n  deploy-docker:\n    name: Build ESPHome ${{ matrix.platform }}\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    runs-on: ubuntu-latest\n    needs: [init]\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - linux/amd64\n          - linux/arm64\n    steps:\n      - uses: actions/checkout@v4.1.7\n      - name: Set up Python\n        uses: actions/setup-python@v5.4.0\n        with:\n          python-version: \"3.9\"\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n      - name: Set up QEMU\n        if: matrix.platform != 'linux/amd64'\n        uses: docker/setup-qemu-action@v3.4.0\n\n      - name: Log in to docker hub\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build docker\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: docker\n          baseimg: docker\n          suffix: \"\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build ha-addon\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: hassio\n          baseimg: hassio\n          suffix: \"hassio\"\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Build lint\n        uses: ./.github/actions/build-image\n        with:\n          platform: ${{ matrix.platform }}\n          target: lint\n          baseimg: docker\n          suffix: lint\n          version: ${{ needs.init.outputs.tag }}\n\n      - name: Sanitize platform name\n        id: sanitize\n        run: |\n          echo \"${{ matrix.platform }}\" | sed 's|/|-|g' > /tmp/platform\n          echo name=$(cat /tmp/platform) >> $GITHUB_OUTPUT\n\n      - name: Upload digests\n        uses: actions/upload-artifact@v4.6.0\n        with:\n          name: digests-${{ steps.sanitize.outputs.name }}\n          path: /tmp/digests\n          retention-days: 1\n\n  deploy-manifest:\n    name: Publish ESPHome ${{ matrix.image.title }} to ${{ matrix.registry }}\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-docker\n    if: github.repository == 'esphome/esphome'\n    permissions:\n      contents: read\n      packages: write\n    strategy:\n      fail-fast: false\n      matrix:\n        image:\n          - title: \"ha-addon\"\n            target: \"hassio\"\n            suffix: \"hassio\"\n          - title: \"docker\"\n            target: \"docker\"\n            suffix: \"\"\n          - title: \"lint\"\n            target: \"lint\"\n            suffix: \"lint\"\n        registry:\n          - ghcr\n          - dockerhub\n    steps:\n      - uses: actions/checkout@v4.1.7\n\n      - name: Download digests\n        uses: actions/download-artifact@v4.1.8\n        with:\n          pattern: digests-*\n          path: /tmp/digests\n          merge-multiple: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3.9.0\n\n      - name: Log in to docker hub\n        if: matrix.registry == 'dockerhub'\n        uses: docker/login-action@v3.3.0\n        with:\n          username: ${{ secrets.DOCKER_USER }}\n          password: ${{ secrets.DOCKER_PASSWORD }}\n      - name: Log in to the GitHub container registry\n        if: matrix.registry == 'ghcr'\n        uses: docker/login-action@v3.3.0\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Generate short tags\n        id: tags\n        run: |\n          output=$(docker/generate_tags.py \\\n            --tag \"${{ needs.init.outputs.tag }}\" \\\n            --suffix \"${{ matrix.image.suffix }}\" \\\n            --registry \"${{ matrix.registry }}\")\n          echo $output\n          for l in $output; do\n            echo $l >> $GITHUB_OUTPUT\n          done\n\n      - name: Create manifest list and push\n        working-directory: /tmp/digests/${{ matrix.image.target }}/${{ matrix.registry }}\n        run: |\n          docker buildx imagetools create $(jq -Rcnr 'inputs | . / \",\" | map(\"-t \" + .) | join(\" \")' <<< \"${{ steps.tags.outputs.tags}}\") \\\n            $(printf '${{ steps.tags.outputs.image }}@sha256:%s ' *)\n\n  deploy-ha-addon-repo:\n    if: github.repository == 'esphome/esphome' && needs.init.outputs.branch_build == 'false'\n    runs-on: ubuntu-latest\n    needs:\n      - init\n      - deploy-manifest\n    steps:\n      - name: Trigger Workflow\n        uses: actions/github-script@v7.0.1\n        with:\n          github-token: ${{ secrets.DEPLOY_HA_ADDON_REPO_TOKEN }}\n          script: |\n            let description = \"ESPHome\";\n            if (context.eventName == \"release\") {\n              description = ${{ toJSON(github.event.release.body) }};\n            }\n            github.rest.actions.createWorkflowDispatch({\n              owner: \"esphome\",\n              repo: \"home-assistant-addon\",\n              workflow_id: \"bump-version.yml\",\n              ref: \"main\",\n              inputs: {\n                version: \"${{ needs.init.outputs.tag }}\",\n                content: description\n              }\n            })\n",
    "source": "gkasprow/esphome",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/gkasprow/esphome/blob/c1992b2cbffff11a4b1ab6016ff1c3ced28bcce0/.github/workflows/release.yml",
    "retrieved_at": "2025-11-06T01:46:08.839544Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including the WinMacBuild job matrix and all steps within each conditional OS execution block.",
    "answer": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# GH actions.\n# We use it to cover windows and mac builds\n# Jenkins is still the primary CI\n\nname: WinMacBuild\n\non:\n  push:\n    branches:\n      - main\n\n  pull_request:\n    branches:\n      - main\n\njobs:\n  Build:\n    strategy:\n      matrix:\n        os: [windows-2016, macOS-latest]\n\n    runs-on: ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Initialize submodules\n      run: git submodule update --recursive --init\n    - uses: actions/cache@v1\n      env:\n        CACHE_NUMBER: 0\n      with:\n        path: ~/conda_pkgs_dir\n        key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('conda/build-environment.yaml') }}\n    - uses: conda-incubator/setup-miniconda@v2\n      with:\n        activate-environment: tvm-build\n        channel-priority: strict\n        environment-file: conda/build-environment.yaml\n        auto-activate-base: false\n        use-only-tar-bz2: true\n    - name: Conda info\n      run: |\n        conda info\n        conda list\n    - name: Conda-Build@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        conda build --output-folder=conda/pkg conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Conda-Build@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        conda build --output-folder=conda/pkg  conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Build iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      run: |\n        IOS_VERSION=\"14.0\"\n        CMAKE_FLAGS=\"-DCMAKE_BUILD_TYPE=Release \\\n                     -DCMAKE_SYSTEM_NAME=iOS \\\n                     -DCMAKE_SYSTEM_VERSION=${IOS_VERSION} \\\n                     -DCMAKE_OSX_SYSROOT=iphonesimulator \\\n                     -DCMAKE_OSX_ARCHITECTURES=x86_64 \\\n                     -DCMAKE_OSX_DEPLOYMENT_TARGET=14.0 \\\n                     -DCMAKE_BUILD_WITH_INSTALL_NAME_DIR=ON \\\n                     -DUSE_IOS_RPC=ON\"\n\n        mkdir build-ios-simulator\n        cd build-ios-simulator\n        cmake .. ${CMAKE_FLAGS}\n        cmake --build . --target ios_rpc\n    - name: Test@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pip install tornado psutil cloudpickle &&\n        export PYTHONPATH=tests/python/contrib:${PYTHONPATH} &&\n        export BUNDLE_ID=org.apache.tvmrpc &&\n        export BUNDLE_PATH=build-ios-simulator/apps/ios_rpc/ios_rpc/src/ios_rpc-build/Release-iphonesimulator/tvmrpc.app &&\n        python -m pytest -v tests/python/contrib/test_rpc_server_device.py\n",
    "source": "Tencent/BlazerML-tvm",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Tencent/BlazerML-tvm/blob/9dd9e33509137ae4011c0524d5312c41a6b82182/.github/workflows/main.yml",
    "retrieved_at": "2025-11-07T01:44:52.898061Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch of the repository trigger the WinMacBuild workflow?",
    "answer": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# GH actions.\n# We use it to cover windows and mac builds\n# Jenkins is still the primary CI\n\nname: WinMacBuild\n\non:\n  push:\n    branches:\n      - main\n\n  pull_request:\n    branches:\n      - main\n\njobs:\n  Build:\n    strategy:\n      matrix:\n        os: [windows-2016, macOS-latest]\n\n    runs-on: ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Initialize submodules\n      run: git submodule update --recursive --init\n    - uses: actions/cache@v1\n      env:\n        CACHE_NUMBER: 0\n      with:\n        path: ~/conda_pkgs_dir\n        key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('conda/build-environment.yaml') }}\n    - uses: conda-incubator/setup-miniconda@v2\n      with:\n        activate-environment: tvm-build\n        channel-priority: strict\n        environment-file: conda/build-environment.yaml\n        auto-activate-base: false\n        use-only-tar-bz2: true\n    - name: Conda info\n      run: |\n        conda info\n        conda list\n    - name: Conda-Build@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        conda build --output-folder=conda/pkg conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Conda-Build@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        conda build --output-folder=conda/pkg  conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Build iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      run: |\n        IOS_VERSION=\"14.0\"\n        CMAKE_FLAGS=\"-DCMAKE_BUILD_TYPE=Release \\\n                     -DCMAKE_SYSTEM_NAME=iOS \\\n                     -DCMAKE_SYSTEM_VERSION=${IOS_VERSION} \\\n                     -DCMAKE_OSX_SYSROOT=iphonesimulator \\\n                     -DCMAKE_OSX_ARCHITECTURES=x86_64 \\\n                     -DCMAKE_OSX_DEPLOYMENT_TARGET=14.0 \\\n                     -DCMAKE_BUILD_WITH_INSTALL_NAME_DIR=ON \\\n                     -DUSE_IOS_RPC=ON\"\n\n        mkdir build-ios-simulator\n        cd build-ios-simulator\n        cmake .. ${CMAKE_FLAGS}\n        cmake --build . --target ios_rpc\n    - name: Test@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pip install tornado psutil cloudpickle &&\n        export PYTHONPATH=tests/python/contrib:${PYTHONPATH} &&\n        export BUNDLE_ID=org.apache.tvmrpc &&\n        export BUNDLE_PATH=build-ios-simulator/apps/ios_rpc/ios_rpc/src/ios_rpc-build/Release-iphonesimulator/tvmrpc.app &&\n        python -m pytest -v tests/python/contrib/test_rpc_server_device.py\n",
    "source": "Tencent/BlazerML-tvm",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Tencent/BlazerML-tvm/blob/9dd9e33509137ae4011c0524d5312c41a6b82182/.github/workflows/main.yml",
    "retrieved_at": "2025-11-07T01:44:53.870792Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# GH actions.\n# We use it to cover windows and mac builds\n# Jenkins is still the primary CI\n\nname: WinMacBuild\n\non:\n  push:\n    branches:\n      - main\n\n  pull_request:\n    branches:\n      - main\n\njobs:\n  Build:\n    strategy:\n      matrix:\n        os: [windows-2016, macOS-latest]\n\n    runs-on: ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Initialize submodules\n      run: git submodule update --recursive --init\n    - uses: actions/cache@v1\n      env:\n        CACHE_NUMBER: 0\n      with:\n        path: ~/conda_pkgs_dir\n        key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('conda/build-environment.yaml') }}\n    - uses: conda-incubator/setup-miniconda@v2\n      with:\n        activate-environment: tvm-build\n        channel-priority: strict\n        environment-file: conda/build-environment.yaml\n        auto-activate-base: false\n        use-only-tar-bz2: true\n    - name: Conda info\n      run: |\n        conda info\n        conda list\n    - name: Conda-Build@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        conda build --output-folder=conda/pkg conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Conda-Build@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        conda build --output-folder=conda/pkg  conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Build iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      run: |\n        IOS_VERSION=\"14.0\"\n        CMAKE_FLAGS=\"-DCMAKE_BUILD_TYPE=Release \\\n                     -DCMAKE_SYSTEM_NAME=iOS \\\n                     -DCMAKE_SYSTEM_VERSION=${IOS_VERSION} \\\n                     -DCMAKE_OSX_SYSROOT=iphonesimulator \\\n                     -DCMAKE_OSX_ARCHITECTURES=x86_64 \\\n                     -DCMAKE_OSX_DEPLOYMENT_TARGET=14.0 \\\n                     -DCMAKE_BUILD_WITH_INSTALL_NAME_DIR=ON \\\n                     -DUSE_IOS_RPC=ON\"\n\n        mkdir build-ios-simulator\n        cd build-ios-simulator\n        cmake .. ${CMAKE_FLAGS}\n        cmake --build . --target ios_rpc\n    - name: Test@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pip install tornado psutil cloudpickle &&\n        export PYTHONPATH=tests/python/contrib:${PYTHONPATH} &&\n        export BUNDLE_ID=org.apache.tvmrpc &&\n        export BUNDLE_PATH=build-ios-simulator/apps/ios_rpc/ios_rpc/src/ios_rpc-build/Release-iphonesimulator/tvmrpc.app &&\n        python -m pytest -v tests/python/contrib/test_rpc_server_device.py\n",
    "source": "Tencent/BlazerML-tvm",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Tencent/BlazerML-tvm/blob/9dd9e33509137ae4011c0524d5312c41a6b82182/.github/workflows/main.yml",
    "retrieved_at": "2025-11-07T01:44:55.014105Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `CACHE_NUMBER` environment variable used to manage the conda package cache?",
    "answer": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# GH actions.\n# We use it to cover windows and mac builds\n# Jenkins is still the primary CI\n\nname: WinMacBuild\n\non:\n  push:\n    branches:\n      - main\n\n  pull_request:\n    branches:\n      - main\n\njobs:\n  Build:\n    strategy:\n      matrix:\n        os: [windows-2016, macOS-latest]\n\n    runs-on: ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Initialize submodules\n      run: git submodule update --recursive --init\n    - uses: actions/cache@v1\n      env:\n        CACHE_NUMBER: 0\n      with:\n        path: ~/conda_pkgs_dir\n        key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('conda/build-environment.yaml') }}\n    - uses: conda-incubator/setup-miniconda@v2\n      with:\n        activate-environment: tvm-build\n        channel-priority: strict\n        environment-file: conda/build-environment.yaml\n        auto-activate-base: false\n        use-only-tar-bz2: true\n    - name: Conda info\n      run: |\n        conda info\n        conda list\n    - name: Conda-Build@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        conda build --output-folder=conda/pkg conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Conda-Build@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        conda build --output-folder=conda/pkg  conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Build iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      run: |\n        IOS_VERSION=\"14.0\"\n        CMAKE_FLAGS=\"-DCMAKE_BUILD_TYPE=Release \\\n                     -DCMAKE_SYSTEM_NAME=iOS \\\n                     -DCMAKE_SYSTEM_VERSION=${IOS_VERSION} \\\n                     -DCMAKE_OSX_SYSROOT=iphonesimulator \\\n                     -DCMAKE_OSX_ARCHITECTURES=x86_64 \\\n                     -DCMAKE_OSX_DEPLOYMENT_TARGET=14.0 \\\n                     -DCMAKE_BUILD_WITH_INSTALL_NAME_DIR=ON \\\n                     -DUSE_IOS_RPC=ON\"\n\n        mkdir build-ios-simulator\n        cd build-ios-simulator\n        cmake .. ${CMAKE_FLAGS}\n        cmake --build . --target ios_rpc\n    - name: Test@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pip install tornado psutil cloudpickle &&\n        export PYTHONPATH=tests/python/contrib:${PYTHONPATH} &&\n        export BUNDLE_ID=org.apache.tvmrpc &&\n        export BUNDLE_PATH=build-ios-simulator/apps/ios_rpc/ios_rpc/src/ios_rpc-build/Release-iphonesimulator/tvmrpc.app &&\n        python -m pytest -v tests/python/contrib/test_rpc_server_device.py\n",
    "source": "Tencent/BlazerML-tvm",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Tencent/BlazerML-tvm/blob/9dd9e33509137ae4011c0524d5312c41a6b82182/.github/workflows/main.yml",
    "retrieved_at": "2025-11-07T01:44:55.888200Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow named \"WinMacBuild\"?",
    "answer": "# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\n# GH actions.\n# We use it to cover windows and mac builds\n# Jenkins is still the primary CI\n\nname: WinMacBuild\n\non:\n  push:\n    branches:\n      - main\n\n  pull_request:\n    branches:\n      - main\n\njobs:\n  Build:\n    strategy:\n      matrix:\n        os: [windows-2016, macOS-latest]\n\n    runs-on: ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Initialize submodules\n      run: git submodule update --recursive --init\n    - uses: actions/cache@v1\n      env:\n        CACHE_NUMBER: 0\n      with:\n        path: ~/conda_pkgs_dir\n        key: ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{ hashFiles('conda/build-environment.yaml') }}\n    - uses: conda-incubator/setup-miniconda@v2\n      with:\n        activate-environment: tvm-build\n        channel-priority: strict\n        environment-file: conda/build-environment.yaml\n        auto-activate-base: false\n        use-only-tar-bz2: true\n    - name: Conda info\n      run: |\n        conda info\n        conda list\n    - name: Conda-Build@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        conda build --output-folder=conda/pkg conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Conda-Build@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        conda build --output-folder=conda/pkg  conda/recipe &&\n        conda install tvm -c ./conda/pkg\n    - name: Build iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      run: |\n        IOS_VERSION=\"14.0\"\n        CMAKE_FLAGS=\"-DCMAKE_BUILD_TYPE=Release \\\n                     -DCMAKE_SYSTEM_NAME=iOS \\\n                     -DCMAKE_SYSTEM_VERSION=${IOS_VERSION} \\\n                     -DCMAKE_OSX_SYSROOT=iphonesimulator \\\n                     -DCMAKE_OSX_ARCHITECTURES=x86_64 \\\n                     -DCMAKE_OSX_DEPLOYMENT_TARGET=14.0 \\\n                     -DCMAKE_BUILD_WITH_INSTALL_NAME_DIR=ON \\\n                     -DUSE_IOS_RPC=ON\"\n\n        mkdir build-ios-simulator\n        cd build-ios-simulator\n        cmake .. ${CMAKE_FLAGS}\n        cmake --build . --target ios_rpc\n    - name: Test@Win\n      if: startsWith(matrix.os, 'windows')\n      shell: cmd /C call {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pytest -v tests/python/all-platform-minimal-test\n    - name: Test iOS RPC@MacOS\n      if: startsWith(matrix.os, 'macOS')\n      shell: bash -l {0}\n      run: >-\n        python -m pip install tornado psutil cloudpickle &&\n        export PYTHONPATH=tests/python/contrib:${PYTHONPATH} &&\n        export BUNDLE_ID=org.apache.tvmrpc &&\n        export BUNDLE_PATH=build-ios-simulator/apps/ios_rpc/ios_rpc/src/ios_rpc-build/Release-iphonesimulator/tvmrpc.app &&\n        python -m pytest -v tests/python/contrib/test_rpc_server_device.py\n",
    "source": "Tencent/BlazerML-tvm",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/Tencent/BlazerML-tvm/blob/9dd9e33509137ae4011c0524d5312c41a6b82182/.github/workflows/main.yml",
    "retrieved_at": "2025-11-07T01:44:56.697569Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building and releasing a Windows installer.",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n  pull_request:\n    branches:\n    - '*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f --depth 1\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ github.ref_name }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "prisma-lab/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/prisma-lab/qgroundcontrol/blob/16607c4d24efc4f1b42d4630fc7001f72ca3301d/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-07T01:44:57.841213Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and conditions trigger this Windows Release workflow to run?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n  pull_request:\n    branches:\n    - '*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f --depth 1\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ github.ref_name }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "prisma-lab/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/prisma-lab/qgroundcontrol/blob/16607c4d24efc4f1b42d4630fc7001f72ca3301d/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-07T01:44:59.412205Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n  pull_request:\n    branches:\n    - '*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f --depth 1\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ github.ref_name }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "prisma-lab/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/prisma-lab/qgroundcontrol/blob/16607c4d24efc4f1b42d4630fc7001f72ca3301d/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-07T01:45:00.320612Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` secrets used for uploading builds to an S3 bucket?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n  pull_request:\n    branches:\n    - '*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f --depth 1\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ github.ref_name }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "prisma-lab/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/prisma-lab/qgroundcontrol/blob/16607c4d24efc4f1b42d4630fc7001f72ca3301d/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-07T01:45:01.304420Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow, specifically what does it build and release?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n  pull_request:\n    branches:\n    - '*'\n    paths-ignore:\n      - 'docs/**'\n      - '.github/workflows/**'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f --depth 1\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.3.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ github.ref_name }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "prisma-lab/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/prisma-lab/qgroundcontrol/blob/16607c4d24efc4f1b42d4630fc7001f72ca3301d/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-07T01:45:02.245517Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: SonarQube analysis\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  sonarqube:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n      with:\n        # Disabling shallow clone is recommended for improving relevancy of reporting.\n        fetch-depth: 0\n\n    # Triggering SonarQube analysis as results of it are required by Quality Gate check.\n    - name: SonarQube Scan\n      uses: sonarsource/sonarqube-scan-action@master\n      env:\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n",
    "source": "ZKFair/zkfair-cdk-validium-node",
    "path": ".github/workflows/sonarqube.yml",
    "url": "https://github.com/ZKFair/zkfair-cdk-validium-node/blob/0e0ae6045e69e6b74cccf5e05ef93dd6490ecf01/.github/workflows/sonarqube.yml",
    "retrieved_at": "2025-11-08T01:39:23.656976Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branches trigger the \"SonarQube analysis\" workflow?",
    "answer": "name: SonarQube analysis\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  sonarqube:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n      with:\n        # Disabling shallow clone is recommended for improving relevancy of reporting.\n        fetch-depth: 0\n\n    # Triggering SonarQube analysis as results of it are required by Quality Gate check.\n    - name: SonarQube Scan\n      uses: sonarsource/sonarqube-scan-action@master\n      env:\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n",
    "source": "ZKFair/zkfair-cdk-validium-node",
    "path": ".github/workflows/sonarqube.yml",
    "url": "https://github.com/ZKFair/zkfair-cdk-validium-node/blob/0e0ae6045e69e6b74cccf5e05ef93dd6490ecf01/.github/workflows/sonarqube.yml",
    "retrieved_at": "2025-11-08T01:39:24.422362Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: SonarQube analysis\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  sonarqube:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n      with:\n        # Disabling shallow clone is recommended for improving relevancy of reporting.\n        fetch-depth: 0\n\n    # Triggering SonarQube analysis as results of it are required by Quality Gate check.\n    - name: SonarQube Scan\n      uses: sonarsource/sonarqube-scan-action@master\n      env:\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n",
    "source": "ZKFair/zkfair-cdk-validium-node",
    "path": ".github/workflows/sonarqube.yml",
    "url": "https://github.com/ZKFair/zkfair-cdk-validium-node/blob/0e0ae6045e69e6b74cccf5e05ef93dd6490ecf01/.github/workflows/sonarqube.yml",
    "retrieved_at": "2025-11-08T01:39:25.164655Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `SONAR_TOKEN` and `SONAR_HOST_URL` secrets used for SonarQube authentication and server location?",
    "answer": "name: SonarQube analysis\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  sonarqube:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n      with:\n        # Disabling shallow clone is recommended for improving relevancy of reporting.\n        fetch-depth: 0\n\n    # Triggering SonarQube analysis as results of it are required by Quality Gate check.\n    - name: SonarQube Scan\n      uses: sonarsource/sonarqube-scan-action@master\n      env:\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n",
    "source": "ZKFair/zkfair-cdk-validium-node",
    "path": ".github/workflows/sonarqube.yml",
    "url": "https://github.com/ZKFair/zkfair-cdk-validium-node/blob/0e0ae6045e69e6b74cccf5e05ef93dd6490ecf01/.github/workflows/sonarqube.yml",
    "retrieved_at": "2025-11-08T01:39:25.967606Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary goal or effect of this SonarQube analysis workflow?",
    "answer": "name: SonarQube analysis\n\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  sonarqube:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n      with:\n        # Disabling shallow clone is recommended for improving relevancy of reporting.\n        fetch-depth: 0\n\n    # Triggering SonarQube analysis as results of it are required by Quality Gate check.\n    - name: SonarQube Scan\n      uses: sonarsource/sonarqube-scan-action@master\n      env:\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n        SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}\n",
    "source": "ZKFair/zkfair-cdk-validium-node",
    "path": ".github/workflows/sonarqube.yml",
    "url": "https://github.com/ZKFair/zkfair-cdk-validium-node/blob/0e0ae6045e69e6b74cccf5e05ef93dd6490ecf01/.github/workflows/sonarqube.yml",
    "retrieved_at": "2025-11-08T01:39:26.575931Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the given workflow's functionality for code coverage analysis and reporting to Coveralls.",
    "answer": "name: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 7.4\n\n      - name: Install dependencies\n        run: composer install --no-progress --no-suggest --optimize-autoloader\n\n      - name: Add coveralls dependency\n        run: composer require --dev php-coveralls/php-coveralls --no-progress --no-suggest --no-interaction\n\n      - name: Run tests with coverage\n        run: composer test-coverage\n\n      - name: Upload coverage to Coveralls\n        env:\n          COVERALLS_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: php vendor/bin/php-coveralls -v\n",
    "source": "webimpress/coding-standard",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/webimpress/coding-standard/blob/6f6a1a90bd9e18fc8bee0660dd1d1ce68cf9fc53/.github/workflows/coverage.yml",
    "retrieved_at": "2025-11-08T01:39:27.515897Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this \"Coverage\" workflow?",
    "answer": "name: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 7.4\n\n      - name: Install dependencies\n        run: composer install --no-progress --no-suggest --optimize-autoloader\n\n      - name: Add coveralls dependency\n        run: composer require --dev php-coveralls/php-coveralls --no-progress --no-suggest --no-interaction\n\n      - name: Run tests with coverage\n        run: composer test-coverage\n\n      - name: Upload coverage to Coveralls\n        env:\n          COVERALLS_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: php vendor/bin/php-coveralls -v\n",
    "source": "webimpress/coding-standard",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/webimpress/coding-standard/blob/6f6a1a90bd9e18fc8bee0660dd1d1ce68cf9fc53/.github/workflows/coverage.yml",
    "retrieved_at": "2025-11-08T01:39:28.128839Z",
    "question_style": "style_2"
  },
  {
    "question": "Which steps within the \"coverage\" job run in parallel or have dependencies on previous steps?",
    "answer": "name: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 7.4\n\n      - name: Install dependencies\n        run: composer install --no-progress --no-suggest --optimize-autoloader\n\n      - name: Add coveralls dependency\n        run: composer require --dev php-coveralls/php-coveralls --no-progress --no-suggest --no-interaction\n\n      - name: Run tests with coverage\n        run: composer test-coverage\n\n      - name: Upload coverage to Coveralls\n        env:\n          COVERALLS_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: php vendor/bin/php-coveralls -v\n",
    "source": "webimpress/coding-standard",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/webimpress/coding-standard/blob/6f6a1a90bd9e18fc8bee0660dd1d1ce68cf9fc53/.github/workflows/coverage.yml",
    "retrieved_at": "2025-11-08T01:39:28.724033Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to authenticate with Coveralls for uploading code coverage data?",
    "answer": "name: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 7.4\n\n      - name: Install dependencies\n        run: composer install --no-progress --no-suggest --optimize-autoloader\n\n      - name: Add coveralls dependency\n        run: composer require --dev php-coveralls/php-coveralls --no-progress --no-suggest --no-interaction\n\n      - name: Run tests with coverage\n        run: composer test-coverage\n\n      - name: Upload coverage to Coveralls\n        env:\n          COVERALLS_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: php vendor/bin/php-coveralls -v\n",
    "source": "webimpress/coding-standard",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/webimpress/coding-standard/blob/6f6a1a90bd9e18fc8bee0660dd1d1ce68cf9fc53/.github/workflows/coverage.yml",
    "retrieved_at": "2025-11-08T01:39:29.491598Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding code quality?",
    "answer": "name: Coverage\n\non: [push, pull_request]\n\njobs:\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: 7.4\n\n      - name: Install dependencies\n        run: composer install --no-progress --no-suggest --optimize-autoloader\n\n      - name: Add coveralls dependency\n        run: composer require --dev php-coveralls/php-coveralls --no-progress --no-suggest --no-interaction\n\n      - name: Run tests with coverage\n        run: composer test-coverage\n\n      - name: Upload coverage to Coveralls\n        env:\n          COVERALLS_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: php vendor/bin/php-coveralls -v\n",
    "source": "webimpress/coding-standard",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/webimpress/coding-standard/blob/6f6a1a90bd9e18fc8bee0660dd1d1ce68cf9fc53/.github/workflows/coverage.yml",
    "retrieved_at": "2025-11-08T01:39:30.116378Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the provided YAML file's functionality, including path filtering, building, linting, testing, and deploying changes.",
    "answer": "---\n# File : cd.yml\n\nname: 'cd'\non:\n  push:\n    branches: [main]\ndefaults:\n  run:\n    shell: 'bash'\njobs:\n  changes:\n    runs-on: 'ubuntu-latest'\n    outputs:\n      ts: ${{ steps.filter.outputs.ts }}\n    steps:\n      - uses: actions/checkout@v2\n      - name: '[check if build necessary]'\n        uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            ts:\n              - '**.ts'\n              - '**.tsx'\n              - '**.json'\n  build-deploy:\n    name: '[cd|build-deploy]'\n    runs-on: 'ubuntu-latest'\n    needs: changes\n    if: ${{ needs.changes.outputs.ts == 'true' }}\n    steps:\n      - name: '[checkout] ${{ github.repository }} project'\n        uses: 'actions/checkout@v2'\n        with:\n          repository: '${{ github.repository }}'\n      - name: '[setup node]'  \n        uses: 'actions/setup-node@v2'\n        with:\n          node-version: '16'\n      - name: '[lint]'\n        run: |\n          echo TBA some linting\n      - name: '[test]'\n        run: |\n          echo TBA some testing\n      - name: '[build]'\n        run: |\n          git config --global url.\"https://github.com/\".insteadOf ssh://git@github.com/\n          git config --global url.\"https://\".insteadOf git://\n          git config --global url.\"https://\".insteadOf ssh://\n          yarn install\n          yarn run build\n          yarn run export\n      - name: '[Add GitHub Sponsors to Readme]'\n        uses: JamesIves/github-sponsors-readme-action@1.0.5\n        with:\n          token: ${{secrets.PAT}}\n          file: 'README.md'\n          minimum: 500\n          \n      - name: '[commit changes]'\n        run: |\n          git config --local user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --local user.name \"github-actions[bot]\"\n          git add .\n          git commit -m \"chore: build\" -a\n      - name: '[push changes]'\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n...\n# End of cd.yml\n",
    "source": "org-roam/org-roam-ui",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/org-roam/org-roam-ui/blob/5ac74960231db0bf7783c2ba7a19a60f582e91ab/.github/workflows/cd.yml",
    "retrieved_at": "2025-11-09T01:48:38.045603Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this GitHub Actions workflow?",
    "answer": "---\n# File : cd.yml\n\nname: 'cd'\non:\n  push:\n    branches: [main]\ndefaults:\n  run:\n    shell: 'bash'\njobs:\n  changes:\n    runs-on: 'ubuntu-latest'\n    outputs:\n      ts: ${{ steps.filter.outputs.ts }}\n    steps:\n      - uses: actions/checkout@v2\n      - name: '[check if build necessary]'\n        uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            ts:\n              - '**.ts'\n              - '**.tsx'\n              - '**.json'\n  build-deploy:\n    name: '[cd|build-deploy]'\n    runs-on: 'ubuntu-latest'\n    needs: changes\n    if: ${{ needs.changes.outputs.ts == 'true' }}\n    steps:\n      - name: '[checkout] ${{ github.repository }} project'\n        uses: 'actions/checkout@v2'\n        with:\n          repository: '${{ github.repository }}'\n      - name: '[setup node]'  \n        uses: 'actions/setup-node@v2'\n        with:\n          node-version: '16'\n      - name: '[lint]'\n        run: |\n          echo TBA some linting\n      - name: '[test]'\n        run: |\n          echo TBA some testing\n      - name: '[build]'\n        run: |\n          git config --global url.\"https://github.com/\".insteadOf ssh://git@github.com/\n          git config --global url.\"https://\".insteadOf git://\n          git config --global url.\"https://\".insteadOf ssh://\n          yarn install\n          yarn run build\n          yarn run export\n      - name: '[Add GitHub Sponsors to Readme]'\n        uses: JamesIves/github-sponsors-readme-action@1.0.5\n        with:\n          token: ${{secrets.PAT}}\n          file: 'README.md'\n          minimum: 500\n          \n      - name: '[commit changes]'\n        run: |\n          git config --local user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --local user.name \"github-actions[bot]\"\n          git add .\n          git commit -m \"chore: build\" -a\n      - name: '[push changes]'\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n...\n# End of cd.yml\n",
    "source": "org-roam/org-roam-ui",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/org-roam/org-roam-ui/blob/5ac74960231db0bf7783c2ba7a19a60f582e91ab/.github/workflows/cd.yml",
    "retrieved_at": "2025-11-09T01:48:38.614227Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which have dependencies on others?",
    "answer": "---\n# File : cd.yml\n\nname: 'cd'\non:\n  push:\n    branches: [main]\ndefaults:\n  run:\n    shell: 'bash'\njobs:\n  changes:\n    runs-on: 'ubuntu-latest'\n    outputs:\n      ts: ${{ steps.filter.outputs.ts }}\n    steps:\n      - uses: actions/checkout@v2\n      - name: '[check if build necessary]'\n        uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            ts:\n              - '**.ts'\n              - '**.tsx'\n              - '**.json'\n  build-deploy:\n    name: '[cd|build-deploy]'\n    runs-on: 'ubuntu-latest'\n    needs: changes\n    if: ${{ needs.changes.outputs.ts == 'true' }}\n    steps:\n      - name: '[checkout] ${{ github.repository }} project'\n        uses: 'actions/checkout@v2'\n        with:\n          repository: '${{ github.repository }}'\n      - name: '[setup node]'  \n        uses: 'actions/setup-node@v2'\n        with:\n          node-version: '16'\n      - name: '[lint]'\n        run: |\n          echo TBA some linting\n      - name: '[test]'\n        run: |\n          echo TBA some testing\n      - name: '[build]'\n        run: |\n          git config --global url.\"https://github.com/\".insteadOf ssh://git@github.com/\n          git config --global url.\"https://\".insteadOf git://\n          git config --global url.\"https://\".insteadOf ssh://\n          yarn install\n          yarn run build\n          yarn run export\n      - name: '[Add GitHub Sponsors to Readme]'\n        uses: JamesIves/github-sponsors-readme-action@1.0.5\n        with:\n          token: ${{secrets.PAT}}\n          file: 'README.md'\n          minimum: 500\n          \n      - name: '[commit changes]'\n        run: |\n          git config --local user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --local user.name \"github-actions[bot]\"\n          git add .\n          git commit -m \"chore: build\" -a\n      - name: '[push changes]'\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n...\n# End of cd.yml\n",
    "source": "org-roam/org-roam-ui",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/org-roam/org-roam-ui/blob/5ac74960231db0bf7783c2ba7a19a60f582e91ab/.github/workflows/cd.yml",
    "retrieved_at": "2025-11-09T01:48:39.241361Z",
    "question_style": "style_3"
  },
  {
    "question": "How are secrets like `PAT` and `GITHUB_TOKEN` used to authenticate actions in the workflow?",
    "answer": "---\n# File : cd.yml\n\nname: 'cd'\non:\n  push:\n    branches: [main]\ndefaults:\n  run:\n    shell: 'bash'\njobs:\n  changes:\n    runs-on: 'ubuntu-latest'\n    outputs:\n      ts: ${{ steps.filter.outputs.ts }}\n    steps:\n      - uses: actions/checkout@v2\n      - name: '[check if build necessary]'\n        uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            ts:\n              - '**.ts'\n              - '**.tsx'\n              - '**.json'\n  build-deploy:\n    name: '[cd|build-deploy]'\n    runs-on: 'ubuntu-latest'\n    needs: changes\n    if: ${{ needs.changes.outputs.ts == 'true' }}\n    steps:\n      - name: '[checkout] ${{ github.repository }} project'\n        uses: 'actions/checkout@v2'\n        with:\n          repository: '${{ github.repository }}'\n      - name: '[setup node]'  \n        uses: 'actions/setup-node@v2'\n        with:\n          node-version: '16'\n      - name: '[lint]'\n        run: |\n          echo TBA some linting\n      - name: '[test]'\n        run: |\n          echo TBA some testing\n      - name: '[build]'\n        run: |\n          git config --global url.\"https://github.com/\".insteadOf ssh://git@github.com/\n          git config --global url.\"https://\".insteadOf git://\n          git config --global url.\"https://\".insteadOf ssh://\n          yarn install\n          yarn run build\n          yarn run export\n      - name: '[Add GitHub Sponsors to Readme]'\n        uses: JamesIves/github-sponsors-readme-action@1.0.5\n        with:\n          token: ${{secrets.PAT}}\n          file: 'README.md'\n          minimum: 500\n          \n      - name: '[commit changes]'\n        run: |\n          git config --local user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --local user.name \"github-actions[bot]\"\n          git add .\n          git commit -m \"chore: build\" -a\n      - name: '[push changes]'\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n...\n# End of cd.yml\n",
    "source": "org-roam/org-roam-ui",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/org-roam/org-roam-ui/blob/5ac74960231db0bf7783c2ba7a19a60f582e91ab/.github/workflows/cd.yml",
    "retrieved_at": "2025-11-09T01:48:39.956066Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this continuous deployment workflow?",
    "answer": "---\n# File : cd.yml\n\nname: 'cd'\non:\n  push:\n    branches: [main]\ndefaults:\n  run:\n    shell: 'bash'\njobs:\n  changes:\n    runs-on: 'ubuntu-latest'\n    outputs:\n      ts: ${{ steps.filter.outputs.ts }}\n    steps:\n      - uses: actions/checkout@v2\n      - name: '[check if build necessary]'\n        uses: dorny/paths-filter@v2\n        id: filter\n        with:\n          filters: |\n            ts:\n              - '**.ts'\n              - '**.tsx'\n              - '**.json'\n  build-deploy:\n    name: '[cd|build-deploy]'\n    runs-on: 'ubuntu-latest'\n    needs: changes\n    if: ${{ needs.changes.outputs.ts == 'true' }}\n    steps:\n      - name: '[checkout] ${{ github.repository }} project'\n        uses: 'actions/checkout@v2'\n        with:\n          repository: '${{ github.repository }}'\n      - name: '[setup node]'  \n        uses: 'actions/setup-node@v2'\n        with:\n          node-version: '16'\n      - name: '[lint]'\n        run: |\n          echo TBA some linting\n      - name: '[test]'\n        run: |\n          echo TBA some testing\n      - name: '[build]'\n        run: |\n          git config --global url.\"https://github.com/\".insteadOf ssh://git@github.com/\n          git config --global url.\"https://\".insteadOf git://\n          git config --global url.\"https://\".insteadOf ssh://\n          yarn install\n          yarn run build\n          yarn run export\n      - name: '[Add GitHub Sponsors to Readme]'\n        uses: JamesIves/github-sponsors-readme-action@1.0.5\n        with:\n          token: ${{secrets.PAT}}\n          file: 'README.md'\n          minimum: 500\n          \n      - name: '[commit changes]'\n        run: |\n          git config --local user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --local user.name \"github-actions[bot]\"\n          git add .\n          git commit -m \"chore: build\" -a\n      - name: '[push changes]'\n        uses: ad-m/github-push-action@master\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          branch: ${{ github.ref }}\n...\n# End of cd.yml\n",
    "source": "org-roam/org-roam-ui",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/org-roam/org-roam-ui/blob/5ac74960231db0bf7783c2ba7a19a60f582e91ab/.github/workflows/cd.yml",
    "retrieved_at": "2025-11-09T01:48:40.530611Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that mirrors the provided YAML, including triggers, job setup, CodeQL analysis, and language matrix.",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ main ]\n  schedule:\n    - cron: '33 10 * * 2'\n  workflow_dispatch:\n    inputs:\n    logLevel:\n      description: 'Log level'\n      required: true\n      default: 'warning'\n      type: choice\n      options:\n      - info\n      - warning\n      - debug\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'csharp', 'javascript' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Setup .NET Core\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: 6.0.x\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "Tulipr9/saas_app",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/Tulipr9/saas_app/blob/80cbdcc4e87fecc97e8451fd5a42d8a3e58f1315/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-11-09T01:48:41.371618Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this CodeQL workflow?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ main ]\n  schedule:\n    - cron: '33 10 * * 2'\n  workflow_dispatch:\n    inputs:\n    logLevel:\n      description: 'Log level'\n      required: true\n      default: 'warning'\n      type: choice\n      options:\n      - info\n      - warning\n      - debug\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'csharp', 'javascript' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Setup .NET Core\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: 6.0.x\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "Tulipr9/saas_app",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/Tulipr9/saas_app/blob/80cbdcc4e87fecc97e8451fd5a42d8a3e58f1315/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-11-09T01:48:41.939194Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the CodeQL workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ main ]\n  schedule:\n    - cron: '33 10 * * 2'\n  workflow_dispatch:\n    inputs:\n    logLevel:\n      description: 'Log level'\n      required: true\n      default: 'warning'\n      type: choice\n      options:\n      - info\n      - warning\n      - debug\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'csharp', 'javascript' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Setup .NET Core\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: 6.0.x\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "Tulipr9/saas_app",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/Tulipr9/saas_app/blob/80cbdcc4e87fecc97e8451fd5a42d8a3e58f1315/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-11-09T01:48:42.628600Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching of artifacts?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ main ]\n  schedule:\n    - cron: '33 10 * * 2'\n  workflow_dispatch:\n    inputs:\n    logLevel:\n      description: 'Log level'\n      required: true\n      default: 'warning'\n      type: choice\n      options:\n      - info\n      - warning\n      - debug\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'csharp', 'javascript' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Setup .NET Core\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: 6.0.x\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "Tulipr9/saas_app",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/Tulipr9/saas_app/blob/80cbdcc4e87fecc97e8451fd5a42d8a3e58f1315/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-11-09T01:48:43.215563Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this CodeQL workflow?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ main ]\n  schedule:\n    - cron: '33 10 * * 2'\n  workflow_dispatch:\n    inputs:\n    logLevel:\n      description: 'Log level'\n      required: true\n      default: 'warning'\n      type: choice\n      options:\n      - info\n      - warning\n      - debug\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'csharp', 'javascript' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Setup .NET Core\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: 6.0.x\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    #  Command-line programs to run using the OS shell.\n    #  See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "Tulipr9/saas_app",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/Tulipr9/saas_app/blob/80cbdcc4e87fecc97e8451fd5a42d8a3e58f1315/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-11-09T01:48:43.789155Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the QA build and deploy process described in the provided YAML.",
    "answer": "name: RNS QA build and deploy\n\non:\n  push:\n    branches: [ qa ]\n\njobs:\n  qa_build_and_deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: Setup Node 14\n      uses: actions/setup-node@v1\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Build site\n      run: yarn build:testnet\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.QA_AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.QA_AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ secrets.TESTNET_AWS_REGION }}\n\n    - name: Deploy site to S3\n      run: |\n        aws s3 sync --delete --only-show-errors build/ ${{ secrets.QA_S3_BUCKET }}",
    "source": "rsksmart/rns-manager-react",
    "path": ".github/workflows/qa-deploy.yml",
    "url": "https://github.com/rsksmart/rns-manager-react/blob/ae0f7ea49da51bcef09c07b9e2c9232e92d57fd9/.github/workflows/qa-deploy.yml",
    "retrieved_at": "2025-11-10T01:49:57.489920Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger the \"RNS QA build and deploy\" workflow?",
    "answer": "name: RNS QA build and deploy\n\non:\n  push:\n    branches: [ qa ]\n\njobs:\n  qa_build_and_deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: Setup Node 14\n      uses: actions/setup-node@v1\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Build site\n      run: yarn build:testnet\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.QA_AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.QA_AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ secrets.TESTNET_AWS_REGION }}\n\n    - name: Deploy site to S3\n      run: |\n        aws s3 sync --delete --only-show-errors build/ ${{ secrets.QA_S3_BUCKET }}",
    "source": "rsksmart/rns-manager-react",
    "path": ".github/workflows/qa-deploy.yml",
    "url": "https://github.com/rsksmart/rns-manager-react/blob/ae0f7ea49da51bcef09c07b9e2c9232e92d57fd9/.github/workflows/qa-deploy.yml",
    "retrieved_at": "2025-11-10T01:49:58.183719Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in the workflow run in parallel or have dependencies on each other?",
    "answer": "name: RNS QA build and deploy\n\non:\n  push:\n    branches: [ qa ]\n\njobs:\n  qa_build_and_deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: Setup Node 14\n      uses: actions/setup-node@v1\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Build site\n      run: yarn build:testnet\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.QA_AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.QA_AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ secrets.TESTNET_AWS_REGION }}\n\n    - name: Deploy site to S3\n      run: |\n        aws s3 sync --delete --only-show-errors build/ ${{ secrets.QA_S3_BUCKET }}",
    "source": "rsksmart/rns-manager-react",
    "path": ".github/workflows/qa-deploy.yml",
    "url": "https://github.com/rsksmart/rns-manager-react/blob/ae0f7ea49da51bcef09c07b9e2c9232e92d57fd9/.github/workflows/qa-deploy.yml",
    "retrieved_at": "2025-11-10T01:49:58.874938Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `QA_AWS_ACCESS_KEY_ID`, `QA_AWS_SECRET_ACCESS_KEY`, `TESTNET_AWS_REGION`, and `QA_S3_BUCKET` secrets used for AWS authentication and S3 deployment?",
    "answer": "name: RNS QA build and deploy\n\non:\n  push:\n    branches: [ qa ]\n\njobs:\n  qa_build_and_deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: Setup Node 14\n      uses: actions/setup-node@v1\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Build site\n      run: yarn build:testnet\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.QA_AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.QA_AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ secrets.TESTNET_AWS_REGION }}\n\n    - name: Deploy site to S3\n      run: |\n        aws s3 sync --delete --only-show-errors build/ ${{ secrets.QA_S3_BUCKET }}",
    "source": "rsksmart/rns-manager-react",
    "path": ".github/workflows/qa-deploy.yml",
    "url": "https://github.com/rsksmart/rns-manager-react/blob/ae0f7ea49da51bcef09c07b9e2c9232e92d57fd9/.github/workflows/qa-deploy.yml",
    "retrieved_at": "2025-11-10T01:49:59.663293Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when code is pushed to the `qa` branch?",
    "answer": "name: RNS QA build and deploy\n\non:\n  push:\n    branches: [ qa ]\n\njobs:\n  qa_build_and_deploy:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: Setup Node 14\n      uses: actions/setup-node@v1\n      with:\n        node-version: '14'\n\n    - name: Install dependencies\n      run: yarn\n\n    - name: Build site\n      run: yarn build:testnet\n\n    - name: Configure AWS credentials\n      uses: aws-actions/configure-aws-credentials@v1\n      with:\n        aws-access-key-id: ${{ secrets.QA_AWS_ACCESS_KEY_ID }}\n        aws-secret-access-key: ${{ secrets.QA_AWS_SECRET_ACCESS_KEY }}\n        aws-region: ${{ secrets.TESTNET_AWS_REGION }}\n\n    - name: Deploy site to S3\n      run: |\n        aws s3 sync --delete --only-show-errors build/ ${{ secrets.QA_S3_BUCKET }}",
    "source": "rsksmart/rns-manager-react",
    "path": ".github/workflows/qa-deploy.yml",
    "url": "https://github.com/rsksmart/rns-manager-react/blob/ae0f7ea49da51bcef09c07b9e2c9232e92d57fd9/.github/workflows/qa-deploy.yml",
    "retrieved_at": "2025-11-10T01:50:00.382300Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML.",
    "answer": "name: Mac MPS\n\non:\n  push:\n    tags:\n      - ciflow/mps/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n\njobs:\n  macos-12-py3-arm64-build:\n    name: macos-12-py3-arm64\n    uses: ./.github/workflows/_mac-build.yml\n    with:\n      sync-tag: macos-12-py3-arm64-build\n      build-environment: macos-12-py3-arm64\n      xcode-version: \"13.3.1\"\n      runner-type: macos-12-xl\n      build-generates-artifacts: true\n      # To match the one pre-installed in the m1 runners\n      python_version: 3.9.12\n      # We need to set the environment file here instead of trying to detect it automatically because\n      # MacOS arm64 is cross-compiled from x86-64. Specifically, it means that arm64 conda environment\n      # is needed when building PyTorch MacOS arm64 from x86-64\n      environment-file: .github/requirements/conda-env-macOS-ARM64\n    secrets:\n      MACOS_SCCACHE_S3_ACCESS_KEY_ID: ${{ secrets.MACOS_SCCACHE_S3_ACCESS_KEY_ID }}\n      MACOS_SCCACHE_S3_SECRET_ACCESS_KEY: ${{ secrets.MACOS_SCCACHE_S3_SECRET_ACCESS_KEY }}\n\n  macos-12-py3-arm64-mps-test:\n    name: macos-12-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      sync-tag: macos-12-py3-arm64-mps-test\n      build-environment: macos-12-py3-arm64\n\n  macos-13-py3-arm64-mps-test:\n    name: macos-13-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      build-environment: macos-12-py3-arm64\n      runs-on: macos-m1-13\n",
    "source": "UEFI-code/PyTorch_For_PoorGuys",
    "path": ".github/workflows/mac-mps.yml",
    "url": "https://github.com/UEFI-code/PyTorch_For_PoorGuys/blob/a66ed97b99aa81e94e5700e495e62fdaa97ecf00/.github/workflows/mac-mps.yml",
    "retrieved_at": "2025-11-10T01:50:01.400206Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Mac MPS workflow to run?",
    "answer": "name: Mac MPS\n\non:\n  push:\n    tags:\n      - ciflow/mps/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n\njobs:\n  macos-12-py3-arm64-build:\n    name: macos-12-py3-arm64\n    uses: ./.github/workflows/_mac-build.yml\n    with:\n      sync-tag: macos-12-py3-arm64-build\n      build-environment: macos-12-py3-arm64\n      xcode-version: \"13.3.1\"\n      runner-type: macos-12-xl\n      build-generates-artifacts: true\n      # To match the one pre-installed in the m1 runners\n      python_version: 3.9.12\n      # We need to set the environment file here instead of trying to detect it automatically because\n      # MacOS arm64 is cross-compiled from x86-64. Specifically, it means that arm64 conda environment\n      # is needed when building PyTorch MacOS arm64 from x86-64\n      environment-file: .github/requirements/conda-env-macOS-ARM64\n    secrets:\n      MACOS_SCCACHE_S3_ACCESS_KEY_ID: ${{ secrets.MACOS_SCCACHE_S3_ACCESS_KEY_ID }}\n      MACOS_SCCACHE_S3_SECRET_ACCESS_KEY: ${{ secrets.MACOS_SCCACHE_S3_SECRET_ACCESS_KEY }}\n\n  macos-12-py3-arm64-mps-test:\n    name: macos-12-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      sync-tag: macos-12-py3-arm64-mps-test\n      build-environment: macos-12-py3-arm64\n\n  macos-13-py3-arm64-mps-test:\n    name: macos-13-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      build-environment: macos-12-py3-arm64\n      runs-on: macos-m1-13\n",
    "source": "UEFI-code/PyTorch_For_PoorGuys",
    "path": ".github/workflows/mac-mps.yml",
    "url": "https://github.com/UEFI-code/PyTorch_For_PoorGuys/blob/a66ed97b99aa81e94e5700e495e62fdaa97ecf00/.github/workflows/mac-mps.yml",
    "retrieved_at": "2025-11-10T01:50:02.031168Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: Mac MPS\n\non:\n  push:\n    tags:\n      - ciflow/mps/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n\njobs:\n  macos-12-py3-arm64-build:\n    name: macos-12-py3-arm64\n    uses: ./.github/workflows/_mac-build.yml\n    with:\n      sync-tag: macos-12-py3-arm64-build\n      build-environment: macos-12-py3-arm64\n      xcode-version: \"13.3.1\"\n      runner-type: macos-12-xl\n      build-generates-artifacts: true\n      # To match the one pre-installed in the m1 runners\n      python_version: 3.9.12\n      # We need to set the environment file here instead of trying to detect it automatically because\n      # MacOS arm64 is cross-compiled from x86-64. Specifically, it means that arm64 conda environment\n      # is needed when building PyTorch MacOS arm64 from x86-64\n      environment-file: .github/requirements/conda-env-macOS-ARM64\n    secrets:\n      MACOS_SCCACHE_S3_ACCESS_KEY_ID: ${{ secrets.MACOS_SCCACHE_S3_ACCESS_KEY_ID }}\n      MACOS_SCCACHE_S3_SECRET_ACCESS_KEY: ${{ secrets.MACOS_SCCACHE_S3_SECRET_ACCESS_KEY }}\n\n  macos-12-py3-arm64-mps-test:\n    name: macos-12-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      sync-tag: macos-12-py3-arm64-mps-test\n      build-environment: macos-12-py3-arm64\n\n  macos-13-py3-arm64-mps-test:\n    name: macos-13-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      build-environment: macos-12-py3-arm64\n      runs-on: macos-m1-13\n",
    "source": "UEFI-code/PyTorch_For_PoorGuys",
    "path": ".github/workflows/mac-mps.yml",
    "url": "https://github.com/UEFI-code/PyTorch_For_PoorGuys/blob/a66ed97b99aa81e94e5700e495e62fdaa97ecf00/.github/workflows/mac-mps.yml",
    "retrieved_at": "2025-11-10T01:50:02.721903Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `MACOS_SCCACHE_S3_ACCESS_KEY_ID` and `MACOS_SCCACHE_S3_SECRET_ACCESS_KEY` used within the `macos-12-py3-arm64-build` job?",
    "answer": "name: Mac MPS\n\non:\n  push:\n    tags:\n      - ciflow/mps/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n\njobs:\n  macos-12-py3-arm64-build:\n    name: macos-12-py3-arm64\n    uses: ./.github/workflows/_mac-build.yml\n    with:\n      sync-tag: macos-12-py3-arm64-build\n      build-environment: macos-12-py3-arm64\n      xcode-version: \"13.3.1\"\n      runner-type: macos-12-xl\n      build-generates-artifacts: true\n      # To match the one pre-installed in the m1 runners\n      python_version: 3.9.12\n      # We need to set the environment file here instead of trying to detect it automatically because\n      # MacOS arm64 is cross-compiled from x86-64. Specifically, it means that arm64 conda environment\n      # is needed when building PyTorch MacOS arm64 from x86-64\n      environment-file: .github/requirements/conda-env-macOS-ARM64\n    secrets:\n      MACOS_SCCACHE_S3_ACCESS_KEY_ID: ${{ secrets.MACOS_SCCACHE_S3_ACCESS_KEY_ID }}\n      MACOS_SCCACHE_S3_SECRET_ACCESS_KEY: ${{ secrets.MACOS_SCCACHE_S3_SECRET_ACCESS_KEY }}\n\n  macos-12-py3-arm64-mps-test:\n    name: macos-12-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      sync-tag: macos-12-py3-arm64-mps-test\n      build-environment: macos-12-py3-arm64\n\n  macos-13-py3-arm64-mps-test:\n    name: macos-13-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      build-environment: macos-12-py3-arm64\n      runs-on: macos-m1-13\n",
    "source": "UEFI-code/PyTorch_For_PoorGuys",
    "path": ".github/workflows/mac-mps.yml",
    "url": "https://github.com/UEFI-code/PyTorch_For_PoorGuys/blob/a66ed97b99aa81e94e5700e495e62fdaa97ecf00/.github/workflows/mac-mps.yml",
    "retrieved_at": "2025-11-10T01:50:03.571248Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the \"Mac MPS\" workflow?",
    "answer": "name: Mac MPS\n\non:\n  push:\n    tags:\n      - ciflow/mps/*\n  workflow_dispatch:\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}\n  cancel-in-progress: true\n\njobs:\n  macos-12-py3-arm64-build:\n    name: macos-12-py3-arm64\n    uses: ./.github/workflows/_mac-build.yml\n    with:\n      sync-tag: macos-12-py3-arm64-build\n      build-environment: macos-12-py3-arm64\n      xcode-version: \"13.3.1\"\n      runner-type: macos-12-xl\n      build-generates-artifacts: true\n      # To match the one pre-installed in the m1 runners\n      python_version: 3.9.12\n      # We need to set the environment file here instead of trying to detect it automatically because\n      # MacOS arm64 is cross-compiled from x86-64. Specifically, it means that arm64 conda environment\n      # is needed when building PyTorch MacOS arm64 from x86-64\n      environment-file: .github/requirements/conda-env-macOS-ARM64\n    secrets:\n      MACOS_SCCACHE_S3_ACCESS_KEY_ID: ${{ secrets.MACOS_SCCACHE_S3_ACCESS_KEY_ID }}\n      MACOS_SCCACHE_S3_SECRET_ACCESS_KEY: ${{ secrets.MACOS_SCCACHE_S3_SECRET_ACCESS_KEY }}\n\n  macos-12-py3-arm64-mps-test:\n    name: macos-12-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      sync-tag: macos-12-py3-arm64-mps-test\n      build-environment: macos-12-py3-arm64\n\n  macos-13-py3-arm64-mps-test:\n    name: macos-13-py3-arm64-mps\n    uses: ./.github/workflows/_mac-test-mps.yml\n    needs: macos-12-py3-arm64-build\n    with:\n      build-environment: macos-12-py3-arm64\n      runs-on: macos-m1-13\n",
    "source": "UEFI-code/PyTorch_For_PoorGuys",
    "path": ".github/workflows/mac-mps.yml",
    "url": "https://github.com/UEFI-code/PyTorch_For_PoorGuys/blob/a66ed97b99aa81e94e5700e495e62fdaa97ecf00/.github/workflows/mac-mps.yml",
    "retrieved_at": "2025-11-10T01:50:04.172927Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML.",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Cypress evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/cypress-evaluator-action\n          ref: v8.2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/cypress-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Cypress evaluation\n        id: evaluator\n        uses: ./.github/actions/cypress-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n          npm-start: true\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts/blob/0e1907d2e82e28b96aabcb7c4a34089b02ea1b48/.github/workflows/main.yml",
    "retrieved_at": "2025-11-11T01:46:42.286156Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events trigger this workflow?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Cypress evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/cypress-evaluator-action\n          ref: v8.2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/cypress-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Cypress evaluation\n        id: evaluator\n        uses: ./.github/actions/cypress-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n          npm-start: true\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts/blob/0e1907d2e82e28b96aabcb7c4a34089b02ea1b48/.github/workflows/main.yml",
    "retrieved_at": "2025-11-11T01:46:42.986918Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what dependencies exist between them?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Cypress evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/cypress-evaluator-action\n          ref: v8.2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/cypress-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Cypress evaluation\n        id: evaluator\n        uses: ./.github/actions/cypress-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n          npm-start: true\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts/blob/0e1907d2e82e28b96aabcb7c4a34089b02ea1b48/.github/workflows/main.yml",
    "retrieved_at": "2025-11-11T01:46:43.712097Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GIT_HUB_PAT` secret used for authenticating the checkout of multiple repositories?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Cypress evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/cypress-evaluator-action\n          ref: v8.2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/cypress-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Cypress evaluation\n        id: evaluator\n        uses: ./.github/actions/cypress-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n          npm-start: true\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts/blob/0e1907d2e82e28b96aabcb7c4a34089b02ea1b48/.github/workflows/main.yml",
    "retrieved_at": "2025-11-11T01:46:44.465725Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow, which runs on pull requests?",
    "answer": "on:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  evaluator:\n    runs-on: self-hosted\n    name: Evaluator\n    steps:\n      - name: Fetch project repository\n        uses: actions/checkout@v3\n\n      - name: Fetch ESLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/eslint-linter-action\n          ref: v3.5\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/eslint-evaluator\n\n      - name: Fetch StyleLint evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/stylelint-linter-action\n          ref: v2.3\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/stylelint-evaluator\n\n      - name: Fetch Blocked Files Checkout action\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/blocked-files-checkout-action\n          ref: v2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/blocked-files-checkout\n\n      - name: Fetch Cypress evaluator\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/cypress-evaluator-action\n          ref: v8.2\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/cypress-evaluator\n\n      - name: Fetch Store evaluation\n        uses: actions/checkout@v3\n        with:\n          repository: betrybe/store-evaluation-action\n          ref: v8.0\n          token: ${{ secrets.GIT_HUB_PAT }}\n          path: .github/actions/store-evaluation\n\n      - name: Setup NodeJS\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Restore protected files\n        uses: ./.github/actions/blocked-files-checkout\n        with:\n          restore_branch: 'main'\n\n      - name: Run ESLint evaluator\n        uses: ./.github/actions/eslint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run StyleLint evaluator\n        uses: ./.github/actions/stylelint-evaluator\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n          pr_number: ${{ github.event.pull_request.number }}\n\n      - name: Run Cypress evaluation\n        id: evaluator\n        uses: ./.github/actions/cypress-evaluator\n        with:\n          pr_author_username: ${{ github.event.pull_request.user.login }}\n          npm-start: true\n\n      - name: Run Store evaluation\n        uses: ./.github/actions/store-evaluation\n        with:\n          evaluation-data: ${{ steps.evaluator.outputs.result }}\n          environment: production\n          token: ${{ secrets.GITHUB_TOKEN }}\n",
    "source": "guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/guilhermeaugusto-dev/Gui772001--projeto-starwars-planets-search-ts/blob/0e1907d2e82e28b96aabcb7c4a34089b02ea1b48/.github/workflows/main.yml",
    "retrieved_at": "2025-11-11T01:46:45.185691Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML file, including build steps, artifact uploads, and S3 deployment.",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/SpiriGroundControlTest",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/SpiriGroundControlTest/blob/00121d4b66079e93d099b002c94101f2774131ca/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-11T01:46:46.147774Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and conditions trigger the execution of this GitHub Actions workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/SpiriGroundControlTest",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/SpiriGroundControlTest/blob/00121d4b66079e93d099b002c94101f2774131ca/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-11T01:46:46.928461Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Windows Release\" workflow run in parallel, and what are their dependencies?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/SpiriGroundControlTest",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/SpiriGroundControlTest/blob/00121d4b66079e93d099b002c94101f2774131ca/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-11T01:46:47.757477Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` secrets used to upload build artifacts to an S3 bucket?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/SpiriGroundControlTest",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/SpiriGroundControlTest/blob/00121d4b66079e93d099b002c94101f2774131ca/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-11T01:46:48.598557Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow concerning QGroundControl?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/SpiriGroundControlTest",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/SpiriGroundControlTest/blob/00121d4b66079e93d099b002c94101f2774131ca/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-11-11T01:46:49.294290Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided Codespell workflow.",
    "answer": "---\nname: Codespell\n\non:\n  push:\n    branches: [master]\n  pull_request:\n    branches: [master]\n\npermissions:\n  contents: read\n\njobs:\n  codespell:\n    name: Check for spelling errors\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n      - name: Codespell\n        uses: codespell-project/actions-codespell@94259cd8be02ad2903ba34a22d9c13de21a74461 # v2.0\n",
    "source": "yaap/external_libfuse",
    "path": ".github/workflows/codespell.yml",
    "url": "https://github.com/yaap/external_libfuse/blob/720740ad252354f593d0f121b24f5fddaf768ae3/.github/workflows/codespell.yml",
    "retrieved_at": "2025-11-12T01:45:54.432808Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch conditions trigger the Codespell workflow to run?",
    "answer": "---\nname: Codespell\n\non:\n  push:\n    branches: [master]\n  pull_request:\n    branches: [master]\n\npermissions:\n  contents: read\n\njobs:\n  codespell:\n    name: Check for spelling errors\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n      - name: Codespell\n        uses: codespell-project/actions-codespell@94259cd8be02ad2903ba34a22d9c13de21a74461 # v2.0\n",
    "source": "yaap/external_libfuse",
    "path": ".github/workflows/codespell.yml",
    "url": "https://github.com/yaap/external_libfuse/blob/720740ad252354f593d0f121b24f5fddaf768ae3/.github/workflows/codespell.yml",
    "retrieved_at": "2025-11-12T01:45:54.999148Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel or depend on the completion of others?",
    "answer": "---\nname: Codespell\n\non:\n  push:\n    branches: [master]\n  pull_request:\n    branches: [master]\n\npermissions:\n  contents: read\n\njobs:\n  codespell:\n    name: Check for spelling errors\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n      - name: Codespell\n        uses: codespell-project/actions-codespell@94259cd8be02ad2903ba34a22d9c13de21a74461 # v2.0\n",
    "source": "yaap/external_libfuse",
    "path": ".github/workflows/codespell.yml",
    "url": "https://github.com/yaap/external_libfuse/blob/720740ad252354f593d0f121b24f5fddaf768ae3/.github/workflows/codespell.yml",
    "retrieved_at": "2025-11-12T01:45:55.647091Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the codespell action utilize any environment variables or secrets for configuration?",
    "answer": "---\nname: Codespell\n\non:\n  push:\n    branches: [master]\n  pull_request:\n    branches: [master]\n\npermissions:\n  contents: read\n\njobs:\n  codespell:\n    name: Check for spelling errors\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n      - name: Codespell\n        uses: codespell-project/actions-codespell@94259cd8be02ad2903ba34a22d9c13de21a74461 # v2.0\n",
    "source": "yaap/external_libfuse",
    "path": ".github/workflows/codespell.yml",
    "url": "https://github.com/yaap/external_libfuse/blob/720740ad252354f593d0f121b24f5fddaf768ae3/.github/workflows/codespell.yml",
    "retrieved_at": "2025-11-12T01:45:56.243005Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this GitHub Actions workflow accomplish?",
    "answer": "---\nname: Codespell\n\non:\n  push:\n    branches: [master]\n  pull_request:\n    branches: [master]\n\npermissions:\n  contents: read\n\njobs:\n  codespell:\n    name: Check for spelling errors\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n      - name: Codespell\n        uses: codespell-project/actions-codespell@94259cd8be02ad2903ba34a22d9c13de21a74461 # v2.0\n",
    "source": "yaap/external_libfuse",
    "path": ".github/workflows/codespell.yml",
    "url": "https://github.com/yaap/external_libfuse/blob/720740ad252354f593d0f121b24f5fddaf768ae3/.github/workflows/codespell.yml",
    "retrieved_at": "2025-11-12T01:45:56.760124Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file replicating the build and push actions defined in the provided YAML, including Docker metadata and registry login.",
    "answer": "# https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md\n\nname: Build\n\non:\n  push:\n    branches:\n      - 'main'\n    tags:\n      - 'v*.*.*'\n\njobs:\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Docker meta\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          # list of Docker images to use as base name for tags\n          images: |\n            ghcr.io/flow-hydraulics/flow-wallet-api\n          # generate Docker tags based on the following events/attributes\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        id: buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: ./docker/wallet/Dockerfile\n          builder: ${{ steps.buildx.outputs.name }}\n          push: ${{ github.event_name != 'pull_request' }}\n          platforms: linux/amd64\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}\n",
    "source": "flow-hydraulics/flow-wallet-api",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/flow-hydraulics/flow-wallet-api/blob/b95ea454c02d892d0de671778f4ed67c67d783dd/.github/workflows/build.yml",
    "retrieved_at": "2025-11-12T01:45:57.676041Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events to the `main` branch or tags matching `v*.*.*` trigger this workflow?",
    "answer": "# https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md\n\nname: Build\n\non:\n  push:\n    branches:\n      - 'main'\n    tags:\n      - 'v*.*.*'\n\njobs:\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Docker meta\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          # list of Docker images to use as base name for tags\n          images: |\n            ghcr.io/flow-hydraulics/flow-wallet-api\n          # generate Docker tags based on the following events/attributes\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        id: buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: ./docker/wallet/Dockerfile\n          builder: ${{ steps.buildx.outputs.name }}\n          push: ${{ github.event_name != 'pull_request' }}\n          platforms: linux/amd64\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}\n",
    "source": "flow-hydraulics/flow-wallet-api",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/flow-hydraulics/flow-wallet-api/blob/b95ea454c02d892d0de671778f4ed67c67d783dd/.github/workflows/build.yml",
    "retrieved_at": "2025-11-12T01:45:58.278024Z",
    "question_style": "style_2"
  },
  {
    "question": "What dependencies or parallel execution exists between the job and steps in this workflow?",
    "answer": "# https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md\n\nname: Build\n\non:\n  push:\n    branches:\n      - 'main'\n    tags:\n      - 'v*.*.*'\n\njobs:\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Docker meta\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          # list of Docker images to use as base name for tags\n          images: |\n            ghcr.io/flow-hydraulics/flow-wallet-api\n          # generate Docker tags based on the following events/attributes\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        id: buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: ./docker/wallet/Dockerfile\n          builder: ${{ steps.buildx.outputs.name }}\n          push: ${{ github.event_name != 'pull_request' }}\n          platforms: linux/amd64\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}\n",
    "source": "flow-hydraulics/flow-wallet-api",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/flow-hydraulics/flow-wallet-api/blob/b95ea454c02d892d0de671778f4ed67c67d783dd/.github/workflows/build.yml",
    "retrieved_at": "2025-11-12T01:45:58.924225Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to authenticate with the GitHub Container Registry?",
    "answer": "# https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md\n\nname: Build\n\non:\n  push:\n    branches:\n      - 'main'\n    tags:\n      - 'v*.*.*'\n\njobs:\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Docker meta\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          # list of Docker images to use as base name for tags\n          images: |\n            ghcr.io/flow-hydraulics/flow-wallet-api\n          # generate Docker tags based on the following events/attributes\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        id: buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: ./docker/wallet/Dockerfile\n          builder: ${{ steps.buildx.outputs.name }}\n          push: ${{ github.event_name != 'pull_request' }}\n          platforms: linux/amd64\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}\n",
    "source": "flow-hydraulics/flow-wallet-api",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/flow-hydraulics/flow-wallet-api/blob/b95ea454c02d892d0de671778f4ed67c67d783dd/.github/workflows/build.yml",
    "retrieved_at": "2025-11-12T01:45:59.610760Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by building and pushing a Docker image to GitHub Container Registry?",
    "answer": "# https://github.com/docker/build-push-action/blob/master/docs/advanced/tags-labels.md\n\nname: Build\n\non:\n  push:\n    branches:\n      - 'main'\n    tags:\n      - 'v*.*.*'\n\njobs:\n\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Docker meta\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          # list of Docker images to use as base name for tags\n          images: |\n            ghcr.io/flow-hydraulics/flow-wallet-api\n          # generate Docker tags based on the following events/attributes\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            type=semver,pattern={{major}}\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v1\n\n      - name: Set up Docker Buildx\n        id: buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.repository_owner }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        id: docker_build\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: ./docker/wallet/Dockerfile\n          builder: ${{ steps.buildx.outputs.name }}\n          push: ${{ github.event_name != 'pull_request' }}\n          platforms: linux/amd64\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}\n",
    "source": "flow-hydraulics/flow-wallet-api",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/flow-hydraulics/flow-wallet-api/blob/b95ea454c02d892d0de671778f4ed67c67d783dd/.github/workflows/build.yml",
    "retrieved_at": "2025-11-12T01:46:00.198506Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow file.",
    "answer": "name: \"End to End\"\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\nconcurrency:\n  group: ${{ github.head_ref }}/e2e\n  cancel-in-progress: true\n\npermissions:\n  contents: read\n\ndefaults:\n  run:\n    working-directory: docker\n\njobs:\n  e2e:\n    name: FUSE Mount\n    runs-on: ubuntu-22.04\n    timeout-minutes: 30\n    steps:\n    - name: Set up Go 1.x\n      uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v2\n      with:\n        go-version: ^1.13\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v2\n\n    - name: Install dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y fuse\n\n    - name: Start SeaweedFS\n      timeout-minutes: 5\n      run: make build_e2e && docker compose -f ./compose/e2e-mount.yml up --wait\n\n    - name: Run FIO 4k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 128k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 1MB\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n        \n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Save logs\n      if: always()\n      run: |\n        docker compose -f ./compose/e2e-mount.yml logs > output.log\n        echo 'Showing last 500 log lines of mount service:'\n        docker compose -f ./compose/e2e-mount.yml logs --tail 500 mount\n\n    - name: Check for data races\n      if: always()\n      continue-on-error: true # TODO: remove this comment to enable build failure on data races (after all are fixed)\n      run: grep -A50 'DATA RACE' output.log && exit 1 || exit 0\n\n    - name: Archive logs\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: output-logs\n        path: docker/output.log\n\n    - name: Cleanup\n      if: always()\n      run: docker compose -f ./compose/e2e-mount.yml down --volumes --remove-orphans --rmi all\n",
    "source": "jingui326/common-seaweedfs",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/jingui326/common-seaweedfs/blob/dc6b75042473b33c5f2fadc2174f1661fbfe4d5d/.github/workflows/e2e.yml",
    "retrieved_at": "2025-11-13T01:47:16.976324Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: \"End to End\"\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\nconcurrency:\n  group: ${{ github.head_ref }}/e2e\n  cancel-in-progress: true\n\npermissions:\n  contents: read\n\ndefaults:\n  run:\n    working-directory: docker\n\njobs:\n  e2e:\n    name: FUSE Mount\n    runs-on: ubuntu-22.04\n    timeout-minutes: 30\n    steps:\n    - name: Set up Go 1.x\n      uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v2\n      with:\n        go-version: ^1.13\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v2\n\n    - name: Install dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y fuse\n\n    - name: Start SeaweedFS\n      timeout-minutes: 5\n      run: make build_e2e && docker compose -f ./compose/e2e-mount.yml up --wait\n\n    - name: Run FIO 4k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 128k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 1MB\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n        \n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Save logs\n      if: always()\n      run: |\n        docker compose -f ./compose/e2e-mount.yml logs > output.log\n        echo 'Showing last 500 log lines of mount service:'\n        docker compose -f ./compose/e2e-mount.yml logs --tail 500 mount\n\n    - name: Check for data races\n      if: always()\n      continue-on-error: true # TODO: remove this comment to enable build failure on data races (after all are fixed)\n      run: grep -A50 'DATA RACE' output.log && exit 1 || exit 0\n\n    - name: Archive logs\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: output-logs\n        path: docker/output.log\n\n    - name: Cleanup\n      if: always()\n      run: docker compose -f ./compose/e2e-mount.yml down --volumes --remove-orphans --rmi all\n",
    "source": "jingui326/common-seaweedfs",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/jingui326/common-seaweedfs/blob/dc6b75042473b33c5f2fadc2174f1661fbfe4d5d/.github/workflows/e2e.yml",
    "retrieved_at": "2025-11-13T01:47:17.675557Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and which steps depend on the successful completion of previous steps within the \"e2e\" job?",
    "answer": "name: \"End to End\"\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\nconcurrency:\n  group: ${{ github.head_ref }}/e2e\n  cancel-in-progress: true\n\npermissions:\n  contents: read\n\ndefaults:\n  run:\n    working-directory: docker\n\njobs:\n  e2e:\n    name: FUSE Mount\n    runs-on: ubuntu-22.04\n    timeout-minutes: 30\n    steps:\n    - name: Set up Go 1.x\n      uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v2\n      with:\n        go-version: ^1.13\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v2\n\n    - name: Install dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y fuse\n\n    - name: Start SeaweedFS\n      timeout-minutes: 5\n      run: make build_e2e && docker compose -f ./compose/e2e-mount.yml up --wait\n\n    - name: Run FIO 4k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 128k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 1MB\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n        \n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Save logs\n      if: always()\n      run: |\n        docker compose -f ./compose/e2e-mount.yml logs > output.log\n        echo 'Showing last 500 log lines of mount service:'\n        docker compose -f ./compose/e2e-mount.yml logs --tail 500 mount\n\n    - name: Check for data races\n      if: always()\n      continue-on-error: true # TODO: remove this comment to enable build failure on data races (after all are fixed)\n      run: grep -A50 'DATA RACE' output.log && exit 1 || exit 0\n\n    - name: Archive logs\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: output-logs\n        path: docker/output.log\n\n    - name: Cleanup\n      if: always()\n      run: docker compose -f ./compose/e2e-mount.yml down --volumes --remove-orphans --rmi all\n",
    "source": "jingui326/common-seaweedfs",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/jingui326/common-seaweedfs/blob/dc6b75042473b33c5f2fadc2174f1661fbfe4d5d/.github/workflows/e2e.yml",
    "retrieved_at": "2025-11-13T01:47:18.482929Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any secrets or environment variables utilized within the docker compose files referenced in this workflow?",
    "answer": "name: \"End to End\"\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\nconcurrency:\n  group: ${{ github.head_ref }}/e2e\n  cancel-in-progress: true\n\npermissions:\n  contents: read\n\ndefaults:\n  run:\n    working-directory: docker\n\njobs:\n  e2e:\n    name: FUSE Mount\n    runs-on: ubuntu-22.04\n    timeout-minutes: 30\n    steps:\n    - name: Set up Go 1.x\n      uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v2\n      with:\n        go-version: ^1.13\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v2\n\n    - name: Install dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y fuse\n\n    - name: Start SeaweedFS\n      timeout-minutes: 5\n      run: make build_e2e && docker compose -f ./compose/e2e-mount.yml up --wait\n\n    - name: Run FIO 4k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 128k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 1MB\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n        \n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Save logs\n      if: always()\n      run: |\n        docker compose -f ./compose/e2e-mount.yml logs > output.log\n        echo 'Showing last 500 log lines of mount service:'\n        docker compose -f ./compose/e2e-mount.yml logs --tail 500 mount\n\n    - name: Check for data races\n      if: always()\n      continue-on-error: true # TODO: remove this comment to enable build failure on data races (after all are fixed)\n      run: grep -A50 'DATA RACE' output.log && exit 1 || exit 0\n\n    - name: Archive logs\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: output-logs\n        path: docker/output.log\n\n    - name: Cleanup\n      if: always()\n      run: docker compose -f ./compose/e2e-mount.yml down --volumes --remove-orphans --rmi all\n",
    "source": "jingui326/common-seaweedfs",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/jingui326/common-seaweedfs/blob/dc6b75042473b33c5f2fadc2174f1661fbfe4d5d/.github/workflows/e2e.yml",
    "retrieved_at": "2025-11-13T01:47:19.311032Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this end-to-end workflow?",
    "answer": "name: \"End to End\"\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\nconcurrency:\n  group: ${{ github.head_ref }}/e2e\n  cancel-in-progress: true\n\npermissions:\n  contents: read\n\ndefaults:\n  run:\n    working-directory: docker\n\njobs:\n  e2e:\n    name: FUSE Mount\n    runs-on: ubuntu-22.04\n    timeout-minutes: 30\n    steps:\n    - name: Set up Go 1.x\n      uses: actions/setup-go@0c52d547c9bc32b1aa3301fd7a9cb496313a4491 # v2\n      with:\n        go-version: ^1.13\n      id: go\n\n    - name: Check out code into the Go module directory\n      uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v2\n\n    - name: Install dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y fuse\n\n    - name: Start SeaweedFS\n      timeout-minutes: 5\n      run: make build_e2e && docker compose -f ./compose/e2e-mount.yml up --wait\n\n    - name: Run FIO 4k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=4k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=4k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 128k\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n\n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=128k'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=128k --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Run FIO 1MB\n      timeout-minutes: 15\n      run: |\n        echo \"Starting FIO at: $(date)\"\n        # Concurrent r/w\n        echo 'Run randrw with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randrw --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1\n        \n        echo \"Verify FIO at: $(date)\"\n        # Verified write\n        echo 'Run randwrite with size=16M bs=1m'\n        docker compose -f ./compose/e2e-mount.yml exec mount timeout -k5 60 fio --name=fiotest --filename=/mnt/seaweedfs/fiotest --size=16M --rw=randwrite --bs=1m --direct=1 --numjobs=8 --ioengine=libaio --iodepth=32 --group_reporting --runtime=30 --time_based=1 --do_verify=0 --verify=crc32c --verify_backlog=1\n\n    - name: Save logs\n      if: always()\n      run: |\n        docker compose -f ./compose/e2e-mount.yml logs > output.log\n        echo 'Showing last 500 log lines of mount service:'\n        docker compose -f ./compose/e2e-mount.yml logs --tail 500 mount\n\n    - name: Check for data races\n      if: always()\n      continue-on-error: true # TODO: remove this comment to enable build failure on data races (after all are fixed)\n      run: grep -A50 'DATA RACE' output.log && exit 1 || exit 0\n\n    - name: Archive logs\n      if: always()\n      uses: actions/upload-artifact@v4\n      with:\n        name: output-logs\n        path: docker/output.log\n\n    - name: Cleanup\n      if: always()\n      run: docker compose -f ./compose/e2e-mount.yml down --volumes --remove-orphans --rmi all\n",
    "source": "jingui326/common-seaweedfs",
    "path": ".github/workflows/e2e.yml",
    "url": "https://github.com/jingui326/common-seaweedfs/blob/dc6b75042473b33c5f2fadc2174f1661fbfe4d5d/.github/workflows/e2e.yml",
    "retrieved_at": "2025-11-13T01:47:20.153553Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow mirroring the provided YAML, including scheduled and manual triggers, Node.js matrix, and NPM package installations.",
    "answer": "name: Npm\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'NPM exact version'\n        required: true\n  schedule:\n    - cron:  '0 0 * * *'\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14, 15, 16]\n    \n    steps:\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n          check-latest: true\n      - name: Update NPM to latest\n        run: npm --version;npm install -g npm;npm --version\n      - name: Install React Native CLI\n        run: npm install -g @react-native-community/cli\n      - name: Init new project\n        run: react-native init --npm test; cd test\n      - name: \"Install version ${{ github.event.inputs.version }}\"\n        run: \"npm install react-native-render-html@${{ github.event.inputs.version }}\"",
    "source": "robertwood-mobile/React-Native-Render-HTML",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/robertwood-mobile/React-Native-Render-HTML/blob/46b7da58eea2392c5d46a11f2b0597278035538e/.github/workflows/npm.yml",
    "retrieved_at": "2025-11-13T01:47:21.242299Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of this \"Npm\" workflow?",
    "answer": "name: Npm\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'NPM exact version'\n        required: true\n  schedule:\n    - cron:  '0 0 * * *'\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14, 15, 16]\n    \n    steps:\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n          check-latest: true\n      - name: Update NPM to latest\n        run: npm --version;npm install -g npm;npm --version\n      - name: Install React Native CLI\n        run: npm install -g @react-native-community/cli\n      - name: Init new project\n        run: react-native init --npm test; cd test\n      - name: \"Install version ${{ github.event.inputs.version }}\"\n        run: \"npm install react-native-render-html@${{ github.event.inputs.version }}\"",
    "source": "robertwood-mobile/React-Native-Render-HTML",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/robertwood-mobile/React-Native-Render-HTML/blob/46b7da58eea2392c5d46a11f2b0597278035538e/.github/workflows/npm.yml",
    "retrieved_at": "2025-11-13T01:47:21.918503Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or sequentially, and what are their dependencies?",
    "answer": "name: Npm\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'NPM exact version'\n        required: true\n  schedule:\n    - cron:  '0 0 * * *'\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14, 15, 16]\n    \n    steps:\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n          check-latest: true\n      - name: Update NPM to latest\n        run: npm --version;npm install -g npm;npm --version\n      - name: Install React Native CLI\n        run: npm install -g @react-native-community/cli\n      - name: Init new project\n        run: react-native init --npm test; cd test\n      - name: \"Install version ${{ github.event.inputs.version }}\"\n        run: \"npm install react-native-render-html@${{ github.event.inputs.version }}\"",
    "source": "robertwood-mobile/React-Native-Render-HTML",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/robertwood-mobile/React-Native-Render-HTML/blob/46b7da58eea2392c5d46a11f2b0597278035538e/.github/workflows/npm.yml",
    "retrieved_at": "2025-11-13T01:47:22.565458Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching or artifacts for node_modules or build outputs?",
    "answer": "name: Npm\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'NPM exact version'\n        required: true\n  schedule:\n    - cron:  '0 0 * * *'\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14, 15, 16]\n    \n    steps:\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n          check-latest: true\n      - name: Update NPM to latest\n        run: npm --version;npm install -g npm;npm --version\n      - name: Install React Native CLI\n        run: npm install -g @react-native-community/cli\n      - name: Init new project\n        run: react-native init --npm test; cd test\n      - name: \"Install version ${{ github.event.inputs.version }}\"\n        run: \"npm install react-native-render-html@${{ github.event.inputs.version }}\"",
    "source": "robertwood-mobile/React-Native-Render-HTML",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/robertwood-mobile/React-Native-Render-HTML/blob/46b7da58eea2392c5d46a11f2b0597278035538e/.github/workflows/npm.yml",
    "retrieved_at": "2025-11-13T01:47:23.361029Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary goal or outcome of this NPM workflow?",
    "answer": "name: Npm\non:\n  workflow_dispatch:\n    inputs:\n      version:\n        description: 'NPM exact version'\n        required: true\n  schedule:\n    - cron:  '0 0 * * *'\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14, 15, 16]\n    \n    steps:\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v2\n        with:\n          node-version: ${{ matrix.node-version }}\n          check-latest: true\n      - name: Update NPM to latest\n        run: npm --version;npm install -g npm;npm --version\n      - name: Install React Native CLI\n        run: npm install -g @react-native-community/cli\n      - name: Init new project\n        run: react-native init --npm test; cd test\n      - name: \"Install version ${{ github.event.inputs.version }}\"\n        run: \"npm install react-native-render-html@${{ github.event.inputs.version }}\"",
    "source": "robertwood-mobile/React-Native-Render-HTML",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/robertwood-mobile/React-Native-Render-HTML/blob/46b7da58eea2392c5d46a11f2b0597278035538e/.github/workflows/npm.yml",
    "retrieved_at": "2025-11-13T01:47:24.114420Z",
    "question_style": "style_5"
  }
]