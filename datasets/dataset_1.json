[
  {
    "question": "Create a GitHub Actions workflow that replicates the CI process of testing CloudFormation Guard rules and building a ruleset, as defined in the provided YAML.",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:57.650917Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch configurations trigger this GitHub Actions workflow?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:58.212878Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:58.635846Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `VERSION` environment variable used in the `buildRuleSet` job's Python script execution?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:59.079387Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or goal of this CI workflow?",
    "answer": "name: Continuous Integration\n\non:\n  push:\n  pull_request:\n    branches:\n      - main\n\nenv:\n  VERSION: \"1.0.2\"\n\njobs:\n  testRules:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Run guard rules tests\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/\n    ## If test fails run step to pull out only failed tests\n    - name: Display Failed Rules Only\n      if: ${{ failure() }}\n      shell: bash\n      run: |\n        curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/aws-cloudformation/cloudformation-guard/main/install-guard.sh | sh\n        export PATH=${PATH}:~/.guard/bin\n        cfn-guard test -d ./rules/ | grep \"FAIL Rules:\" -B 2 -A 1\n  buildRuleSet:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repo\n        uses: actions/checkout@v2\n      - run: |\n          chmod +x ./mappings/build.py\n          python3 ./mappings/build.py -r $VERSION\n        shell: bash\n      - uses: actions/upload-artifact@v3\n        with:\n          name: ruleset-build\n          path: |\n            docker/output/\n            mappings/rule_set_guard_rules_registry_all_rules.json\n          if-no-files-found: error\n",
    "source": "aws-cloudformation/aws-guard-rules-registry",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/aws-cloudformation/aws-guard-rules-registry/blob/7f7340c26ae5d5e8874651dbffeb12e0e9f505b6/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-06T12:39:59.523621Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML's PR GPU tests, including concurrency, matrix strategy, and secrets.",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:00.262442Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"PR GPU tests\" workflow?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:00.703950Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:01.091911Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `MCLOUD_API_KEY` secret used within the `pytest-gpu` job?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:01.665699Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, which runs GPU-based pytest jobs on pull requests and pushes to main/release branches?",
    "answer": "name: PR GPU tests\non:\n  push:\n    branches:\n    - main\n    - release/*\n  pull_request_target:\n    branches:\n    - main\n    - release/**\n  workflow_dispatch:\n# Cancel old runs when a new commit is pushed to the same branch if not on main or dev\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\njobs:\n  pytest-gpu:\n    uses: ./.github/workflows/pytest-gpu.yaml\n    strategy:\n      matrix:\n        include:\n        - name: 'gpu-latest'\n          container: mosaicml/pytorch:latest  # mosaicml/pytorch:1.13.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n        - name: 'gpu-2.0.1'\n          container: mosaicml/pytorch:2.0.1_cu117-python3.10-ubuntu20.04\n          markers: 'gpu'\n          pytest_command: 'coverage run -m pytest'\n    name: ${{ matrix.name }}\n    if: github.repository_owner == 'mosaicml'\n    with:\n      container: ${{ matrix.container }}\n      mcloud-timeout: 1200\n      name: ${{ matrix.name }}\n      pytest-command: ${{ matrix.pytest_command }}\n      pytest-markers: ${{ matrix.markers }}\n      python-version: 3.9\n    secrets:\n      mcloud-api-key: ${{ secrets.MCLOUD_API_KEY }}\n",
    "source": "kyegomez/Andromeda",
    "path": ".github/workflows/pr-gpu.yaml",
    "url": "https://github.com/kyegomez/Andromeda/blob/991bd81d8c4ed072ec4e6bc2b9c8fc66903463cc/.github/workflows/pr-gpu.yaml",
    "retrieved_at": "2025-09-06T12:40:02.253606Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the cabal CI build process defined in the provided YAML file.",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:14.635683Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on which branches trigger this GitHub Actions workflow?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:15.203021Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:15.707179Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached paths for cabal packages, store, and dist-newstyle differentiated for different GHC versions?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:16.206172Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this Cabal CI workflow?",
    "answer": "name: Cabal CI\n\non:\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n    name: cabal ${{ matrix.ghc }}\n    runs-on: ubuntu-16.04\n    strategy:\n      matrix:\n        ghc: [\"8.10.1\", \"8.8.1\", \"8.6.5\", \"8.6.4\", \"8.6.3\", \"8.6.2\"]\n        cabal: [\"3.0\"]\n\n    steps:\n    - uses: actions/checkout@v1\n    - uses: actions/setup-haskell@v1\n      name: Setup Haskell\n      with:\n        ghc-version: ${{ matrix.ghc }}\n        cabal-version: ${{ matrix.cabal }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/packages\n      with:\n        path: ~/.cabal/packages\n        key: cabal-packages-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache ~/.cabal/store\n      with:\n        path: ~/.cabal/store\n        key: cabal-store-${{ matrix.ghc }}\n\n    - uses: actions/cache@v1\n      name: Cache dist-newstyle\n      with:\n        path: dist-newstyle\n        key: dist-newstyle-${{ matrix.ghc }}\n\n    - name: Install dependencies\n      run: |\n        cabal update\n    - name: Build\n      run: |\n        cabal new-build\n",
    "source": "sdiehl/pairing",
    "path": ".github/workflows/cabal.yml",
    "url": "https://github.com/sdiehl/pairing/blob/fa41b722d9f260bd00be0b250ce7cc5324f26a09/.github/workflows/cabal.yml",
    "retrieved_at": "2025-09-06T13:06:16.714720Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided YAML, including Go setup, Redis service, and tests.",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:17.347426Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:17.829708Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Run Tests' workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:18.272708Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize environment variables, secrets, caching, or artifacts to enhance its testing process?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:18.768610Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this \"Run Tests\" workflow?",
    "answer": "name: Run Tests\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - uses: actions/setup-go@v2\n      with:\n        go-version: '^1.16.3'\n    - uses: supercharge/redis-github-action@1.2.0\n      with:\n        redis-version: 6\n    - run: go test -v -race ./\n",
    "source": "microsoft/redplex",
    "path": ".github/workflows/validate.yml",
    "url": "https://github.com/microsoft/redplex/blob/248ac9a6adfc13bb2da2404bea767dde69dc0272/.github/workflows/validate.yml",
    "retrieved_at": "2025-09-06T13:06:19.160046Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Flatpak CI workflow.",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:20.860858Z",
    "question_style": "style_1"
  },
  {
    "question": "What push or pull request events on the main or flatpak-1.x.x branches trigger this workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:21.546192Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and what dependencies exist between the jobs and their steps?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:22.268307Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the build and test processes in the workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:22.852477Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the \"Flatpak CI\" workflow?",
    "answer": "name: Flatpak CI\n\non:\n  push:\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n  pull_request:\n    paths-ignore:\n    - README.md\n    - CONTRIBUTING.md\n    - NEWS\n    - COPYING\n    - CODE_OF_CONDUCT.md\n    - uncrustify.cfg\n    - uncrustify.sh\n    branches:\n    - main\n    - flatpak-1.0.x\n    - flatpak-1.2.x\n    - flatpak-1.4.x\n    - flatpak-1.6.x\n    - flatpak-1.8.x\n    - flatpak-1.10.x\n    - flatpak-1.12.x\n    - flatpak-1.14.x\n\npermissions:\n  contents: read\n\njobs:\n  check:\n    name: Build with gcc and test\n    runs-on: ubuntu-22.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse3-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev bubblewrap xdg-dbus-proxy \\\n        python3-pip meson ninja-build libyaml-dev libstemmer-dev gperf itstool libmalcontent-0-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Build appstream dependency # (We need at least 0.15.3 for the g_once fix)\n      run: |\n        sudo pip3 install 'meson~=0.62'\n        git clone --branch v0.15.4 --depth 1 --no-tags https://github.com/ximion/appstream.git ./appstream\n        pushd ./appstream\n        meson setup --prefix=/usr _build\n        ninja -C _build\n        sudo ninja -C _build install\n        popd\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --with-curl --with-system-bubblewrap --with-system-dbus-proxy\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  # This is similar to the above, but runs on an older OS with some different configuration:\n  # * Soup instead of curl\n  # * Use built in bubblewrap instead of external\n  # * Use built in xdg-dbus-proxy instead of external\n  # * Disable malcontent build-dependency\n  check-alt2:\n    name: Build with gcc and test (older)\n    runs-on: ubuntu-20.04\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev e2fslibs-dev\n        # One of the tests wants this\n        sudo mkdir /tmp/flatpak-com.example.App-OwnedByRoot\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      # We don't do gtk-doc or GObject-Introspection here, because they can\n      # clash with AddressSanitizer. Instead, the clang build enables those.\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure  --enable-internal-checks --enable-asan --disable-introspection --without-curl\n        popd\n      env:\n        CFLAGS: -O2 -Wp,-D_FORTIFY_SOURCE=2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    # We build with Ubuntu 18.04's GLib to prove that we can, but there's a\n    # race condition that makes it fail tests, so upgrade to a version from\n    # a PPA before running the tests: see\n    # https://github.com/flatpak/flatpak/pull/3121,\n    # https://gitlab.gnome.org/GNOME/glib/-/issues/1014\n    - name: Upgrade GLib before running tests\n      run: |\n        sudo apt-get install -y libglib2.0-dev\n    - name: Run tests\n      run: make -C _build check -j $(getconf _NPROCESSORS_ONLN)\n      env:\n        ASAN_OPTIONS: detect_leaks=0 # Right now we're not fully clean, but this gets us use-after-free etc\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n\n  clang:\n    permissions:\n      security-events: write # for codeql\n    name: Build with clang and analyze\n    runs-on: ubuntu-20.04\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'cpp', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python' ]\n        # Learn more:\n        # https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/configuring-code-scanning#changing-the-languages-that-are-analyzed\n    steps:\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        # queries: ./path/to/local/query, your-org/your-repo/queries@main\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-bionic main' # Needed for updates to work\n        sudo apt-get update\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: configure\n      run: ./autogen.sh\n      env:\n        CC: clang\n        CFLAGS: -Werror=unused-variable\n    - name: Build flatpak\n      run: make -j $(getconf _NPROCESSORS_ONLN)\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n  valgrind:\n    name: Run tests in valgrind\n    needs: check # Don't run expensive test if main check fails\n    runs-on: ubuntu-22.04 # Might as well test with a different one too\n    if: ${{ false }} # Currently Valgrind takes too long and always fails\n    steps:\n    - name: Install Dependencies\n      run: |\n        sudo add-apt-repository ppa:flatpak/stable\n        sudo apt-get update\n        sudo add-apt-repository 'deb https://download.mono-project.com/repo/ubuntu stable-focal main' # Needed for updates to work\n        sudo apt-get install -y libglib2.0-dev attr automake gettext autopoint bison  dbus gtk-doc-tools \\\n        libfuse-dev ostree libostree-dev libarchive-dev libzstd-dev libcap-dev libattr1-dev libdw-dev libelf-dev python3-pyparsing \\\n        libjson-glib-dev shared-mime-info desktop-file-utils libpolkit-agent-1-dev libpolkit-gobject-1-dev \\\n        libseccomp-dev libsoup2.4-dev libcurl4-openssl-dev libsystemd-dev libxml2-utils libgpgme11-dev gobject-introspection \\\n        libgirepository1.0-dev libappstream-dev libdconf-dev clang socat meson libdbus-1-dev \\\n        valgrind e2fslibs-dev\n    - name: Check out flatpak\n      uses: actions/checkout@v3\n      with:\n        submodules: true\n    - name: Create logs dir\n      run: mkdir test-logs\n    - name: autogen.sh\n      run: NOCONFIGURE=1 ./autogen.sh\n    - name: configure\n      run: |\n        mkdir _build\n        pushd _build\n        ../configure --enable-gtk-doc --enable-gtk-doc-html --enable-introspection\n        popd\n      env:\n        CFLAGS: -O2\n    - name: Build flatpak\n      run: make -C _build -j $(getconf _NPROCESSORS_ONLN)\n    - name: Distcheck\n      run: make -C _build distcheck\n    - name: Run tests under valgrind\n      run: make -C _build check\n      env:\n        FLATPAK_TESTS_VALGRIND: true\n    - name: Collect overall test logs on failure\n      if: failure()\n      run: mv _build/test-suite.log test-logs/ || true\n    - name: Collect individual test logs on cancel\n      if: failure() || cancelled()\n      run: mv _build/tests/*.log test-logs/ || true\n    - name: Upload test logs\n      uses: actions/upload-artifact@v3\n      if: failure() || cancelled()\n      with:\n        name: test logs\n        path: test-logs\n",
    "source": "endlessm/flatpak",
    "path": ".github/workflows/check.yml",
    "url": "https://github.com/endlessm/flatpak/blob/787caf96aaf2b233020a776397a2584ee079af44/.github/workflows/check.yml",
    "retrieved_at": "2025-09-07T01:43:23.463969Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided CodeQL workflow for code analysis.",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:24.177596Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedule configurations trigger this CodeQL workflow to run?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:24.838621Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the CodeQL workflow run in parallel, and which have dependencies on others?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:25.402337Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching or artifacts?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:25.796755Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CodeQL workflow?",
    "answer": "# For most projects, this workflow file will not need changing; you simply need\n# to commit it to your repository.\n#\n# You may wish to alter this file to override the set of languages analyzed,\n# or to provide custom queries or build logic.\n#\n# ******** NOTE ********\n# We have attempted to detect the languages in your repository. Please check\n# the `language` matrix defined below to confirm you have the correct set of\n# supported CodeQL languages.\n#\nname: \"CodeQL\"\n\non:\n  push:\n    branches: [ \"dev\", master ]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [ \"dev\" ]\n  schedule:\n    - cron: '22 22 * * 2'\n\njobs:\n  analyze:\n    name: Analyze\n    runs-on: ubuntu-latest\n    permissions:\n      actions: read\n      contents: read\n      security-events: write\n\n    strategy:\n      fail-fast: false\n      matrix:\n        language: [ 'java', 'javascript', 'python' ]\n        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    # Initializes the CodeQL tools for scanning.\n    - name: Initialize CodeQL\n      uses: github/codeql-action/init@v2\n      with:\n        languages: ${{ matrix.language }}\n        # If you wish to specify custom queries, you can do so here or in a config file.\n        # By default, queries listed here will override any specified in a config file.\n        # Prefix the list here with \"+\" to use these queries and those in the config file.\n        \n        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n        # queries: security-extended,security-and-quality\n\n        \n    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n    # If this step fails, then you should remove it and run the build manually (see below)\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    # ℹ️ Command-line programs to run using the OS shell.\n    # 📚 See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n\n    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n\n    # - run: |\n    #   echo \"Run, Build Application using script\"\n    #   ./location_of_script_within_repo/buildscript.sh\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n",
    "source": "ibi-group/datatools-server",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/ibi-group/datatools-server/blob/80c716e3048828d50e68ee53d10453e658cfdeeb/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-09-07T01:43:26.215093Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that duplicates the functionality of the provided YAML, assigning reviewers based on a configuration file.",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:07.200490Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request event triggers this workflow?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:07.654947Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or are contingent upon the completion of others?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:08.210769Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the `auto_assign.yml` configuration file contain any secrets or environment variables?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:08.811271Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding pull requests?",
    "answer": "# This file is related to assigning the Project Lead for the PRs\n\nname: 'Add Project Lead as Reviewer'\non: pull_request\n\njobs:\n  add-reviews:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: kentaro-m/auto-assign-action@v1.1.2\n        with:\n          configuration-path: \".github/auto_assign.yml\"\n",
    "source": "KamalDGRT/yii2-portfolio",
    "path": ".github/workflows/assign_pr.yml",
    "url": "https://github.com/KamalDGRT/yii2-portfolio/blob/5671dcf57fcc4d3451520d36f155dc8263ffc35f/.github/workflows/assign_pr.yml",
    "retrieved_at": "2025-09-08T01:43:09.188007Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Crowdin Action workflow.",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:09.946922Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch trigger this Crowdin synchronization workflow?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:10.489654Z",
    "question_style": "style_2"
  },
  {
    "question": "Does this workflow have any jobs or steps that execute in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:11.147387Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `CROWDIN_PROJECT_ID` and `CROWDIN_PERSONAL_TOKEN` secrets used within the Crowdin Action?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:11.601051Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Crowdin Action workflow?",
    "answer": "name: Crowdin Action\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  synchronize-with-crowdin:\n    runs-on: ubuntu-latest\n\n    steps:\n\n    - name: Checkout\n      uses: actions/checkout@v2\n\n    - name: crowdin action\n      uses: crowdin/github-action@1.4.2\n      with:\n        upload_translations: true\n        download_translations: true\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        CROWDIN_PROJECT_ID: ${{ secrets.CROWDIN_PROJECT_ID }}\n        CROWDIN_PERSONAL_TOKEN: ${{ secrets.CROWDIN_PERSONAL_TOKEN }}\n",
    "source": "sagivo/calendso-2",
    "path": ".github/workflows/crowdin.yml",
    "url": "https://github.com/sagivo/calendso-2/blob/0d50d278bbb734598e112f507334596544a44955/.github/workflows/crowdin.yml",
    "retrieved_at": "2025-09-08T01:43:12.000806Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML, including triggers, jobs, and steps.",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:09.001404Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the repository trigger the Zephyr West Command Tests workflow?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:10.639143Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"West Command Tests\" workflow execute in parallel, and which have dependencies on others?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:12.890911Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the pip cache keys constructed and how do they differ across operating systems?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:13.422547Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of the \"Zephyr West Command Tests\" workflow?",
    "answer": "# Copyright (c) 2020 Linaro Limited.\n# SPDX-License-Identifier: Apache-2.0\n\nname: Zephyr West Command Tests\n\non:\n  push:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n  pull_request:\n    paths:\n    - 'scripts/west-commands.yml'\n    - 'scripts/west_commands/**'\n    - '.github/workflows/west_cmds.yml'\n\njobs:\n  west-commnads:\n    name: West Command Tests\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        python-version: [3.6, 3.7, 3.8]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        exclude:\n          - os: macos-latest\n            python-version: 3.6\n          - os: windows-latest\n            python-version: 3.6\n    steps:\n    - name: checkout\n      uses: actions/checkout@v2\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: cache-pip-linux\n      if: startsWith(runner.os, 'Linux')\n      uses: actions/cache@v1\n      with:\n        path: ~/.cache/pip\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: cache-pip-mac\n      if: startsWith(runner.os, 'macOS')\n      uses: actions/cache@v1\n      with:\n        path: ~/Library/Caches/pip\n        # Trailing '-' was just to get a different cache name\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}-\n    - name: cache-pip-win\n      if: startsWith(runner.os, 'Windows')\n      uses: actions/cache@v1\n      with:\n        path: ~\\AppData\\Local\\pip\\Cache\n        key: ${{ runner.os }}-pip-${{ matrix.python-version }}\n        restore-keys: |\n          ${{ runner.os }}-pip-${{ matrix.python-version }}\n    - name: install pytest\n      run: |\n        pip3 install wheel\n        pip3 install pytest west pyelftools canopen progress mypy intelhex psutil\n    - name: run pytest-win\n      if: runner.os == 'Windows'\n      run: |\n        python ./scripts/west_commands/run_tests.py\n    - name: run pytest-mac-linux\n      if: runner.os != 'Windows'\n      run: |\n        ./scripts/west_commands/run_tests.py\n",
    "source": "GPE-Sistemas/zephyr-ncs-gpe",
    "path": ".github/workflows/west_cmds.yml",
    "url": "https://github.com/GPE-Sistemas/zephyr-ncs-gpe/blob/fe0c5d10e02de3083a4044aa51a97144e749d144/.github/workflows/west_cmds.yml",
    "retrieved_at": "2025-09-09T01:40:14.095184Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:14.898486Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Autograding Tests workflow?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:15.321558Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:15.761589Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to pass results between autograding steps?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:16.528527Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this autograding tests workflow?",
    "answer": "name: Autograding Tests\n'on':\n  - push\n  - workflow_dispatch\n  - repository_dispatch\npermissions:\n  checks: write\n  actions: read\n  contents: read\njobs:\n  run-autograding-tests:\n    runs-on: ubuntu-latest\n    if: github.actor != 'github-classroom[bot]'\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Download mempool\n        uses: GuillaumeFalourd/clone-github-repo-action@v2.3\n        with:\n          owner: 'SummerOfBitcoin'\n          repository: 'code-challenge-2024-mempool'\n      - name: Validate block\n        id: validate-block\n        uses: SummerOfBitcoin/code-challenge-2024-grader@v2.8\n        with:\n          test-name: 'Validate block '\n          command: chmod +x ./run.sh && ./run.sh\n          timeout: 10\n          max-fee: 20616923\n          max-score: 100\n          passing-score: 60\n      - name: Autograding Reporter\n        uses: SummerOfBitcoin/autograding-grading-reporter@v2.2\n        env:\n          VALIDATE-BLOCK_RESULTS: \"${{steps.validate-block.outputs.result}}\"\n        with:\n          runners: validate-block\n",
    "source": "Hugongra/code-challenge-2024-Hugongra",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/Hugongra/code-challenge-2024-Hugongra/blob/493c09fba612c14feb89bfc7e245b81c8be2b541/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-09T01:40:17.127774Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:43.700037Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch and pull requests targeting specific paths trigger this workflow?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:44.204297Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:44.830953Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the virtual environment cached and what key is used to invalidate it?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:45.385604Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow?",
    "answer": "name: Add model like runner\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n    types: [opened, synchronize, reopened]\n\njobs:\n  run_tests_templates_like:\n    name: \"Add new model like template tests\"\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install dependencies\n        run: |\n          sudo apt -y update && sudo apt install -y libsndfile1-dev\n\n      - name: Load cached virtual environment\n        uses: actions/cache@v2\n        id: cache\n        with:\n          path: ~/venv/\n          key: v4-tests_model_like-${{ hashFiles('setup.py') }}\n\n      - name: Create virtual environment on cache miss\n        if: steps.cache.outputs.cache-hit != 'true'\n        run: |\n          python -m venv ~/venv && . ~/venv/bin/activate\n          pip install --upgrade pip!=21.3\n          pip install -e .[dev]\n\n      - name: Check transformers location\n        # make `transformers` available as package (required since we use `-e` flag) and check it's indeed from the repo.\n        run: |\n          . ~/venv/bin/activate\n          python setup.py develop\n          transformers_install=$(pip list -e | grep transformers)\n          transformers_install_array=($transformers_install)\n          transformers_loc=${transformers_install_array[-1]}\n          transformers_repo_loc=$(pwd .)\n          if [ \"$transformers_loc\" != \"$transformers_repo_loc\" ]; then\n              echo \"transformers is from $transformers_loc but it shoud be from $transformers_repo_loc/src.\"\n              echo \"A fix is required. Stop testing.\"\n              exit 1\n          fi\n\n      - name: Create model files\n        run: |\n          . ~/venv/bin/activate\n          transformers-cli add-new-model-like --config_file tests/fixtures/add_distilbert_like_config.json --path_to_repo .\n          make style\n          make fix-copies\n\n      - name: Run all PyTorch modeling test\n        run: |\n          . ~/venv/bin/activate\n          python -m pytest -n 2 --dist=loadfile -s --make-reports=tests_new_models tests/bert_new/test_modeling_bert_new.py\n\n      - name: Run style changes\n        run: |\n          . ~/venv/bin/activate\n          make style && make quality && make repo-consistency\n\n      - name: Failure short reports\n        if: ${{ always() }}\n        run: cat reports/tests_new_models/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: run_all_tests_new_models_test_reports\n          path: reports/tests_new_models\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/add-model-like.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/add-model-like.yml",
    "retrieved_at": "2025-09-10T01:36:45.947137Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the given YAML, checking out code, linting the repository, and saving the repolinter report as an artifact.",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:46.965726Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Repolinter\" workflow to run?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:47.490513Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Repolinter\" workflow execute concurrently or sequentially, based on dependencies?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:48.126477Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables or secrets for authentication or configuration within the repolinter container?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:48.772199Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function of this GitHub Actions workflow?",
    "answer": "# SPDX-License-Identifier: Apache-2.0\n# Hyperledger Repolinter Action\n\nname: Repolinter\n\non:\n  workflow_dispatch:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    container: ghcr.io/todogroup/repolinter:v0.10.1\n    steps:\n      - name: Checkout Code\n        uses: actions/checkout@v4\n      - name: Lint Repo\n        continue-on-error: true\n        run: bundle exec /app/bin/repolinter.js --rulesetUrl https://raw.githubusercontent.com/hyperledger-labs/hyperledger-community-management-tools/master/repo_structure/repolint.json --format markdown | tee /repolinter-report.md\n      - name: Save repolinter-report file\n        uses: actions/upload-artifact@v3\n        with:\n          name: repolinter-report\n          path: /repolinter-report.md\n",
    "source": "NJITBlockchainLab/bifold",
    "path": ".github/workflows/repolinter.yml",
    "url": "https://github.com/NJITBlockchainLab/bifold/blob/c8d91286782825cbb4c32f80305b443b37b46168/.github/workflows/repolinter.yml",
    "retrieved_at": "2025-09-10T01:36:49.345357Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML, including the matrix strategy and steps.",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:07.744083Z",
    "question_style": "style_1"
  },
  {
    "question": "What events involving the `main` branch trigger this GitHub Actions workflow?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:08.157954Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow are executed concurrently or depend on the successful completion of other jobs or steps?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:08.905314Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Meson build?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:09.343040Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by running builds and tests on Windows using MSVC?",
    "answer": "name: msvc\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n\njobs:\n  msvc:\n    runs-on: ${{ matrix.os }}\n\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [windows-2019, windows-latest]\n        include:\n          - name: msvc-2019-x86\n            os: windows-2019\n            ARCH: x86\n          - name: msvc-2019-amd64\n            os: windows-latest\n            ARCH: amd64\n    name: ${{ matrix.name }}\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Setup Ccache\n      uses: hendrikmuhs/ccache-action@c92f40bee50034e84c763e33b317c77adaa81c92 # v1.2.13\n      with:\n        variant: sccache\n        key: ${{ github.job }}-${{ matrix.os }}-${{ matrix.ARCH }}\n    - name: Setup Python\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: '3.x'\n    - name: Setup MSVC\n      uses: ilammy/msvc-dev-cmd@0b201ec74fa43914dc39ae48a89fd1d8cb592756 # v1.13.0\n      with:\n        arch : ${{ matrix.ARCH }}\n    - name: Install Python Dependencies\n      run: |\n        pip3 install -r .ci/requirements.txt --require-hashes\n    - name: Setup Meson\n      run: |\n          sccache --version\n          meson setup build `\n            --wrap-mode=forcefallback `\n            --buildtype=release `\n            -Dglib=enabled `\n            -Dfreetype=enabled `\n            -Dgdi=enabled `\n            -Ddirectwrite=enabled\n    - name: Build\n      run: meson compile -Cbuild\n    - name: Test\n      run: meson test --print-errorlogs --suite=harfbuzz -Cbuild\n",
    "source": "YOU-i-Labs/harfbuzz",
    "path": ".github/workflows/msvc-ci.yml",
    "url": "https://github.com/YOU-i-Labs/harfbuzz/blob/adf995a44927ca4dba3083e6dc766023a6f460d9/.github/workflows/msvc-ci.yml",
    "retrieved_at": "2025-09-11T01:39:09.896200Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML for Docker CI.",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:10.791414Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/path conditions trigger this GitHub Actions workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:11.308987Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and what dependencies exist between them?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:11.933524Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the Docker build cache layers being scoped and utilized in the workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:12.427823Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow?",
    "answer": "name: Docker CI\n\non:\n  push:\n    branches: [ master ]\n    paths-ignore:\n      - 'tests/Auto-GPT-test-cassettes'\n      - 'tests/challenges/current_score.json'\n  pull_request:\n    branches: [ master, release-*, stable ]\n\nconcurrency:\n  group: ${{ format('docker-ci-{0}', github.head_ref && format('pr-{0}', github.event.pull_request.number) || github.sha) }}\n  cancel-in-progress: ${{ github.event_name == 'pull_request' }}\n\nenv:\n  IMAGE_NAME: auto-gpt\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        build-type: [release, dev]\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n\n    - if: runner.debug\n      run: |\n        ls -al\n        du -hs *\n\n    - id: build\n      name: Build image\n      uses: docker/build-push-action@v3\n      with:\n        build-args: BUILD_TYPE=${{ matrix.build-type }}\n        tags: ${{ env.IMAGE_NAME }}\n        load: true    # save to docker images\n        # cache layers in GitHub Actions cache to speed up builds\n        cache-from: type=gha,scope=docker-${{ matrix.build-type }}\n        cache-to: type=gha,scope=docker-${{ matrix.build-type }},mode=max\n\n    - name: Generate build report\n      env:\n        event_name: ${{ github.event_name }}\n        event_ref: ${{ github.event.ref }}\n        event_ref_type: ${{ github.event.ref}}\n\n        build_type: ${{ matrix.build-type }}\n\n        prod_branch: stable\n        dev_branch: master\n        repository: ${{ github.repository }}\n        base_branch: ${{ github.ref_name != 'master' && github.ref_name != 'stable' && 'master' || 'stable' }}\n\n        current_ref: ${{ github.ref_name }}\n        commit_hash: ${{ github.event.after }}\n        source_url: ${{ format('{0}/tree/{1}', github.event.repository.url, github.event.release && github.event.release.tag_name || github.sha) }}\n        push_forced_label: ${{ github.event.forced && '☢️ forced' || '' }}\n\n        new_commits_json: ${{ toJSON(github.event.commits) }}\n        compare_url_template: ${{ format('/{0}/compare/{{base}}...{{head}}', github.repository) }}\n\n        github_context_json: ${{ toJSON(github) }}\n        job_env_json: ${{ toJSON(env) }}\n        vars_json: ${{ toJSON(vars) }}\n\n      run: .github/workflows/scripts/docker-ci-summary.sh >> $GITHUB_STEP_SUMMARY\n      continue-on-error: true\n\n  test:\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v3\n        with:\n          submodules: true\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - id: build\n        name: Build image\n        uses: docker/build-push-action@v3\n        with:\n          build-args: BUILD_TYPE=dev  # include pytest\n          tags: ${{ env.IMAGE_NAME }}\n          load: true                  # save to docker images\n          # cache layers in GitHub Actions cache to speed up builds\n          cache-from: type=gha,scope=docker-dev\n          cache-to: type=gha,scope=docker-dev,mode=max\n\n      - id: test\n        name: Run tests\n        env:\n          CI: true\n          PLAIN_OUTPUT: True\n          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n        run: |\n          set +e\n          test_output=$(\n            docker run --env CI --env OPENAI_API_KEY --entrypoint python ${{ env.IMAGE_NAME }} -m \\\n            pytest -v --cov=autogpt --cov-branch --cov-report term-missing \\\n              --numprocesses=4 --durations=10 \\\n              tests/unit tests/integration 2>&1\n          )\n          test_failure=$?\n\n          echo \"$test_output\"\n\n          cat << $EOF >> $GITHUB_STEP_SUMMARY\n          # Tests $([ $test_failure = 0 ] && echo '✅' || echo '❌')\n          \\`\\`\\`\n          $test_output\n          \\`\\`\\`\n          $EOF\n\n          exit $test_failure\n",
    "source": "elder-plinius/Synthia",
    "path": ".github/workflows/docker-ci.yml",
    "url": "https://github.com/elder-plinius/Synthia/blob/bfe457a4a4bc97f6293b586d3e53eb95b7433830/.github/workflows/docker-ci.yml",
    "retrieved_at": "2025-09-11T01:39:12.920169Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:47.886680Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:48.405808Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'PR Reports' workflow run in parallel or have dependencies on each other?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:48.974546Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the downloaded artifacts named and used in the subsequent \"Publish Test Report\" step?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:49.537729Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the \"PR Reports\" workflow?",
    "answer": "# ----------------------------------------------------------------------------\n# Copyright 2021 The Netty Project\n#\n# The Netty Project licenses this file to you under the Apache License,\n# version 2.0 (the \"License\"); you may not use this file except in compliance\n# with the License. You may obtain a copy of the License at:\n#\n#   https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations\n# under the License.\n# ----------------------------------------------------------------------------\nname: PR Reports\non:\n  workflow_run:\n    workflows: [ \"Build PR\" ]\n    types:\n      - completed\nenv:\n  MAVEN_OPTS: -Dhttp.keepAlive=false -Dmaven.wagon.http.pool=false -Dmaven.wagon.http.retryhandler.count=5 -Dmaven.wagon.httpconnectionManager.ttlSeconds=240\n\npermissions: read-all\n\njobs:\n  tests:\n    permissions:\n      actions: read  # for dawidd6/action-download-artifact to query and download artifacts\n      checks: write  # for scacap/action-surefire-report to publish result as PR check\n      pull-requests: read  # for dawidd6/action-download-artifact to query commit hash\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        ignore-if-missing: [false]\n        include:\n          - setup: linux-x86_64-java8\n            ignore-if-missing: true\n          - setup: linux-x86_64-java11\n          - setup: linux-x86_64-java11-boringssl\n          - setup: linux-x86_64-java17\n          - setup: linux-x86_64-java18\n          - setup: linux-x86_64-java21\n          - setup: linux-x86_64-java22\n          - setup: windows-x86_64-java11-boringssl\n    continue-on-error: ${{ matrix.ignore-if-missing }}\n    steps:\n      - name: Download Artifacts\n        uses: dawidd6/action-download-artifact@v3.0.0\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          workflow: ${{ github.event.workflow_run.workflow_id }}\n          workflow_conclusion: completed\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          # File location set in ci-pr.yml and must be coordinated.\n          name: test-results-${{ matrix.setup }}\n      - name: Publish Test Report\n        uses: scacap/action-surefire-report@v1.7.3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          report_paths: '**/target/surefire-reports/TEST-*.xml'\n          commit: ${{ github.event.workflow_run.head_commit.id }}\n          check_name: ${{ matrix.setup }} test reports\n",
    "source": "leviYX/netty-source-code",
    "path": ".github/workflows/ci-pr-reports.yml",
    "url": "https://github.com/leviYX/netty-source-code/blob/2e93efc254676719aaa4002af349ba23f9da7fd0/.github/workflows/ci-pr-reports.yml",
    "retrieved_at": "2025-09-12T01:27:50.042603Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the given YAML file.",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:50.750108Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the \"Refresh Citation Style Language Files\" workflow?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:51.293624Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:51.727033Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GH_TOKEN_UPDATE_GRADLE_WRAPPER` secret used for creating a pull request?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:52.295196Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow for Citation Style Language files?",
    "answer": "name: Refresh Citation Style Language Files\n\non:\n  schedule:\n    # run on 1st and 15th of each month\n    - cron: '1 2 1,15 * *'\n  workflow_dispatch:\n\njobs:\n  publish:\n    name: Refresh Citation Style Language Files\n    runs-on: ubuntu-latest\n    if: github.repository == 'JabRef/jabref'\n    steps:\n      - name: Checkout source\n        uses: actions/checkout@v2\n        with:\n          ref: main\n          fetch-depth: 0\n      - name: Initialize git\n        run: |\n          git checkout main\n          git config --local core.editor /usr/bin/cat\n          git config user.name \"github actions\"\n          git config user.email \"jabrefmail+webfeedback@gmail.com\"\n      - name: Add csl-styles remote\n        run: git remote add -f csl-styles https://github.com/citation-style-language/styles.git\n      - name: Update csl-styles\n        run: |\n          git subtree pull --prefix buildres/csl/csl-styles csl-styles master --squash || true\n          cp buildres/csl/csl-styles/acm-siggraph.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/ieee.csl src/main/resources/csl-styles/\n          cp buildres/csl/csl-styles/turabian-author-date.csl src/main/resources/csl-styles/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - name: Add csl-locales remote\n        run: git remote add -f csl-locales https://github.com/citation-style-language/locales.git\n      - name: Update csl-locales\n        run: |\n          git subtree pull --prefix buildres/csl/csl-locales csl-locales master --squash || true\n          cp buildres/csl/csl-locales/locales.json src/main/resources/csl-locales/\n          cp buildres/csl/csl-locales/locales-en-US.xml src/main/resources/csl-locales/\n          git add .\n          git commit -m\"Refresh example styles\" || true\n      - uses: peter-evans/create-pull-request@v3\n        with:\n          token: ${{ secrets.GH_TOKEN_UPDATE_GRADLE_WRAPPER }}\n          branch: refresh-csl\n          commit-message: Update CSL styles\n          title: \"[Bot] Update CSL styles\"\n          labels: dependencies\n",
    "source": "tjfernandes/SE2122_57464_58763_57677_58125_63764",
    "path": ".github/workflows/refresh-csl-subtrees.yml",
    "url": "https://github.com/tjfernandes/SE2122_57464_58763_57677_58125_63764/blob/545d42658484a4315751ecac830c3da4f194fc25/.github/workflows/refresh-csl-subtrees.yml",
    "retrieved_at": "2025-09-12T01:27:52.728036Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML workflow for building and releasing a Linux application.",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:23:58.757204Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger this GitHub Actions workflow?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:23:59.288759Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:00.068947Z",
    "question_style": "style_3"
  },
  {
    "question": "How are AWS credentials securely passed and used to upload build artifacts to S3 buckets?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:00.920743Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow, particularly the resulting artifact?",
    "answer": "name: Linux Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl.AppImage\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=installer CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Create AppImage\n        working-directory:  ${{ runner.temp }}/shadow_build_dir\n        run:                ${SOURCE_DIR}/deploy/create_linux_appimage.sh ${SOURCE_DIR} ./staging ./package;\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_release.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_release.yml",
    "retrieved_at": "2025-09-13T01:24:01.410011Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow file.",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:02.000327Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:02.553000Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which have dependencies on others?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.137403Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the Android build environment within the workflow?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.586826Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or outcome of this GitHub Actions workflow?",
    "answer": "\n# This is a basic workflow to help you get started with Actions\n\nname: Build\n\n# Controls when the action will run. \non:\n  # Triggers the workflow on push or pull request events but only for the master branch\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  # This workflow contains a single job called \"build\"\n\n  buildAndroid:\n    name: buildAndroid\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@main\n\n      - name: Setup Android NDK\n        uses: nttld/setup-ndk@main\n        id: setup-ndk\n        with:\n          ndk-version: r15c\n\n      - name: Setup Java JDK\n        uses: actions/setup-java@main\n        with:\n          distribution: 'zulu'\n          java-version: 11\n\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@main\n\n      - name: Setup Haxe\n        uses: krdlab/setup-haxe@v1.2.0\n        with:\n          haxe-version: 4.2.0\n\n      - name: Install Haxelib\n        run: |\n          haxelib setup ~/haxelib\n          haxelib install hxcpp 4.2.1 > /dev/null\n          haxelib install lime 7.9.0\n          haxelib install openfl 9.1.0\n          haxelib --never install flixel 4.11.0\n          haxelib run lime setup flixel\n          haxelib install flixel-tools\n          haxelib install flixel-ui\n          haxelib install flixel-addons 2.11.0\n          haxelib install tjson\n          haxelib install hxjsonast\n          haxelib install hscript\n          haxelib git hxCodec https://github.com/SPLCoding/hxCodec-but-it-works-xd.git\n          haxelib git linc_luajit https://github.com/Sirox228/linc_luajit\n          haxelib git extension-androidtools https://github.com/MaysLastPlay77/extension-androidtools\n          haxelib install hxcpp-debug-server\n          haxelib list\n      - name: Create Version Tag\n        run: echo \"${{github.run_id}}\" > VERSION\n\n      - name: Setup Lime\n        run: |\n          haxelib run lime setup -alias -y\n          haxelib run lime config ANDROID_SDK $ANDROID_HOME\n          haxelib run lime config ANDROID_NDK_ROOT $ANDROID_NDK_HOME\n          haxelib run lime config JAVA_HOME $JAVA_HOME\n          haxelib run lime config ANDROID_SETUP true\n          haxelib set lime 7.9.0\n          haxelib set openfl 9.1.0\n          haxelib set flixel 4.11.0\n          haxelib set flixel-addons 2.11.0\n          haxelib set hxcpp 4.2.1\n        env:\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n\n      - name: Compile\n        run: haxelib run lime build android -D NO_PRECOMPILED_HEADERS --app-version=\"4.0.0-${{ github.run_id}}\"\n\n      - name: Publish Artifact\n        uses: actions/upload-artifact@main\n        with:\n          name: buildAndroid\n          path: export/release/android/bin/app/build/outputs/apk/debug\n",
    "source": "NighCyan/FNF-TG-Engine",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/NighCyan/FNF-TG-Engine/blob/84be9d5daa633cad25344c76d2fc40117cb63b5b/.github/workflows/main.yml",
    "retrieved_at": "2025-09-13T01:24:03.930093Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:05.348385Z",
    "question_style": "style_1"
  },
  {
    "question": "What events on the `main` branch or pull requests trigger this workflow?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:05.975770Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Main / Pull requests build\" workflow execute in parallel or sequentially based on dependencies?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:06.453365Z",
    "question_style": "style_3"
  },
  {
    "question": "How are Maven packages cached and restored based on the OS and pom.xml files?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:07.056527Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or goal of this pull request build workflow?",
    "answer": "name: \"Main / Pull requests build\"\non:\n    pull_request:\n        paths-ignore:\n            - '.txt'\n            - 'LICENSE'\n            - 'docs/**'\n        branches: [ main ]\n    push:\n        branches:\n            - main\n\njobs:\n    build:\n        runs-on: ${{ matrix.os }}\n        strategy:\n            fail-fast: true\n            matrix:\n                os: [ windows-latest, ubuntu-latest, macos-13 ]\n            max-parallel: 1\n        steps:\n            -   uses: actions/checkout@v4.1.6\n            -   name: Set up JDK 21\n                uses: actions/setup-java@v4.2.1\n                with:\n                    distribution: 'temurin'\n                    java-version: 21\n                    architecture: x64\n            -   name: Cache Maven packages\n                uses: actions/cache@v4.0.2\n                with:\n                    path: ~/.m2\n                    key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}\n                    restore-keys: ${{ runner.os }}-m2-\n            -   name: Build with Maven\n                run: mvn --no-transfer-progress verify\n",
    "source": "juhablkdk/MyWebGoat",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/juhablkdk/MyWebGoat/blob/a738c5c74d9405b947c6882ffa6513a77f12e4bd/.github/workflows/build.yml",
    "retrieved_at": "2025-09-14T01:43:07.615127Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:08.426622Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Evaluation\" workflow?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:08.880122Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within jobs run in parallel, and are there any inter-job dependencies defined in the workflow?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:09.464978Z",
    "question_style": "style_3"
  },
  {
    "question": "How are artifacts used to persist and access the load_balancer.txt file?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:10.005816Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or goal of this workflow file?",
    "answer": "name: Evaluation\n\n# Run this workflow every time a new commit pushed to your repository\non: push\n\njobs:\n\n  unit_tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n\n      - name: Test with pytest\n        timeout-minutes: 2\n        run: |\n          pytest -vv --timeout=20\n\n\n  bash_tests:\n    name: Bash Tests\n    runs-on: ubuntu-latest\n\n    steps:\n      # Checks out a copy of your repository on the ubuntu-latest machine\n      - name: Checkout code\n        uses: actions/checkout@v2\n\n      - name: Set up Python 3.9\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.9\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pytest\n          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n          chmod +x *.sh\n\n      - name: Launch servers into background\n        run: |\n          bash ./setup.sh > load_balancer.txt &\n\n      - name: stress test on standby\n        run: |\n          bash ./stress_test.sh\n\n      - name: load_balancer Logs\n        uses: actions/upload-artifact@v2\n        with:\n          name: load_balancer logs\n          path: load_balancer.txt\n          retention-days: 1\n",
    "source": "RGarrido03/CD-Guiao-4",
    "path": ".github/workflows/score.yml",
    "url": "https://github.com/RGarrido03/CD-Guiao-4/blob/6cb1b3affae06edfedae5d2fe80a07dc7a4d0276/.github/workflows/score.yml",
    "retrieved_at": "2025-09-14T01:43:10.572437Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including CI, releasing packages, building Docker images, and creating releases.",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:19.408130Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow to run, considering its configuration?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:20.178877Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:21.021421Z",
    "question_style": "style_3"
  },
  {
    "question": "How are secrets used to authenticate and authorize the publishing of packages to PyPI?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:21.654952Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow regarding Langflow releases and Docker builds?",
    "answer": "name: Langflow Release\nrun-name: Langflow Release by @${{ github.actor }}\n\non:\n  workflow_dispatch:\n    inputs:\n      release_package_base:\n        description: \"Release Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      release_package_main:\n        description: \"Release Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_base:\n        description: \"Build Docker Image for Langflow Base\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_main:\n        description: \"Build Docker Image for Langflow\"\n        required: true\n        type: boolean\n        default: false\n      build_docker_ep:\n        description: \"Build Docker Image for Langflow with Entrypoint\"\n        required: false\n        type: boolean\n        default: false\n      pre_release:\n        description: \"Pre-release\"\n        required: false\n        type: boolean\n        default: false\n      create_release:\n        description: \"Whether to create a gh release\"\n        required: false\n        type: boolean\n        default: true\n\n\njobs:\n  ci:\n    if: ${{ github.event.inputs.release_package_base == 'true' || github.event.inputs.release_package_main == 'true' }}\n    name: CI\n    uses: ./.github/workflows/ci.yml\n    with:\n      python-versions: \"['3.10', '3.11', '3.12']\"\n      frontend-tests-folder: \"tests\"\n      release: true\n\n  release-base:\n    name: Release Langflow Base\n    needs: [ci]\n    if: inputs.release_package_base == true\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n      skipped: ${{ steps.check-version.outputs.skipped }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow-base' | awk '{print $3}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow-base/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            echo skipped=true >> $GITHUB_OUTPUT\n            exit 0\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n            echo skipped=false >> $GITHUB_OUTPUT\n          fi\n      - name: Build project for distribution\n        if: steps.check-version.outputs.skipped == 'false'\n        run: make build base=true args=\"--wheel\"\n      - name: Test CLI\n        if: steps.check-version.outputs.skipped == 'false'\n        run: |\n          # TODO: Unsure why the whl is not built in src/backend/base/dist\n          mkdir src/backend/base/dist\n          mv dist/*.whl src/backend/base/dist\n          uv pip install src/backend/base/dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/api/v1/auto_login; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        if: steps.check-version.outputs.skipped == 'false'\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish base=true\n      - name: Upload Artifact\n        if: steps.check-version.outputs.skipped == 'false'\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-base\n          path: src/backend/base/dist\n\n  release-main:\n    name: Release Langflow Main\n    if: inputs.release_package_main == true\n    needs: [release-base]\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.check-version.outputs.version }}\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n      - name: Setup Environment\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n\n      # If pre-release is true, we need to check if  [\"a\", \"b\", \"rc\", \"dev\", \"post\"] is in the version string\n      # if the version string is incorrect, we need to exit the workflow\n      - name: Check if pre-release\n        if: inputs.pre_release == 'true'\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          if [[ \"${version}\" =~ ^([0-9]+\\.)?([0-9]+\\.)?[0-9]+((a|b|rc|dev|post)([0-9]+))$ ]]; then\n            echo \"Pre-release version detected. Continuing with the release.\"\n          else\n            echo \"Invalid pre-release version detected. Exiting the workflow.\"\n            exit 1\n          fi\n      - name: Check Version\n        id: check-version\n        run: |\n          version=$(uv tree | grep 'langflow' | grep -v 'langflow-base' | awk '{print $2}' | sed 's/^v//')\n          last_released_version=$(curl -s \"https://pypi.org/pypi/langflow/json\" | jq -r '.releases | keys | .[]' | sort -V | tail -n 1)\n          if [ \"$version\" = \"$last_released_version\" ]; then\n            echo \"Version $version is already released. Skipping release.\"\n            exit 1\n          else\n            echo version=$version >> $GITHUB_OUTPUT\n          fi\n      - name: Wait for PyPI Propagation\n        if: needs.release-base.outputs.skipped == 'false'\n        run: sleep 300 # wait for 5 minutes to ensure PyPI propagation\n\n      - name: Build project for distribution\n        run: make build main=true args=\"--no-sources --wheel\"\n      - name: Test CLI\n        run: |\n          uv pip install dist/*.whl\n          uv run python -m langflow run --host 127.0.0.1 --port 7860 --backend-only &\n          SERVER_PID=$!\n          # Wait for the server to start\n          timeout 120 bash -c 'until curl -f http://127.0.0.1:7860/health_check; do sleep 2; done' || (echo \"Server did not start in time\" && kill $SERVER_PID && exit 1)\n          # Terminate the server\n          kill $SERVER_PID || (echo \"Failed to terminate the server\" && exit 1)\n          sleep 20 # give the server some time to terminate\n          # Check if the server is still running\n          if kill -0 $SERVER_PID 2>/dev/null; then\n            echo \"Failed to terminate the server\"\n            exit 0\n          else\n            echo \"Server terminated successfully\"\n          fi\n      - name: Publish to PyPI\n        env:\n          UV_PUBLISH_TOKEN: ${{ secrets.PYPI_API_TOKEN }}\n        run: |\n          make publish main=true\n      - name: Upload Artifact\n        uses: actions/upload-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n\n  call_docker_build_base:\n    name: Call Docker Build Workflow for Langflow Base\n    if: inputs.build_docker_base == true\n    needs: [release-base, release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      base_version: ${{ needs.release-base.outputs.version }}\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: base\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main:\n    name: Call Docker Build Workflow for Langflow\n    if: inputs.build_docker_main == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main\n      pre_release: ${{ inputs.pre_release }}\n    secrets: inherit\n\n  call_docker_build_main_ep:\n    name: Call Docker Build Workflow for Langflow with Entrypoint\n    if: inputs.build_docker_ep == true\n    needs: [release-main]\n    uses: ./.github/workflows/docker-build.yml\n    with:\n      main_version: ${{ needs.release-main.outputs.version }}\n      release_type: main-ep\n      pre_release: False\n    secrets: inherit\n\n  create_release:\n    name: Create Release\n    runs-on: ubuntu-latest\n    needs: release-main\n    steps:\n      - uses: actions/download-artifact@v4\n        with:\n          name: dist-main\n          path: dist\n      - name: Create Release\n        uses: ncipollo/release-action@v1\n        with:\n          artifacts: \"dist/*\"\n          token: ${{ secrets.GITHUB_TOKEN }}\n          draft: false\n          generateReleaseNotes: true\n          prerelease: ${{ inputs.pre_release }}\n          tag: ${{ needs.release-main.outputs.version }}\n          commit: ${{ github.ref }}\n",
    "source": "GenuineArt/langflow-ai",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/GenuineArt/langflow-ai/blob/e47639af93b6ed8b940196d65b826eca0b316f24/.github/workflows/release.yml",
    "retrieved_at": "2025-09-15T01:44:22.245106Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality defined in the provided YAML file.",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:22.931027Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the Chromatic workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:24.145355Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'chromatic' job can run in parallel, and which depend on the completion of others?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:24.703239Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `CHROMATIC_PROJECT_TOKEN` and `GITHUB_TOKEN` secrets used within the workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:25.275545Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the Chromatic workflow?",
    "answer": "name: Chromatic\n\non:\n  workflow_dispatch:\n  pull_request_review:\n    types: [submitted]\n    branches:\n      - 'master'\n    paths:\n      - packages/design-system/**\n      - .github/workflows/chromatic.yml\n\nconcurrency:\n  group: chromatic-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  chromatic:\n    if: ${{ github.event.review.state == 'approved' && !contains(github.event.pull_request.labels.*.name, 'community') }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4.1.1\n        with:\n          fetch-depth: 0\n      - run: corepack enable\n      - uses: actions/setup-node@v4.0.2\n        with:\n          node-version: 20.x\n          cache: 'pnpm'\n      - run: pnpm install --frozen-lockfile\n\n      - name: Publish to Chromatic\n        uses: chromaui/action@v11\n        id: chromatic_tests\n        continue-on-error: true\n        with:\n          workingDir: packages/design-system\n          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}\n          exitZeroOnChanges: false\n\n      - name: Success comment\n        if: steps.chromatic_tests.outcome == 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            :white_check_mark: No visual regressions found.\n\n      - name: Fail comment\n        if: steps.chromatic_tests.outcome != 'success'\n        uses: peter-evans/create-or-update-comment@v4.0.0\n        with:\n          issue-number: ${{ github.event.pull_request.number }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          edit-mode: replace\n          body: |\n            [:warning: Visual regressions found](${{steps.chromatic_tests.outputs.url}}): ${{steps.chromatic_tests.outputs.changeCount}}\n",
    "source": "wsdevv/n8n-clockify-workaround",
    "path": ".github/workflows/chromatic.yml",
    "url": "https://github.com/wsdevv/n8n-clockify-workaround/blob/a77b9bf3b3b616a908320a2002d7af886f760882/.github/workflows/chromatic.yml",
    "retrieved_at": "2025-09-15T01:44:25.721204Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the functionality of the provided YAML workflow, including build steps, dependency installations, ccache usage, and unit testing.",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:35.868645Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch configurations trigger this GitHub Actions workflow?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:36.464809Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which ones depend on the completion of others?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:37.109653Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the ccache key generated, and what timestamp is included in it?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:37.740442Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this Linux Debug and Test workflow?",
    "answer": "name: Linux Debug and Test\n\non:\n  push:\n    branches:\n    - 'master'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       desktop\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install QGC source dependencies\n        run:  sudo apt-get install -y libsdl2-dev\n\n      - name: Install Gstreamer dev packages\n        run:  sudo apt-get install -y libgstreamer-plugins-base1.0-dev libgstreamer1.0-0:amd64 libgstreamer1.0-dev\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Install post-link dependencies\n        run:  sudo apt-get install -y binutils patchelf\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        run:  |\n              qmake -r ${SOURCE_DIR}/qgroundcontrol.pro CONFIG+=debug CONFIG+=${BUILD_TYPE}\n              make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Setup for unit tests\n        working-directory: ${{ runner.temp }}/shadow_build_dir  \n        run:  |\n              mkdir -p ~/.config/QtProject/\n              cp ${SOURCE_DIR}/test/qtlogging.ini ~/.config/QtProject/\n              export QT_FATAL_WARNINGS=1\n\n      - name: Run unit tests\n        uses: GabrielBB/xvfb-action@v1\n        with:\n          working-directory:  ${{ runner.temp }}/shadow_build_dir  \n          run:                ./staging/qgroundcontrol-start.sh --unittest\n",
    "source": "DiegoJRAleixandre/RemoteID-for-QgroundControl",
    "path": ".github/workflows/linux_debug.yml",
    "url": "https://github.com/DiegoJRAleixandre/RemoteID-for-QgroundControl/blob/36c8c702551389cfee92cb9062f3b1dc2628024e/.github/workflows/linux_debug.yml",
    "retrieved_at": "2025-09-16T01:36:38.384451Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that mirrors the functionality of the provided YAML, including draft release creation.",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:39.416065Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or events trigger the \"Draft release\" workflow?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:40.084185Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in the workflow execute concurrently or sequentially, based on dependencies?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:40.593643Z",
    "question_style": "style_3"
  },
  {
    "question": "Is any caching explicitly configured beyond the npm cache for node setup?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:41.116149Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of this workflow, particularly regarding releases and changelogs?",
    "answer": "name: Draft release\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.ref }}\n  cancel-in-progress: true\n\non:\n  workflow_dispatch:\n\njobs:\n  release:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: setup config\n        run: |\n          git config --global user.email \"release-bot@aave.com\"\n          git config --global user.name \"Release bot :robot:\"\n\n      - uses: actions/setup-node@v2\n        with:\n          node-version: '16'\n          cache: 'npm'\n\n      - name: install\n        run: npm i -g standard-version\n\n      # this ci will just generate the changelog in a pr\n      - name: release\n        run: |\n          standard-version --message \"chore(release): Release v%s :rocket: :tada:\" --skip.tag\n          git checkout -b release/${{ github.sha }}\n          git push origin release/${{ github.sha }}\n\n      - name: version\n        id: version\n        run: echo ::set-output name=VERSION::$(node -pe \"require('./package.json').version\")\n\n      - uses: actions/github-script@v5\n        with:\n          script: |\n            github.rest.pulls.create({\n              title: 'chore(release): release ${{ steps.version.outputs.VERSION }} :rocket: :tada:',\n              body: 'Please review and refine the changelog carefully, before approving this pr.',\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              head: 'release/${{ github.sha }}',\n              base: 'master'\n            })\n",
    "source": "aave/aave-ui",
    "path": ".github/workflows/draft-release.yml",
    "url": "https://github.com/aave/aave-ui/blob/f34f1cfc4fa6c1128b31eaa70b37b5b2109d1dc5/.github/workflows/draft-release.yml",
    "retrieved_at": "2025-09-16T01:36:41.872902Z",
    "question_style": "style_5"
  },
  {
    "question": "Write a GitHub Actions workflow YAML file that replicates the functionality, including build matrix, CMake configuration, testing, artifact creation, and release/publish steps, as defined in the provided YAML file.",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:45.692383Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the CMake Build Matrix workflow?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:46.378879Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:47.190637Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to specify compiler paths within the CMake configuration?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:47.799320Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this CMake Build Matrix workflow?",
    "answer": "name: CMake Build Matrix\n\non: [push, pull_request]\n\nenv:\n  CMAKE_VERSION: 3.21.1\n  NINJA_VERSION: 1.10.2\n  BUILD_TYPE: Release\n\njobs:\n  build:\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              os: windows-latest,\n              artifact: \"Windows-MSVC.7z\",\n              build_type: \"Release\",\n              cc: \"cl\",\n              cxx: \"cl\",\n              environment_script: \"C:/Program Files/Microsoft Visual Studio/2022/Enterprise/VC/Auxiliary/Build/vcvars64.bat\",\n              archiver: \"7z a\",\n              generators: \"Visual Studio 17 2022\",\n            }\n          - {\n              name: \"Ubuntu_GCC_10\",\n              os: ubuntu-latest,\n              artifact: \"Linux.7z\",\n              build_type: \"Release\",\n              cc: \"gcc-10\",\n              cxx: \"g++-10\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"Ubuntu_GCC_11\",\n              os: ubuntu-latest,\n              artifact: \"Linux-GCC-11.7z\",\n              build_type: \"Release\",\n              cc: \"gcc\",\n              cxx: \"g++\",\n              archiver: \"7z a\",\n              generators: \"Ninja\",\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              os: macos-latest,\n              artifact: \"macOS.7z\",\n              build_type: \"Release\",\n              cc: \"clang\",\n              cxx: \"clang++\",\n              archiver: \"7za a\",\n              generators: \"Ninja\",\n            }\n\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Print env\n        run: |\n          echo github.event.action: ${{ github.event.action }}\n          echo github.event_name: ${{ github.event_name }}\n\n      - name: Download Ninja and CMake\n        shell: cmake -P {0}\n        run: |\n          set(cmake_version $ENV{CMAKE_VERSION})\n          set(ninja_version $ENV{NINJA_VERSION})\n\n          message(STATUS \"Using host CMake version: ${CMAKE_VERSION}\")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(ninja_suffix \"win.zip\")\n            set(cmake_suffix \"windows-x86_64.zip\")\n            set(cmake_dir \"cmake-${cmake_version}-windows-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ninja_suffix \"linux.zip\")\n            set(cmake_suffix \"linux-x86_64.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-linux-x86_64/bin\")\n          elseif (\"${{ runner.os }}\" STREQUAL \"macOS\")\n            set(ninja_suffix \"mac.zip\")\n            set(cmake_suffix \"macos-universal.tar.gz\")\n            set(cmake_dir \"cmake-${cmake_version}-macos-universal/CMake.app/Contents/bin\")\n          endif()\n\n          set(ninja_url \"https://github.com/ninja-build/ninja/releases/download/v${ninja_version}/ninja-${ninja_suffix}\")\n          file(DOWNLOAD \"${ninja_url}\" ./ninja.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./ninja.zip)\n\n          set(cmake_url \"https://github.com/Kitware/CMake/releases/download/v${cmake_version}/cmake-${cmake_version}-${cmake_suffix}\")\n          file(DOWNLOAD \"${cmake_url}\" ./cmake.zip SHOW_PROGRESS)\n          execute_process(COMMAND ${CMAKE_COMMAND} -E tar xvf ./cmake.zip)\n\n          # Add to PATH environment variable\n          file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${cmake_dir}\" cmake_dir)\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${cmake_dir}\")\n\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            execute_process(\n              COMMAND chmod +x ninja\n              COMMAND chmod +x ${cmake_dir}/cmake\n            )\n          endif()\n\n      - name: Install gcc-11\n        shell: bash\n        if: endsWith(matrix.config.name, 'GCC_11')\n        run: |\n          sudo apt-get update\n          sudo apt-get install gcc-11 g++-11\n          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 110 --slave /usr/bin/g++ g++ /usr/bin/g++-11 --slave /usr/bin/gcov gcov /usr/bin/gcov-11\n\n      - name: Install ccache\n        shell: cmake -P {0}\n        run: |\n          if(\"${{ runner.os }}\" STREQUAL \"Windows\")\n            # If ccache behaves badly on windows, skip this step\n            execute_process(COMMAND choco install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"macOS\")\n            execute_process(COMMAND brew install ccache)\n          elseif(\"${{ runner.os }}\" STREQUAL \"Linux\")\n            set(ccache_version \"4.6.3\")\n            set(ccache_dist \"ccache-${ccache_version}-linux-x86_64\")\n            set(ccache_url \"https://github.com/ccache/ccache/releases/download/v${ccache_version}/${ccache_dist}.tar.xz\")\n            file(DOWNLOAD \"${ccache_url}\" ./ccache.tar.xz SHOW_PROGRESS)\n            execute_process(COMMAND ${CMAKE_COMMAND} -E tar zxvf ./ccache.tar.xz)\n            # Add to PATH environment variable\n            file(TO_CMAKE_PATH \"$ENV{GITHUB_WORKSPACE}/${ccache_dist}\" ccache_dir)\n            set(path_separator \":\")\n            file(APPEND \"$ENV{GITHUB_PATH}\" \"$ENV{GITHUB_WORKSPACE}${path_separator}${ccache_dir}\")\n          else()\n            message(FATAL_ERROR, \"${{ runner.os }} is not supported\")\n          endif()\n\n      - name: Setup ccache\n        # If ccache behaves badly on windows, skip this step\n        # if: runner.os != 'Windows'\n        uses: Chocobo1/setup-ccache-action@v1\n        with:\n          install_ccache: false\n          update_packager_index: false\n          prepend_symlinks_to_path: false\n          windows_compile_environment: msvc # this field is required\n\n      - name: Configure\n        shell: cmake -P {0}\n        run: |\n          set(ENV{CC} ${{ matrix.config.cc }})\n          set(ENV{CXX} ${{ matrix.config.cxx }})\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            execute_process(\n              COMMAND \"${{ matrix.config.environment_script }}\" && set\n              OUTPUT_FILE environment_script_output.txt\n            )\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          set(path_separator \":\")\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(path_separator \";\")\n          endif()\n          set(ENV{PATH} \"$ENV{GITHUB_WORKSPACE}${path_separator}$ENV{PATH}\")\n\n          # If ccache shows some strange behavior on windows, you can easily\n          # disable it here by setting the variable to \"OFF\"\n          if (NOT \"${{ runner.os }}\" STREQUAL \"Windows\")\n            set(enable_ccache \"ON\")\n          else()\n            set(enable_ccache \"ON\")\n          endif()\n\n          execute_process(\n            COMMAND cmake\n              -S .\n              -B build\n              -D CMAKE_BUILD_TYPE=$ENV{BUILD_TYPE}\n              -G Ninja\n              -D USE_CCACHE=${enable_ccache}\n              -D CMAKE_MAKE_PROGRAM=ninja\n              -D ASAP_BUILD_TESTS=ON\n              -D ASAP_BUILD_EXAMPLES=ON\n              -D CMAKE_INSTALL_PREFIX=install\n              -D CMAKE_VERBOSE_MAKEFILE=ON\n            RESULT_VARIABLE result\n          )\n          if (NOT result EQUAL 0)\n            message(FATAL_ERROR \"Bad exit status\")\n          endif()\n\n      - name: Build\n        shell: cmake -P {0}\n        run: |\n          set(ENV{NINJA_STATUS} \"[%f/%t %o/sec] \")\n\n          if (\"${{ runner.os }}\" STREQUAL \"Windows\" AND NOT \"x${{ matrix.config.environment_script }}\" STREQUAL \"x\")\n            file(STRINGS environment_script_output.txt output_lines)\n            foreach(line IN LISTS output_lines)\n              if (line MATCHES \"^([a-zA-Z0-9_-]+)=(.*)$\")\n                set(ENV{${CMAKE_MATCH_1}} \"${CMAKE_MATCH_2}\")\n              endif()\n            endforeach()\n          endif()\n\n          execute_process(\n            COMMAND cmake --build build --target all\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"FAILED:.*$\" error_message \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" error_message \"${error_message}\")\n            message(\"::error::${error_message}\")\n            message(FATAL_ERROR \"Build failed\")\n          endif()\n\n      - name: Run tests\n        shell: cmake -P {0}\n        run: |\n          include(ProcessorCount)\n          ProcessorCount(N)\n\n          set(ENV{CTEST_OUTPUT_ON_FAILURE} \"ON\")\n\n          execute_process(\n            COMMAND ctest -j ${N}\n            WORKING_DIRECTORY build\n            RESULT_VARIABLE result\n            OUTPUT_VARIABLE output\n            ERROR_VARIABLE output\n            ECHO_OUTPUT_VARIABLE ECHO_ERROR_VARIABLE\n          )\n          if (NOT result EQUAL 0)\n            string(REGEX MATCH \"[0-9]+% tests.*[0-9.]+ sec.*$\" test_results \"${output}\")\n            string(REPLACE \"\\n\" \"%0A\" test_results \"${test_results}\")\n            message(\"::error::${test_results}\")\n            message(FATAL_ERROR \"Running tests failed!\")\n          endif()\n\n      - name: Install Strip\n        run: cmake --install build --strip\n\n      - name: Pack\n        working-directory: install\n        run: cmake -E tar cfv ../${{ matrix.config.artifact }} --format=7zip .\n\n      - name: Upload\n        uses: actions/upload-artifact@v1\n        with:\n          path: ./${{ matrix.config.artifact }}\n          name: ${{ matrix.config.artifact }}\n\n  release:\n    if: contains(github.ref, 'tags/v')\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Create Release\n        id: create_release\n        uses: actions/create-release@v1.0.0\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          tag_name: ${{ github.ref }}\n          release_name: Release ${{ github.ref }}\n          draft: false\n          prerelease: false\n\n      - name: Store Release url\n        run: |\n          echo \"${{ steps.create_release.outputs.upload_url }}\" > ./upload_url\n\n      - uses: actions/upload-artifact@v1\n        with:\n          path: ./upload_url\n          name: upload_url\n\n  publish:\n    if: contains(github.ref, 'tags/v')\n    name: ${{ matrix.config.name }}\n    runs-on: ${{ matrix.config.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {\n              name: \"Windows Latest MSVC\",\n              artifact: \"Windows-MSVC.7z\",\n              os: windows-latest,\n            }\n          - {\n              name: \"Ubuntu Latest GCC\",\n              artifact: \"Linux.7z\",\n              os: ubuntu-latest,\n            }\n          - {\n              name: \"macOS Latest Clang\",\n              artifact: \"macOS.7z\",\n              os: macos-latest,\n            }\n    needs: release\n\n    steps:\n      - name: Download artifact\n        uses: actions/download-artifact@v1\n        with:\n          name: ${{ matrix.config.artifact }}\n          path: ./\n\n      - name: Download URL\n        uses: actions/download-artifact@v1\n        with:\n          name: upload_url\n          path: ./\n\n      - id: set_upload_url\n        run: |\n          upload_url=`cat ./upload_url`\n          echo ::set-output name=upload_url::$upload_url\n        shell: bash\n\n      - name: Upload to Release\n        id: upload_to_release\n        uses: actions/upload-release-asset@v1.0.1\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        with:\n          upload_url: ${{ steps.set_upload_url.outputs.upload_url }}\n          asset_path: ./${{ matrix.config.artifact }}\n          asset_name: ${{ matrix.config.artifact }}\n          asset_content_type: application/x-gtar\n",
    "source": "yunghegel/opengl_starter",
    "path": ".github/workflows/cmake-build.yml",
    "url": "https://github.com/yunghegel/opengl_starter/blob/78e4a5f89a2f6f8dbe9dc4606caa356445c6a041/.github/workflows/cmake-build.yml",
    "retrieved_at": "2025-09-17T01:36:48.484151Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML, including manual triggering and job dependencies.",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:49.240251Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this workflow?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:49.928942Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:50.743527Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:51.436497Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Chaining Jobs\" workflow?",
    "answer": "# Display name of workflow\nname: Chaining Jobs\n\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API.\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      run-job-3:\n        description: \"Run job 3\"\n        required: true\n        type: boolean\n\njobs:\n\n  job-1:\n    name: Job 1\n    runs-on: ubuntu-latest\n    steps:\n    - name: Output for Job 1\n      run: echo \"Hello from Job 1. Run Job 3 equals ${{ github.event.inputs.run-job-3 }}\" \n\n  job-2:\n    name: Job 2\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 2\n      run: echo \"Hello from Job 2\"\n\n  job-3:\n    name: Job 3\n    #if: github.event.inputs.run-job-3 == 'true'\n    runs-on: ubuntu-latest\n    #needs:\n    #  - job-1\n    steps:\n    - name: Output for Job 3\n      run: echo \"Hello from Job 3\"\n\n  job-4:\n    name: Job 4\n    runs-on: ubuntu-latest\n    # if: always()\n    needs:\n      - job-2\n      - job-3\n    steps:\n    - name: Output for Job 4\n      run: echo \"Hello from Job 4\"\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/3-chaining.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/3-chaining.yaml",
    "retrieved_at": "2025-09-17T01:36:51.945256Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:23.604546Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events to the main branch or release branches trigger this workflow?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:24.157497Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow have dependencies on others, or run in parallel?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:24.659384Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `PROJECT_ID`, `PR_CLUSTER`, and `ZONE` environment variables used for deployment in the workflow?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:25.165513Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CI workflow triggered on pushes to main or release branches?",
    "answer": "# Copyright 2020 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nname: \"Continuous Integration - Main/Release\"\non:\n  push:\n    # run on pushes to main or release/*\n    branches:\n      - main\n      - release/*\njobs:\n  code-tests:\n    runs-on: [self-hosted, is-enabled]\n    steps:\n    - uses: actions/checkout@v3\n    - uses: actions/setup-dotnet@v2\n      with:\n        dotnet-version: '6.0.100'\n    - uses: actions/setup-go@v3\n      with:\n        go-version: '1.17.5'\n    - name: Go Unit Tests\n      timeout-minutes: 10\n      run: |\n        for SERVICE in \"shippingservice\" \"productcatalogservice\"; do\n          echo \"testing $SERVICE...\"\n          pushd src/$SERVICE\n          go test\n          popd\n        done\n    - name: C# Unit Tests\n      timeout-minutes: 10\n      run: |\n        dotnet test src/cartservice/\n  deployment-tests:\n    runs-on: [self-hosted, is-enabled]\n    needs: code-tests\n    strategy:\n      matrix:\n        profile: [\"local-code\"]\n      fail-fast: true\n    steps:\n    - uses: actions/checkout@v3\n    - name: Build + Deploy PR images to GKE\n      timeout-minutes: 20\n      run: |\n        PR_NUMBER=$(echo $GITHUB_REF | awk 'BEGIN { FS = \"/\" } ; { print $3 }')\n        NAMESPACE=\"pr${PR_NUMBER}\"\n        echo \"::set-env name=NAMESPACE::$NAMESPACE\"\n        echo \"::set-env name=PR_NUMBER::$PR_NUMBER\"\n\n        gcloud container clusters get-credentials $PR_CLUSTER --zone $ZONE --project $PROJECT_ID\n        cat <<EOF | kubectl apply -f -\n        apiVersion: v1\n        kind: Namespace\n        metadata:\n          name: $NAMESPACE\n        EOF\n        echo Deploying application\n        skaffold config set --global local-cluster false\n        skaffold run --default-repo=gcr.io/$PROJECT_ID/$GITHUB_REF --tag=$GITHUB_SHA --namespace=$NAMESPACE\n      env:\n        ACTIONS_ALLOW_UNSECURE_COMMANDS: true\n        PROJECT_ID: \"online-boutique-ci\"\n        PR_CLUSTER: \"online-boutique-prs\"\n        ZONE: \"us-central1-c\"\n    - name: Wait For Pods\n      timeout-minutes: 20\n      run: |\n        set -x\n        kubectl config set-context --current --namespace=$NAMESPACE\n        kubectl wait --for=condition=available --timeout=1000s deployment/redis-cart\n        kubectl wait --for=condition=available --timeout=1000s deployment/adservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/cartservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/checkoutservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/currencyservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/emailservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/frontend\n        kubectl wait --for=condition=available --timeout=1000s deployment/loadgenerator\n        kubectl wait --for=condition=available --timeout=1000s deployment/paymentservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/productcatalogservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/recommendationservice\n        kubectl wait --for=condition=available --timeout=1000s deployment/shippingservice\n    - name: Smoke Test\n      timeout-minutes: 5\n      run: |\n        set -x\n        # start fresh loadgenerator pod\n        kubectl delete pod -l app=loadgenerator\n        # wait for requests to come in\n        REQUEST_COUNT=\"0\"\n        while [[ \"$REQUEST_COUNT\"  -lt \"50\"  ]]; do\n            sleep 5\n            REQUEST_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $2}')\n        done\n        # ensure there are no errors hitting endpoints\n        ERROR_COUNT=$(kubectl logs -l app=loadgenerator | grep Aggregated | awk '{print $3}' | sed \"s/[(][^)]*[)]//g\")\n        if [[ \"$ERROR_COUNT\" -gt \"0\" ]]; then\n          exit 1\n        fi\n",
    "source": "cnych/microservices-demo",
    "path": ".github/workflows/ci-master.yaml",
    "url": "https://github.com/cnych/microservices-demo/blob/05b1d749855b6cc50ab17ce3527af741886c66e9/.github/workflows/ci-master.yaml",
    "retrieved_at": "2025-09-18T01:36:25.695384Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML.",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:26.333703Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:26.884146Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:27.493639Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `PRIVATE_KEY` secret used for deployment?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:27.983691Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow deploy, or what is its main effect when triggered?",
    "answer": "name: deploy\n\non: push\n\n# It is important to specify \"concurrency\" for the workflow,\n# to prevent concurrency between different deploys.\nconcurrency: production_environment\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup PHP\n        uses: shivammathur/setup-php@v2\n        with:\n          php-version: '8.2'\n\n      - name: Install dependencies\n        run: composer install\n\n      - name: Deploy\n        uses: deployphp/action@v1\n        with:\n          dep: deploy\n          private-key: ${{ secrets.PRIVATE_KEY }}\n",
    "source": "RalfHei/Hajusrakendused",
    "path": ".github/workflows/deploy.yml",
    "url": "https://github.com/RalfHei/Hajusrakendused/blob/f59f7414d2a1ff64cb7b0d5b3f973b6b55922400/.github/workflows/deploy.yml",
    "retrieved_at": "2025-09-18T01:36:28.418899Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building and releasing an Android application.",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:12.200623Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger this Android 64-bit Release workflow?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:12.900370Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what dependencies exist between them?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:13.477554Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` secrets used for uploading builds to S3?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:14.064841Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this Android 64-bit Release workflow?",
    "answer": "# The 32 and 64 bit version of these actions should be kept in sync\nname: Android 64-bit Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: bash\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl64.apk\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  ubuntu-20.04\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v3\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         linux\n          target:       android\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: true\n\n      - name: Install Android NDK\n        uses: nttld/setup-ndk@v1\n        id: setup-ndk\n        with:\n          ndk-version: r21e\n          add-to-path: false\n\n      - name: Remove Android SDK android-33-ext\n        run: |\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext5\"\n            ${ANDROID_SDK_ROOT}/cmdline-tools/latest/bin/sdkmanager --uninstall \"platforms;android-33-ext4\"\n\n      - name: Install ccache\n        run:  sudo apt-get install ccache\n\n      - name: Prepare ccache timestamp\n        id: ccache_cache_timestamp\n        shell: cmake -P {0}\n        run: |\n          string(TIMESTAMP current_date \"%Y-%m-%d-%H;%M;%S\" UTC)\n          message(\"::set-output name=timestamp::${current_date}\")\n\n      - name: ccache cache files\n        uses: actions/cache@v2\n        with:\n          path:         ~/.ccache\n          key:          ${{ runner.os }}-ccache-${{steps.ccache_cache_timestamp.outputs.timestamp}}\n          restore-keys: ${{ runner.os }}-ccache-\n\n      - name: Setup ccache\n        run: |\n            mkdir -p ~/.ccache\n            echo \"base_dir = ${GITHUB_WORKSPACE}\" > ~/.ccache/ccache.conf\n            echo \"compression = true\" >> ~/.ccache/ccache.conf\n            echo \"compression_level = 5\" >> ~/.ccache/ccache.conf\n            ccache -s\n            ccache -z\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}/shadow_build_dir\n\n      - name:               Install gstreamer\n        working-directory:  ${{ github.workspace }}\n        run: |\n            wget --quiet https://gstreamer.freedesktop.org/data/pkg/android/1.18.5/gstreamer-1.0-android-universal-1.18.5.tar.xz\n            mkdir gstreamer-1.0-android-universal-1.18.5\n            tar xf gstreamer-1.0-android-universal-1.18.5.tar.xz -C gstreamer-1.0-android-universal-1.18.5\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Update android manifest\n        run: |\n          if [ $GIT_BRANCH_NAME != \"Stable*\" ]; then\n            ${SOURCE_DIR}/tools/update_android_manifest_package.sh ${GIT_BRANCH_NAME}\n          fi\n\n      - name: Build\n        working-directory: ${{ runner.temp }}/shadow_build_dir\n        env:\n          ANDROID_KEYSTORE_PASSWORD: ${{ secrets.ANDROID_KEYSTORE_PASSWORD }}\n          ANDROID_NDK_ROOT: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK_LATEST_HOME: ${{ steps.setup-ndk.outputs.ndk-path }}\n          ANDROID_NDK: ${{ steps.setup-ndk.outputs.ndk-path }}\n        run:  |\n            qmake -r ${SOURCE_DIR}/qgroundcontrol.pro -spec android-clang CONFIG+=${BUILD_TYPE} CONFIG+=installer ANDROID_ABIS=\"arm64-v8a\"\n            make -j2\n\n      - name: ccache post-run\n        run:  ccache -s\n\n      - name: Save artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}/shadow_build_dir/package/${{ env.ARTIFACT }}\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/builds/${GIT_BRANCH_NAME}/${ARTIFACT} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}/shadow_build_dir/package\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${ARTIFACT} s3://qgroundcontrol/latest/${ARTIFACT} --region us-west-2 --acl public-read\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/android_64_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/android_64_release.yml",
    "retrieved_at": "2025-09-19T01:39:14.683598Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the provided YAML, focusing on build inputs, Docker build with buildx and bake, and testing.",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:15.821641Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or trigger initiates this workflow?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:16.307348Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or depend on the completion of others?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:16.895115Z",
    "question_style": "style_3"
  },
  {
    "question": "How are DOCKERHUB_USERNAME and DOCKERHUB_TOKEN secrets used for Docker login and pushing images?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:17.482458Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this \"Build\" workflow?",
    "answer": "name: Build\n\non:\n  workflow_call:\n    inputs:\n      repo:\n        required: true\n        type: string\n        description: \"'erpnext' or 'frappe'\"\n      version:\n        required: true\n        type: string\n        description: \"Major version, git tags should match 'v{version}.*'; or 'develop'\"\n      push:\n        required: true\n        type: boolean\n      python_version:\n        required: true\n        type: string\n        description: Python Version\n      node_version:\n        required: true\n        type: string\n        description: NodeJS Version\n    secrets:\n      DOCKERHUB_USERNAME:\n        required: true\n      DOCKERHUB_TOKEN:\n        required: true\n\njobs:\n  build:\n    name: Build\n    runs-on: ubuntu-latest\n    services:\n      registry:\n        image: registry:2\n        ports:\n          - 5000:5000\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Buildx\n        uses: docker/setup-buildx-action@v3\n        with:\n          driver-opts: network=host\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo ${{ inputs.repo }} --version ${{ inputs.version }}\n\n      - name: Set build args\n        run: |\n          echo \"PYTHON_VERSION=${{ inputs.python_version }}\" >> \"$GITHUB_ENV\"\n          echo \"NODE_VERSION=${{ inputs.node_version }}\" >> \"$GITHUB_ENV\"\n\n      - name: Build\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n        env:\n          REGISTRY_USER: localhost:5000/frappe\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Install dependencies\n        run: |\n          python -m venv venv\n          venv/bin/pip install -r requirements-test.txt\n\n      - name: Test\n        run: venv/bin/pytest --color=yes\n\n      - name: Login\n        if: ${{ inputs.push }}\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Push\n        if: ${{ inputs.push }}\n        uses: docker/bake-action@v4.1.0\n        with:\n          push: true\n",
    "source": "UvRoxx/frappe_docker",
    "path": ".github/workflows/docker-build-push.yml",
    "url": "https://github.com/UvRoxx/frappe_docker/blob/ad80c98d33bbe2c1aa9a43df2471ed9e10712030/.github/workflows/docker-build-push.yml",
    "retrieved_at": "2025-09-19T01:39:18.052124Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file for building and releasing a Windows installer.",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:06.895119Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch/tag patterns trigger the Windows Release workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:07.401446Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and what are the dependencies between them?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.018699Z",
    "question_style": "style_3"
  },
  {
    "question": "How are AWS access key ID and secret access key secrets used to configure AWS CLI for S3 uploads?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.557027Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or outcome of this Windows Release workflow?",
    "answer": "name: Windows Release\n\non:\n  push:\n    branches:\n      - 'master'\n      - 'Stable*'\n    tags:\n      - 'v*'\n  pull_request:\n    branches:\n    - '*'\n\ndefaults:\n  run:\n    shell: cmd\n\nenv:\n  SOURCE_DIR:   ${{ github.workspace }}\n  QT_VERSION:   5.15.2\n  ARTIFACT:     QGroundControl-installer.exe\n  BUILD_TYPE:   ${{ fromJSON('[\"DailyBuild\", \"StableBuild\"]')[ github.ref_type == 'tag' || contains(github.ref, 'Stable_' ) ] }}\n\njobs:\n  build:\n    runs-on:  windows-2019\n\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v2\n        with:\n          submodules: recursive\n\n      - name: Get all tags for correct version determination\n        working-directory:  ${{ github.workspace }}\n        run: |\n          git fetch --all --tags -f\n\n      - name: Install Qt\n        uses: jurplel/install-qt-action@v2\n        with:\n          version:      ${{ env.QT_VERSION }}\n          host:         windows\n          target:       desktop\n          arch:         win64_msvc2019_64\n          dir:          ${{ runner.temp }}\n          modules:      qtcharts\n          setup-python: false\n\n      - name: Download JOM\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    http://download.qt.io/official_releases/jom/jom.zip\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Unzip JOM\n        working-directory: ${{ runner.temp }}\n        run:  |\n              7z x jom.zip -ojom\n\n      - name: Download Gstreamer\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Download Gstreamer dev\n        uses: suisei-cn/actions-download-file@v1.4.0\n        with:\n          url:    https://s3-us-west-2.amazonaws.com/qgroundcontrol/dependencies/gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi\n          target: ${{ runner.temp }}\\\n          retry-times: 10\n\n      - name: Install Gstreamer\n        run:  |\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n            cmd /c start /wait msiexec /package ${{ runner.temp }}\\gstreamer-1.0-devel-msvc-x86_64-1.18.1.msi /passive ADDLOCAL=ALL\n\n      - name: Create build directory\n        run:  mkdir ${{ runner.temp }}\\shadow_build_dir\n\n      - name: Set up Visual Studio shell\n        uses: egor-tensin/vs-shell@v2\n        with:\n          arch: x64\n\n      - name: Build\n        working-directory: ${{ runner.temp }}\\shadow_build_dir\n        run:  |\n              qmake -r ${{ env.SOURCE_DIR }}\\qgroundcontrol.pro CONFIG+=installer CONFIG+=${{ env. BUILD_TYPE }}\n              ${{ runner.temp }}\\jom\\jom -j2\n\n      - name: Save installer artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: ${{ env.ARTIFACT }}\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\${{ env.ARTIFACT }}\n\n      - name: Save PDB artifact\n        uses: actions/upload-artifact@master\n        with:\n          name: qgroundcontrol.pdb\n          path: ${{ runner.temp }}\\shadow_build_dir\\staging\\qgroundcontrol.pdb\n\n      # This will set GIT_BRANCH_NAME environment variable\n      - name: Git branch name\n        id:   git-branch-name\n        uses: EthanSK/git-branch-name-action@v1\n\n      - name: Upload build to S3 Bucket\n        if:                 github.event_name == 'push'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/builds/${{ env.GIT_BRANCH_NAME }}/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n      - name: Upload tagged stable build to S3 latest Bucket\n        if:                 github.event_name == 'push' && github.ref_type == 'tag'\n        working-directory:  ${{ runner.temp }}\\shadow_build_dir\\staging\n        run: |\n              aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}\n              aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n              aws s3 cp ${{ env.ARTIFACT }} s3://qgroundcontrol/latest/${{ env.ARTIFACT }} --region us-west-2 --acl public-read\n\n",
    "source": "HETONGAPP/qgroundcontrol",
    "path": ".github/workflows/windows_release.yml",
    "url": "https://github.com/HETONGAPP/qgroundcontrol/blob/1ac709c82d5eb592e7db1d5af7d275055bfa2d2a/.github/workflows/windows_release.yml",
    "retrieved_at": "2025-09-20T01:27:08.937286Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:09.709914Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Deploy PROD EMBED\" workflow?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:10.316188Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and what dependencies exist between the defined jobs?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:10.893132Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `NETLIFY_AUTH_TOKEN` and `GH_PACKAGES` secrets used within the deployment and image building steps, respectively?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:11.485790Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this GitHub Actions workflow?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Deploy PROD EMBED\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the master branch\non:\n  workflow_dispatch:\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n  deploy_embed_eu:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    timeout-minutes: 80\n    if: \"!contains(github.event.head_commit.message, 'ci skip')\"\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://eu.widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0c830b50-df83-480b-ba36-a7f3176efcc8\n        timeout-minutes: 1\n\n  # This workflow contains a single job called \"build\"\n  deploy_embed_us:\n    environment: Production\n    # The type of runner that the job will run on\n    runs-on: ubuntu-latest\n    needs: deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        env:\n          WIDGET_URL: https://widget.novu.co\n        run: CI='' npm run build:prod\n\n      - name: Deploy EMBED to PROD\n        uses: nwtgck/actions-netlify@v1.2\n        with:\n          publish-dir: libs/embed/dist\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          deploy-message: prod\n          production-deploy: true\n          alias: Prod\n          github-deployment-environment: Production\n        env:\n          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n          NETLIFY_SITE_ID: 0689c015-fca0-4940-a26d-3e33f561bc48\n        timeout-minutes: 1\n\n  deploy_embed:\n    environment: Production\n    runs-on: ubuntu-latest\n    needs:\n      - deploy_embed_us\n      - deploy_embed_eu\n    timeout-minutes: 80\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/setup-project\n\n      # Runs a single command using the runners shell\n      - name: Build\n        run: CI='' npm run build:embed\n\n      - name: Build\n        working-directory: libs/embed\n        run: CI='' npm run build:prod\n\n      - name: Remove build outputs\n        working-directory: libs/embed\n        run: rm -rf dist\n\n      - name: Build, tag, and push image to ghcr.io\n        id: build-image\n        env:\n          REGISTRY_OWNER: novuhq\n          DOCKER_NAME: novu/embed\n          IMAGE_TAG: ${{ github.sha }}\n          GH_ACTOR: ${{ github.actor }}\n          GH_PASSWORD: ${{ secrets.GH_PACKAGES }}\n        run: |\n          echo $GH_PASSWORD | docker login ghcr.io -u $GH_ACTOR --password-stdin \n          docker build -t ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG -f libs/embed/Dockerfile .\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker tag ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:prod\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:latest\n          docker push ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\n          echo \"::set-output name=IMAGE::ghcr.io/$REGISTRY_OWNER/$DOCKER_NAME:$IMAGE_TAG\"\n",
    "source": "X-oss-byte/Novu",
    "path": ".github/workflows/prod-deploy-embed.yml",
    "url": "https://github.com/X-oss-byte/Novu/blob/43fd935e56d4c37152640f4649cc5f24482b1a19/.github/workflows/prod-deploy-embed.yml",
    "retrieved_at": "2025-09-20T01:27:12.023621Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:35.303967Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions initiate the \"Lint Python\" workflow?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:35.754971Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Lint Python' workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:36.328623Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used within the Mypy execution step?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:36.854320Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this Python linting workflow?",
    "answer": "name: Lint Python\n\non:\n  workflow_call:\n  workflow_dispatch:\n    inputs:\n      branch:\n        description: \"(Optional) Branch to checkout\"\n        required: false\n        type: string\nenv:\n  POETRY_VERSION: \"1.8.2\"\n\n\njobs:\n  lint:\n    name: Run Mypy\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version:\n          - \"3.13\"\n          - \"3.12\"\n          - \"3.11\"\n          - \"3.10\"\n    steps:\n      - name: Check out the code at a specific ref\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ inputs.branch || github.ref }}\n          persist-credentials: true\n      - name: \"Setup Environment\"\n        uses: ./.github/actions/setup-uv\n      - name: Install the project\n        run: uv sync --dev\n      - name: Run Mypy\n        run: |\n          uv run mypy --namespace-packages -p \"langflow\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.github_token }}\n      - name: Minimize uv cache\n        run: uv cache prune --ci\n",
    "source": "nawadkar/langflow-auth0",
    "path": ".github/workflows/lint-py.yml",
    "url": "https://github.com/nawadkar/langflow-auth0/blob/9a9be60857a4317b71ea8ac26d01afe247b3f224/.github/workflows/lint-py.yml",
    "retrieved_at": "2025-09-21T01:45:37.245982Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file, including triggering, environment variables, jobs, and steps.",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:38.456284Z",
    "question_style": "style_1"
  },
  {
    "question": "What events—workflow completion, pushes to `ci_*` branches with specific path changes, or repository dispatches—trigger this workflow?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:39.637544Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow run in parallel or depend on the completion of other jobs or steps?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:40.568281Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets `CI_SLACK_BOT_TOKEN`, `CI_SLACK_CHANNEL_ID`, `CI_SLACK_CHANNEL_ID_DAILY`, `CI_SLACK_CHANNEL_DUMMY_TESTS`, `CI_SLACK_REPORT_CHANNEL_ID`, and `ACCESS_REPO_INFO_TOKEN` used?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:41.759143Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow in the `transformers` repository's CI process?",
    "answer": "name: Self-hosted runner (push)\n\non:\n  workflow_run:\n    workflows: [\"Self-hosted runner (push-caller)\"]\n    branches: [\"main\"]\n    types: [completed]\n  push:\n    branches:\n      - ci_*\n      - ci-*\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n      - \".github/**\"\n      - \"templates/**\"\n      - \"utils/**\"\n  repository_dispatch:\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  PYTEST_TIMEOUT: 60\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n  CUDA_VISIBLE_DEVICES: 0,1\n\njobs:\n  setup:\n    name: Setup\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n      test_map: ${{ steps.set-matrix.outputs.test_map }}\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # `CI_BRANCH_PUSH`: The branch name from the push event\n        # `CI_BRANCH_WORKFLOW_RUN`: The name of the branch on which this workflow is triggered by `workflow_run` event\n        # `CI_BRANCH`: The non-empty branch name from the above two (one and only one of them is empty)\n        # `CI_SHA_PUSH`: The commit SHA from the push event\n        # `CI_SHA_WORKFLOW_RUN`: The commit SHA that triggers this workflow by `workflow_run` event\n        # `CI_SHA`: The non-empty commit SHA from the above two (one and only one of them is empty)\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Fetch the tests to run\n        working-directory: /transformers\n        # TODO: add `git-python` in the docker images\n        run: |\n          pip install --upgrade git-python\n          python3 utils/tests_fetcher.py --diff_with_last_commit | tee test_preparation.txt\n\n      - name: Report fetched tests\n        uses: actions/upload-artifact@v3\n        with:\n          name: test_fetched\n          path: /transformers/test_preparation.txt\n\n      - id: set-matrix\n        name: Organize tests into models\n        working-directory: /transformers\n        # The `keys` is used as GitHub actions matrix for jobs, i.e. `models/bert`, `tokenization`, `pipeline`, etc.\n        # The `test_map` is used to get the actual identified test files under each key.\n        # If no test to run (so no `test_map.json` file), create a dummy map (empty matrix will fail)\n        run: |\n          if [ -f test_map.json ]; then\n              keys=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); d = list(test_map.keys()); print(d)')\n              test_map=$(python3 -c 'import json; fp = open(\"test_map.json\"); test_map = json.load(fp); fp.close(); print(test_map)')\n          else\n              keys=$(python3 -c 'keys = [\"dummy\"]; print(keys)')\n              test_map=$(python3 -c 'test_map = {\"dummy\": []}; print(test_map)')\n          fi\n          echo $keys\n          echo $test_map\n          echo \"matrix=$keys\" >> $GITHUB_OUTPUT\n          echo \"test_map=$test_map\" >> $GITHUB_OUTPUT\n\n  run_tests_single_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    needs: setup\n    # `dummy` means there is no test to run\n    if: contains(fromJson(needs.setup.outputs.matrix), 'dummy') != true\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-all-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          echo \"${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        env:\n          MKL_SERVICE_FORCE_INTEL: 1\n        working-directory: /transformers\n        run: |\n          python3 -m pytest -n 2 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} ${{ fromJson(needs.setup.outputs.test_map)[matrix.folders] }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_torch_cuda_extensions_single_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  run_tests_torch_cuda_extensions_multi_gpu:\n    name: Torch CUDA extension tests\n    needs: setup\n    if: contains(fromJson(needs.setup.outputs.matrix), 'deepspeed') || contains(fromJson(needs.setup.outputs.matrix), 'extended')\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [multi-gpu]\n    runs-on: ['${{ matrix.machine_type }}', nvidia-gpu, t4, push-ci]\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-latest-gpu-push-ci\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - name: Update clone using environment variables\n        working-directory: /workspace/transformers\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - name: Reinstall transformers in edit mode (remove the one installed during docker image build)\n        working-directory: /workspace/transformers\n        run: python3 -m pip uninstall -y transformers && python3 -m pip install -e .\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 python3 -m pip install deepspeed --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Show installed libraries and their versions\n        working-directory: /workspace/transformers\n        run: pip freeze\n\n      - name: Run all non-slow selected tests on GPU\n        working-directory: /workspace/transformers\n        # TODO: Here we pass all tests in the 2 folders for simplicity. It's better to pass only the identified tests.\n        run: |\n          python -m pytest -n 1 --dist=loadfile -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v3\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-22.04\n    if: always()\n    needs: [\n        setup,\n        run_tests_single_gpu,\n        run_tests_multi_gpu,\n        run_tests_torch_cuda_extensions_single_gpu,\n        run_tests_torch_cuda_extensions_multi_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      # Necessary to get the correct branch name and commit SHA for `workflow_run` event\n      # We also take into account the `push` event (we might want to test some changes in a branch)\n      - name: Prepare custom environment variables\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          CI_BRANCH_PUSH=${{ github.event.ref }}\n          CI_BRANCH_PUSH=${CI_BRANCH_PUSH/'refs/heads/'/''}\n          CI_BRANCH_WORKFLOW_RUN=${{ github.event.workflow_run.head_branch }}\n          CI_SHA_PUSH=${{ github.event.head_commit.id }}\n          CI_SHA_WORKFLOW_RUN=${{ github.event.workflow_run.head_sha }}\n          echo $CI_BRANCH_PUSH\n          echo $CI_BRANCH_WORKFLOW_RUN\n          echo $CI_SHA_PUSH\n          echo $CI_SHA_WORKFLOW_RUN\n          [[ ! -z \"$CI_BRANCH_PUSH\" ]] && echo \"CI_BRANCH=$CI_BRANCH_PUSH\" >> $GITHUB_ENV || echo \"CI_BRANCH=$CI_BRANCH_WORKFLOW_RUN\" >> $GITHUB_ENV\n          [[ ! -z \"$CI_SHA_PUSH\" ]] && echo \"CI_SHA=$CI_SHA_PUSH\" >> $GITHUB_ENV || echo \"CI_SHA=$CI_SHA_WORKFLOW_RUN\" >> $GITHUB_ENV\n\n      - name: print environment variables\n        run: |\n          echo \"env.CI_BRANCH = ${{ env.CI_BRANCH }}\"\n          echo \"env.CI_SHA = ${{ env.CI_SHA }}\"\n\n      - uses: actions/checkout@v3\n        # To avoid failure when multiple commits are merged into `main` in a short period of time.\n        # Checking out to an old commit beyond the fetch depth will get an error `fatal: reference is not a tree: ...\n        # (Only required for `workflow_run` event, where we get the latest HEAD on `main` instead of the event commit)\n        with:\n          fetch-depth: 20\n\n      - name: Update clone using environment variables\n        run: |\n          echo \"original branch = $(git branch --show-current)\"\n          git fetch && git checkout ${{ env.CI_BRANCH }}\n          echo \"updated branch = $(git branch --show-current)\"\n          git checkout ${{ env.CI_SHA }}\n          echo \"log = $(git log -n 1)\"\n\n      - uses: actions/download-artifact@v3\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          ACCESS_REPO_INFO_TOKEN: ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n          CI_EVENT: push\n          CI_TITLE_PUSH: ${{ github.event.head_commit.message }}\n          CI_TITLE_WORKFLOW_RUN: ${{ github.event.workflow_run.head_commit.message }}\n          CI_SHA: ${{ env.CI_SHA }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          pip show slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "mudigosa/LLM-Transformers",
    "path": ".github/workflows/self-push.yml",
    "url": "https://github.com/mudigosa/LLM-Transformers/blob/4edffda636fb2bf673282b31163e598b5872994e/.github/workflows/self-push.yml",
    "retrieved_at": "2025-09-21T01:45:42.686480Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:43.532464Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the HalKit - Deploy workflow?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:43.993423Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'deploy' job execute concurrently, and are there any dependencies between them?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:44.560229Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `NUGET_API_KEY` secret used to authenticate with the NuGet repository during package publishing?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:45.072353Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the HalKit - Deploy workflow?",
    "answer": "name: HalKit - Deploy\n\non: workflow_dispatch\n\njobs:\n  deploy:\n\n    runs-on: windows-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Setup .NET\n      uses: actions/setup-dotnet@v1\n      with:\n        dotnet-version: '3.1.x'\n    - name: Restore dependencies\n      run: dotnet restore\n    - name: Create the package\n      run: dotnet build --configuration Release src/HalKit/HalKit.csproj --no-restore\n    - name: Publish the package\n      uses: brandedoutcast/publish-nuget@v2.5.5\n      with:\n        PROJECT_FILE_PATH: src/HalKit/HalKit.csproj\n        VERSION_FILE_PATH: Version.props\n        VERSION_REGEX: ^\\s*<VersionPrefix>(.*)<\\/VersionPrefix>\\s*$\n        TAG_COMMIT: true\n        TAG_FORMAT: v*\n        NUGET_KEY: ${{secrets.NUGET_API_KEY}}\n        NUGET_SOURCE: https://api.nuget.org\n        INCLUDE_SYMBOLS: true\n",
    "source": "viagogo/HalKit",
    "path": ".github/workflows/halkit-deploy.yml",
    "url": "https://github.com/viagogo/HalKit/blob/ff312c4dfa4f47052df8923f5ee2c30e2d22638b/.github/workflows/halkit-deploy.yml",
    "retrieved_at": "2025-09-22T01:45:45.645652Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:46.447661Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:46.827407Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run in parallel, and which depend on the successful completion of others?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:47.325178Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the workflow utilize any secrets for installation, building, or testing?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:47.829174Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or goal of this CI workflow?",
    "answer": "name: ci\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-22.04\n    steps:\n      # Checkout Repository\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup CCache\n        uses: hendrikmuhs/ccache-action@v1.2\n\n      # Install Tools\n      - name: Install Tools\n        run: |\n          sudo apt-get install wget build-essential ninja-build\n          sudo apt-get install libevent-dev libjson-c-dev flex bison\n          sudo apt-get install libfl-dev libfl2 zlib1g-dev\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.9\"\n          cache: \"pip\"\n          cache-dependency-path: \"setup.py\"\n\n      - name: Install Python dependencies\n        run: |\n          python3 -m pip install setuptools requests pexpect meson\n\n      # Install (n)Migen / LiteX / Cores\n      - name: Install LiteX\n        run: |\n          python3 litex_setup.py --config=full --init --install --user --dev\n\n      # Install GCC Toolchains\n      - name: Install GCC Toolchains\n        run: |\n          sudo python3 litex_setup.py --gcc=riscv\n          sudo python3 litex_setup.py --gcc=openrisc\n          sudo python3 litex_setup.py --gcc=powerpc\n\n      # Build / Install GHDL\n      - name: Build GHDL\n        run: |\n          sudo apt-get install gnat llvm\n          git clone https://github.com/ghdl/ghdl.git\n          cd ghdl\n          ./configure --with-llvm-config\n          make\n          sudo make install\n\n      # Build / Install Verilator\n      - name: Build Verilator\n        run: |\n          sudo apt-get install help2man\n          export PATH=\"/usr/lib/ccache:/usr/local/opt/ccache/libexec:$PATH\"\n          git clone https://github.com/verilator/verilator\n          cd verilator\n          git checkout 7d2d32420a630befa4097170ecbf227e04e32522\n          autoconf\n          ./configure\n          make -j$(nproc)\n          sudo make install\n\n      # Install Project\n      - name: Install Project\n        run: python3 setup.py develop --user\n\n      # Test\n      - name: Run Tests\n        run: |\n          python3 setup.py test\n",
    "source": "kuznia-rdzeni/litex_",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/kuznia-rdzeni/litex_/blob/6ec1e14269f1b984c0355989a9dbeca6802d21cc/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-22T01:45:48.325879Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that performs code linting using npm, similar to the provided workflow.",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:11.875366Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this code linting workflow?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:12.418227Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Code Linting\" workflow execute concurrently or sequentially based on dependencies?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:13.061312Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:13.587829Z",
    "question_style": "style_4"
  },
  {
    "question": "What's the primary function of this code linting workflow?",
    "answer": "name: Code Linting\n\non: [push, pull_request]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v1\n      - run: npm install\n      - run: >\n          npm install $(node -e \"const deps=require('./package.json').peerDependencies;\n          console.log(Object.keys(deps).map(key=>key+'@'+deps[key]).join(' '));\")\n      - run: npm run lint\n",
    "source": "MannyCooper/hexo-theme-candy",
    "path": ".github/workflows/lint.yml",
    "url": "https://github.com/MannyCooper/hexo-theme-candy/blob/ba535961a05f514e00cd97aad4ab3afd9a5cfcd2/.github/workflows/lint.yml",
    "retrieved_at": "2025-09-23T01:37:14.201472Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file equivalent to the provided example, ensuring identical triggers, jobs, and steps.",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:15.098500Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of the \"unitTest\" workflow?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:15.894821Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"unitTest\" workflow run concurrently or have dependencies on each other?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:16.569190Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching of dependencies or artifacts?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:17.341224Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this unit testing workflow?",
    "answer": "\nname: unitTest\n\non: [push, pull_request]\n\njobs:     \n  unit-test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [14.x, 15.x]\n\n    steps:\n      - uses: actions/checkout@v2\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v1\n        with:\n          node-version: ${{ matrix.node-version }}\n      - run: npm ci\n      - run: npm run build --if-present\n      - run: npm run test:unit",
    "source": "mendixlabs/CustomDropdown",
    "path": ".github/workflows/npm.yml",
    "url": "https://github.com/mendixlabs/CustomDropdown/blob/4fb9416a401b60f329eba2625a336bf05fb7d7c3/.github/workflows/npm.yml",
    "retrieved_at": "2025-09-23T01:37:17.853593Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided RSpec workflow.",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:27.278692Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the RSpec workflow in this YAML file?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:30.849680Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently, and which depend on the completion of others?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:32.627790Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `CC_TEST_REPORTER_ID` secret used by the `paambaati/codeclimate-action` action?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:38.604183Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this RSpec workflow?",
    "answer": "name: RSpec\non:\n  - push\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: ruby/setup-ruby@v1\n        with:\n          ruby-version: 2.5\n          bundler-cache: true\n\n      - name: Run tests\n        run: bundle exec rspec\n\n      - name: 'Upload Coverage Report'\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: ./coverage\n\n  coverage:\n    needs: [ test ]\n    name: coverage\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - name: Download Coverage Report\n      uses: actions/download-artifact@v4\n      with:\n        name: coverage-report\n        path: ./coverage\n    - uses: paambaati/codeclimate-action@v9.0.0\n      env:\n        # Set CC_TEST_REPORTER_ID as secret of your repo\n        CC_TEST_REPORTER_ID: ${{secrets.CC_TEST_REPORTER_ID}}\n      with:\n        debug: true\n",
    "source": "Sage/class_kit",
    "path": ".github/workflows/rspec.yml",
    "url": "https://github.com/Sage/class_kit/blob/947f4aef126b0a1906d7275df834ac2f51456c28/.github/workflows/rspec.yml",
    "retrieved_at": "2025-09-24T01:38:39.170898Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow, including jobs, steps, and configurations.",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:40.637710Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and/or push events trigger this workflow?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:42.155194Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs in this workflow run in parallel, and which have dependencies or a specific execution order?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:43.351300Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any secrets used within this workflow, and if so, where are they utilized?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:44.559832Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow file?",
    "answer": "# To enable retrying a job on failure or a specific timeout, instead of the run step, use uses: nick-fields/retry@v2.9.0(see the linux-gcc-make-tsan jsob)\n# To retry only on timeout set retry_on: timeout\n# To retry only on error set retry_on: error\n# For more information on the retry action see https://github.com/nick-fields/retry\n\nname: Compile and Testrun\n\non:\n  pull_request:\n    types: [opened]\n  push:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}\n  cancel-in-progress: true\n\njobs:\n  android-arm64-v8a-ndk-latest-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_LATEST_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-arm64-v8a-ndk-cmake:\n   runs-on: ubuntu-22.04\n   steps:\n       - uses: actions/checkout@v3\n       - uses: nttld/setup-ndk@v1\n         with:\n            ndk-version: r25c\n            add-to-path: true\n       - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  android-armeabi-v7a-ndk-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: nttld/setup-ndk@v1\n        with:\n          ndk-version: r25c\n          add-to-path: true\n      - run: cmake -S$GITHUB_WORKSPACE -B$HOME/android-build -DANDROID_ABI=armeabi-v7a -DANDROID_PLATFORM=android-21 -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK_HOME/build/cmake/android.toolchain.cmake && cmake --build $HOME/android-build --target all\n\n  linux-gcc-make:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-cxx20:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev redis-server libmysqlclient-dev\n      - run: ./configure --config=Linux-c++20 --everything --omit=PDF && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/MySQL Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/ODBC Data/PostgreSQL Data/MySQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-asan-no-soo:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF --no-soo && make all -s -j4 SANITIZEFLAGS=-fsanitize=address && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-ubsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=PDF && make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"Data/MySQL Data/ODBC Data/PostgreSQL MongoDB\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-tsan:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: ./configure --everything --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip && make all -s -j4 SANITIZEFLAGS=-fsanitize=thread && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            ./ci/runtests.sh TSAN\n\n  linux-gcc-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build libssl-dev unixodbc-dev libmysqlclient-dev redis-server\n      - run: cmake -S. -Bcmake-build -GNinja -DENABLE_PDF=OFF -DENABLE_TESTS=ON && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-emscripten-cmake:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install cmake ninja-build emscripten\n      - run: emcmake cmake -H. -B cmake-build -DENABLE_ACTIVERECORD_COMPILER=OFF -DENABLE_PAGECOMPILER=OFF -DENABLE_PAGECOMPILER_FILE2PAGE=off && emmake cmake --build cmake-build --target all -j4\n# TODO: How to run unit tests in emscripten?\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#            cd cmake-build &&\n#            sudo -s\n#            PWD=`pwd`\n#            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)\"\n\n  linux-gcc-make-cross-armhf:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: >-\n          sudo apt-get -y update &&\n          sudo apt-get -y install crossbuild-essential-armhf\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            ./configure --config=ARM-Linux --everything --omit=PDF,Crypto,NetSSL_OpenSSL,JWT,Data/MySQL,Data/ODBC,Data/PostgreSQL,PageCompiler,PageCompiler/File2Page &&\n            make all -s -j4 ARCHFLAGS=\"-mcpu=cortex-a8 -mfloat-abi=hard -mfpu=neon\" TOOL=arm-linux-gnueabihf\n\n  macos-clang-make:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --cflags=\"-fvisibility=hidden\" --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@1.1/include\" --library-path=\"/usr/local/opt/openssl@1.1/lib\" &&\n          make all -s -j4\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<SyslogTest>.testOldBSD,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-cmake-openssl:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@1.1 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@1.1 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DENABLE_PDF=OFF -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-cmake-openssl3-visibility-hidden:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: cmake -S. -Bcmake-build -DCMAKE_CXX_VISIBILITY_PRESET=hidden -DENABLE_ENCODINGS_COMPILER=ON -DENABLE_PDF=ON -DENABLE_SEVENZIP=ON -DENABLE_CPPPARSER=ON -DENABLE_TESTS=ON -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl@3 -DMYSQL_ROOT_DIR=/usr/local/opt/mysql-client && cmake --build cmake-build --target all\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build &&\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            PWD=`pwd`\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(PostgreSQL)|(MongoDB)|(Redis)\"\n\n  macos-clang-make-openssl3-tsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=CppParser,Encodings,Data/MySQL,Data/ODBC,Data/PostgreSQL,MongoDB,PageCompiler,PDF,PocoDoc,ProGen,Redis,SevenZip\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=thread\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh TSAN\n\n  macos-clang-make-openssl3-ubsan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=undefined\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n  macos-clang-make-openssl3-asan:\n    runs-on: macos-12\n    steps:\n      - uses: actions/checkout@v3\n      - run: brew install openssl@3 mysql-client unixodbc libpq\n      - run: >-\n          ./configure --everything --no-prefix --no-samples --omit=PDF\n          --odbc-include=/usr/local/opt/unixodbc/include --odbc-lib=/usr/local/opt/unixodbc/lib\n          --mysql-include=/usr/local/opt/mysql-client/include --mysql-lib=/usr/local/opt/mysql-client/lib\n          --include-path=\"/usr/local/opt/openssl@3/include\" --library-path=\"/usr/local/opt/openssl@3/lib\" &&\n          make all -s -j4 SANITIZEFLAGS=-fsanitize=address\n\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            CPPUNIT_IGNORE=\"\n            CppUnit::TestCaller<ThreadTest>.testTrySleep,\n            CppUnit::TestCaller<TimestampTest>.testTimestamp,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<UniqueExpireLRUCacheTest>.testExpireN,\n            CppUnit::TestCaller<ExpireLRUCacheTest>.testAccessExpireN,\n            CppUnit::TestCaller<PollSetTest>.testPollClosedServer\"\n            EXCLUDE_TESTS=\"Redis Data/MySQL Data/ODBC Data/PostgreSQL MongoDB PDF\"\n            ./ci/runtests.sh\n\n#   windows-2019-msvc-cmake:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy,\n#         class CppUnit::TestCaller<class PollSetTest>.testPollClosedServer\n#     steps:\n#       - uses: actions/checkout@v3\n#       - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#       - run: cmake --build cmake-build --config Release\n#       - uses: ./.github/actions/retry-action\n#          with:\n#             timeout_minutes: 90\n#             max_attempts: 3\n#             retry_on: any\n#             command: >-\n#             cd cmake-build;\n#             ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n#   windows-2019-msvc-buildwin-x64:\n#     runs-on: windows-2019\n#     env:\n#       CPPUNIT_IGNORE: >-\n#         class CppUnit::TestCaller<class PathTest>.testFind,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#         class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#         class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#         class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#         class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#     steps:\n#       - uses: actions/checkout@v3\n#       - uses: ./.github/actions/retry-action\n#         with:\n#           timeout_minutes: 90\n#           max_attempts: 3\n#           retry_on: any\n#           command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2019-msvc-buildwin-win32:\n#    runs-on: windows-2019\n#    env:\n#      CPPUNIT_IGNORE: class CppUnit::TestCaller<class PathTest>.testFind,class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,class CppUnit::TestCaller<class ICMPClientTest>.testPing,class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: .\\buildwin.ps1 -poco_base . -vs 160 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-buildwin-x64:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform x64 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n#  windows-2022-msvc-buildwin-win32:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - uses: ./.github/actions/retry-action\n#      with:\n#        timeout_minutes: 90\n#        max_attempts: 3\n#        retry_on: any\n#        command: .\\buildwin.ps1 -poco_base . -vs 170 -action build -linkmode all -config release -platform Win32 -samples -tests -omit \"Crypto,NetSSL_OpenSSL,Data/MySQL,Data/PostgreSQL,JWT\"\n\n  windows-2022-msvc-cmake:\n    runs-on: windows-2022\n    env:\n      CPPUNIT_IGNORE: >-\n        class CppUnit::TestCaller<class PathTest>.testFind,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n    steps:\n      - uses: actions/checkout@v3\n      - run: cmake -S. -Bcmake-build -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n      - run: cmake --build cmake-build --config Release\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            cd cmake-build;\n            ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Release\n\n# missing asan dll path\n#  windows-2022-msvc-cmake-asan:\n#    runs-on: windows-2022\n#    env:\n#      CPPUNIT_IGNORE: >-\n#        class CppUnit::TestCaller<class PathTest>.testFind,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testSendToReceiveFrom,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testPing,\n#        class CppUnit::TestCaller<class ICMPClientTest>.testBigPing,\n#        class CppUnit::TestCaller<class ICMPSocketTest>.testMTU,\n#        class CppUnit::TestCaller<class HTTPSClientSessionTest>.testProxy,\n#        class CppUnit::TestCaller<class HTTPSStreamFactoryTest>.testProxy\n#    steps:\n#      - uses: actions/checkout@v3\n#      - run: cmake -S. -Bcmake-build -DPOCO_SANITIZE_ASAN=ON -DENABLE_NETSSL_WIN=ON -DENABLE_NETSSL=OFF -DENABLE_CRYPTO=OFF -DENABLE_JWT=OFF -DENABLE_DATA=ON -DENABLE_DATA_ODBC=ON -DENABLE_DATA_MYSQL=OFF -DENABLE_DATA_POSTGRESQL=OFF -DENABLE_TESTS=ON\n#      - run: cmake --build cmake-build --config Debug\n#      - uses: ./.github/actions/retry-action\n#        with:\n#          timeout_minutes: 90\n#          max_attempts: 3\n#          retry_on: any\n#          command: >-\n#          cd cmake-build;\n#          ctest --output-on-failure -E \"(DataMySQL)|(DataODBC)|(Redis)|(MongoDB)\" -C Debug\n\n  linux-gcc-make-mysql:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev  mysql-client\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/SQLite,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n# TODO tests sometimes failing on testTransaction and testReconnect\n  linux-gcc-make-postgres:\n    runs-on: ubuntu-22.04\n    services:\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/ODBC,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-redis:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: |\n          curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n          echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n          sudo apt-get -y update\n          sudo apt-get -y install redis\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-mongodb:\n    runs-on: ubuntu-22.04\n    steps:\n      - uses: actions/checkout@v3\n      - uses: supercharge/mongodb-github-action@1.10.0\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/ODBC,Data/MySQL,Data/SQLite,Data/PostgreSQL,Encodings,JSON,JWT,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/ODBC Data/MySQL Data/SQLite Data/PostgreSQL Encodings Foundation JSON JWT Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-odbc:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n      postgres:\n        image: postgres:16.0\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n      oracle:\n        image: container-registry.oracle.com/database/express:21.3.0-xe\n        env:\n          ORACLE_PWD: poco\n        ports:\n          - 1521:1521\n      sqlserver:\n        image: mcr.microsoft.com/mssql/server:2022-latest\n        env:\n          MSSQL_PID: Express\n          ACCEPT_EULA: Y\n          MSSQL_SA_PASSWORD: Pocopoco1\n        ports:\n          - 1433:1433\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update && sudo apt -y install libssl-dev unixodbc-dev libmysqlclient-dev mysql-client alien libaio1 gnupg2 curl #odbc-postgresql\n      - run: ./configure --everything --no-samples --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/MySQL,Data/PostgreSQL,Data/SQLite,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      # - name: Setup MySQL ODBC connector\n      #   run: |\n      #     wget https://dev.mysql.com/get/Downloads/Connector-ODBC/8.2/mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      #     wget https://dev.mysql.com/get/Downloads/MySQL-8.2/mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb\n      #     sudo dpkg -i mysql-community-client-plugins_8.2.0-1ubuntu22.04_amd64.deb mysql-connector-odbc_8.2.0-1ubuntu22.04_amd64.deb\n      # - name: Setup Oracle ODBC connector\n      #   run: |\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     wget https://download.oracle.com/otn_software/linux/instantclient/2112000/oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-basic-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-sqlplus-21.12.0.0.0-1.x86_64.rpm\n      #     sudo alien --scripts ./oracle-instantclient-odbc-21.12.0.0.0-1.x86_64.rpm\n      #     sudo apt install ./oracle-instantclient-basic_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-sqlplus_21.12.0.0.0-2_amd64.deb\n      #     sudo apt install ./oracle-instantclient-odbc_21.12.0.0.0-2_amd64.deb\n      #     sudo /usr/lib/oracle/21/client64/bin/odbc_update_ini.sh / \"/usr/lib/oracle/21/client64/lib\" \"\" \"\"  \"/etc/odbc.ini\"\n      - name: Setup SQL Server ODBC connector\n        run: |\n           curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n           curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n           sudo apt-get update\n           sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/MySQL Data/PostgreSQL Data/SQLite Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n\n  linux-gcc-make-sqlite-no-sqlparser:\n    runs-on: ubuntu-22.04\n    services:\n      mysql:\n        image: mysql:8.1.0\n        env:\n          MYSQL_ALLOW_EMPTY_PASSWORD: yes\n          MYSQL_USER: pocotest\n          MYSQL_PASSWORD: pocotest\n          MYSQL_DATABASE: pocotest\n        ports:\n          - 3306:3306\n    steps:\n      - uses: actions/checkout@v3\n      - run: sudo apt -y update\n      - run: ./configure --everything --no-samples --no-sqlparser --omit=ActiveRecord,ApacheConnector,CppParser,Crypto,Data/PostgreSQL,Data/MySQL,Data/ODBC,Encodings,JSON,JWT,MongoDB,Net,NetSSL_OpenSSL,NetSSL_Win,PDF,PageCompiler,PocoDoc,ProGen,Prometheus,Redis,SevenZip,Util,XML,Zip && make all -s -j4 && sudo make install\n      - uses: ./.github/actions/retry-action\n        with:\n          timeout_minutes: 90\n          max_attempts: 3\n          retry_on: any\n          command: >-\n            sudo -s\n            EXCLUDE_TESTS=\"ActiveRecord ApacheConnector CppParser CppUnit Crypto Data Data/PostgreSQL Data/ODBC Data/MySQL Encodings Foundation JSON JWT MongoDB Net NetSSL_OpenSSL NetSSL_Win PDF PageCompiler PocoDoc ProGen Prometheus Redis SevenZip Util XML Zip\"\n            ./ci/runtests.sh\n",
    "source": "ISISComputingGroup/poco",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/ISISComputingGroup/poco/blob/5cc749aa5baa4405ec2f74ea72975f37f81361c0/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-24T01:38:45.786915Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the provided Java CI workflow's functionality, including matrix testing across different JDKs.",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:47.879074Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the \"Java CI\" workflow?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:48.449883Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Java CI\" workflow execute in parallel, and which ones have dependencies?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:49.049110Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching or artifacts to optimize build times or share data between jobs?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:49.601829Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Java CI workflow?",
    "answer": "name: Java CI\n\non: [push]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-18.04]\n        java: [8, 8.0.192, 11, 11.0.2, 13, 13.0.4, 15, 16-ea]\n      fail-fast: false\n      max-parallel: 2          \n    name: Test JDK ${{ matrix.java }}, ${{ matrix.os }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up JDK\n      uses: actions/setup-java@v1\n      with:\n        java-version: ${{ matrix.java }}\n    - name: Test with Maven\n      run: mvn test -B --file pom.xml\n",
    "source": "amihaiemil/docker-java-api",
    "path": ".github/workflows/maven.yml",
    "url": "https://github.com/amihaiemil/docker-java-api/blob/653943a3012fe104ff5d226351cebbe52785eba5/.github/workflows/maven.yml",
    "retrieved_at": "2025-09-25T01:38:50.022553Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML, building an Emscripten project with CMake and running tests.",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:50.786635Z",
    "question_style": "style_1"
  },
  {
    "question": "What events (or actions) trigger this GitHub Actions workflow?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:51.453911Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the emscripten job execute concurrently, and what are any dependency relationships between them?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:51.944303Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching mechanisms or artifact uploads/downloads to optimize performance or share build outputs?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:52.610004Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this Emscripten build workflow?",
    "answer": "name: Build (Emscripten)\n\non: [push, pull_request]\n\njobs:\n  emscripten:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: mymindstorm/setup-emsdk@v10\n        with:\n          version: 2.0.27\n      - name: Configure CMake\n        run: |\n          emcmake cmake -S . -B build \\\n            -DSDL_TESTS=ON \\\n            -DSDL_INSTALL_TESTS=ON \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_INSTALL_PREFIX=prefix\n      - name: Build\n        run: cmake --build build/ --verbose\n      - name: Run build-time tests\n        run: |\n          set -eu\n          export SDL_TESTS_QUICK=1\n          ctest -VV --test-dir build/\n      - name: Install\n        run: |\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          cmake --install build/\n      - name: Verify CMake configuration files\n        run: |\n          emcmake cmake -S cmake/test -B cmake_config_build \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DTEST_SHARED=FALSE \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/emscripten.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/emscripten.yml",
    "retrieved_at": "2025-09-25T01:38:53.127114Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the build process defined in the provided YAML.",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:24.778961Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events or pull requests targeting the main branch trigger this workflow?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:25.334395Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow execute concurrently or have dependencies on the completion of others?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:25.916409Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching or artifacts?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:26.522032Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish by building and packaging the C++ project?",
    "answer": "name: Cpp\n\non:\n  push:\n  pull_request:\n    branches: \n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        os: [ ubuntu-22.04, ubuntu-20.04 ]\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v4\n    - name: Install dependencies\n      run: sudo apt-get install -y build-essential cmake libasio-dev\n    - name: Build and pack\n      run: mkdir build && cd build && cmake -DBUILD_TESTS=ON .. && cmake --build . && cpack    \n",
    "source": "westonrobot/ugv_sdk",
    "path": ".github/workflows/standalone-ci.yml",
    "url": "https://github.com/westonrobot/ugv_sdk/blob/58436e9c1732474566e249ce7f726e12e26304d6/.github/workflows/standalone-ci.yml",
    "retrieved_at": "2025-09-26T01:38:27.194691Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:27.961120Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch conditions trigger this workflow to automatically minify CSS/JS files?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:28.601227Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'build' job execute in parallel, and are there any dependencies between them?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:29.201323Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching/artifacts for its execution?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:29.725202Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow file?",
    "answer": "# This is a basic workflow to help you get started with Actions\n\nname: Auto Minify CSS/JS file\n\n# Controls when the action will run. Triggers the workflow on push or pull request\n# events but only for the dev branch\non:\n  push:\n    branches: [ dev ]\n    paths:\n      - 'public/assets/css/**'\n      - 'public/assets/js/**'\n      - 'public/theme/material/css/**'\n      - 'public/theme/material/js/**'\n  pull_request:\n    branches: [ dev ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Auto Minify Theme CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/css'\n      - name: Auto Minify Theme JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/theme/material/js'\n      - name: Auto Minify CSS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/css'\n      - name: Auto Minify JS file\n        uses: nizarmah/auto-minify@master\n        with:\n          directory: 'public/assets/js'\n      - name: Auto committing minified files\n        uses: stefanzweifel/git-auto-commit-action@v3.0.0\n        with:\n          repository: 'public'\n          commit_message: \"Github Action: Auto Minified Theme CSS/JS Files\"\n          branch: ${{ github.ref }}\n",
    "source": "iamsaltedfish/sspanel-v3-tabler",
    "path": ".github/workflows/minify.yml",
    "url": "https://github.com/iamsaltedfish/sspanel-v3-tabler/blob/fa82f6ba92e3a2da6439d62d3a712be96db1e575/.github/workflows/minify.yml",
    "retrieved_at": "2025-09-26T01:38:30.274429Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for building, publishing, and deploying to Google Kubernetes Engine.",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:14.024695Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this GitHub Actions workflow?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:15.152485Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow are configured to run in parallel or sequentially based on dependencies?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:16.006794Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GKE_PROJECT` secret used to define the `PROJECT_ID` environment variable?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:17.477718Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this GitHub Actions workflow?",
    "answer": "# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the \"main\" branch.\n#\n# To configure this workflow:\n#\n# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.\n#\n# 2. Create and configure a Workload Identity Provider for GitHub (https://github.com/google-github-actions/auth#setting-up-workload-identity-federation)\n#\n# 3. Change the values for the GAR_LOCATION, GKE_ZONE, GKE_CLUSTER, IMAGE, REPOSITORY and DEPLOYMENT_NAME environment variables (below).\n#\n# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke-kustomize\n\nname: Build and Deploy to GKE\n\non:\n  push:\n    branches:\n      - \"main\"\n\nenv:\n  PROJECT_ID: ${{ secrets.GKE_PROJECT }}\n  GAR_LOCATION: us-central1 # TODO: update region of the Artifact Registry\n  GKE_CLUSTER: cluster-1    # TODO: update to cluster name\n  GKE_ZONE: us-central1-c   # TODO: update to cluster zone\n  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name\n  REPOSITORY: samples # TODO: update to Artifact Registry docker repository\n  IMAGE: static-site\n\njobs:\n  setup-build-publish-deploy:\n    name: Setup, Build, Publish, and Deploy\n    runs-on: ubuntu-latest\n    environment: production\n\n    permissions:\n      contents: 'read'\n      id-token: 'write'\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    # Configure Workload Identity Federation and generate an access token.\n    - id: 'auth'\n      name: 'Authenticate to Google Cloud'\n      uses: 'google-github-actions/auth@v0'\n      with:\n        token_format: 'access_token'\n        workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'\n        service_account: 'my-service-account@my-project.iam.gserviceaccount.com'\n\n    # Alternative option - authentication via credentials json\n    # - id: 'auth'\n    #   uses: 'google-github-actions/auth@v0'\n    #   with:\n    #     credentials_json: '${{ secrets.GCP_CREDENTIALS }}'\n\n    - name: Docker configuration\n      run: |-\n        echo ${{steps.auth.outputs.access_token}} | docker login -u oauth2accesstoken --password-stdin https://$GAR_LOCATION-docker.pkg.dev\n    # Get the GKE credentials so we can deploy to the cluster\n    - name: Set up GKE credentials\n      uses: google-github-actions/get-gke-credentials@v0\n      with:\n        cluster_name: ${{ env.GKE_CLUSTER }}\n        location: ${{ env.GKE_ZONE }}\n\n    # Build the Docker image\n    - name: Build\n      run: |-\n        docker build \\\n          --tag \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\" \\\n          --build-arg GITHUB_SHA=\"$GITHUB_SHA\" \\\n          --build-arg GITHUB_REF=\"$GITHUB_REF\" \\\n          .\n    # Push the Docker image to Google Artifact Registry\n    - name: Publish\n      run: |-\n        docker push \"$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\"\n    # Set up kustomize\n    - name: Set up Kustomize\n      run: |-\n        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64\n        chmod u+x ./kustomize\n    # Deploy the Docker image to the GKE cluster\n    - name: Deploy\n      run: |-\n        # replacing the image name in the k8s template\n        ./kustomize edit set image LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/IMAGE:TAG=$GAR_LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/$IMAGE:$GITHUB_SHA\n        ./kustomize build . | kubectl apply -f -\n        kubectl rollout status deployment/$DEPLOYMENT_NAME\n        kubectl get services -o wide\n",
    "source": "jyotidabass/PCOS-APP",
    "path": ".github/workflows/google.yml",
    "url": "https://github.com/jyotidabass/PCOS-APP/blob/4295c7d6206fbe54938d1c0b02780f0bea78572d/.github/workflows/google.yml",
    "retrieved_at": "2025-09-27T01:27:18.653146Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for lz4 CI.",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:19.828372Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the lz4 CI workflow?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:23.754631Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel, and which ones have dependencies that dictate their execution order?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:24.590543Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables like `FIXME__LZ4_CI_IGNORE`, `CC`, and `CXX` used to manage compiler options and control error handling?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:32.425251Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this GitHub Actions workflow for the lz4 project?",
    "answer": "# For details, see README.md in this directory.\n\n###############################################################\n# C compilers\n#\n# - gcc\n# - clang\n#\n# Known Issue\n# - All test cases which described as 'fail' must be fixed and replaced with 'true'.\n#   - gcc-11 (x32, x86) : \"../lib/lz4hc.c:148: LZ4HC_countBack: Assertion `(size_t)(match - mMin) < (1U<<31)' failed.\"\n#   - all clangs (x32, x86) : \"../lib/lz4hc.c:282: int LZ4HC_InsertAndGetWiderMatch(...): Assertion `matchPtr >= lowPrefixPtr' failed.\"\n#\nname: lz4 CI\non: [push, pull_request]\njobs:\n  lz4-c-compilers:\n    name: CC=${{ matrix.cc }}, ${{ matrix.os }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #\n          #   pkgs    : apt-get package names.  It can include multiple package names which are delimited by space.\n          #   cc      : C compiler executable.\n          #   cxx     : C++ compiler executable for `make ctocpptest`.\n          #   x32     : Set 'true' if compiler supports x32.  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x32 but fails for now.  'fail' cases must be removed.\n          #   x86     : Set 'true' if compiler supports x86 (-m32).  Otherwise, set 'false'.\n          #             Set 'fail' if it supports x86 but fails for now.  'fail' cases must be removed.\n          #   cxxtest : Set 'true' if it can be compiled as C++ code.  Otherwise, set 'false'.\n          #   os      : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          # cc\n          { pkgs: '',                                                   cc: cc,        cxx: c++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n\n          # gcc\n          { pkgs: '',                                                   cc: gcc,       cxx: g++,         x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'gcc-11 g++-11 lib32gcc-11-dev libx32gcc-11-dev',     cc: gcc-11,    cxx: g++-11,      x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-10 lib32gcc-10-dev libx32gcc-10-dev',            cc: gcc-10,    cxx: g++-10,      x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-9  lib32gcc-9-dev  libx32gcc-9-dev',             cc: gcc-9,     cxx: g++-9,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-8 g++-8 lib32gcc-8-dev libx32gcc-8-dev',         cc: gcc-8,     cxx: g++-8,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-7 g++-7 lib32gcc-7-dev libx32gcc-7-dev',         cc: gcc-7,     cxx: g++-7,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'gcc-6 g++-6 lib32gcc-6-dev libx32gcc-6-dev',         cc: gcc-6,     cxx: g++-6,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-5 g++-5 lib32gcc-5-dev libx32gcc-5-dev',         cc: gcc-5,     cxx: g++-5,       x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'gcc-4.8 g++-4.8 lib32gcc-4.8-dev libx32gcc-4.8-dev', cc: gcc-4.8,   cxx: g++-4.8,     x32: 'true', x86: 'true', cxxtest: 'true',  os: ubuntu-18.04,  },\n\n          # clang\n          { pkgs: 'lib32gcc-11-dev libx32gcc-11-dev',                   cc: clang,     cxx: clang++,     x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-latest, },\n          { pkgs: 'clang-12  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-12,  cxx: clang++-12,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-11  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-11,  cxx: clang++-11,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-10  lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-10,  cxx: clang++-10,  x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-9   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-9,   cxx: clang++-9,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-8   lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-8,   cxx: clang++-8,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-7   lib32gcc-7-dev  libx32gcc-7-dev',          cc: clang-7,   cxx: clang++-7,   x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-6.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-6.0, cxx: clang++-6.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-20.04,  },\n          { pkgs: 'clang-5.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-5.0, cxx: clang++-5.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-4.0 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-4.0, cxx: clang++-4.0, x32: 'fail', x86: 'fail', cxxtest: 'true',  os: ubuntu-18.04,  },\n          { pkgs: 'clang-3.9 lib32gcc-11-dev libx32gcc-11-dev',         cc: clang-3.9, cxx: clang++-3.9, x32: 'fail', x86: 'fail', cxxtest: 'false', os: ubuntu-18.04,  },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      # We globally set CC and CXX to improve compatibility with .travis.yml\n      CC: ${{ matrix.cc }}\n      CXX: ${{ matrix.cxx }}\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $CC && which $CC && $CC --version\n        echo && type $CXX && which $CXX && $CXX --version\n\n    - name: make\n      if: always()\n      run: make V=1\n\n    - name: make all\n      if: always()\n      run: make V=1 clean all\n\n    - name: make c_standards (C90)\n      if: always()\n      run: make V=1 clean c_standards_c90\n\n    - name: make c_standards (C11)\n      if: always()\n      run: make V=1 clean c_standards_c11\n\n    - name: make c-to-c++\n      if: always()\n      run: make V=1 clean ctocpptest\n\n    - name: make cxxtest\n      if: ${{ matrix.cxxtest == 'true' }}\n      run: make V=1 clean cxxtest\n\n    - name: make -C programs default\n      if: always()\n      run: make V=1 -C programs clean default\n\n    - name: make -C programs default -D_FORTIFY_SOURCE=2\n      if: always()\n      run: CFLAGS='-fPIC' LDFLAGS='-pie -fPIE -D_FORTIFY_SOURCE=2' make V=1 -C programs clean default\n\n    - name: make -C tests test-lz4\n      if: always()\n      run: MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4\n\n    - name: make clangtest (clang only)\n      if: ${{ startsWith( matrix.cc , 'clang' ) }}\n      run: make V=1 clean clangtest\n\n    - name: make -C tests test MOREFLAGS='-mx32'\n      if: ${{ matrix.x32 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test\n\n    - name: make -C tests test-lz4c32\n      if: ${{ matrix.x86 == 'true' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32\n\n\n    ###############################################################\n    #                                                             #\n    #      Remove this block when we stabilize the tests.         #\n    #                                                             #\n\n    - name: make -C tests test MOREFLAGS='-mx32' || echo Ignore failure for now.\n      if: ${{ matrix.x32 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-mx32' make V=1 -C tests clean test || $FIXME__LZ4_CI_IGNORE\n\n    - name: make -C tests test-lz4c32 || echo Ignore failure for now.\n      if: ${{ matrix.x86 == 'fail' }}\n      run: LDFLAGS='-Wl,--verbose' MOREFLAGS='-Werror' make V=1 -C tests clean test-lz4c32 || $FIXME__LZ4_CI_IGNORE\n\n    #                                                             #\n    ###############################################################\n\n\n\n###############################################################\n# LZ4 self tests\n#\n# - Benchmark\n# - Fuzzer\n# - LZ4 Frame\n# - LZ4 versions\n# - Custom LZ4_DISTANCE_MAX\n#\n  lz4-benchmark:\n    name: Benchmark\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: benchmark (-C tests test-lz4)\n      run: make V=1 -C tests test-lz4\n\n    - name: benchmark (-C tests test-lz4c)\n      run: make V=1 -C tests test-lz4c\n\n    - name: benchmark (-C tests test-lz4c32)\n      run: make V=1 -C tests test-lz4c32\n\n    - name: benchmark (-C tests test-fullbench)\n      run: make V=1 -C tests test-fullbench\n\n    - name: benchmark (-C tests test-fullbench32)\n      run: make V=1 -C tests test-fullbench32\n\n\n  lz4-fuzzer:\n    name: Fuzzer test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: fuzzer\n      run: make V=1 -C tests test-fuzzer\n\n    - name: fuzzer32\n      run: make V=1 -C tests test-fuzzer32\n\n\n  lz4-versions:\n    name: LZ4 versions test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: make -C tests versionsTest\n      run: make V=1 -C tests versionsTest\n\n\n  lz4-frame:\n    name: LZ4 frame test\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n\n    - name: LZ4 frame test\n      run: make V=1 -C tests test-frametest\n\n    - name: LZ4 frame test (32-bit)\n      run: make V=1 -C tests test-frametest32\n\n\n  # Custom LZ4_DISTANCE_MAX ; lz4-wlib (CLI linked to dynamic library); LZ4_USER_MEMORY_FUNCTIONS\n  lz4-custom-distance:\n    name: Custom LZ4_DISTANCE_MAX\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: custom LZ4_DISTANCE_MAX\n      run: |\n        MOREFLAGS='-DLZ4_DISTANCE_MAX=8000' make V=1 check\n        make V=1 clean\n        make V=1 -C programs lz4-wlib\n        make V=1 clean\n        make V=1 -C tests fullbench-wmalloc  # test LZ4_USER_MEMORY_FUNCTIONS\n        make V=1 clean\n        CC=\"c++ -Wno-deprecated\" make V=1 -C tests fullbench-wmalloc  # stricter function signature check\n\n\n\n###############################################################\n# Check tools\n#\n# - cppcheck\n# - scan-build\n# - valgrind\n# - ubsan\n# - asan\n# - unicode-lint\n# - build examples\n#\n  lz4-cppcheck:\n    name: make cppcheck\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install cppcheck\n\n    - name: Environment info\n      run: echo && type cppcheck && which cppcheck && cppcheck --version\n\n    - name: cppcheck\n      # This test script ignores the exit code of cppcheck.\n      # See known issues in README.md.\n      run: make V=1 clean cppcheck || echo There are some cppcheck reports but we ignore it.\n\n\n  lz4-scan-build:\n    name: make staticAnalyze\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install clang-tools\n\n    - name: Environment info\n      run: |\n        echo && type gcc && which gcc && gcc --version\n        echo && type clang && which clang && clang --version\n        echo && type scan-build && which scan-build               # scan-build doesn't have any --version equivalent option\n        echo && type make && which make && make -v\n        echo && cat /proc/cpuinfo || echo /proc/cpuinfo is not present\n\n    - name: make staticAnalyze\n      run: make V=1 clean staticAnalyze\n\n\n  lz4-valgrind:\n    name: valgrind\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install valgrind\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type valgrind && which valgrind && valgrind --version\n\n    - name: valgrind\n      run: make V=1 -C tests test-mem\n\n\n  lz4-ubsan-x64:\n    name: Linux x64 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: ubsan\n      #########################################################\n      # For now, we ignore the exit code of `make usan`.\n      # See \"Known issues / lz4-ubsan-x64\" in README.md\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: make V=1 clean usan MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-ubsan-x86:\n    name: Linux x86 ubsan\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install lib32gcc-11-dev\n\n    - name: ubsan32\n      #########################################################\n      # For now, we ignore the exit code of `make usan32`.\n      # See \"Known issues / lz4-ubsaan-x86\" in README.md.\n      # When we'll resolve this issue, remove \"|| $FIXME__LZ4_CI_IGNORE\"\n      #########################################################\n      run: CC=clang make V=1 clean usan32 MOREFLAGS='-Wcomma -Werror' || $FIXME__LZ4_CI_IGNORE\n\n\n  lz4-asan-x64:\n    name: Linux x64 ASAN\n    runs-on: ubuntu-latest\n    env:                        # Set environment variables\n      FIXME__LZ4_CI_IGNORE : ' echo Error.  But we ignore it for now.'\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: setup\n      run: sudo sysctl -w vm.mmap_min_addr=4096\n\n    - name: frametest\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-frametest\n\n    - name: fuzzer\n      run: CC=clang MOREFLAGS=-fsanitize=address make V=1 -C tests clean test-fuzzer\n\n  unicode-lint:\n    name: lint unicode in ./lib/, ./tests/ and ./programs/\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: unicode lint\n      run: bash ./tests/unicode_lint.sh\n\n\n  lz4-examples:\n    name: make examples\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type c++ && which c++ && c++ --version\n\n    - name: examples\n      run: make V=1 clean examples\n\n    - name: examples (compile as C++ code)\n      run: make V=1 -C examples clean cxxtest\n\n\n###############################################################\n# Platforms\n#\n# - QEMU (ARM, ARM64, PPC, PPC64LE, S390X)\n# - macOS\n#\n\n  # QEMU\n  # All tests use QEMU (static) and gcc cross compiler.\n  #\n  # note:\n  #   We don't employ completely matrix method which provides `MOREFLAGS`\n  #   etc in the matrix.  Because some platform may need its special\n  #   compiler options and test.\n  #   For example, xxHash already has tests for scalar and SIMD version of\n  #   it.  But compiler options are quite different between platforms.\n  #\n  #   So, please keep them simple and independent.\n  #\n  lz4-qemu-platforms:\n    name: QEMU ${{ matrix.type }}\n    strategy:\n      fail-fast: false  # 'false' means Don't stop matrix workflows even if some matrix instance failed.\n      matrix:\n        include: [\n          # You can access the following values via ${{ matrix.??? }}\n          #   type : Architecture type for `if:` statement.\n          #   pkgs : apt-get package names.  You can include multiple packages which are delimited by space.\n          #   xcc  : gcc cross C compiler executable.\n          #   xemu : QEMU static emulator executable.\n          #   os   : GitHub Actions YAML workflow label.  See https://github.com/actions/virtual-environments#available-environments\n\n          { type: ARM,      pkgs: 'qemu-system-arm   gcc-arm-linux-gnueabi',     xcc: arm-linux-gnueabi-gcc,     xemu: qemu-arm-static,     os: ubuntu-latest, },\n          { type: ARM64,    pkgs: 'qemu-system-arm   gcc-aarch64-linux-gnu',     xcc: aarch64-linux-gnu-gcc,     xemu: qemu-aarch64-static, os: ubuntu-latest, },\n          { type: PPC,      pkgs: 'qemu-system-ppc   gcc-powerpc-linux-gnu',     xcc: powerpc-linux-gnu-gcc,     xemu: qemu-ppc-static,     os: ubuntu-latest, },\n          { type: PPC64LE,  pkgs: 'qemu-system-ppc   gcc-powerpc64le-linux-gnu', xcc: powerpc64le-linux-gnu-gcc, xemu: qemu-ppc64le-static, os: ubuntu-latest, },\n          { type: S390X,    pkgs: 'qemu-system-s390x gcc-s390x-linux-gnu',       xcc: s390x-linux-gnu-gcc,       xemu: qemu-s390x-static,   os: ubuntu-latest, },\n        ]\n\n    runs-on: ${{ matrix.os }}\n    env:                        # Set environment variables\n      XCC: ${{ matrix.xcc }}\n      XEMU: ${{ matrix.xemu }}\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: apt-get install\n      run: |\n        sudo apt-get update\n        sudo apt-get install gcc-multilib\n        sudo apt-get install qemu-utils qemu-user-static\n        sudo apt-get install ${{ matrix.pkgs }}\n\n    - name: Environment info\n      run: |\n        echo && type $XCC && which $XCC && $XCC --version\n        echo && $XCC -v                       # Show built-in specs\n        echo && type $XEMU && which $XEMU && $XEMU --version\n\n    - name: ARM64\n      if: ${{ matrix.type == 'ARM64' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: ARM\n      if: ${{ matrix.type == 'ARM' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC\n      if: ${{ matrix.type == 'PPC' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n    - name: PPC64LE\n      if: ${{ matrix.type == 'PPC64LE' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU MOREFLAGS=-m64\n\n    - name: S390X\n      if: ${{ matrix.type == 'S390X' }}\n      run: make V=1 platformTest CC=$XCC QEMU_SYS=$XEMU\n\n\n  # macOS\n  lz4-platform-macos-latest:\n    name: macOS\n    runs-on: macos-latest\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n        echo && sysctl -a | grep machdep.cpu   # cpuinfo\n\n    - name: make default\n      run: CFLAGS=\"-Werror\" make V=1 clean default\n\n    - name: make test\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion'\n\n    - name: make test | tee\n      # test scenario where `stdout` is not the console\n      run: make V=1 clean test MOREFLAGS='-Werror -Wconversion -Wno-sign-conversion' | tee\n\n\n\n###############################################################\n# Build systems\n#\n# - make\n# - cmake\n# - meson\n#\n\n  # make\n  lz4-build-make:\n    name: make\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cc && which cc && cc --version\n        echo && type make && which make && make -v\n\n    - name: make\n      run: make V=1\n\n\n  lz4-build-make-travis-install:\n    name: make travis-install\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: travis-install\n      run: make V=1 clean travis-install\n\n    - name: travis-install result\n      run: |\n        echo && echo Installed files\n        ( cd ~/install_test_dir; find .; )\n\n\n  # cmake\n  lz4-build-cmake:\n    name: cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n\n    - name: Environment info\n      run: |\n        echo && type cmake && which cmake && cmake --version\n        echo && type make && which make && make -v\n\n    - name: cmake\n      run: |\n        cd build/cmake\n        mkdir build\n        cd build\n        cmake ..\n        CFLAGS=-Werror make VERBOSE=1\n\n\n  # Invoke cmake via Makefile\n  lz4-build-make-cmake:\n    name: make cmake\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - name: make cmake\n      # V=1 for lz4 Makefile, VERBOSE=1 for cmake Makefile.\n      run: make V=1 VERBOSE=1 clean cmake\n\n\n  # Meson\n  lz4-build-meson:\n    name: Meson + Ninja\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2 # https://github.com/actions/checkout\n    - uses: actions/setup-python@v2 # https://github.com/actions/setup-python\n      with:\n        python-version: '3.x'\n\n    - name: Install\n      run: |\n        sudo apt-get update\n        sudo apt-get install tree ninja-build\n        python -m pip install --upgrade pip\n        pip3 install --user meson\n\n    - name: Environment info\n      run: |\n        echo && type clang && which clang && clang --version\n        echo && type python && which python && python --version\n        echo && type meson && which meson && meson --version\n\n    - name: meson\n      # 'run: >' replaces all newlines in the following block with spaces\n      run: >\n        meson setup\n        --buildtype=debug\n        -Db_lundef=false\n        -Dauto_features=enabled\n        -Ddefault_library=both\n        -Dbin_programs=true\n        -Dbin_contrib=true\n        -Dbin_tests=true\n        -Dbin_examples=true\n        contrib/meson build\n\n    - name: staging\n      run: |\n        cd build\n        DESTDIR=./staging ninja install\n        tree ./staging\n\n\n\n############################################################\n# Check git tag for LZ4 releases\n#\n  lz4-check-tag:\n    name: git version tag checking for release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: make -C tests checkTag\n      if: startsWith(github.ref, 'refs/tags/v')   # If git tag name starts with 'v'\n      run: |\n        echo \"tag=${GITHUB_REF#refs/*/}\"\n        make -C tests checkTag\n        tests/checkTag ${GITHUB_REF#refs/*/}\n\n\n\n############################################################\n# Gather CI environment information.\n#\n  lz4-env-info:\n    name: GH-Actions Virtual Env Info (${{ matrix.os }})\n    strategy:\n      matrix:\n        include: [\n          { os: ubuntu-latest,  }, # https://github.com/actions/virtual-environments/\n          { os: ubuntu-20.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu2004-README.md\n          { os: ubuntu-18.04,   }, # https://github.com/actions/virtual-environments/blob/main/images/linux/Ubuntu1804-README.md\n        ]\n\n    runs-on: ${{ matrix.os }}\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: init\n      run: |\n        sudo apt-get update\n\n    - name: cc --version\n      run: echo && type cc && which cc && cc --version\n\n    - name: gcc --version\n      run: echo && type gcc && which gcc && gcc --version\n\n    - name: clang --version\n      run: echo && type clang && which clang && clang --version\n\n    - name: make -v\n      run: echo && type make && which make && make -v\n\n    - name: g++ --version\n      run: echo && type g++ && which g++ && g++ --version\n\n    - name: git --version\n      run: echo && type git && which git && git --version\n\n    - name: gcc packages (apt-cache)\n      run: apt-cache search gcc | grep \"^gcc-[0-9\\.]* \" | sort\n\n    - name: lib32gcc packages for i386 (apt-cache)\n      run: apt-cache search lib32gcc | grep \"^lib32gcc-\" | sort\n\n    - name: libx32gcc packages for x32 (apt-cache)\n      run: apt-cache search libx32gcc | grep \"^libx32gcc-\" | sort\n\n    - name: gcc multilib packages (apt-cache)\n      run: apt-cache search multilib | grep \"gcc-\" | sort\n\n    - name: clang packages (apt-cache)\n      run: apt-cache search clang | grep \"^clang-[0-9\\.]* \" | sort\n\n    - name: QEMU packages (apt-cache)\n      run: apt-cache search qemu | grep \"^qemu-system-.*QEMU full system\" | sort\n",
    "source": "crdroidandroid/android_external_lz4",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/crdroidandroid/android_external_lz4/blob/96c6f5cda6e9b247370709fc4914a3bb31b48ce8/.github/workflows/ci.yml",
    "retrieved_at": "2025-09-27T01:27:33.558522Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the given YAML, triggered on merged pull requests to main, to verify and comment on labeling.",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} 👋\\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:28.519746Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and branches trigger this workflow?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} 👋\\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:29.077871Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} 👋\\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:29.679901Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to authenticate and authorize actions within the workflow?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} 👋\\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:30.361815Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow do when a pull request is merged into the main branch?",
    "answer": "name: pr-labels\n\non:\n  pull_request:\n    branches: main\n    types: closed\n\njobs:\n  is-properly-labeled:\n    if: github.event.pull_request.merged == true\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v2\n      - name: Set up python\n        uses: actions/setup-python@v2\n      - name: Install requests\n        run: pip install requests\n      - name: Process commit and find merger responsible for labeling\n        id: commit\n        run: echo \"::set-output name=merger::$(python .github/verify_pr_labels.py ${{ github.event.pull_request.number }})\"\n      - name: 'Comment PR'\n        uses: actions/github-script@0.3.0\n        if: ${{ steps.commit.outputs.merger != '' }}\n        with:\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          script: |\n            const { issue: { number: issue_number }, repo: { owner, repo }  } = context;\n            github.issues.createComment({ issue_number, owner, repo, body: 'Hey ${{ steps.commit.outputs.merger }} 👋\\nYou merged this PR, but it is not correctly labeled. The list of valid labels is available at https://github.com/mindee/doctr/blob/main/.github/verify_pr_labels.py' });\n",
    "source": "DSKonstantin/doctr",
    "path": ".github/workflows/pr-labels.yml",
    "url": "https://github.com/DSKonstantin/doctr/blob/eee2b3739a6ac84eeb71449084aac0ecf5056936/.github/workflows/pr-labels.yml",
    "retrieved_at": "2025-09-28T01:46:30.947002Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the build, test, and badge generation steps defined in the provided YAML file.",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:31.763265Z",
    "question_style": "style_1"
  },
  {
    "question": "What push events to the `main` branch, excluding the `badges` branch, trigger this workflow?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:32.341056Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"BuildAndTest\" workflow are executed in parallel, and what are their dependencies?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:32.973415Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used to push badge commits to the `badges` branch?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:33.548272Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow related to code evaluation and reporting?",
    "answer": "    name: BuildAndTest\n\n    on:\n      push:\n        branches:\n        - 'main'\n        - '!badges'\n\n    jobs:\n      build:\n        name: Autograding\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v2\n            with:\n              fetch-depth: 0 # otherwise, you will failed to push refs to dest repo\n\n          - name: Build\n            run: |\n              cd src/\n              make\n\n          # add id to step so outputs can be referenced\n          - uses: dilinade/autograding@v2\n            id: autograder\n            continue-on-error: true\n\n          # make dir for badges\n          - name: badges branch and make dir\n            run: |\n              git checkout badges || git checkout -b badges\n              mkdir -p .github/badges\n\n          # make points badge\n          - name: points badge\n            uses: emibcn/badge-action@v2.0.2\n            with:\n              LABEL: 'Points'\n              STATUS: ${{ steps.autograder.outputs.Points }}\n              COLOR: cyan\n              path: '.github/badges/points.svg'\n\n          # commit and push badge if score has changed\n          - name: Commit badge\n            run: |\n              git config --local user.email \"action@github.com\"\n              git config --local user.name \"GitHub Action\"\n              git add '.github/badges/points.svg'\n              git commit -m \"Add/Update badge\"\n            continue-on-error: true\n          - name: Push badge commit\n            uses: ad-m/github-push-action@master\n            if: ${{ success() }}\n            with:\n              github_token: ${{ secrets.GITHUB_TOKEN }}\n              branch: badges\n              force: true",
    "source": "brianej/part2ics",
    "path": ".github/workflows/classroom.yml",
    "url": "https://github.com/brianej/part2ics/blob/9a0cfdb4f643d2dcdd4f4139b3f50ada107cc564/.github/workflows/classroom.yml",
    "retrieved_at": "2025-09-28T01:46:34.209685Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that builds a mkdocs site with Python 3.11, installing dependencies from requirements.txt.",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:23.632802Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:23.989028Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow definition execute concurrently or in a specific sequential order?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:24.447137Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching/artifacts?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:24.913408Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this \"Build and Test\" workflow?",
    "answer": "name: Build and Test\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.11]\n\n    steps:\n    - uses: actions/checkout@44c2b7a8a4ea60a981eaca3cf939b5f4305c123b # v4.1.5\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@82c7e631bb3cdc910f68e0081d67478d79c6982d # v5.1.0\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n    - name: Build\n      run: mkdocs build --clean --strict -f mkdocs.yml -d site\n\n",
    "source": "decred/dcrdocs",
    "path": ".github/workflows/python.yml",
    "url": "https://github.com/decred/dcrdocs/blob/46d93edf560c092412620c1d7826ab3ca6d46106/.github/workflows/python.yml",
    "retrieved_at": "2025-09-29T01:42:25.465073Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file replicating the given workflow, including inputs, environment variables, and steps for releasing Axios.",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:26.286817Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions trigger the \"Release Axios\" workflow?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:26.790572Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel or have dependencies on other steps?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:27.337585Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `NPM_TOKEN` and `GITHUB_TOKEN` secrets used within the workflow?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:27.822014Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose of the \"Release Axios\" workflow?",
    "answer": "name: Release Axios\non:\n  workflow_dispatch:\n    inputs:\n      type:\n        type: choice\n        description: Choose release type\n        options:\n          - auto\n          - patch\n          - minor\n          - major\n        default: auto\n      beta:\n        type: boolean\n        description: Prerelease\n        default: false\n      npm:\n        type: boolean\n        description: NPM release\n        default: true\n      dry:\n        type: boolean\n        description: Dry release\n        default: false\njobs:\n  releaseIt:\n    runs-on: ubuntu-latest\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}\n    steps:\n      - uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n      - name: git config\n        run: |\n          git config user.name \"${GITHUB_ACTOR}\"\n          git config user.email \"${GITHUB_ACTOR}@users.noreply.github.com\"\n      - name: Setup node\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          cache: npm\n      - name: npm credentials\n        run: npm config set //registry.npmjs.org/:_authToken $NPM_TOKEN\n      - run: npm install\n      - name: release\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          TYPE_ARG: ${{ fromJSON('{\"auto\":\"\", \"patch\":\"--patch\", \"minor\":\"--minor\", \"major\":\"--major\"}')[github.event.inputs.type] }}\n          BETA_ARG: ${{ github.event.inputs.beta == 'true' && '--preRelease=beta' || '' }}\n          DRY_ARG: ${{ github.event.inputs.dry == 'true' && '--dry-run' || '' }}\n        run: npm run release -- --ci --verbose $TYPE_ARG $BETA_ARG $DRY_ARG\n      - name: npm-release\n        if: ${{ github.event.inputs.dry == 'false' && github.event.inputs.npm == 'true' }}\n        run: npm publish\n",
    "source": "sgtest/pinned-axios",
    "path": ".github/workflows/release.yml",
    "url": "https://github.com/sgtest/pinned-axios/blob/a48a63ad823fc20e5a6a705f05f09842ca49f48c/.github/workflows/release.yml",
    "retrieved_at": "2025-09-29T01:42:28.382363Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file replicating the build process defined in the given workflow.",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:29.700610Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch trigger this GitHub Actions workflow?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:30.356903Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow's \"build\" job execute concurrently, and are there any dependencies between them?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:31.273104Z",
    "question_style": "style_3"
  },
  {
    "question": "How are node modules and Next.js build artifacts cached to optimize build times?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:32.290211Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this \"Build\" workflow?",
    "answer": "---\nname: Build\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: ['20.17.0']\n        # See supported Node.js release schedule at https://nodejs.org/en/about/releases/\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Use Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n          cache-dependency-path: |\n            **/package-lock.json\n\n      # https://nextjs.org/docs/pages/building-your-application/deploying/ci-build-caching#github-actions\n      - uses: actions/cache@v4\n        with:\n          path: |\n            ~/.npm\n            ${{ github.workspace }}/.next/cache\n\n          key: ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-${{ hashFiles('**/*.js', '**/*.jsx', '**/*.ts', '**/*.tsx') }}\n          restore-keys: |\n            ${{ runner.os }}-nextjs-${{ hashFiles('**/package-lock.json') }}-\n\n      - run: npm ci\n      - run: npm run build\n",
    "source": "anaisbetts/postiz",
    "path": ".github/workflows/build.yaml",
    "url": "https://github.com/anaisbetts/postiz/blob/c33b9bffea8a2da90700412c8de2c2774340786f/.github/workflows/build.yaml",
    "retrieved_at": "2025-09-30T01:36:33.603829Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:35.689033Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:36.265951Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within the workflow run in parallel, and which ones depend on the successful completion of others?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:39.063500Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the build and test processes for different platforms?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:41.805861Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this Android build workflow?",
    "answer": "name: Build (Android)\n\non: [push, pull_request]\n\njobs:\n  android:\n    name: ${{ matrix.platform.name }}\n    runs-on: ubuntu-latest\n\n    strategy:\n      fail-fast: false\n      matrix:\n        platform:\n          - { name: Android.mk  }\n          - { name: CMake, cmake: 1, android_abi: \"arm64-v8a\", android_platform: 23, arch: \"aarch64\" }\n\n    steps:\n      - uses: actions/checkout@v2\n      - uses: nttld/setup-ndk@v1\n        id: setup_ndk\n        with:\n          ndk-version: r21e\n      - name: Build (Android.mk)\n        if: ${{ matrix.platform.name == 'Android.mk' }}\n        run: |\n          ./build-scripts/androidbuildlibs.sh\n      - name: Setup (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          sudo apt-get update\n          sudo apt-get install ninja-build pkg-config\n      - name: Configure (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -B build \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DSDL_STATIC_PIC=ON \\\n            -DCMAKE_INSTALL_PREFIX=prefix \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -GNinja\n      - name: Build (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --build build --config Release --parallel --verbose\n      - name: Install (CMake)\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake --install build --config Release\n          echo \"SDL2_DIR=$(pwd)/prefix\" >> $GITHUB_ENV\n          ( cd prefix; find ) | LC_ALL=C sort -u\n      - name: Verify CMake configuration files\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          cmake -S cmake/test -B cmake_config_build -G Ninja \\\n            -DCMAKE_TOOLCHAIN_FILE=${{ steps.setup_ndk.outputs.ndk-path }}/build/cmake/android.toolchain.cmake \\\n            -DANDROID_PLATFORM=${{ matrix.platform.android_platform }} \\\n            -DANDROID_ABI=${{ matrix.platform.android_abi }} \\\n            -DCMAKE_BUILD_TYPE=Release \\\n            -DCMAKE_PREFIX_PATH=${{ env.SDL2_DIR }}\n          cmake --build cmake_config_build --verbose\n      - name: Verify sdl2-config\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PATH=${{ env.SDL2_DIR }}/bin:$PATH\n          cmake/test/test_sdlconfig.sh\n      - name: Verify sdl2.pc\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export CC=\"${{ steps.setup_ndk.outputs.ndk-path }}/toolchains/llvm/prebuilt/linux-x86_64/bin/clang --target=${{ matrix.platform.arch }}-none-linux-androideabi${{ matrix.platform.android_platform }}\"\n          export PKG_CONFIG_PATH=${{ env.SDL2_DIR }}/lib/pkgconfig\n          cmake/test/test_pkgconfig.sh\n      - name: Verify Android.mk\n        if: ${{ matrix.platform.name == 'CMake' }}\n        run: |\n          export NDK_MODULE_PATH=${{ env.SDL2_DIR }}/share/ndk-modules\n          ndk-build -C ${{ github.workspace }}/cmake/test APP_PLATFORM=android-${{ matrix.platform.android_platform }} APP_ABI=${{ matrix.platform.android_abi }} NDK_OUT=$PWD NDK_LIBS_OUT=$PWD V=1\n",
    "source": "8212369/SDL",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/8212369/SDL/blob/2c421816ca4e645219bc70398df9bf4b862edbd0/.github/workflows/android.yml",
    "retrieved_at": "2025-09-30T01:36:43.000448Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:10.793612Z",
    "question_style": "style_1"
  },
  {
    "question": "What events (push, pull request, schedule) and file paths trigger this workflow?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:12.143708Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow run in parallel, and which ones have dependencies on others?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:12.904984Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables used to configure the west modules cache?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:13.887850Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this workflow, specifically what kind of application does it build and test?",
    "answer": "name: Build\n\non:\n  push:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  pull_request:\n    paths:\n      - \".github/workflows/build.yml\"\n      - \"app/**\"\n  schedule:\n    - cron: \"22 4 * * *\"\n\njobs:\n  build:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    container:\n      image: docker.io/zmkfirmware/zmk-build-arm:3.5\n    needs: compile-matrix\n    strategy:\n      matrix:\n        include: ${{ fromJSON(needs.compile-matrix.outputs.include-list) }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Cache west modules\n        uses: actions/cache@v4\n        env:\n          cache-name: cache-zephyr-modules\n        with:\n          path: |\n            modules/\n            tools/\n            zephyr/\n            bootloader/\n          key: ${{ runner.os }}-build-${{ env.cache-name }}-${{ hashFiles('app/west.yml') }}\n          restore-keys: |\n            ${{ runner.os }}-build-${{ env.cache-name }}-\n            ${{ runner.os }}-build-\n            ${{ runner.os }}-\n        timeout-minutes: 2\n        continue-on-error: true\n      - name: Initialize workspace (west init)\n        run: west init -l app\n      - name: Update modules (west update)\n        run: west update\n      - name: Export Zephyr CMake package (west zephyr-export)\n        run: west zephyr-export\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install @actions/artifact\n        run: npm install @actions/artifact\n      - name: Build\n        uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n\n            const execSync = require('child_process').execSync;\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Build`)\n\n                const output = execSync(`west build -s app -p -b ${{ matrix.board }} -- ${shieldArgs.shield ? '-DSHIELD=\"' + shieldArgs.shield + '\"' : ''} ${shieldArgs['cmake-args'] || ''}`);\n\n                console.log(output.toString());\n              } catch (e) {\n                console.error(`::error::Failed to build ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n      - name: Upload artifacts\n        uses: actions/github-script@v7\n        continue-on-error: ${{ github.event_name == 'pull_request' }}\n        id: boards-upload\n        with:\n          script: |\n            const fs = require('fs');\n            const {default: artifact} = require('@actions/artifact');\n\n            const buildShieldArgs = JSON.parse(`${{ matrix.shieldArgs }}`);\n\n            let error = false;\n\n            for (const shieldArgs of buildShieldArgs) {\n              try {\n                console.log(`::group::${{ matrix.board}} ${shieldArgs.shield} Upload`)\n\n                const fileExtensions = [\"hex\", \"uf2\"];\n\n                const files = fileExtensions\n                  .map(extension => \"build/zephyr/zmk.\" + extension)\n                  .filter(path => fs.existsSync(path));\n\n                const rootDirectory = 'build/zephyr';\n                const options = {\n                    continueOnError: true\n                }\n\n                const cmakeName = shieldArgs['cmake-args'] ? '-' + (shieldArgs.nickname || shieldArgs['cmake-args'].split(' ').join('')) : '';\n                const artifactName = `${{ matrix.board }}${shieldArgs.shield ? '-' + shieldArgs.shield : ''}${cmakeName}-zmk`;\n\n                await artifact.uploadArtifact(artifactName, files, rootDirectory, options);\n              } catch (e) {\n                console.error(`::error::Failed to upload ${{ matrix.board }} ${shieldArgs.shield} ${shieldArgs['cmake-args']}`);\n                console.error(e);\n                error = true;\n              } finally {\n                console.log('::endgroup::');\n              }\n            }\n\n            if (error) {\n              throw new Error('Failed to build one or more configurations');\n            }\n  compile-matrix:\n    if: ${{ always() }}\n    runs-on: ubuntu-latest\n    needs: [core-coverage, board-changes, nightly]\n    outputs:\n      include-list: ${{ steps.compile-list.outputs.result }}\n    steps:\n      - name: Join build lists\n        uses: actions/github-script@v7\n        id: compile-list\n        with:\n          script: |\n            const coreCoverage = `${{ needs.core-coverage.outputs.core-include }}` || \"[]\";\n            const boardChanges = `${{ needs.board-changes.outputs.boards-include }}` || \"[]\";\n            const nightly = `${{ needs.nightly.outputs.nightly-include }}` || \"[]\";\n\n            const combined = [\n              ...JSON.parse(coreCoverage),\n              ...JSON.parse(boardChanges),\n              ...JSON.parse(nightly)\n            ];\n            const combinedUnique = [...new Map(combined.map(el => [JSON.stringify(el), el])).values()];\n\n            const perBoard = {};\n\n            for (const configuration of combinedUnique) {\n              if (!perBoard[configuration.board])\n                perBoard[configuration.board] = [];\n\n              perBoard[configuration.board].push({\n                shield: configuration.shield,\n                'cmake-args': configuration['cmake-args'],\n                nickname: configuration.nickname\n              })\n            }\n\n            return Object.entries(perBoard).map(([board, shieldArgs]) => ({\n              board,\n              shieldArgs: JSON.stringify(shieldArgs),\n            }));\n  core-coverage:\n    if: ${{ needs.get-changed-files.outputs.core-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: get-changed-files\n    outputs:\n      core-include: ${{ steps.core-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: core-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const coreCoverage = yaml.load(fs.readFileSync('app/core-coverage.yml', 'utf8'));\n\n            let include = coreCoverage.board.flatMap(board =>\n              coreCoverage.shield.map(shield => ({ board, shield }))\n            );\n\n            return [...include, ...coreCoverage.include];\n  board-changes:\n    if: ${{ needs.get-changed-files.outputs.board-changes == 'true' }}\n    runs-on: ubuntu-latest\n    needs: [get-grouped-hardware, get-changed-files]\n    outputs:\n      boards-include: ${{ steps.boards-list.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - uses: actions/github-script@v7\n        id: boards-list\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const changedFiles = JSON.parse(`${{ needs.get-changed-files.outputs.changed-files }}`);\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n            const boardChanges = new Set(changedFiles.filter(f => f.startsWith('app/boards')).map(f => f.split('/').slice(0, 4).join('/')));\n\n            return (await Promise.all([...boardChanges].flatMap(async bc => {\n              const globber = await glob.create(bc + \"/*.zmk.yml\");\n              const files = await globber.glob();\n\n              const aggregated = files.flatMap((f) =>\n                yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n              );\n\n              const boardAndShield = (b, s) => {\n                if (s.siblings) {\n                  return s.siblings.map(shield => ({\n                    board: b.id,\n                    shield,\n                  }));\n                } else {\n                  return {\n                    board: b.id,\n                    shield: s.id\n                  };\n                }\n              }\n\n              return aggregated.flatMap(hm => {\n                switch (hm.type) {\n                  case \"board\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      if (hm.siblings) {\n                        return hm.siblings.map(board => ({\n                          board,\n                        }));\n                      } else {\n                        return {\n                          board: hm.id\n                        };\n                      }\n                    } else if (hm.exposes) {\n                      return hm.exposes.flatMap(i =>\n                        metadata.interconnects[i].shields.flatMap(s => boardAndShield(hm, s))\n                      );\n                    } else {\n                      console.error(\"Board without keys or interconnect\");\n                    }\n                    break;\n                  case \"shield\":\n                    if (hm.features && hm.features.includes(\"keys\")) {\n                      return hm.requires.flatMap(i =>\n                        metadata.interconnects[i].boards.flatMap(b => boardAndShield(b, hm))\n                      );\n                    } else {\n                      console.warn(\"Unhandled shield without keys\");\n                      return [];\n                    }\n                    break;\n                  case \"interconnect\":\n                    return [];\n                }\n              });\n            }))).flat();\n  nightly:\n    if: ${{ github.event_name == 'schedule' }}\n    runs-on: ubuntu-latest\n    needs: get-grouped-hardware\n    outputs:\n      nightly-include: ${{ steps.nightly-list.outputs.result }}\n    steps:\n      - name: Create nightly list\n        uses: actions/github-script@v7\n        id: nightly-list\n        with:\n          script: |\n            const metadata = JSON.parse(`${{ needs.get-grouped-hardware.outputs.organized-metadata }}`);\n\n            let includeOnboard = metadata.onboard.flatMap(b => {\n              if (b.siblings) {\n                return b.siblings.map(board => ({\n                  board,\n                }));\n              } else {\n                return {\n                  board: b.id,\n                };\n              }\n            });\n\n            let includeInterconnect = Object.values(metadata.interconnects).flatMap(i =>\n              i.boards.flatMap(b =>\n                i.shields.flatMap(s => {\n                  if (s.siblings) {\n                    return s.siblings.map(shield => ({\n                      board: b.id,\n                      shield,\n                    }));\n                  } else {\n                    return {\n                      board: b.id,\n                      shield: s.id,\n                    };\n                  }\n                })\n              )\n            );\n\n            return [...includeOnboard, ...includeInterconnect];\n  get-grouped-hardware:\n    runs-on: ubuntu-latest\n    outputs:\n      organized-metadata: ${{ steps.organize-metadata.outputs.result }}\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Use Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"14.x\"\n      - name: Install js-yaml\n        run: npm install js-yaml\n      - name: Aggregate Metadata\n        uses: actions/github-script@v7\n        id: aggregate-metadata\n        with:\n          script: |\n            const fs = require('fs');\n            const yaml = require('js-yaml');\n\n            const globber = await glob.create(\"app/boards/**/*.zmk.yml\");\n            const files = await globber.glob();\n\n            const aggregated = files.flatMap((f) =>\n              yaml.loadAll(fs.readFileSync(f, \"utf8\"))\n            );\n\n            return JSON.stringify(aggregated).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n\n      - name: Organize Metadata\n        uses: actions/github-script@v7\n        id: organize-metadata\n        with:\n          script: |\n            const hardware = JSON.parse(`${{ steps.aggregate-metadata.outputs.result }}`);\n\n            const grouped = hardware.reduce((agg, hm) => {\n              switch (hm.type) {\n                case \"board\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    agg.onboard.push(hm);\n                  } else if (hm.exposes) {\n                    hm.exposes.forEach((element) => {\n                      let ic = agg.interconnects[element] || {\n                        boards: [],\n                        shields: [],\n                      };\n                      ic.boards.push(hm);\n                      agg.interconnects[element] = ic;\n                    });\n                  } else {\n                    console.error(\"Board without keys or interconnect\");\n                  }\n                  break;\n                case \"shield\":\n                  if (hm.features && hm.features.includes(\"keys\")) {\n                    hm.requires.forEach((id) => {\n                      let ic = agg.interconnects[id] || { boards: [], shields: [] };\n                      ic.shields.push(hm);\n                      agg.interconnects[id] = ic;\n                    });\n                  }\n                  break;\n                case \"interconnect\":\n                  let ic = agg.interconnects[hm.id] || { boards: [], shields: [] };\n                  ic.interconnect = hm;\n                  agg.interconnects[hm.id] = ic;\n                  break;\n              }\n              return agg;\n            },\n            { onboard: [], interconnects: {} });\n\n            return JSON.stringify(grouped).replace(/\\\\/g,\"\\\\\\\\\").replace(/`/g,\"\\\\`\");\n          result-encoding: string\n  get-changed-files:\n    if: ${{ github.event_name != 'schedule' }}\n    runs-on: ubuntu-latest\n    outputs:\n      changed-files: ${{ steps.changed-files.outputs.all_changed_files }}\n      board-changes: ${{ steps.board-changes.outputs.result }}\n      core-changes: ${{ steps.core-changes.outputs.result }}\n    steps:\n      - uses: tj-actions/changed-files@v42\n        id: changed-files\n        with:\n          json: true\n          escape_json: false\n      - uses: actions/github-script@v7\n        id: board-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            return boardChanges.length ? 'true' : 'false';\n          result-encoding: string\n      - uses: actions/github-script@v7\n        id: core-changes\n        with:\n          script: |\n            const changedFiles = JSON.parse(`${{ steps.changed-files.outputs.all_changed_files }}`);\n            const boardChanges = changedFiles.filter(f => f.startsWith('app/boards'));\n            const appChanges = changedFiles.filter(f => f.startsWith('app'));\n            const ymlChanges = changedFiles.includes('.github/workflows/build.yml');\n            return boardChanges.length < appChanges.length || ymlChanges ? 'true' : 'false';\n          result-encoding: string\n",
    "source": "tilaktilak/zmk-config",
    "path": ".github/workflows/build.yml",
    "url": "https://github.com/tilaktilak/zmk-config/blob/0d3a4b7bbb199103d151ee1cadde613101859054/.github/workflows/build.yml",
    "retrieved_at": "2025-10-01T01:48:14.640269Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality defined in the provided YAML file.",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:15.270386Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch conditions trigger this GitHub Actions workflow?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:15.802393Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"build\" job run in parallel, and which have dependencies on others?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:16.392990Z",
    "question_style": "style_3"
  },
  {
    "question": "What checksum.txt file determines the Gradle cache key?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:16.981101Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose of this \"blueprints\" workflow?",
    "answer": "name: blueprints\n\non:\n  push:\n    branches:\n      - main\n      - views\n  pull_request:\n    branches:\n      - main\n      - views\n\njobs:\n  build:\n    runs-on: macos-latest # Needed for emulators\n    timeout-minutes: 45\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Copy CI gradle.properties\n        run: mkdir -p ~/.gradle ; cp .github/ci-gradle.properties ~/.gradle/gradle.properties\n\n      - name: Set up JDK 11\n        uses: actions/setup-java@v1\n        with:\n          java-version: 11\n\n      - uses: actions/cache@v2\n        with:\n          path: |\n            ~/.gradle/caches/modules-*\n            ~/.gradle/caches/jars-*\n            ~/.gradle/caches/build-cache-*\n          key: gradle-${{ hashFiles('checksum.txt') }}\n\n      - name: Build project and UnitTest\n        run: ./gradlew assembleDebug compileDebugUnitTestKotlin\n\n      - name: Spotless\n        # Spotless is not gradle configuration cache compliant. To allow the rest of the build\n        # comply, run spotless with a gradle init script and disable the cache.\n        run: ./gradlew spotlessCheck --init-script gradle/init.gradle.kts --no-configuration-cache\n\n      - name: Unit tests\n        run: ./gradlew testDebugUnitTest\n\n      # Needed to accept licenses\n      - name: Setup Android SDK\n        uses: android-actions/setup-android@v2\n\n      - name: Compile AndroidTests\n        run: ./gradlew compileDebugAndroidTestKotlin\n\n      - name: Run instrumentation tests\n        uses: reactivecircus/android-emulator-runner@v2\n        with:\n          api-level: 31\n          arch: x86_64\n          disable-animations: true\n          disk-size: 2000M\n          heap-size: 600M\n          script: ./gradlew connectedDebugAndroidTest\n\n      - name: Upload build reports\n        if: always()\n        uses: actions/upload-artifact@v2\n        with:\n          name: build-reports\n          path: app/build/reports/\n\n      - name: Upload all outputs\n        if: failure()\n        uses: actions/upload-artifact@v2\n        with:\n          name: outputs\n          path: app/build/outputs/\n",
    "source": "naderagain/ArchitectureCompose",
    "path": ".github/workflows/blueprints.yaml",
    "url": "https://github.com/naderagain/ArchitectureCompose/blob/7372f270b54d230007c911de39a2b48fd3fce217/.github/workflows/blueprints.yaml",
    "retrieved_at": "2025-10-01T01:48:17.519988Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML that replicates the given workflow's deployment to GitHub Pages.",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:32.004998Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branches trigger this continuous deployment workflow?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:32.448246Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within this workflow execute in parallel or have interdependencies?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:33.021530Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `GITHUB_TOKEN` secret used for deploying to GitHub Pages?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:33.585298Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when code is pushed to the develop branch?",
    "answer": "name: Continuous Deployment\non:\n  push:\n    branches:\n      - develop\n\njobs:\n  deployment:\n    name: Deploy to GitHub Page\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-node@v2\n        with:\n          node-version: \"16\"\n\n      - name: copy package.json to public\n        run: cp package.json ./public\n\n      - name: Export\n        run: yarn export\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./out\n          commit_message: ${{ github.event.head_commit.message }}\n",
    "source": "fractaldotbox/pedialab.io",
    "path": ".github/workflows/cd.yml",
    "url": "https://github.com/fractaldotbox/pedialab.io/blob/ad0293db761bf78c8644d5abc008361e3b304af2/.github/workflows/cd.yml",
    "retrieved_at": "2025-10-02T01:36:34.142596Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow for deploying a Jekyll site to GitHub Pages.",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:35.631775Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Deploy Jekyll site to Pages\" GitHub Actions workflow?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:36.131956Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which ones depend on the completion of others?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:37.290464Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `JEKYLL_ENV` environment variable used to configure the Jekyll build process?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:38.656883Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the purpose or main effect of this GitHub Actions workflow?",
    "answer": "# This workflow uses actions that are not certified by GitHub.\n# They are provided by a third-party and are governed by\n# separate terms of service, privacy policy, and support\n# documentation.\n\n# Sample workflow for building and deploying a Jekyll site to GitHub Pages\nname: Deploy Jekyll site to Pages\n\non:\n  # Runs on pushes targeting the default branch\n  push:\n    branches: [$default-branch]\n\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\n\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Ruby\n        uses: ruby/setup-ruby@8575951200e472d5f2d95c625da0c7bec8217c42 # v1.161.0\n        with:\n          ruby-version: '3.1' # Not needed with a .ruby-version file\n          bundler-cache: true # runs 'bundle install' and caches installed gems automatically\n          cache-version: 0 # Increment this number if you need to re-download cached gems\n      - name: Setup Pages\n        id: pages\n        uses: actions/configure-pages@v4\n      - name: Build with Jekyll\n        # Outputs to the './_site' directory by default\n        run: bundle exec jekyll build --baseurl \"${{ steps.pages.outputs.base_path }}\"\n        env:\n          JEKYLL_ENV: production\n      - name: Upload artifact\n        # Automatically uploads an artifact from the './_site' directory by default\n        uses: actions/upload-pages-artifact@v3\n\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4\n",
    "source": "ryanlundqvist/old_site",
    "path": ".github/workflows/jekyll.yml",
    "url": "https://github.com/ryanlundqvist/old_site/blob/30d60942d0714da7b45584b317a0fa2a1bb31ec5/.github/workflows/jekyll.yml",
    "retrieved_at": "2025-10-02T01:36:40.403306Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided Gofmt workflow.",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:08.595721Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of this Gofmt workflow?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:09.135691Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow execute concurrently, and what are their dependencies?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:09.516259Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching mechanisms?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:10.072851Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of the Gofmt workflow in this repository?",
    "answer": "name: Gofmt\non:\n  push:\n  pull_request:\n  schedule:\n    # Run every 12 hours, at the 15 minute mark. E.g.\n    # 2020-11-29 00:15:00 UTC, 2020-11-29 12:15:00 UTC, 2020-11-30 00:15:00 UTC\n    - cron:  '15 */12 * * *'\njobs:\n\n  build:\n    name: Gofmt check\n    runs-on: ubuntu-latest\n    steps:\n\n    - name: Check out code\n      uses: actions/checkout@v2\n\n    - name: Check gofmt\n      uses: Jerome1337/gofmt-action@v1.0.4\n      with:\n        gofmt-path: './'\n        gofmt-flags: -l -s\n",
    "source": "UPB-SysSec/zcrypto",
    "path": ".github/workflows/gofmt.yml",
    "url": "https://github.com/UPB-SysSec/zcrypto/blob/61e202e461fa216dad41913a36a17e45e1004762/.github/workflows/gofmt.yml",
    "retrieved_at": "2025-10-03T01:36:10.648185Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:11.391950Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the \"Stable build\" GitHub Actions workflow?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:11.971886Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:12.564558Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets DOCKERHUB_USERNAME and DOCKERHUB_TOKEN used in the docker-build-push workflow?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:13.384871Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or purpose of this \"Stable build\" workflow?",
    "answer": "name: Stable build\n\non:\n  pull_request:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n      - .github/workflows/build_stable.yml\n\n  push:\n    branches:\n      - main\n    paths:\n      - images/nginx/**\n      - images/socketio/**\n      - images/worker/**\n      - overrides/**\n      - tests/**\n      - compose.yaml\n      - docker-bake.hcl\n      - example.env\n\n  # Triggered from frappe/frappe and frappe/erpnext on releases\n  repository_dispatch:\n\n  workflow_dispatch:\n\njobs:\n  v12:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"12\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v13:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"13\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  v14:\n    uses: ./.github/workflows/docker-build-push.yml\n    with:\n      repo: erpnext\n      version: \"14\"\n      push: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    secrets:\n      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}\n      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}\n\n  update_versions:\n    name: Update example.env and pwd.yml\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.10\"\n\n      - name: Get latest versions\n        run: python3 ./.github/scripts/get_latest_tags.py --repo erpnext --version 14\n\n      - name: Update\n        run: |\n          python3 ./.github/scripts/update_example_env.py\n          python3 ./.github/scripts/update_pwd.py\n\n      - name: Push\n        run: |\n          git config --global user.name github-actions\n          git config --global user.email github-actions@github.com\n          git add example.env pwd.yml\n          if [ -z \"$(git status --porcelain)\" ]; then\n            echo \"versions did not change, exiting.\"\n            exit 0\n          else\n            echo \"version changed, pushing changes...\"\n            git commit -m \"chore: Update example.env\"\n            git pull --rebase\n            git push origin main\n          fi\n\n  release_helm:\n    name: Release Helm\n    runs-on: ubuntu-latest\n    if: ${{ github.repository == 'frappe/frappe_docker' && github.event_name != 'pull_request' }}\n    needs: v14\n\n    steps:\n      - name: Setup deploy key\n        uses: webfactory/ssh-agent@v0.5.4\n        with:\n          ssh-private-key: ${{ secrets.HELM_DEPLOY_KEY }}\n\n      - name: Setup Git Credentials\n        run: |\n          git config --global user.email \"41898282+github-actions[bot]@users.noreply.github.com\"\n          git config --global user.name \"github-actions[bot]\"\n\n      - name: Release\n        run: |\n          git clone git@github.com:frappe/helm.git && cd helm\n          pip install -r release_wizard/requirements.txt\n          ./release_wizard/wizard 14 patch --remote origin --ci\n",
    "source": "excel-azmin/Frappe-Docker",
    "path": ".github/workflows/build_stable.yml",
    "url": "https://github.com/excel-azmin/Frappe-Docker/blob/a537ad8ac0e5bb8e3f32e816866b3cbcd2339407/.github/workflows/build_stable.yml",
    "retrieved_at": "2025-10-03T01:36:13.904631Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow mirroring the provided YAML, including inputs, concurrency, jobs (build, jest, behat, complete), and steps within each job.",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:14.845857Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:15.512523Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs and steps within those jobs run in parallel, and which depend on the successful completion of others?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:16.234538Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached files (SSL certificates, node modules, etc.) used across different jobs?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:17.004727Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow for coverage?",
    "answer": "name: Coverage\n\non:\n  workflow_dispatch:\n    inputs:\n      behat_tags:\n        description: 'Behat tags to execute'\n      moodle_branch:\n        description: 'Moodle branch'\n        required: true\n        default: 'main'\n      moodle_repository:\n        description: 'Moodle repository'\n        required: true\n        default: 'https://github.com/moodle/moodle.git'\n\nconcurrency:\n    group: coverage-${{ github.ref }}\n    cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}\n\njobs:\n\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      tags: ${{ steps.set-tags.outputs.tags }}\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - name: Install npm dependencies\n        working-directory: app\n        run: npm ci --no-audit\n\n      - name: Build app\n        working-directory: app\n        run: npm run build:test\n        env:\n          MOODLE_APP_COVERAGE: true\n\n      - name: Generate SSL certificates\n        working-directory: app\n        run: |\n          mkdir ./ssl\n          openssl req -x509 -nodes \\\n            -days 365 \\\n            -newkey rsa:2048 \\\n            -keyout ./ssl/certificate.key \\\n            -out ./ssl/certificate.crt \\\n            -subj=\"/O=Moodle\"\n\n      - name: Build Behat plugin\n        working-directory: app\n        run: ./scripts/build-behat-plugin.js ../plugin\n\n      - name: Prepare Behat tags\n        id: set-tags\n        working-directory: app\n        run: |\n          if [ -z $BEHAT_TAGS ]; then\n            tags_json=`.github/scripts/print_behat_tags_json.sh`\n            echo \"tags=$tags_json\" >> $GITHUB_OUTPUT;\n          else\n            echo \"tags=[\\\"$BEHAT_TAGS\\\"]\" >> $GITHUB_OUTPUT;\n          fi\n        env:\n          BEHAT_TAGS: ${{ github.event.inputs.behat_tags }}\n\n      # We need to upload an artifact so that the download-artifact action\n      # in the \"complete\" job does not fail if no other artifacts were uploaded.\n      - name: Create build logs\n        run: touch logs.txt\n\n      - name: Upload build logs\n        uses: actions/upload-artifact@v4\n        with:\n          name: build\n          path: logs.txt\n\n      - uses: actions/cache/save@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n  jest:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Run Jest tests\n        working-directory: app\n        run: |\n          NODE_ENV=testing npx gulp\n          npx jest --coverage --coverageReporters=json\n          mkdir ../coverage-jsons\n          mv coverage/coverage-final.json ../coverage-jsons/jest.json\n\n      - uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-jest\n          path: coverage-jsons\n\n  behat:\n    runs-on: ubuntu-latest\n    needs: build\n    continue-on-error: true\n\n    strategy:\n      matrix:\n        tags: ${{ fromJSON(needs.build.outputs.tags) }}\n\n    services:\n\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_USER: 'postgres'\n          POSTGRES_HOST_AUTH_METHOD: 'trust'\n        ports:\n          - 5432:5432\n        options: --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 3\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: shivammathur/setup-php@v2\n        with:\n          php-version: 8.1\n          ini-values: max_input_vars=5000\n          coverage: none\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - name: Launch Docker images\n        working-directory: app\n        run: |\n          docker run -d --rm \\\n              -p 8001:443 \\\n              --name moodleapp \\\n              -v ./www:/usr/share/nginx/html \\\n              -v ./nginx.conf:/etc/nginx/conf.d/default.conf \\\n              -v ./ssl/certificate.crt:/etc/ssl/certificate.crt \\\n              -v ./ssl/certificate.key:/etc/ssl/certificate.key \\\n              nginx:alpine\n          docker run -d --rm -p 8002:80 --name bigbluebutton moodlehq/bigbluebutton_mock:latest\n\n      - name: Initialise moodle-plugin-ci\n        run: |\n          composer create-project -n --no-dev --prefer-dist moodlehq/moodle-plugin-ci ci ^4.4\n          echo $(cd ci/bin; pwd) >> $GITHUB_PATH\n          echo $(cd ci/vendor/bin; pwd) >> $GITHUB_PATH\n          sudo locale-gen en_AU.UTF-8\n\n          # Install nvm v0.39.7 as a temporary workaround for issue:\n          # https://github.com/moodlehq/moodle-plugin-ci/issues/309\n          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\n\n      - name: Install Behat Snapshots plugin\n        run: moodle-plugin-ci add-plugin moodlemobile/moodle-local_behatsnapshots\n\n      - name: Install moodle-plugin-ci\n        run: moodle-plugin-ci install --plugin ./plugin --db-host=127.0.0.1\n        env:\n          DB: pgsql\n          MOODLE_BRANCH: ${{ github.event.inputs.moodle_branch || 'main' }}\n          MOODLE_REPO: ${{ github.event.inputs.moodle_repository || 'https://github.com/moodle/moodle.git' }}\n          MOODLE_BEHAT_IONIC_WWWROOT: https://localhost:8001\n          MOODLE_BEHAT_DEFAULT_BROWSER: chrome\n          MOODLE_BEHAT_CHROME_CAPABILITIES: \"['extra_capabilities' => ['chromeOptions' => ['args' => ['--ignore-certificate-errors', '--allow-running-insecure-content']]]]\"\n\n      - name: Update config\n        run: |\n          moodle-plugin-ci add-config \"\\$CFG->behat_extraallowedsettings = ['forced_plugin_settings'];\"\n          moodle-plugin-ci add-config \"\\$CFG->forced_plugin_settings = ['local_moodleappbehat' => ['coverage_path' => '$GITHUB_WORKSPACE/moodle/coverage/']];\"\n          moodle-plugin-ci add-config 'define(\"TEST_MOD_BIGBLUEBUTTONBN_MOCK_SERVER\", \"http://localhost:8002/hash\" . sha1($CFG->wwwroot));'\n\n      - name: Run Behat tests\n        run: moodle-plugin-ci behat --auto-rerun 3 --profile chrome --tags=\"@app&&~@local&&$BEHAT_TAGS\"\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n          MOODLE_BEHAT_SELENIUM_IMAGE: selenium/standalone-chrome:120.0\n\n      - name: Merge Coverage jsons\n        working-directory: app\n        run: |\n          mkdir ../coverage-jsons\n          mkdir -p ../moodle/coverage/\n          echo \"{}\" > ../moodle/coverage/base.json\n          npx nyc merge ../moodle/coverage/ ../coverage-jsons/$BEHAT_TAGS.json\n        env:\n          BEHAT_TAGS: ${{ matrix.tags }}\n\n      - name: Upload Coverage JSONs\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-jsons-${{ matrix.tags }}\n          path: coverage-jsons\n\n      - name: Upload Snapshot failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: snapshot_failures-${{ matrix.tags }}\n          path: moodle/local/moodleappbehat/tests/behat/snapshots/failures/*\n\n      - name: Upload Behat failures\n        uses: actions/upload-artifact@v4\n        if: ${{ failure() }}\n        with:\n          name: behat_failures-${{ matrix.tags }}\n          path: moodledata/behat_dump/*\n\n  complete:\n    runs-on: ubuntu-latest\n    needs: [behat, jest]\n\n    steps:\n\n      - uses: actions/checkout@v4\n        with:\n          path: app\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version-file: 'app/.nvmrc'\n\n      - uses: actions/cache/restore@v4\n        with:\n          key: build-${{ github.sha }}\n          path: |\n            app/ssl/**/*\n            app/node_modules/**/*\n            app/www/**/*\n            plugin/**/*\n\n      - uses: actions/download-artifact@v4\n        with:\n          path: artifacts\n\n      - name: Prepare coverage jsons\n        run: |\n          mkdir ./app/coverage-jsons\n          mv ./artifacts/coverage-jsons-*/* ./app/coverage-jsons\n          rm ./artifacts/coverage-jsons* -r\n\n      - name: Check failure artifacts\n        run: |\n          rm ./artifacts/build -rf\n          if [ -n \"$(ls -A ./artifacts)\" ]; then\n            echo \"There were some failures in the previous jobs\"\n            exit 1\n          fi\n\n      - name: Generate Coverage report\n        working-directory: app\n        run: |\n          npx nyc merge ./coverage-jsons/ .nyc_output/out.json\n          npx nyc report --reporter=html-spa\n          cp .nyc_output/out.json coverage/coverage-final.json\n\n      - name: Upload Coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-html\n          path: app/coverage/*\n",
    "source": "rejozacharia/athenamobile",
    "path": ".github/workflows/coverage.yml",
    "url": "https://github.com/rejozacharia/athenamobile/blob/c9ad95cb441f0a36cedae71bc8fca79aa4a4face/.github/workflows/coverage.yml",
    "retrieved_at": "2025-10-04T01:26:17.619198Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:18.338412Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this CI workflow?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:18.801847Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs run in parallel, and which jobs depend on the completion of other jobs?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:19.303394Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any caching mechanisms for dependencies or build artifacts to optimize build times?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:19.895770Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this CI workflow for Flutter projects?",
    "answer": "name: CI\non:\n  pull_request:\n    branches:\n      - master\n\njobs:\n  flutter_test:\n    name: Run flutter test and analyze\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter analyze\n      - run: flutter test\n\n  build_ios:\n    name: Build Flutter (iOS)\n    needs: [flutter_test]\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build ios --release --no-codesign\n\n  build_appbundle:\n    name: Build Flutter (Android)\n    needs: [flutter_test]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: actions/setup-java@v1\n        with:\n          java-version: \"12.x\"\n      - uses: subosito/flutter-action@v1\n        with:\n          channel: \"stable\"\n      - run: flutter pub get\n      - run: flutter clean\n      - run: flutter build appbundle\n",
    "source": "RobertBrunhage/flutter-github-action",
    "path": ".github/workflows/ci.yml",
    "url": "https://github.com/RobertBrunhage/flutter-github-action/blob/914ce62c03493dc621b8a679350add24e2327252/.github/workflows/ci.yml",
    "retrieved_at": "2025-10-04T01:26:20.454697Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that mirrors the functionality of the provided YAML file, including scheduled runs, manual triggering, building a Go-based CLI, and uploading an artifact.",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:45.214998Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of the \"AVS Rewards Claim\" workflow?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:45.686155Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow execute concurrently, and which have dependencies on others?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:46.177049Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the `RPC_URL` secret used to authenticate the reward claim process?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:46.690464Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this AVS Rewards Claim workflow?",
    "answer": "name: AVS Rewards Claim\n\non:\n  # Run weekly on Monday at 00:00 UTC\n  schedule:\n    - cron: '0 0 * * 1'\n  \n  # Allow manual trigger\n  workflow_dispatch:\n\njobs:\n  claim-rewards:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      \n      - name: Set up Go\n        uses: actions/setup-go@v5\n        with:\n          go-version: '^1.21'\n      \n      - name: Build AVS CLI\n        run: make build\n      \n      - name: Claim rewards\n        env:\n          RPC_URL: ${{ secrets.RPC_URL }}\n        run: |\n          ./avs-cli claim-rewards --all --recipient 0x0c83EAe1FE72c390A02E426572854931EefF93BA\n          # Verify the file was created\n          ls -la avs-operator-bulk-reward-claim-0.json\n      \n      - name: Upload rewards claim file\n        uses: actions/upload-artifact@v4\n        with:\n          name: avs-rewards-claim\n          path: avs-operator-bulk-reward-claim-0.json\n          retention-days: 7\n",
    "source": "etherfi-protocol/etherfi-avs-operator-CLI",
    "path": ".github/workflows/avs_rewards_claim.yml",
    "url": "https://github.com/etherfi-protocol/etherfi-avs-operator-CLI/blob/6889c5e988e791669cfad92adb09fc33860e7c5c/.github/workflows/avs_rewards_claim.yml",
    "retrieved_at": "2025-10-05T01:45:47.100251Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file equivalent to the provided YAML configuration.",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:47.705378Z",
    "question_style": "style_1"
  },
  {
    "question": "What event and branch trigger this workflow to deploy to Firebase Hosting?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:48.243771Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the build_and_deploy job execute in parallel or have dependencies on each other?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:48.788404Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP` and `GITHUB_TOKEN` secrets used for authentication and deployment?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:49.355531Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this workflow?",
    "answer": "# This file was auto-generated by the Firebase CLI\n# https://github.com/firebase/firebase-tools\n\nname: Deploy to Firebase Hosting on merge\n'on':\n  push:\n    branches:\n      - master\njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm ci && npm run build\n      - uses: FirebaseExtended/action-hosting-deploy@v0\n        with:\n          repoToken: '${{ secrets.GITHUB_TOKEN }}'\n          firebaseServiceAccount: '${{ secrets.FIREBASE_SERVICE_ACCOUNT_HURRICANE_AGATHA_2022_MAP }}'\n          channelId: live\n          projectId: hurricane-agatha-2022-map\n",
    "source": "Ihovanna/hurricane-agatha-map",
    "path": ".github/workflows/firebase-hosting-merge.yml",
    "url": "https://github.com/Ihovanna/hurricane-agatha-map/blob/61d4f80eaf76a04bcf454625f2dfc75b0fd7db2e/.github/workflows/firebase-hosting-merge.yml",
    "retrieved_at": "2025-10-05T01:45:49.840303Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:31.013603Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers the Cypress Tests workflow?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:31.438046Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Cypress Tests' workflow run concurrently or have dependencies on one another?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:32.087772Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the Cypress run step utilize any environment variables or secrets for configuration?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:32.520191Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this Cypress Tests workflow?",
    "answer": "name: Cypress Tests\n\non: push\n\njobs:\n  cypress-run:\n    runs-on: ubuntu-22.04\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # Install npm dependencies, cache them correctly\n      # and run all Cypress tests\n      - name: Cypress run\n        uses: cypress-io/github-action@v6\n        with:\n          start: npx cypress run\n",
    "source": "dquynh1610-test/Testcypress",
    "path": ".github/workflows/cybress.yml",
    "url": "https://github.com/dquynh1610-test/Testcypress/blob/d072a363ea30d530ebf776d4e0631709e3640261/.github/workflows/cybress.yml",
    "retrieved_at": "2025-10-06T01:39:33.060286Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file.",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:33.668039Z",
    "question_style": "style_1"
  },
  {
    "question": "What event triggers this GitHub Actions workflow to run?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:34.096441Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or have dependencies on one another?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:34.616701Z",
    "question_style": "style_3"
  },
  {
    "question": "Does the 'ruby/setup-ruby' action use caching, and if so, how is the cache configured?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:35.112248Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main goal or function of this pull request workflow?",
    "answer": "on: [pull_request]\n\njobs:\n  wilco:\n    runs-on: ubuntu-latest\n    name: Pr checks\n\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n\n      - uses: ruby/setup-ruby@v1\n        with:\n          working-directory: backend\n          bundler-cache: true\n\n      - name: Wilco checks\n        id: Wilco\n        uses: trywilco/actions@main\n        with:\n          owner: ${{ github.repository_owner }}\n  Lint:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: frontend\n    steps:\n      - name: Check out project\n        uses: actions/checkout@v2\n      - name: Lint code\n        uses: actions/setup-node@v1\n        with:\n          node-version: '16'\n          cache: 'yarn'\n      - run: yarn install\n      - run: yarn lint\n",
    "source": "Wilcolab/Anythink-Market-keomW",
    "path": ".github/workflows/wilco-actions.yml",
    "url": "https://github.com/Wilcolab/Anythink-Market-keomW/blob/0817a1cb6aa8cfaed2620e785c445bd5c1802544/.github/workflows/wilco-actions.yml",
    "retrieved_at": "2025-10-06T01:39:35.717347Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow mirroring the provided YAML, including triggering, OS matrix, environment variables, container, checkout, and build steps.",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:23.361933Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull requests or pushes to the master branch trigger this workflow?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:23.891225Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'Cross CI workflow' run in parallel or sequentially based on dependencies?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:24.544833Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `ROS_DISTRO`, `AUTOWARE_CROSS_TARGET_PLATFORM`, `AUTOWARE_TARGET_ARCH`, `AUTOWARE_TOOLCHAIN_FILE_PATH`, and `AUTOWARE_SYSROOT` environment variables used within the build script?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:25.271922Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this cross-compilation CI workflow?",
    "answer": "name: Cross CI workflow\n\non:\n  pull_request:\n  push:\n    branches:\n      - master\n\njobs:\n\n  build-cross:\n\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest]\n      fail-fast: false\n\n    env:\n      ROS_DISTRO: melodic\n      AUTOWARE_CROSS_TARGET_PLATFORM: generic-aarch64\n      AUTOWARE_TARGET_ARCH: aarch64\n      AUTOWARE_TOOLCHAIN_FILE_PATH: ${{ github.workspace }}/cross_toolchain.cmake\n      AUTOWARE_SYSROOT: /sysroot/generic-aarch64\n\n    container:\n      image: autoware/build:generic-aarch64-melodic-bleedingedge\n\n    steps:\n\n    - name: Checkout repo\n      uses: actions/checkout@v2\n\n    - name: Build repo\n      run: |\n        mkdir -p src_tmp/ && mv `find -maxdepth 1 -not -name . -not -name src_tmp` src_tmp/ && mv src_tmp/ src/\n        sudo apt-get update -qq && sudo apt-get install -y python3-vcstool gcc git wget\n        wget https://raw.githubusercontent.com/Autoware-AI/docker/master/crossbuild/cross_toolchain.cmake\n        bash -c 'source $AUTOWARE_SYSROOT/opt/ros/${ROS_DISTRO}/setup.bash; \\\n        colcon build --merge-install \\\n          --cmake-args \\\n          -DCMAKE_TOOLCHAIN_FILE=$AUTOWARE_TOOLCHAIN_FILE_PATH \\\n          -DCMAKE_SYSTEM_PROCESSOR=$AUTOWARE_TARGET_ARCH \\\n          -DCMAKE_PREFIX_PATH=\"$(pwd)/install;${AUTOWARE_SYSROOT}/opt/ros/${ROS_DISTRO}\" \\\n          -DCMAKE_FIND_ROOT_PATH=$(pwd)/install/;'\n",
    "source": "autowarefoundation/qpoases_vendor",
    "path": ".github/workflows/cross-ci.yaml",
    "url": "https://github.com/autowarefoundation/qpoases_vendor/blob/ca4e3e1e1c796f4ce4e17e46ba4372607d87f87b/.github/workflows/cross-ci.yaml",
    "retrieved_at": "2025-10-07T01:37:25.780985Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML that replicates the functionality of the provided YAML file for labeling.",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:26.634985Z",
    "question_style": "style_1"
  },
  {
    "question": "What events and branch(es) trigger the \"Labeler\" workflow?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:27.117208Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, or depend on the completion of other jobs or steps?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:27.688851Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, or caching/artifacts for the labeler action?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:28.267303Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of the \"Labeler\" workflow?",
    "answer": "name: Labeler\n\non:\n  push:\n    branches:\n      - main\n      - master\n\njobs:\n  labeler:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out the repository\n        uses: actions/checkout@v2.4.0\n\n      - name: Run Labeler\n        uses: crazy-max/ghaction-github-labeler@v3.1.1\n        with:\n          skip-delete: true\n",
    "source": "AnthonyTechnologies/python-precog",
    "path": ".github/workflows/labeler.yml",
    "url": "https://github.com/AnthonyTechnologies/python-precog/blob/bb98bfab65477d78f9eea7113b9ebdb598545a32/.github/workflows/labeler.yml",
    "retrieved_at": "2025-10-07T01:37:28.778369Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality, inputs, environment variables, outputs, and steps outlined in the provided YAML file.",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:38.277809Z",
    "question_style": "style_1"
  },
  {
    "question": "What event or action triggers the execution of this GitHub Actions workflow?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:38.967270Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which depend on the completion of others?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:39.819871Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables overridden and accessed at the workflow, job, and step levels?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:40.589609Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this GitHub Actions workflow?",
    "answer": "# Workflow to demonstrate variables and context objects\n\nname: Variables and Context\n\n# Controls when the action will run. Workflow runs when manually triggered using the UI or API\non:\n  workflow_dispatch:\n    # Inputs the workflow accepts.\n    inputs:\n      name:\n        # Friendly description to be shown in the UI instead of 'name'\n        description: 'Person to greet'\n        # Default value if no value is explicitly provided\n        default: 'World'\n        # Input has to be provided for the workflow to run\n        required: true\n\nenv:\n  VAR1: myworkflowvar1\n  VAR2: myworkflowvar2\n  VAR3: myworkflowvar3\n\n# A workflow run is made up of one or more jobs that can run sequentially or in parallel\njobs:\n\n  job1:\n    runs-on: ubuntu-latest \n\n    # Steps represent a sequence of tasks that will be executed as part of the job\n    steps:\n      - name: Dump GitHub context\n        env:\n          GITHUB_CONTEXT: ${{ toJSON(github) }}\n        run: echo \"$GITHUB_CONTEXT\"\n      \n  #step/job output variables\n  job2:\n    runs-on: ubuntu-latest\n    \n    outputs:\n      output1: ${{ steps.step1.outputs.step1value }}\n      output2: ${{ steps.step2.outputs.step2value }}\n    \n    steps:\n      - name: Step 1\n        id: step1\n        # run: echo \"::set-output name=step1value::hello\"\n        run: echo \"step1value=hello\" >> $GITHUB_OUTPUT\n\n      - name: Step 2\n        id: step2\n        # run: echo \"::set-output name=step2value::world\"\n        run: echo \"step2value=world\" >> $GITHUB_OUTPUT\n  \n  job3:\n    runs-on: ubuntu-latest\n    needs: job2\n    steps:\n      - run: echo ${{needs.job2.outputs.output1}} ${{needs.job2.outputs.output2}}\n\n  # access/set env and secrets \n  job4:\n    runs-on: ubuntu-latest\n    env:\n      VAR2: myjobvar2\n      VAR3: myjobvar3\n      SECRET: ${{ secrets.mySecret }}\n    steps:\n\n      - run: |\n          echo $VAR1\n          echo ${{env.VAR1}}\n\n          echo \"\"\n\n          echo $VAR2\n\n          echo $VAR3\n\n          echo $SECRET\n        env: \n          VAR3: mystepvar3\n",
    "source": "nampereira/desofs-tp04",
    "path": ".github/workflows/2-context.yaml",
    "url": "https://github.com/nampereira/desofs-tp04/blob/a901b8f0160c924cc14bc6013b432e8bed448453/.github/workflows/2-context.yaml",
    "retrieved_at": "2025-10-08T01:37:41.175675Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that, on push to tags matching \"v*.*.*\", builds and pushes a Docker image to Docker Hub with multiple platforms.",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:42.220356Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` events, specifically related to tags, trigger this workflow?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:42.777243Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the Docker Hub push workflow run concurrently or sequentially based on dependencies?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:43.457895Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the DOCKERHUB_TOKEN secret used to authenticate with Docker Hub?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:43.965765Z",
    "question_style": "style_4"
  },
  {
    "question": "What does this workflow accomplish when a tagged commit is pushed?",
    "answer": "name: Push to Docker Hub\n\non:\n  push:\n    tags:\n      - \"v*.*.*\"\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v3\n      -\n        name: Git fetch everything\n        run: git fetch --prune --unshallow\n      -\n        name: Get Github tag\n        id: meta\n        run: |\n          echo \"::set-output name=tag::$(git describe --always --tags --match='v*')\"\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v2\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2\n        with:\n          registry: docker.io\n          username: tharsishq\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v3\n        with:\n          context: .\n          push: true\n          platforms: linux/amd64, linux/386, linux/arm64\n          tags: tharsishq/evmos:latest, tharsishq/evmos:${{ steps.meta.outputs.tag }}\n",
    "source": "T0psecurity/cascadia_evm_chain",
    "path": ".github/workflows/docker-push.yml",
    "url": "https://github.com/T0psecurity/cascadia_evm_chain/blob/04db9674bc67808dab4df8f4f304c6cb12988cc6/.github/workflows/docker-push.yml",
    "retrieved_at": "2025-10-08T01:37:44.617461Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the build CI process defined in the provided YAML file.",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:16.883310Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` and `pull_request` events on the `master` branch trigger this workflow?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:17.411137Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"build\" job execute concurrently or have dependencies on other steps?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:18.044548Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow use any environment variables, secrets, or caching for build processes or artifacts?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:18.598152Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary goal or outcome of this CI build workflow?",
    "answer": "name: Build CI\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: set up JDK 1.8\n      uses: actions/setup-java@v1\n      with:\n        java-version: 1.8\n    - name: build samples\n      run: |\n        pushd samples\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build OboeTester\n      run: |\n        pushd apps/OboeTester\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n    - name: build fxlab\n      run: |\n        pushd apps/fxlab\n        chmod +x gradlew\n        ./gradlew -q clean bundleDebug\n        popd\n \n",
    "source": "riscv-android-src/platform-external-oboe",
    "path": ".github/workflows/android.yml",
    "url": "https://github.com/riscv-android-src/platform-external-oboe/blob/41903ecc57b52e977c1089cc4c171164c43e00c9/.github/workflows/android.yml",
    "retrieved_at": "2025-10-09T01:38:19.120908Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that replicates the given YAML, generating and updating documentation on push events, excluding the master branch.",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:19.869748Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow, excluding pushes to the master branch?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:20.454351Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow run in parallel or depend on the successful completion of other jobs or steps?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:20.988268Z",
    "question_style": "style_3"
  },
  {
    "question": "How is the GITHUB_TOKEN secret used for authenticating git pushes?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:21.570704Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this workflow?",
    "answer": "name: Generate docs\n\non:\n  push:\n    branches-ignore:\n      - master\n\njobs:\n  build-sources:\n    name: Generate docs\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - os: ubuntu-20.04\n            url: https://github.com/neovim/neovim/releases/download/nightly/nvim-linux64.tar.gz\n    steps:\n      - uses: actions/checkout@v2\n      - run: date +%F > todays-date\n      - name: Restore cache for today's nightly.\n        uses: actions/cache@v2\n        with:\n          path: _neovim\n          key: ${{ runner.os }}-${{ matrix.url }}-${{ hashFiles('todays-date') }}\n\n      - name: Prepare\n        run: |\n          test -d _neovim || {\n            mkdir -p _neovim\n            curl -sL ${{ matrix.url }} | tar xzf - --strip-components=1 -C \"${PWD}/_neovim\"\n          }\n          mkdir -p ~/.local/share/nvim/site/pack/vendor/start\n          git clone --depth 1 https://github.com/nvim-lua/plenary.nvim ~/.local/share/nvim/site/pack/vendor/start/plenary.nvim\n          git clone --depth 1 https://github.com/tjdevries/tree-sitter-lua ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          ln -s $(pwd) ~/.local/share/nvim/site/pack/vendor/start\n\n      - name: Build parser\n        run: |\n          # We have to build the parser every single time to keep up with parser changes\n          cd ~/.local/share/nvim/site/pack/vendor/start/tree-sitter-lua\n          make dist\n          cd -\n\n      - name: Generating docs\n        run: |\n          export PATH=\"${PWD}/_neovim/bin:${PATH}\"\n          export VIM=\"${PWD}/_neovim/share/nvim/runtime\"\n          nvim --version\n          make docgen\n\n      # inspired by nvim-lspconfigs\n      - name: Update documentation\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          COMMIT_MSG: |\n            [docgen] Update doc/telescope.txt\n            skip-checks: true\n        run: |\n          git config user.email \"actions@github\"\n          git config user.name \"Github Actions\"\n          git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${GITHUB_REPOSITORY}.git\n          git add doc/\n          # Only commit and push if we have changes\n          git diff --quiet && git diff --staged --quiet || (git commit -m \"${COMMIT_MSG}\"; git push origin HEAD:${GITHUB_REF})\n",
    "source": "LuizCalaa/telescope.nvim",
    "path": ".github/workflows/docgen.yml",
    "url": "https://github.com/LuizCalaa/telescope.nvim/blob/f48aa95a73a5ba09ac5d79b2e0a7aa38a33ae076/.github/workflows/docgen.yml",
    "retrieved_at": "2025-10-09T01:38:22.131752Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML that replicates the functionality of the provided workflow YAML file.",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:54.990807Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this GitHub Actions workflow to run?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:55.659310Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within this workflow are configured to run in parallel, and which ones have dependencies on the successful completion of other jobs?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:56.493452Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the `CI_SLACK_*` secrets used to send notifications to different Slack channels?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:57.216890Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or result of this GitHub Actions workflow?",
    "answer": "name: Self-hosted runner (nightly)\n\n# Note that each job's dependencies go into a corresponding docker file.\n#\n# For example for `run_all_tests_torch_cuda_extensions_gpu` the docker image is\n# `huggingface/transformers-pytorch-deepspeed-latest-gpu`, which can be found at\n# `docker/transformers-pytorch-deepspeed-latest-gpu/Dockerfile`\n\non:\n  repository_dispatch:\n# Disable temporarily until the test suite can be run under 12 hours.\n#  schedule:\n#    - cron: \"0 16 * * *\"\n\nenv:\n  HF_HOME: /mnt/cache\n  TRANSFORMERS_IS_CI: yes\n  OMP_NUM_THREADS: 8\n  MKL_NUM_THREADS: 8\n  RUN_SLOW: yes\n  SIGOPT_API_TOKEN: ${{ secrets.SIGOPT_API_TOKEN }}\n  TF_FORCE_GPU_ALLOW_GROWTH: true\n  RUN_PT_TF_CROSS_TESTS: 1\n\njobs:\n  check_runner_status:\n    name: Check Runner Status\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout transformers\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 2\n\n      - name: Check Runner Status\n        run: python utils/check_self_hosted_runner.py --target_runners single-gpu-scheduled-ci-runner-docker,multi-gpu-scheduled-ci-runner-docker --token ${{ secrets.ACCESS_REPO_INFO_TOKEN }}\n\n  check_runners:\n    name: Check Runners\n    needs: check_runner_status\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  setup:\n    name: Setup\n    needs: check_runners\n    strategy:\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n    steps:\n      - name: Update clone\n        working-directory: /transformers\n        run: |\n          git fetch && git checkout ${{ github.sha }}\n\n      - name: Cleanup\n        working-directory: /transformers\n        run: |\n          rm -rf tests/__pycache__\n          rm -rf tests/models/__pycache__\n          rm -rf reports\n\n      - id: set-matrix\n        name: Identify models to test\n        working-directory: /transformers/tests\n        run: |\n          echo \"::set-output name=matrix::$(python3 -c 'import os; tests = os.getcwd(); model_tests = os.listdir(os.path.join(tests, \"models\")); d1 = sorted(list(filter(os.path.isdir, os.listdir(tests)))); d2 = sorted(list(filter(os.path.isdir, [f\"models/{x}\" for x in model_tests]))); d1.remove(\"models\"); d = d2 + d1; print(d)')\"\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n  run_tests_single_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [single-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus 0 --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_tests_multi_gpu:\n    name: Model tests\n    strategy:\n      fail-fast: false\n      matrix:\n        folders: ${{ fromJson(needs.setup.outputs.matrix) }}\n        machine_type: [multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    container:\n      image: huggingface/transformers-all-latest-torch-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    needs: setup\n    steps:\n      - name: Echo folder ${{ matrix.folders }}\n        shell: bash\n        # For folders like `models/bert`, set an env. var. (`matrix_folders`) to `models_bert`, which will be used to\n        # set the artifact folder names (because the character `/` is not allowed).\n        run: |\n          echo \"${{ matrix.folders }}\"\n          matrix_folders=${{ matrix.folders }}\n          matrix_folders=${matrix_folders/'models/'/'models_'}\n          echo \"$matrix_folders\"\n          echo \"matrix_folders=$matrix_folders\" >> $GITHUB_ENV\n\n      - name: Update clone\n        working-directory: /transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /transformers\n        run: |\n          python3 utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /transformers\n        run: python3 -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }} tests/${{ matrix.folders }}\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_all_tests_gpu_${{ env.matrix_folders }}_test_reports\n          path: /transformers/reports/${{ matrix.machine_type }}_tests_gpu_${{ matrix.folders }}\n\n  run_all_tests_torch_cuda_extensions_gpu:\n    name: Torch CUDA extension tests\n    strategy:\n      fail-fast: false\n      matrix:\n        machine_type: [single-gpu, multi-gpu]\n    runs-on: ${{ format('{0}-{1}', matrix.machine_type, 'docker') }}\n    needs: setup\n    container:\n      image: huggingface/transformers-pytorch-deepspeed-nightly-gpu\n      options: --gpus all --shm-size \"16gb\" --ipc host -v /mnt/cache/.cache/huggingface:/mnt/cache/\n    steps:\n      - name: Update clone\n        working-directory: /workspace/transformers\n        run: git fetch && git checkout ${{ github.sha }}\n\n      - name: Remove cached torch extensions\n        run: rm -rf /github/home/.cache/torch_extensions/\n\n      # To avoid unknown test failures\n      - name: Pre build DeepSpeed *again*\n        working-directory: /workspace\n        run: |\n          python3 -m pip uninstall -y deepspeed\n          rm -rf DeepSpeed\n          git clone https://github.com/microsoft/DeepSpeed && cd DeepSpeed && rm -rf build\n          DS_BUILD_CPU_ADAM=1 DS_BUILD_FUSED_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 python3 -m pip install . --global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v --disable-pip-version-check\n\n      - name: NVIDIA-SMI\n        run: |\n          nvidia-smi\n\n      - name: Environment\n        working-directory: /workspace/transformers\n        run: |\n          python utils/print_env.py\n\n      - name: Run all tests on GPU\n        working-directory: /workspace/transformers\n        run: |\n          python -m pytest -v --make-reports=${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu tests/deepspeed tests/extended\n\n      - name: Failure short reports\n        if: ${{ failure() }}\n        continue-on-error: true\n        run: cat /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu/failures_short.txt\n\n      - name: Test suite reports artifacts\n        if: ${{ always() }}\n        uses: actions/upload-artifact@v2\n        with:\n          name: ${{ matrix.machine_type }}_run_tests_torch_cuda_extensions_gpu_test_reports\n          path: /workspace/transformers/reports/${{ matrix.machine_type }}_tests_torch_cuda_extensions_gpu\n\n  send_results:\n    name: Send results to webhook\n    runs-on: ubuntu-latest\n    if: always()\n    needs: [\n      check_runner_status,\n      check_runners,\n      setup,\n      run_tests_single_gpu,\n      run_tests_multi_gpu,\n      run_all_tests_torch_cuda_extensions_gpu\n    ]\n    steps:\n      - name: Preliminary job status\n        shell: bash\n        # For the meaning of these environment variables, see the job `Setup`\n        run: |\n          echo \"Runner availability: ${{ needs.check_runner_status.result }}\"\n          echo \"Runner status: ${{ needs.check_runners.result }}\"\n          echo \"Setup status: ${{ needs.setup.result }}\"\n\n      - uses: actions/checkout@v2\n      - uses: actions/download-artifact@v2\n      - name: Send message to Slack\n        env:\n          CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}\n          CI_SLACK_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID }}\n          CI_SLACK_CHANNEL_ID_DAILY: ${{ secrets.CI_SLACK_CHANNEL_ID_DAILY }}\n          CI_SLACK_CHANNEL_DUMMY_TESTS: ${{ secrets.CI_SLACK_CHANNEL_DUMMY_TESTS }}\n          CI_SLACK_REPORT_CHANNEL_ID: ${{ secrets.CI_SLACK_CHANNEL_ID_PAST_FUTURE }}\n          CI_EVENT: nightly-build\n          RUNNER_STATUS: ${{ needs.check_runner_status.result }}\n          RUNNER_ENV_STATUS: ${{ needs.check_runners.result }}\n          SETUP_STATUS: ${{ needs.setup.result }}\n        # We pass `needs.setup.outputs.matrix` as the argument. A processing in `notification_service.py` to change\n        # `models/bert` to `models_bert` is required, as the artifact names use `_` instead of `/`.\n        run: |\n          pip install slack_sdk\n          python utils/notification_service.py \"${{ needs.setup.outputs.matrix }}\"\n",
    "source": "da03/hierarchical_diffusion_LM",
    "path": ".github/workflows/self-nightly-scheduled.yml",
    "url": "https://github.com/da03/hierarchical_diffusion_LM/blob/53005cd4b1ca697fd3fece5b4f103af40df9299d/.github/workflows/self-nightly-scheduled.yml",
    "retrieved_at": "2025-10-10T01:38:58.042524Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML workflow.",
    "answer": "﻿name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:38:59.203934Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or actions trigger the execution of this GitHub Actions workflow?",
    "answer": "﻿name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:38:59.806485Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel or have dependencies on other jobs or steps?",
    "answer": "﻿name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:39:00.324578Z",
    "question_style": "style_3"
  },
  {
    "question": "Is caching properly configured and utilized within the pnpm setup and node setup steps?",
    "answer": "﻿name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:39:00.935456Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or outcome of this \"Verify Content\" workflow?",
    "answer": "﻿name: Verify Content\n\non:\n  pull_request:\n  push:\n    paths:\n    - '.github/workflows/content.yml'\n    - 'data/src/**'\n  workflow_dispatch:\n\n\njobs:\n  pack:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - uses: pnpm/action-setup@v4\n      name: Install pnpm\n      with:\n        version: 10\n        run_install: false\n\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '22.x'\n        cache: 'pnpm'\n\n    - uses: actions/setup-java@v4\n      with:\n        distribution: 'temurin'\n        java-version: '17'\n\n    - run: pnpm i\n\n    - name: Pack\n      run: npm run build\n",
    "source": "xsolisolisoli/webgame",
    "path": ".github/workflows/content.yml",
    "url": "https://github.com/xsolisolisoli/webgame/blob/c2442d1d0b076154da1f6e872c310f72afbe75d4/.github/workflows/content.yml",
    "retrieved_at": "2025-10-10T01:39:01.481669Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided workflow.",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:11.014518Z",
    "question_style": "style_1"
  },
  {
    "question": "What `push` and `pull_request` events on the `main` branch trigger this workflow?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:11.510419Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the workflow execute in parallel or serially based on dependencies?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:11.920866Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:12.518357Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this Node.js CI workflow?",
    "answer": "name: Node.js CI \n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [20.x]\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v3\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v3\n      with:\n        node-version: ${{ matrix.node-version }}\n\n    - name: Install dependencies\n      run:  npm install || yarn install\n\n    - name: Start application\n      run: npm start\n",
    "source": "chamara321/Dracula-2.0",
    "path": ".GitHub/Workflows/main.yml",
    "url": "https://github.com/chamara321/Dracula-2.0/blob/cb8e8644902e9ae3875ff97f251bf4d08623fd7e/.GitHub/Workflows/main.yml",
    "retrieved_at": "2025-10-11T01:27:12.945856Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that triggers on workflow dispatch and a daily cron schedule, building and uploading Python wheels to PyPI.",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:13.770943Z",
    "question_style": "style_1"
  },
  {
    "question": "What events or schedules trigger the execution of the \"Wheels\" workflow?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:14.329352Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the \"Wheels\" workflow run in parallel, and which depend on others?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:14.820949Z",
    "question_style": "style_3"
  },
  {
    "question": "Are any secrets used to authenticate the wheel uploads to PyPI?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:15.383201Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or effect of this \"Wheels\" workflow?",
    "answer": "name: Wheels\non:\n  workflow_dispatch:\n  schedule:    \n    - cron: \"0 0 * * *\"\n\njobs:\n\n  Build-Wheels:\n    \n    runs-on: [self-hosted, V100]\n\n    steps:\n\n      - name: Checkout\n        uses: actions/checkout@v2\n\n      - name: Patch setup.py\n        run: |\n          #sed -i 's/name\\=\\\"triton\\\"/name=\"triton-nightly\"/g' python/setup.py\n          export LATEST_DATE=$(TZ=UTC0 git show --quiet --date='format-local:%Y%m%d' --format=\"%cd\")\n          sed -i -r \"s/version\\=\\\"(.*)\\\"/version=\\\"\\1-dev\"$LATEST_DATE\"\\\"/g\" python/setup.py\n          echo \"\" >> python/setup.cfg\n          echo \"[build_ext]\" >> python/setup.cfg\n          echo \"base-dir=/project\" >> python/setup.cfg\n\n      - name: Build wheels\n        run: |\n          export CIBW_MANYLINUX_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_MANYLINUX_PYPY_X86_64_IMAGE=\"manylinux2014\"\n          export CIBW_BEFORE_BUILD=\"pip install cmake;\\\n                                    yum install -y llvm11 llvm11-devel llvm11-static llvm11-libs zlib-devel;\"\n          export CIBW_SKIP=\"{cp,pp}35-*\"\n          export CIBW_BUILD=\"{cp,pp}3*-manylinux_x86_64\"\n          python3 -m cibuildwheel python --output-dir wheelhouse\n\n\n      - name: Upload wheels to PyPI\n        run: |\n          python3 -m twine upload wheelhouse/* --skip-existing",
    "source": "YukeWang96/TCGNN-trition",
    "path": ".github/workflows/wheels.yml",
    "url": "https://github.com/YukeWang96/TCGNN-trition/blob/ca7b55d3b3caa22f94f0d5be5e689191432dc1fc/.github/workflows/wheels.yml",
    "retrieved_at": "2025-10-11T01:27:15.952451Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow that triggers on pull requests with the \"visual\" label, and runs Percy visual tests with the specified environment, steps, and secrets.",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:51.095529Z",
    "question_style": "style_1"
  },
  {
    "question": "What pull request events and conditions trigger this Percy visual tests workflow?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:51.531335Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run concurrently or have dependencies on other jobs or steps?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:52.043521Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the secrets NPM_TOKEN, GITHUB_TOKEN, ENTERPRISE_TOKEN, and PERCY_TOKEN used within the workflow steps?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:52.659131Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main function or result of this workflow when triggered by a pull request?",
    "answer": "# Triggers Percy job on pull requests that contain \"visual\" label\nname: Percy visual tests\n\non:\n  pull_request:\n    types: [synchronize, labeled]\n\njobs:\n  percy:\n    if: contains(github.event.pull_request.labels.*.name, 'visual')\n    timeout-minutes: 30\n    runs-on: buildjet-4vcpu-ubuntu-2004\n    env:\n      NPM_TOKEN: ${{ secrets.NPM_TOKEN }}\n      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n      MB_EDITION: ee\n      MB_PREMIUM_EMBEDDING_TOKEN: ${{ secrets.ENTERPRISE_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n      - name: Prepare front-end environment\n        uses: ./.github/actions/prepare-frontend\n      - name: Prepare back-end environment\n        uses: ./.github/actions/prepare-backend\n      - name: Prepare cypress environment\n        uses: ./.github/actions/prepare-cypress\n      - run: ./bin/build\n      - name: Get the version info\n        run: |\n          jar xf target/uberjar/metabase.jar version.properties\n          mv version.properties resources/\n      - name: Run maildev\n        run: docker run -d -p 80:80 -p 25:25 maildev/maildev:1.1.0\n      - name: Percy Test\n        run: yarn run test-visual-run\n        env:\n          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}\n",
    "source": "NEST-Protocol/NEST-Workspace",
    "path": ".github/workflows/percy-visual-label.yml",
    "url": "https://github.com/NEST-Protocol/NEST-Workspace/blob/294575aad465e05f66422f5bf9e32eeec7f77587/.github/workflows/percy-visual-label.yml",
    "retrieved_at": "2025-10-12T01:41:53.166450Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML workflow, including trigger conditions, jobs, steps, and conditional execution.",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ✅' : 'failed ❌'}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:54.001422Z",
    "question_style": "style_1"
  },
  {
    "question": "What specific issue comment triggers this benchmark workflow?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ✅' : 'failed ❌'}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:54.536818Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in this workflow run in parallel, and which depend on the completion of others?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ✅' : 'failed ❌'}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:55.156569Z",
    "question_style": "style_3"
  },
  {
    "question": "How are `WANDB_API_KEY`, `HUGGING_FACE_HUB_TOKEN`, and `PERSONAL_ACCESS_TOKEN_GITHUB` secrets used to authenticate with external services?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ✅' : 'failed ❌'}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:55.770565Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function of this GitHub Actions workflow triggered by issue comments?",
    "answer": "name: \"Benchmark on Comment\"\n\n# https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows\non:\n  issue_comment:\n    types: [created]\n\njobs:\n  Benchmark:\n    strategy:\n      fail-fast: true\n      matrix:\n        python-version: [3.9]\n        os: [self-hosted]\n\n    name: Benchmark\n    # Only run if it#s a PR and the comment contains /Benchmark\n    if: github.event.issue.pull_request && startsWith(github.event.comment.body, '/benchmark-trl-experiments') && contains(FromJSON('[\"vwxyzjn\", \"younesbelkada\", \"lvwerra\", \"lewtun\"]'), github.actor)\n    runs-on: ${{ matrix.os }}\n\n    steps:\n      - name: Get branch of PR\n        uses: xt0rted/pull-request-comment-branch@v1\n        id: comment-branch\n      - name: Set latest commit status as pending\n        uses: myrotvorets/set-commit-status-action@master\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: pending\n      - name: Checkout `main` branch\n        uses: actions/checkout@v3\n      - name: Checkout PR branch\n        run: gh pr checkout $PR_NUMBER\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          PR_NUMBER: ${{ github.event.issue.number }}\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      # - name: Cleanup pip packages (specific to self-hosted runners)\n      #   run: |\n      #     echo PATH is $PATH\n      #     echo PYTHONPATH is $PYTHONPATH\n      #     echo which python is $(which python)\n      #     echo which pip is $(which pip)\n\n      #     pip_list=$(pip list --format=freeze | grep -v \"^pip==\" | grep -v \"^setuptools==\")\n      #     if [ ! -z \"$pip_list\" ]; then\n      #         echo \"$pip_list\" | xargs pip uninstall -y\n      #     fi\n      - name: Print python depdenencies\n        run: pip list --format=freeze\n      - name: Install dependencies\n        run: |\n          pip install .[test,benchmark]\n\n      - name: Login\n        run: wandb login ${{ secrets.WANDB_API_KEY }} && huggingface-cli login --token ${{ secrets.HUGGING_FACE_HUB_TOKEN }}\n      - name: Run benchmark\n        env:\n          GITHUB_CONTEXT: ${{ toJson(github) }}\n          PERSONAL_ACCESS_TOKEN_GITHUB: ${{ secrets.PERSONAL_ACCESS_TOKEN_GITHUB }}\n        run: |\n          COMMENT=\"${{ github.event.comment.body }}\"\n          if [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level1.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level1.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level1.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level1_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level2.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level2.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level2.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level2_plot.sh\" bash benchmark/benchmark_and_report.sh\n          elif [[ \"$COMMENT\" == *\"/benchmark-trl-experiments benchmark/benchmark_level3.sh\"* ]]; then\n            echo \"Running benchmark/benchmark_level3.sh\"\n            BENCHMARK_SCRIPT=\"benchmark/benchmark_level3.sh\" BENCHMARK_PLOT_SCRIPT=\"benchmark/benchmark_level3_plot.sh\" bash benchmark/benchmark_and_report.sh\n          else\n            echo \"Invalid command in comment. Skipping execution.\"\n          fi\n\n      # send message to PR\n      - name: Setup Node.js 16\n        uses: actions/setup-node@v3\n        with:\n          node-version: 16\n      - name: Add workflow result as comment on PR\n        uses: actions/github-script@v6\n        if: always()\n        with:\n          script: |\n            const name = '${{ github.workflow\t}}';\n            const url = '${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}';\n            const success = '${{ job.status }}' === 'success';\n            const body = `${name}: ${success ? 'succeeded ✅' : 'failed ❌'}\\n${url}`;\n\n            await github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: body\n            })\n      - name: Set latest commit status as ${{ job.status }}\n        uses: myrotvorets/set-commit-status-action@master\n        if: always()\n        with:\n          sha: ${{ steps.comment-branch.outputs.head_sha }}\n          token: ${{ secrets.GITHUB_TOKEN }}\n          status: ${{ job.status }}\n",
    "source": "1485840691-eng/trl",
    "path": ".github/workflows/benchmark.yml",
    "url": "https://github.com/1485840691-eng/trl/blob/6d6537c6c1cf053663c98929e3f30e374f6f0af7/.github/workflows/benchmark.yml",
    "retrieved_at": "2025-10-12T01:41:56.381971Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file equivalent to the provided YAML, performing code scanning with CodeQL on push, pull requests, and a scheduled cron job.",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      # ℹ️ Command-line programs to run using the OS shell.\n      # 📚 https://git.io/JvXDl\n\n      # ✏️ If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:04.379627Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this GitHub Actions workflow?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      # ℹ️ Command-line programs to run using the OS shell.\n      # 📚 https://git.io/JvXDl\n\n      # ✏️ If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:04.815193Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps in the workflow run in parallel or have dependencies on each other?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      # ℹ️ Command-line programs to run using the OS shell.\n      # 📚 https://git.io/JvXDl\n\n      # ✏️ If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:05.223683Z",
    "question_style": "style_3"
  },
  {
    "question": "Does this workflow utilize any environment variables, secrets, caching, or artifacts?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      # ℹ️ Command-line programs to run using the OS shell.\n      # 📚 https://git.io/JvXDl\n\n      # ✏️ If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:05.789922Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose of this CodeQL code scanning workflow?",
    "answer": "name: 'Code scanning - action'\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    # The branches below must be a subset of the branches above\n    branches: [main]\n  schedule:\n    - cron: '0 13 * * 1'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.event.number || github.ref }}\n  cancel-in-progress: true\n\npermissions:\n  security-events: write\n\njobs:\n  CodeQL-Build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@93ea575cb5d8a053eaa0ac8fa3b40d7e05a33cc8 # tag=v3.1.0\n\n      - name: Delete fixtures to suppress false positives\n        run: |\n          find ./lib -type d -name '__fixtures__' -exec rm -rf {} \\; || true\n\n      # Initializes the CodeQL tools for scanning.\n      - name: Initialize CodeQL\n        uses: github/codeql-action/init@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n        with:\n          languages: javascript\n\n        # Override language selection by uncommenting this and choosing your languages\n        # with:\n        #   languages: go, javascript, csharp, python, cpp, java\n      # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n      # If this step fails, then you should remove it and run the build manually (see below)\n      - name: Autobuild\n        uses: github/codeql-action/autobuild@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n\n      # ℹ️ Command-line programs to run using the OS shell.\n      # 📚 https://git.io/JvXDl\n\n      # ✏️ If the Autobuild fails above, remove it and uncomment the following three lines\n      #    and modify them (or add more) to build your code if your project\n      #    uses a compiled language\n\n      #- run: |\n      #   make bootstrap\n      #   make release\n\n      - name: Perform CodeQL Analysis\n        uses: github/codeql-action/analyze@678fc3afe258fb2e0cdc165ccf77b85719de7b3c # v2.1.33\n",
    "source": "sap-contributions/renovate-devcontainer",
    "path": ".github/workflows/codeql-analysis.yml",
    "url": "https://github.com/sap-contributions/renovate-devcontainer/blob/f9cbe1646e3e893b41fb585c7cf285283d5b844d/.github/workflows/codeql-analysis.yml",
    "retrieved_at": "2025-10-13T01:45:06.337692Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file that replicates the functionality of the provided YAML file for running linters.",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:07.059115Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger this workflow to run?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:07.604068Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs within this workflow run in parallel, and are there any dependencies between them?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:08.159913Z",
    "question_style": "style_3"
  },
  {
    "question": "How are the cached pip dependencies utilized and restored in the workflow?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:08.838743Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary purpose or effect of this \"Linters\" workflow?",
    "answer": "name: Linters\n\non:\n  pull_request:\n  workflow_dispatch:\n  push:\n    branches: [ develop ]\n\npermissions:\n  contents: read\n\nconcurrency:\n  group: commitcheck-frappe-${{ github.event.number }}\n  cancel-in-progress: true\n\njobs:\n  commit-lint:\n    name: 'Semantic Commits'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 200\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 16\n          check-latest: true\n\n      - name: Check commit titles\n        run: |\n          npm install @commitlint/cli @commitlint/config-conventional\n          npx commitlint --verbose --from ${{ github.event.pull_request.base.sha }} --to ${{ github.event.pull_request.head.sha }}\n\n  docs-required:\n    name: 'Documentation Required'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - name: 'Setup Environment'\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: actions/checkout@v3\n\n      - name: Validate Docs\n        env:\n          PR_NUMBER: ${{ github.event.number }}\n        run: |\n          pip install requests --quiet\n          python $GITHUB_WORKSPACE/.github/helper/documentation.py $PR_NUMBER\n\n  linter:\n    name: 'Frappe Linter'\n    runs-on: ubuntu-latest\n    if: github.event_name == 'pull_request'\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n      - uses: pre-commit/action@v3.0.0\n\n      - name: Download Semgrep rules\n        run: git clone --depth 1 https://github.com/frappe/semgrep-rules.git frappe-semgrep-rules\n\n      - name: Run Semgrep rules\n        run: |\n          pip install semgrep==0.97.0\n          semgrep ci --config ./frappe-semgrep-rules/rules --config r/python.lang.correctness\n\n  deps-vulnerable-check:\n    name: 'Vulnerable Dependency Check'\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.10'\n\n      - uses: actions/checkout@v3\n\n      - name: Cache pip\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/*requirements.txt', '**/pyproject.toml', '**/setup.py') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n            ${{ runner.os }}-\n\n      - run: |\n          pip install pip-audit\n          cd ${GITHUB_WORKSPACE}\n          sed -i '/dropbox/d' pyproject.toml   # Remove dropbox temporarily https://github.com/dropbox/dropbox-sdk-python/pull/456\n          pip-audit --desc on --ignore-vuln GHSA-4xqq-73wg-5mjp .\n",
    "source": "vigneshdevelopr/frappe",
    "path": ".github/workflows/linters.yml",
    "url": "https://github.com/vigneshdevelopr/frappe/blob/5985d4c0db13be9a75efef25f3ed686ae45cc7aa/.github/workflows/linters.yml",
    "retrieved_at": "2025-10-13T01:45:09.371209Z",
    "question_style": "style_5"
  },
  {
    "question": "Generate a GitHub Actions workflow YAML file equivalent to the provided example, ensuring identical triggers, jobs, and steps.",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:37.266087Z",
    "question_style": "style_1"
  },
  {
    "question": "What events trigger the execution of this CI workflow?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:37.708248Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'industrial_ci' job run in parallel, and are there any dependencies between them?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:38.254762Z",
    "question_style": "style_3"
  },
  {
    "question": "How are environment variables from the matrix strategy utilized within the industrial_ci action?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:38.838790Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the primary function or impact of this continuous integration workflow?",
    "answer": "name: CI\n\non: [push, pull_request]\n\njobs:\n  industrial_ci:\n    strategy:\n      matrix:\n        env:\n          - {ROS_DISTRO: melodic}\n          - {ROS_DISTRO: noetic}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses: 'ros-industrial/industrial_ci@master'\n        env: ${{matrix.env}}\n",
    "source": "rosdistro-bloom-testing/async_web_server_cpp-release",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/rosdistro-bloom-testing/async_web_server_cpp-release/blob/6037dea2de6517f717e036f28db88fc72c448557/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:39.529121Z",
    "question_style": "style_5"
  },
  {
    "question": "Create a GitHub Actions workflow replicating the functionality of the provided YAML file, including triggers, concurrency, and job steps.",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:40.664801Z",
    "question_style": "style_1"
  },
  {
    "question": "What push branches and file paths, or pull request file paths, trigger this CI workflow?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:41.314053Z",
    "question_style": "style_2"
  },
  {
    "question": "Which jobs or steps within the 'CI' workflow execute concurrently, and which have dependencies?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:42.168435Z",
    "question_style": "style_3"
  },
  {
    "question": "How are caching and artifacts utilized to optimize dependency management and test execution?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:42.767928Z",
    "question_style": "style_4"
  },
  {
    "question": "What is the main purpose or effect of this CI workflow?",
    "answer": "name: CI\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n  pull_request:\n    paths:\n      - 'src/**'\n      - 'tests/**'\n      - 'pnpm-lock.yaml'\n      - '.github/workflows/main.yml'\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}\n  cancel-in-progress: true\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n\n    env:\n      PLAYWRIGHT_BROWSERS_PATH: 0\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/cache@v4\n        with:\n          path: /home/runner/.local/share/pnpm/store\n          key: ${{ runner.os }}-${{ hashFiles('**/pnpm-lock.yaml') }}\n          restore-keys: |\n            ${{ runner.os }}-\n      - uses: pnpm/action-setup@v3\n        with:\n          version: 9\n          run_install: true\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: 'pnpm'\n\n      - name: Type Check\n        run: pnpm type-check\n\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n\n      - name: Run e2e tests\n        run: |\n          pnpm build\n          pnpm test:ci-e2e\n\n      - name: Run unit tests\n        run: pnpm test:ci\n\n      - name: Coverage\n        uses: davelosert/vitest-coverage-report-action@v2.5.0\n        if: ${{ always() }}\n",
    "source": "hellonobug9/vue3-template",
    "path": ".github/workflows/main.yml",
    "url": "https://github.com/hellonobug9/vue3-template/blob/82d0743456e3703239c284c10df062b0b10f8ff9/.github/workflows/main.yml",
    "retrieved_at": "2025-10-14T01:38:43.279679Z",
    "question_style": "style_5"
  }
]